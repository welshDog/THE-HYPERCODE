{
  "file_name": "code_analyzer_ai.py",
  "file_path": "C:\\Users\\lyndz\\Downloads\\hypercode PROJECT\\hypercode\\src\\core\\hypercode-\\code_analyzer_ai.py",
  "file_size": 10769,
  "created": "2025-11-18T21:08:17.642884",
  "modified": "2025-11-26T02:00:12.346342",
  "file_type": "code",
  "content_hash": "0a2929d0c1adf5925845208099c52b05",
  "content_type": "text",
  "content": "#!/usr/bin/env python3\n\"\"\"\nPerplexity AI Code Analyzer for HyperCode\nProvides intelligent code analysis and improvement suggestions\n\"\"\"\n\nimport sys\nfrom pathlib import Path\n\n# Add src to path before other imports\nsys.path.insert(0, str(Path(__file__).parent / \"src\"))\n\nimport ast\nimport json\nfrom typing import Dict, List\n\nfrom hypercode.perplexity_client import PerplexityClient\n\n\nclass CodeAnalyzerAI:\n    \"\"\"AI-powered code analyzer for HyperCode\"\"\"\n\n    def __init__(self):\n        self.perplexity = PerplexityClient()\n\n    def analyze_file(self, file_path: str) -> Dict:\n        \"\"\"Analyze a Python file with AI assistance\"\"\"\n        print(f\"Analyzing {file_path}...\")\n\n        try:\n            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                content = f.read()\n\n            # Parse AST for basic analysis\n            tree = ast.parse(content)\n\n            basic_analysis = {\n                \"file_path\": file_path,\n                \"lines_of_code\": len(content.splitlines()),\n                \"functions\": len(\n                    [\n                        node\n                        for node in ast.walk(tree)\n                        if isinstance(node, ast.FunctionDef)\n                    ]\n                ),\n                \"classes\": len(\n                    [node for node in ast.walk(tree) if isinstance(node, ast.ClassDef)]\n                ),\n                \"imports\": len(\n                    [\n                        node\n                        for node in ast.walk(tree)\n                        if isinstance(node, (ast.Import, ast.ImportFrom))\n                    ]\n                ),\n                \"complexity_indicators\": self._analyze_complexity(tree),\n                \"docstrings\": self._check_docstrings(tree),\n            }\n\n            # Get AI analysis\n            ai_analysis = self._get_ai_code_analysis(content, file_path)\n\n            return {**basic_analysis, \"ai_insights\": ai_analysis}\n\n        except Exception as e:\n            return {\n                \"file_path\": file_path,\n                \"error\": str(e),\n                \"ai_insights\": f\"Error analyzing file: {e}\",\n            }\n\n    def _analyze_complexity(self, tree: ast.AST) -> Dict:\n        \"\"\"Analyze code complexity indicators\"\"\"\n        complexity = {\n            \"nested_loops\": 0,\n            \"nested_conditions\": 0,\n            \"long_functions\": 0,\n            \"large_classes\": 0,\n        }\n\n        for node in ast.walk(tree):\n            if isinstance(node, ast.FunctionDef):\n                # Check for long functions\n                if len(node.body) > 20:\n                    complexity[\"long_functions\"] += 1\n\n                # Check for nested structures\n                for child in ast.walk(node):\n                    if isinstance(child, (ast.For, ast.While)):\n                        # Count nested loops\n                        parent_count = sum(\n                            1\n                            for parent in ast.walk(node)\n                            if isinstance(parent, (ast.For, ast.While))\n                        )\n                        if parent_count > 1:\n                            complexity[\"nested_loops\"] += 1\n                    elif isinstance(child, ast.If):\n                        # Count nested conditions\n                        parent_count = sum(\n                            1 for parent in ast.walk(node) if isinstance(parent, ast.If)\n                        )\n                        if parent_count > 2:\n                            complexity[\"nested_conditions\"] += 1\n\n            elif isinstance(node, ast.ClassDef):\n                # Check for large classes\n                if len(node.body) > 15:\n                    complexity[\"large_classes\"] += 1\n\n        return complexity\n\n    def _check_docstrings(self, tree: ast.AST) -> Dict:\n        \"\"\"Check for docstring coverage\"\"\"\n        docstrings = {\n            \"functions_with_docs\": 0,\n            \"functions_total\": 0,\n            \"classes_with_docs\": 0,\n            \"classes_total\": 0,\n            \"module_has_docstring\": False,\n        }\n\n        for node in ast.walk(tree):\n            if isinstance(node, ast.FunctionDef):\n                docstrings[\"functions_total\"] += 1\n                if (\n                    node.body\n                    and isinstance(node.body[0], ast.Expr)\n                    and isinstance(node.body[0].value, ast.Constant)\n                    and isinstance(node.body[0].value.value, str)\n                ):\n                    docstrings[\"functions_with_docs\"] += 1\n\n            elif isinstance(node, ast.ClassDef):\n                docstrings[\"classes_total\"] += 1\n                if (\n                    node.body\n                    and isinstance(node.body[0], ast.Expr)\n                    and isinstance(node.body[0].value, ast.Constant)\n                    and isinstance(node.body[0].value.value, str)\n                ):\n                    docstrings[\"classes_with_docs\"] += 1\n\n        # Check module docstring (first statement in module)\n        if (\n            tree.body\n            and isinstance(tree.body[0], ast.Expr)\n            and isinstance(tree.body[0].value, ast.Constant)\n            and isinstance(tree.body[0].value.value, str)\n        ):\n            docstrings[\"module_has_docstring\"] = True\n\n        return docstrings\n\n    def _get_ai_code_analysis(self, code: str, file_path: str) -> str:\n        \"\"\"Get AI analysis of code from Perplexity\"\"\"\n        prompt = f\"\"\"\n        You are an expert Python code reviewer analyzing the HyperCode project.\n\n        Please analyze this Python file ({file_path}) and provide:\n\n        1. Code quality assessment (1-10 scale)\n        2. Specific improvement suggestions\n        3. Potential bugs or issues\n        4. Best practices recommendations\n        5. Neurodivergent-friendly code suggestions (clear naming, explicit logic, good documentation)\n\n        Code to analyze:\n        ```python\n        {code[:2000]}  # Limit to first 2000 chars for context\n        ```\n\n        Provide specific, actionable feedback with line numbers where relevant.\n        \"\"\"\n\n        response = self.perplexity.query(prompt)\n\n        if \"choices\" in response and response[\"choices\"]:\n            return response[\"choices\"][0][\"message\"][\"content\"]\n        else:\n            return \"Failed to get AI analysis\"\n\n    def analyze_project(self, project_path: str = \".\") -> Dict:\n        \"\"\"Analyze entire project\"\"\"\n        print(f\"Analyzing project at {project_path}...\")\n\n        project_path = Path(project_path)\n        python_files = list(project_path.rglob(\"*.py\"))\n\n        # Skip certain directories\n        python_files = [\n            f\n            for f in python_files\n            if not any(\n                skip in str(f) for skip in [\"__pycache__\", \".git\", \"venv\", \"env\"]\n            )\n        ]\n\n        analyses = []\n        project_stats = {\n            \"total_files\": len(python_files),\n            \"total_lines\": 0,\n            \"total_functions\": 0,\n            \"total_classes\": 0,\n            \"files_with_errors\": 0,\n        }\n\n        for file_path in python_files:\n            analysis = self.analyze_file(str(file_path))\n            analyses.append(analysis)\n\n            # Update project stats\n            if \"error\" not in analysis:\n                project_stats[\"total_lines\"] += analysis[\"lines_of_code\"]\n                project_stats[\"total_functions\"] += analysis[\"functions\"]\n                project_stats[\"total_classes\"] += analysis[\"classes\"]\n            else:\n                project_stats[\"files_with_errors\"] += 1\n\n        # Get project-level AI insights\n        project_ai_insights = self._get_project_ai_insights(analyses, project_stats)\n\n        return {\n            \"project_path\": str(project_path),\n            \"project_stats\": project_stats,\n            \"file_analyses\": analyses,\n            \"ai_project_insights\": project_ai_insights,\n        }\n\n    def _get_project_ai_insights(self, analyses: List[Dict], stats: Dict) -> str:\n        \"\"\"Get AI insights for the entire project\"\"\"\n        prompt = f\"\"\"\n        You are an expert software architect reviewing the HyperCode project.\n\n        Based on this project analysis, provide strategic recommendations:\n\n        Project Statistics:\n        - Total files: {stats['total_files']}\n        - Total lines of code: {stats['total_lines']}\n        - Total functions: {stats['total_functions']}\n        - Total classes: {stats['total_classes']}\n        - Files with errors: {stats['files_with_errors']}\n\n        Key findings from file analyses:\n        {json.dumps([a.get('ai_insights', 'No insights') for a in analyses[:5]], indent=2)[:1000]}\n\n        Please provide:\n        1. Overall project architecture assessment\n        2. Code quality trends and patterns\n        3. Recommendations for improving maintainability\n        4. Suggestions for better neurodivergent-friendly code organization\n        5. Priority areas for refactoring\n        \"\"\"\n\n        response = self.perplexity.query(prompt)\n\n        if \"choices\" in response and response[\"choices\"]:\n            return response[\"choices\"][0][\"message\"][\"content\"]\n        else:\n            return \"Failed to get project AI insights\"\n\n    def save_analysis(\n        self, analysis: Dict, filename: str = \"code_analysis_report.json\"\n    ):\n        \"\"\"Save analysis to file\"\"\"\n        with open(filename, \"w\") as f:\n            json.dump(analysis, f, indent=2)\n        print(f\"Code analysis saved to {filename}\")\n\n    def print_summary(self, analysis: Dict):\n        \"\"\"Print analysis summary\"\"\"\n        print(\"\\n\" + \"=\" * 60)\n        print(\"HYPERCODE CODE ANALYSIS SUMMARY\")\n        print(\"=\" * 60)\n\n        stats = analysis[\"project_stats\"]\n        print(f\"Files analyzed: {stats['total_files']}\")\n        print(f\"Total lines of code: {stats['total_lines']}\")\n        print(f\"Total functions: {stats['total_functions']}\")\n        print(f\"Total classes: {stats['total_classes']}\")\n        print(f\"Files with errors: {stats['files_with_errors']}\")\n\n        print(\"\\nPROJECT AI INSIGHTS:\")\n        print(\"-\" * 40)\n        print(analysis[\"ai_project_insights\"])\n\n\ndef main():\n    \"\"\"Main function\"\"\"\n    analyzer = CodeAnalyzerAI()\n\n    # Analyze current project\n    analysis = analyzer.analyze_project()\n\n    # Save and display results\n    analyzer.save_analysis(analysis)\n    analyzer.print_summary(analysis)\n\n    print(\"\\n[SUCCESS] Code analysis completed!\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
  "metadata": {},
  "relative_path": "src\\core\\hypercode-\\code_analyzer_ai.py",
  "id": "9f1da7fc891d4cbaa37a0bde937b6ec6"
}