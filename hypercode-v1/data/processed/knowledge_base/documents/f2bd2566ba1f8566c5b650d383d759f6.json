{
  "file_name": "cli.py",
  "file_path": "C:\\Users\\lyndz\\Downloads\\hypercode PROJECT\\hypercode\\live_research\\cli.py",
  "file_size": 7445,
  "created": "2025-12-04T12:44:11.838527",
  "modified": "2025-12-04T12:44:12.373295",
  "file_type": "code",
  "content_hash": "c567f9773f90429ee983900fe47de108",
  "content_type": "text",
  "content": "import argparse\nimport json\nimport sys\nfrom pathlib import Path\nfrom typing import Dict, Any\nfrom datetime import datetime\nfrom .database import setup_database\n\n\ndef print_entry(entry: Dict[str, Any], detailed: bool = False):\n    \"\"\"Print a research entry in a readable format.\"\"\"\n    print(\"\\n\" + \"=\" * 80)\n    print(f\"ID:      {entry['id']}\")\n    print(f\"Date:    {entry['date']}\")\n    print(f\"Topic:   {entry['topic']}\")\n    if entry.get(\"source\"):\n        print(f\"Source:  {entry['source']}\")\n    if \"tags\" in entry and entry[\"tags\"]:\n        print(f\"Tags:    {', '.join(entry['tags'])}\")\n\n    if detailed:\n        if entry.get(\"summary\"):\n            print(\"\\nSummary:\")\n            print(\"-\" * 40)\n            print(entry[\"summary\"])\n\n        if entry.get(\"details\"):\n            print(\"\\nDetails:\")\n            print(\"-\" * 40)\n            print(entry[\"details\"])\n\n        print(f\"\\nCreated:  {entry['created_at']}\")\n        print(f\"Updated:  {entry['updated_at']}\")\n\n    print(\"=\" * 80 + \"\\n\")\n\n\ndef search_entries(args):\n    \"\"\"Search for research entries.\"\"\"\n    db = setup_database()\n    results = db.search_entries(query=args.query, tag=args.tag, limit=args.limit)\n\n    if not results:\n        print(\"No matching entries found.\")\n        return\n\n    print(f\"\\nFound {len(results)} entries:\")\n    for entry in results:\n        print(f\"- {entry['date']}: {entry['topic']} (ID: {entry['id']})\")\n        if args.verbose:\n            print_entry(entry, detailed=True)\n\n    if not args.verbose and len(results) > 0:\n        print(\n            \"\\nUse --verbose to see full entry details or 'research view ID' to view a specific entry.\"\n        )\n\n\ndef view_entry(args):\n    \"\"\"View a specific research entry by ID.\"\"\"\n    db = setup_database()\n    entry = db.get_research_entry(args.entry_id)\n\n    if not entry:\n        print(f\"No entry found with ID: {args.entry_id}\")\n        sys.exit(1)\n\n    print_entry(entry, detailed=True)\n\n\ndef add_entry(args):\n    \"\"\"Add a new research entry.\"\"\"\n    db = setup_database()\n\n    entry_data = {\n        \"id\": args.id or f\"{datetime.now().strftime('%Y%m%d')}-{hash(datetime.now())}\",\n        \"date\": args.date or datetime.now().strftime(\"%Y-%m-%d\"),\n        \"topic\": args.topic,\n        \"source\": args.source or \"\",\n        \"summary\": args.summary or \"\",\n        \"details\": args.details or \"\",\n        \"tags\": [t.strip() for t in args.tags.split(\",\")] if args.tags else [],\n    }\n\n    if db.add_research_entry(entry_data):\n        print(f\"Successfully added entry with ID: {entry_data['id']}\")\n        if args.view:\n            view_entry(argparse.Namespace(entry_id=entry_data[\"id\"]))\n    else:\n        print(\"Failed to add entry.\")\n        sys.exit(1)\n\n\ndef import_entries(args):\n    \"\"\"Import entries from a JSON file.\"\"\"\n    db = setup_database()\n    json_path = Path(args.json_file)\n\n    if not json_path.exists():\n        print(f\"Error: File not found: {json_path}\")\n        sys.exit(1)\n\n    try:\n        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n            entries = json.load(f)\n\n        if not isinstance(entries, list):\n            entries = [entries]\n\n        success_count = 0\n        for entry in entries:\n            if db.add_research_entry(entry):\n                success_count += 1\n                if args.verbose:\n                    print(\n                        f\"Imported: {entry.get('id', 'N/A')} - {entry.get('topic', 'No topic')}\"\n                    )\n\n        print(f\"\\nSuccessfully imported {success_count}/{len(entries)} entries.\")\n\n    except (json.JSONDecodeError, IOError) as e:\n        print(f\"Error importing from {json_path}: {e}\")\n        sys.exit(1)\n\n\ndef export_entries(args):\n    \"\"\"Export all entries to a JSON file.\"\"\"\n    db = setup_database()\n    entries = db.search_entries(limit=None)  # Get all entries\n\n    if not entries:\n        print(\"No entries to export.\")\n        return\n\n    output_file = (\n        Path(args.output_file) if args.output_file else Path(\"research_export.json\")\n    )\n\n    try:\n        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n            json.dump(entries, f, indent=2, ensure_ascii=False, default=str)\n\n        print(f\"Successfully exported {len(entries)} entries to {output_file}\")\n\n    except IOError as e:\n        print(f\"Error exporting to {output_file}: {e}\")\n        sys.exit(1)\n\n\ndef main():\n    \"\"\"Main CLI entry point.\"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"Research Management System CLI\",\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n    )\n\n    # Global arguments\n    parser.add_argument(\n        \"--verbose\", \"-v\", action=\"store_true\", help=\"Enable verbose output\"\n    )\n\n    # Subcommands\n    subparsers = parser.add_subparsers(dest=\"command\", help=\"Command to run\")\n\n    # Search command\n    search_parser = subparsers.add_parser(\"search\", help=\"Search research entries\")\n    search_parser.add_argument(\"query\", nargs=\"?\", default=\"\", help=\"Search query\")\n    search_parser.add_argument(\"--tag\", help=\"Filter by tag\")\n    search_parser.add_argument(\n        \"--limit\", type=int, default=10, help=\"Maximum number of results\"\n    )\n    search_parser.set_defaults(func=search_entries)\n\n    # View command\n    view_parser = subparsers.add_parser(\"view\", help=\"View a specific entry\")\n    view_parser.add_argument(\"entry_id\", help=\"ID of the entry to view\")\n    view_parser.set_defaults(func=view_entry)\n\n    # Add command\n    add_parser = subparsers.add_parser(\"add\", help=\"Add a new research entry\")\n    add_parser.add_argument(\"--id\", help=\"Entry ID (auto-generated if not provided)\")\n    add_parser.add_argument(\"--date\", help=\"Date (YYYY-MM-DD, defaults to today)\")\n    add_parser.add_argument(\"--topic\", required=True, help=\"Research topic\")\n    add_parser.add_argument(\"--source\", help=\"Source of information\")\n    add_parser.add_argument(\"--summary\", help=\"Brief summary\")\n    add_parser.add_argument(\"--details\", help=\"Detailed notes\")\n    add_parser.add_argument(\"--tags\", help=\"Comma-separated list of tags\")\n    add_parser.add_argument(\n        \"--view\", action=\"store_true\", help=\"View the entry after adding\"\n    )\n    add_parser.set_defaults(func=add_entry)\n\n    # Import command\n    import_parser = subparsers.add_parser(\n        \"import\", help=\"Import entries from JSON file\"\n    )\n    import_parser.add_argument(\"json_file\", help=\"Path to JSON file to import\")\n    import_parser.add_argument(\n        \"--verbose\", \"-v\", action=\"store_true\", help=\"Show import progress\"\n    )\n    import_parser.set_defaults(func=import_entries)\n\n    # Export command\n    export_parser = subparsers.add_parser(\"export\", help=\"Export all entries to JSON\")\n    export_parser.add_argument(\n        \"--output\", \"-o\", dest=\"output_file\", help=\"Output file path\"\n    )\n    export_parser.set_defaults(func=export_entries)\n\n    # Parse arguments and execute the appropriate function\n    args = parser.parse_args()\n\n    if not args.command:\n        parser.print_help()\n        sys.exit(1)\n\n    try:\n        args.func(args)\n    except Exception as e:\n        print(f\"Error: {e}\", file=sys.stderr)\n        if args.verbose:\n            import traceback\n\n            traceback.print_exc()\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n",
  "metadata": {},
  "relative_path": "live_research\\cli.py",
  "id": "f2bd2566ba1f8566c5b650d383d759f6"
}