{
  "file_name": "hypercode_poc.py",
  "file_path": "C:\\Users\\lyndz\\Downloads\\hypercode PROJECT\\hypercode\\hypercode\\src\\hypercode_poc.py",
  "file_size": 8365,
  "created": "2025-11-26T23:37:35.647187",
  "modified": "2025-11-26T23:37:35.647187",
  "file_type": "code",
  "content_hash": "40121868e301617a1dd0adae59d1a7ac",
  "content_type": "text",
  "content": "\"\"\"\nHyperCode POC - Neurodivergent-First Programming Language\nResearch-Backed Implementation\n\nCombining:\n- PlankalkÃ¼l (1942): Spatial layout + explicit types\n- Brainfuck (1993): Minimalism (8 core operations)\n- Befunge (1993): 2D spatial programming\n- Whitespace (2003): Pattern-based syntax\n+ Modern AI integration + Accessibility-first design\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom enum import Enum\nfrom typing import Any, Dict, List, Tuple\n\n\nclass TokenType(Enum):\n    \"\"\"Brainfuck-inspired core + modern aliases\"\"\"\n\n    MOVE_RIGHT, MOVE_LEFT = \">\", \"<\"\n    INCREMENT, DECREMENT = \"+\", \"-\"\n    OUTPUT, INPUT = \".\", \",\"\n    LOOP_START, LOOP_END = \"[\", \"]\"\n    LET, PRINT, IF, ELSE = \"let\", \"print\", \"if\", \"else\"\n    LOOP, WHILE, FN, RETURN = \"loop\", \"while\", \"fn\", \"return\"\n    STRING = \"STRING\"\n    NUMBER = \"NUMBER\"\n    IDENTIFIER = \"IDENTIFIER\"\n    EOF = \"EOF\"\n\n\n@dataclass\nclass Token:\n    type: TokenType\n    value: str\n    line: int\n    column: int\n\n\nclass UserConfidenceLevel(Enum):\n    BEGINNER = \"beginner\"\n    INTERMEDIATE = \"intermediate\"\n    ADVANCED = \"advanced\"\n    EXPERT = \"expert\"\n\n\nclass EnhancedLexer:\n    \"\"\"Smart tokenizer with escape handling + accessibility focus\"\"\"\n\n    def __init__(self):\n        self.tokens = []\n        self.line, self.column, self.position = 1, 1, 0\n        self.source = \"\"\n        self.brainfuck_ops = {\n            \">\": \">\",\n            \"<\": \"<\",\n            \"+\": \"+\",\n            \"-\": \"-\",\n            \".\": \".\",\n            \",\": \",\",\n            \"[\": \"[\",\n            \"]\": \"]\",\n        }\n        self.keywords = {\n            \"let\": \"let\",\n            \"print\": \"print\",\n            \"if\": \"if\",\n            \"else\": \"else\",\n            \"loop\": \"loop\",\n            \"fn\": \"fn\",\n        }\n\n    def tokenize(self, source: str) -> Tuple[List[Token], List[str]]:\n        self.source, self.position, self.line, self.column = source, 0, 1, 1\n        self.tokens, errors = [], []\n\n        while self.position < len(self.source):\n            char = self.source[self.position]\n\n            if char in \" \\t\":\n                self.advance()\n            elif char == \"\\n\":\n                self.line += 1\n                self.column, self.position = 1, self.position + 1\n            elif char == \"#\":\n                while (\n                    self.position < len(self.source)\n                    and self.source[self.position] != \"\\n\"\n                ):\n                    self.advance()\n            elif char in '\"' + \"'\":  # String handling\n                self.handle_string(char, errors)\n            elif char.isdigit():\n                self.handle_number()\n            elif char.isalpha() or char == \"_\":\n                self.handle_identifier()\n            elif char in self.brainfuck_ops:\n                self.tokens.append(\n                    Token(\n                        TokenType(self.brainfuck_ops[char]),\n                        char,\n                        self.line,\n                        self.column,\n                    )\n                )\n                self.advance()\n            else:\n                errors.append(f\"Unknown char: {char} at L{self.line}:C{self.column}\")\n                self.advance()\n\n        self.tokens.append(Token(TokenType.EOF, \"\", self.line, self.column))\n        return self.tokens, errors\n\n    def handle_string(self, quote, errors):\n        start_line, start_col = self.line, self.column\n        self.advance()\n        value = \"\"\n        while self.position < len(self.source):\n            c = self.source[self.position]\n            if c == \"\\\\\" and self.position + 1 < len(self.source):\n                next_c = self.source[self.position + 1]\n                if next_c in \"nt\":\n                    value += \"\\n\" if next_c == \"n\" else \"\\t\"\n                    self.advance()\n                    self.advance()\n                else:\n                    value += c\n                    self.advance()\n            elif c == quote:\n                self.advance()\n                self.tokens.append(\n                    Token(TokenType.STRING, value, start_line, start_col)\n                )\n                return\n            else:\n                value += c\n                self.advance()\n        errors.append(f\"Unclosed string at L{start_line}:C{start_col}\")\n\n    def handle_number(self):\n        value = \"\"\n        start_col = self.column\n        while self.position < len(self.source) and self.source[self.position].isdigit():\n            value += self.source[self.position]\n            self.advance()\n        self.tokens.append(Token(TokenType.NUMBER, value, self.line, start_col))\n\n    def handle_identifier(self):\n        value = \"\"\n        start_col = self.column\n        while self.position < len(self.source) and (\n            self.source[self.position].isalnum() or self.source[self.position] == \"_\"\n        ):\n            value += self.source[self.position]\n            self.advance()\n        token_type = self.keywords.get(value, \"IDENTIFIER\")\n        self.tokens.append(\n            Token(\n                (\n                    TokenType(token_type)\n                    if token_type != \"IDENTIFIER\"\n                    else TokenType.IDENTIFIER\n                ),\n                value,\n                self.line,\n                start_col,\n            )\n        )\n\n    def advance(self):\n        self.position += 1\n        self.column += 1\n\n\nclass ContextAwareErrorMessenger:\n    \"\"\"Friendly, adaptive error messages\"\"\"\n\n    def __init__(self):\n        self.errors = []\n\n    def format_error(self, msg: str, line: int, col: int, level: UserConfidenceLevel):\n        if level == UserConfidenceLevel.BEGINNER:\n            return f\"Hey! Issue at L{line}:C{col} - {msg}. Tip: Check syntax here.\"\n        else:\n            return f\"L{line}:C{col} - {msg}\"\n\n\nclass SemanticContextStreamer:\n    \"\"\"Understand programmer intent from tokens\"\"\"\n\n    def analyze(self, tokens: List[Token]) -> Dict[str, Any]:\n        intent = \"unknown\"\n        patterns = []\n        for token in tokens:\n            if token.type == TokenType.LET:\n                intent, patterns = \"assignment\", [\"declaration\"]\n            elif token.type == TokenType.IF:\n                intent, patterns = \"conditional\", [\"branching\"]\n            elif token.type == TokenType.LOOP:\n                intent, patterns = \"iteration\", [\"looping\"]\n        return {\n            \"intent\": intent,\n            \"patterns\": patterns,\n            \"confidence\": len(patterns) / 3.0,\n        }\n\n\nclass ConfidenceTracker:\n    \"\"\"Adapt system guidance to user skill level\"\"\"\n\n    def __init__(self, level=UserConfidenceLevel.BEGINNER):\n        self.level = level\n        self.actions, self.errors = 0, 0\n\n    def record(self, success: bool):\n        self.actions += 1\n        if not success:\n            self.errors += 1\n\n\nclass HyperCodePOC:\n    \"\"\"Main system: Lexer + Error Messenger + Semantic Analyzer + Confidence Tracker\"\"\"\n\n    def __init__(self, level=UserConfidenceLevel.BEGINNER):\n        self.lexer = EnhancedLexer()\n        self.error_messenger = ContextAwareErrorMessenger()\n        self.semantic = SemanticContextStreamer()\n        self.confidence = ConfidenceTracker(level)\n        self.last_tokens, self.last_errors = [], []\n\n    def compile(self, code: str) -> Dict[str, Any]:\n        tokens, errors = self.lexer.tokenize(code)\n        self.last_tokens, self.last_errors = tokens, errors\n        semantic = self.semantic.analyze(tokens)\n        return {\n            \"status\": \"success\" if not errors else \"warning\",\n            \"tokens\": len(tokens),\n            \"intent\": semantic[\"intent\"],\n            \"patterns\": semantic[\"patterns\"],\n            \"confidence\": min(semantic[\"confidence\"], 1.0),\n            \"errors\": errors,\n        }\n\n\n# Demo\nif __name__ == \"__main__\":\n    hc = HyperCodePOC()\n\n    demos = [\n        (\"let x = 42\", \"Simple variable\"),\n        ('print \"Hello\"', \"Output\"),\n        ('if (x > 0) { print \"yes\" }', \"Conditional\"),\n        ('loop { print \"spin\" }', \"Loop\"),\n    ]\n\n    for code, desc in demos:\n        result = hc.compile(code)\n        print(f\"{desc}: {result['intent']} ({result['confidence']:.0%})\")\n",
  "metadata": {},
  "relative_path": "hypercode\\src\\hypercode_poc.py",
  "id": "de1f4fb51a556a726ef91af5c0c943ab"
}