{
  "file_name": "HYPERCORE_INTERPRETER.py",
  "file_path": "C:\\Users\\lyndz\\Downloads\\hypercode PROJECT\\hypercode\\scripts\\HYPERCORE_INTERPRETER.py",
  "file_size": 14996,
  "created": "2025-12-03T11:29:54.301422",
  "modified": "2025-12-03T11:29:57.433336",
  "file_type": "code",
  "content_hash": "8b8423a1f83b5e359961915fffc22223",
  "content_type": "text",
  "content": "# HyperCore Reference Implementation\n\nThis is a **working Python interpreter** for NeuroCore. It demonstrates the formal semantics and can execute all NeuroCore programs.\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nHyperCore Interpreter\nA minimal, deterministic Turing-complete machine with emoji anchors.\n\"\"\"\n\nimport sys\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Optional\nfrom collections import defaultdict\n\n@dataclass\nclass Token:\n    type: str\n    value: str\n    line: int\n    col: int\n\nclass Lexer:\n    \"\"\"Tokenize NeuroCore source into instructions and labels.\"\"\"\n    \n    CORE_INSTRUCTIONS = set('+-<>.,[]')\n    EMOJIS = {'ðŸ§ ', 'ðŸŽ¯', 'ðŸ”„', 'ðŸ“Š', 'ðŸ’¾', 'âš ï¸'}\n    \n    def __init__(self, source: str):\n        self.source = source\n        self.pos = 0\n        self.line = 1\n        self.col = 1\n        self.tokens: List[Token] = []\n    \n    def error(self, msg: str):\n        raise SyntaxError(f\"Lexer error at {self.line}:{self.col}: {msg}\")\n    \n    def peek(self, offset=0) -> Optional[str]:\n        \"\"\"Look ahead at character without consuming.\"\"\"\n        idx = self.pos + offset\n        return self.source[idx] if idx < len(self.source) else None\n    \n    def consume(self) -> Optional[str]:\n        \"\"\"Consume and return next character.\"\"\"\n        if self.pos >= len(self.source):\n            return None\n        ch = self.source[self.pos]\n        self.pos += 1\n        if ch == '\\n':\n            self.line += 1\n            self.col = 1\n        else:\n            self.col += 1\n        return ch\n    \n    def skip_whitespace_and_comments(self):\n        \"\"\"Skip whitespace and comment lines.\"\"\"\n        while self.pos < len(self.source):\n            ch = self.peek()\n            if ch in ' \\t\\n':\n                self.consume()\n            elif ch == '#':\n                # Skip until end of line\n                while self.peek() and self.peek() != '\\n':\n                    self.consume()\n            else:\n                break\n    \n    def tokenize(self) -> List[Token]:\n        \"\"\"Scan source and produce token list.\"\"\"\n        self.tokens = []\n        \n        while self.pos < len(self.source):\n            self.skip_whitespace_and_comments()\n            \n            if self.pos >= len(self.source):\n                break\n            \n            start_line, start_col = self.line, self.col\n            ch = self.peek()\n            \n            # Check for emoji\n            if ch in self.EMOJIS:\n                emoji = self.consume()\n                self.tokens.append(Token('EMOJI', emoji, start_line, start_col))\n            \n            # Check for label definition: [flow:name]\n            elif ch == '[':\n                if self.peek(1) == 'f' and self.peek(2) == 'l':\n                    # Could be [flow:...] or [zero?jump:...] or [jump:...]\n                    # Let's check the full pattern\n                    lookahead = self.source[self.pos:self.pos+20]\n                    \n                    if lookahead.startswith('[flow:'):\n                        self.consume()  # [\n                        self.consume()  # f\n                        self.consume()  # l\n                        self.consume()  # o\n                        self.consume()  # w\n                        self.consume()  # :\n                        label_name = self._read_identifier()\n                        if self.consume() != ']':\n                            self.error(\"Expected ] after label name\")\n                        self.tokens.append(Token('LABEL', label_name, start_line, start_col))\n                    \n                    elif lookahead.startswith('[zero?jump:'):\n                        self.consume()  # [\n                        # Read \"zero?jump:\"\n                        for _ in range(11):  # len(\"[zero?jump:\")\n                            self.consume()\n                        label_name = self._read_identifier()\n                        if self.consume() != ']':\n                            self.error(\"Expected ] after label name\")\n                        self.tokens.append(Token('ZERO_JUMP', label_name, start_line, start_col))\n                    \n                    elif lookahead.startswith('[jump:'):\n                        self.consume()  # [\n                        # Read \"jump:\"\n                        for _ in range(6):  # len(\"[jump:\")\n                            self.consume()\n                        label_name = self._read_identifier()\n                        if self.consume() != ']':\n                            self.error(\"Expected ] after label name\")\n                        self.tokens.append(Token('JUMP', label_name, start_line, start_col))\n                    \n                    else:\n                        # Regular [ bracket\n                        self.consume()\n                        self.tokens.append(Token('LBRACKET', '[', start_line, start_col))\n                \n                else:\n                    # Regular [ bracket\n                    self.consume()\n                    self.tokens.append(Token('LBRACKET', '[', start_line, start_col))\n            \n            elif ch == ']':\n                self.consume()\n                self.tokens.append(Token('RBRACKET', ']', start_line, start_col))\n            \n            elif ch in self.CORE_INSTRUCTIONS:\n                self.consume()\n                self.tokens.append(Token(ch, ch, start_line, start_col))\n            \n            else:\n                # Unknown character; skip it (or treat as comment)\n                self.consume()\n        \n        return self.tokens\n    \n    def _read_identifier(self) -> str:\n        \"\"\"Read identifier: [a-zA-Z_][a-zA-Z0-9_]*\"\"\"\n        ident = ''\n        while self.pos < len(self.source):\n            ch = self.peek()\n            if ch and (ch.isalnum() or ch == '_'):\n                ident += self.consume()\n            else:\n                break\n        return ident\n\n\nclass Parser:\n    \"\"\"Parse tokens into an AST.\"\"\"\n    \n    def __init__(self, tokens: List[Token]):\n        self.tokens = tokens\n        self.pos = 0\n    \n    def peek(self, offset=0) -> Optional[Token]:\n        idx = self.pos + offset\n        return self.tokens[idx] if idx < len(self.tokens) else None\n    \n    def consume(self) -> Optional[Token]:\n        tok = self.peek()\n        if tok:\n            self.pos += 1\n        return tok\n    \n    def parse(self) -> List:\n        \"\"\"Parse into a flat instruction list.\"\"\"\n        instructions = []\n        while self.pos < len(self.tokens):\n            tok = self.peek()\n            if tok.type == 'EMOJI':\n                self.consume()\n                instructions.append(('EMOJI', tok.value))\n            elif tok.type == 'LABEL':\n                self.consume()\n                instructions.append(('LABEL', tok.value))\n            elif tok.type == 'ZERO_JUMP':\n                self.consume()\n                instructions.append(('ZERO_JUMP', tok.value))\n            elif tok.type == 'JUMP':\n                self.consume()\n                instructions.append(('JUMP', tok.value))\n            elif tok.type in ['+', '-', '<', '>', '.', ',']:\n                instr = tok.type\n                self.consume()\n                instructions.append((instr, None))\n            elif tok.type == 'LBRACKET':\n                self.consume()\n                instructions.append(('[', None))\n            elif tok.type == 'RBRACKET':\n                self.consume()\n                instructions.append((']', None))\n            else:\n                self.pos += 1\n        return instructions\n\n\nclass LabelResolver:\n    \"\"\"Resolve labels to instruction indices.\"\"\"\n    \n    def __init__(self, instructions: List):\n        self.instructions = instructions\n        self.label_map: Dict[str, int] = {}\n        self._resolve()\n    \n    def _resolve(self):\n        \"\"\"Two-pass label resolution.\"\"\"\n        # Pass 1: Build label map\n        executable_index = 0\n        for instr_type, value in self.instructions:\n            if instr_type == 'LABEL':\n                self.label_map[value] = executable_index\n            elif instr_type not in ['EMOJI']:  # EMOJI doesn't increment index\n                executable_index += 1\n        \n        # Pass 2: Validate jumps\n        for instr_type, value in self.instructions:\n            if instr_type in ['ZERO_JUMP', 'JUMP']:\n                if value not in self.label_map:\n                    raise RuntimeError(f\"Undefined label: {value}\")\n    \n    def get_target(self, label: str) -> int:\n        \"\"\"Get instruction index for a label.\"\"\"\n        return self.label_map[label]\n\n\nclass VM:\n    \"\"\"Virtual machine: execute NeuroCore bytecode.\"\"\"\n    \n    def __init__(self, instructions: List, label_map: Dict[str, int]):\n        self.instructions = instructions\n        self.label_map = label_map\n        \n        # State\n        self.tape: Dict[int, int] = defaultdict(int)  # Sparse array\n        self.dp = 0  # Data pointer\n        self.ip = 0  # Instruction pointer\n        self.running = True\n        \n        # Bracket matching cache\n        self._bracket_cache: Dict[int, int] = {}\n        self._build_bracket_map()\n    \n    def _build_bracket_map(self):\n        \"\"\"Pre-compute bracket matching for [ and ].\"\"\"\n        stack = []\n        executable_index = 0\n        \n        for instr_type, _ in self.instructions:\n            if instr_type == '[':\n                stack.append(executable_index)\n                self._bracket_cache[executable_index] = None  # Will be filled on ]\n            elif instr_type == ']':\n                if not stack:\n                    raise RuntimeError(\"Unmatched ]\")\n                open_idx = stack.pop()\n                close_idx = executable_index\n                self._bracket_cache[open_idx] = close_idx\n                self._bracket_cache[close_idx] = open_idx\n                executable_index += 1\n            elif instr_type not in ['EMOJI', 'LABEL']:\n                executable_index += 1\n        \n        if stack:\n            raise RuntimeError(\"Unmatched [\")\n    \n    def _get_executable_index(self, raw_index: int) -> int:\n        \"\"\"Convert raw instruction index to executable instruction index.\"\"\"\n        count = 0\n        for i, (instr_type, _) in enumerate(self.instructions):\n            if i == raw_index:\n                return count\n            if instr_type not in ['EMOJI', 'LABEL']:\n                count += 1\n        return count\n    \n    def step(self) -> bool:\n        \"\"\"Execute one instruction. Return True if still running.\"\"\"\n        if not self.running or self.ip >= len(self.instructions):\n            self.running = False\n            return False\n        \n        instr_type, value = self.instructions[self.ip]\n        \n        if instr_type == '+':\n            self.tape[self.dp] = (self.tape[self.dp] + 1) % 256\n        elif instr_type == '-':\n            self.tape[self.dp] = (self.tape[self.dp] - 1) % 256\n        elif instr_type == '>':\n            self.dp += 1\n        elif instr_type == '<':\n            self.dp -= 1\n        elif instr_type == '.':\n            print(chr(self.tape[self.dp]), end='', flush=True)\n        elif instr_type == ',':\n            try:\n                ch = sys.stdin.read(1)\n                self.tape[self.dp] = ord(ch) if ch else 0\n            except EOFError:\n                self.tape[self.dp] = 0\n        elif instr_type == '[':\n            if self.tape[self.dp] == 0:\n                # Jump to matching ]\n                match_idx = self._bracket_cache[self.ip]\n                self.ip = match_idx  # Will increment at end of step\n        elif instr_type == ']':\n            if self.tape[self.dp] != 0:\n                # Jump back to matching [\n                match_idx = self._bracket_cache[self.ip]\n                self.ip = match_idx  # Will increment at end of step\n        elif instr_type == 'ZERO_JUMP':\n            if self.tape[self.dp] == 0:\n                target_idx = self.label_map[value]\n                # Find raw instruction index for this target\n                count = 0\n                for i, (typ, _) in enumerate(self.instructions):\n                    if typ not in ['EMOJI', 'LABEL']:\n                        if count == target_idx:\n                            self.ip = i - 1  # Will increment at end of step\n                            break\n                        count += 1\n        elif instr_type == 'JUMP':\n            target_idx = self.label_map[value]\n            # Find raw instruction index for this target\n            count = 0\n            for i, (typ, _) in enumerate(self.instructions):\n                if typ not in ['EMOJI', 'LABEL']:\n                    if count == target_idx:\n                        self.ip = i - 1  # Will increment at end of step\n                        break\n                    count += 1\n        elif instr_type in ['EMOJI', 'LABEL']:\n            # No-op; don't increment IP separately\n            self.ip += 1\n            return self.running\n        \n        self.ip += 1\n        return self.running\n    \n    def run(self):\n        \"\"\"Execute until program halts.\"\"\"\n        while self.step():\n            pass\n\n\ndef main():\n    if len(sys.argv) < 2:\n        print(\"Usage: python3 hypercore.py <program.hypercore>\")\n        sys.exit(1)\n    \n    with open(sys.argv[1], 'r') as f:\n        source = f.read()\n    \n    # Parse\n    lexer = Lexer(source)\n    tokens = lexer.tokenize()\n    \n    parser = Parser(tokens)\n    instructions = parser.parse()\n    \n    # Resolve labels\n    resolver = LabelResolver(instructions)\n    \n    # Execute\n    vm = VM(instructions, resolver.label_map)\n    vm.run()\n\n\nif __name__ == '__main__':\n    main()\n```\n\n---\n\n## Usage\n\n```bash\n# Save as hypercore.py\n\n# Create a test program\ncat > test_h.hypercore << 'EOF'\nðŸ§ \n++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++.\nðŸŽ¯\nEOF\n\n# Run it\npython3 hypercore.py test_h.hypercore\n# Output: H\n```\n\n---\n\n## Implementation Notes\n\n1. **Sparse Tape:** Using a `defaultdict(int)` allows unbounded tape in both directions\n2. **Bracket Caching:** Pre-compute bracket matches for O(1) jump performance\n3. **Label Resolution:** Two-pass (label collection, then validation and jump replacement)\n4. **Execution:** Standard fetch-decode-execute cycle\n5. **Determinism:** Every instruction has well-defined semantics; no side effects except I/O and tape mutation\n\n---\n\n## Testing\n\nRun against the example programs:\n\n```bash\npython3 hypercore.py examples/print_H.hypercore\n# Expected: H\n\npython3 hypercore.py examples/echo_until_nul.hypercore\n# Expected: Echo input back until NUL\n\npython3 hypercore.py examples/hello_world.hypercore\n# Expected: Hello, World! (or variant)\n```\n\n---\n\n## Performance Optimizations (Not Included)\n\n- **JIT compilation:** Translate to native code\n- **Strength reduction:** Replace loops with direct arithmetic\n- **Lazy tape allocation:** Only allocate cells on access\n- **Inline caching:** Cache label target addresses during execution\n\n---\n\n*This interpreter is the foundation. A real implementation would add debugging, profiling, and optimization passes.*\n",
  "metadata": {},
  "relative_path": "scripts\\HYPERCORE_INTERPRETER.py",
  "id": "eeff9c968913a570af25e958a17a754b"
}