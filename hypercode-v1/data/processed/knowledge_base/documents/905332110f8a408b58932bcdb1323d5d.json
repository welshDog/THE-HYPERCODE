{
  "file_name": "tokens.py",
  "file_path": "C:\\Users\\lyndz\\Downloads\\hypercode PROJECT\\hypercode\\src\\core\\tokens.py",
  "file_size": 2877,
  "created": "2025-11-25T00:49:21.687910",
  "modified": "2025-11-30T19:01:29.755944",
  "file_type": "code",
  "content_hash": "df007efd9f8abd94ea582a8a7144da8b",
  "content_type": "text",
  "content": "# src/core/tokens.py\n\"\"\"\nHyperCode Token Types and Definitions\n\nDefines all token types used in the HyperCode language.\n\"\"\"\nfrom enum import Enum\nfrom typing import Any\n\n\nclass TokenType(Enum):\n    # Single-character tokens\n    LEFT_PAREN = \"(\"\n    RIGHT_PAREN = \")\"\n    LEFT_BRACE = \"{\"\n    RIGHT_BRACE = \"}\"\n    COMMA = \",\"\n    DOT = \".\"\n    MINUS = \"-\"\n    PLUS = \"+\"\n    SEMICOLON = \";\"\n    SLASH = \"/\"\n    STAR = \"*\"\n    PERCENT = \"%\"\n    BANG = \"!\"\n    EQUAL = \"=\"\n    LESS = \"<\"\n    GREATER = \">\"\n    COLON = \":\"\n    QUESTION = \"?\"\n    PIPE = \"|\"\n    AT = \"@\"\n\n    # One or two character tokens\n    BANG_EQUAL = \"!=\"\n    EQUAL_EQUAL = \"==\"\n    LESS_EQUAL = \"<=\"\n    GREATER_EQUAL = \">=\"\n    ARROW = \"->\"\n\n    # Literals\n    IDENTIFIER = \"IDENTIFIER\"\n    STRING = \"STRING\"\n    NUMBER = \"NUMBER\"\n    DOCSTRING = \"DOCSTRING\"\n    \n    # Keywords\n    AND = \"and\"\n    BLOCK = \"block\"\n    BREAK = \"break\"\n    CLASS = \"class\"\n    CONTINUE = \"continue\"\n    ELSE = \"else\"\n    FALSE = \"false\"\n    FOR = \"for\"\n    FUNC = \"func\"\n    IF = \"if\"\n    NIL = \"nil\"\n    OR = \"or\"\n    PRINT = \"print\"\n    RETURN = \"return\"\n    SUPER = \"super\"\n    THIS = \"this\"\n    TRUE = \"true\"\n    LET = \"let\"\n    WHILE = \"while\"\n    \n    # Special tokens\n    EOF = \"EOF\"\n    ERROR = \"ERROR\"\n\nclass Token:\n    \"\"\"\n    Represents a token in the HyperCode language.\n    \n    Attributes:\n        type: The type of the token (from TokenType)\n        lexeme: The actual text that was matched\n        literal: The literal value (for numbers, strings, etc.)\n        line: The line number where the token appears (1-based)\n        column: The column number where the token starts (1-based)\n    \"\"\"\n    def __init__(\n        self,\n        type: TokenType,\n        lexeme: str,\n        literal: Any,\n        line: int,\n        column: int\n    ):\n        self.type = type\n        self.lexeme = lexeme\n        self.literal = literal\n        self.line = line\n        self.column = column\n    \n    def __str__(self) -> str:\n        return f\"{self.type} {self.lexeme} {self.literal}\"\n    \n    def __repr__(self) -> str:\n        return f\"<Token {self.type} '{self.lexeme}' at {self.line}:{self.column}>\"\n\n\n# Keywords mapping for quick lookup\nKEYWORDS = {\n    'and': TokenType.AND,\n    'block': TokenType.BLOCK,\n    'break': TokenType.BREAK,\n    'class': TokenType.CLASS,\n    'continue': TokenType.CONTINUE,\n    'else': TokenType.ELSE,\n    'false': TokenType.FALSE,\n    'for': TokenType.FOR,\n    'func': TokenType.FUNC,\n    'if': TokenType.IF,\n    'nil': TokenType.NIL,\n    'or': TokenType.OR,\n    'print': TokenType.PRINT,\n    'return': TokenType.RETURN,\n    'super': TokenType.SUPER,\n    'this': TokenType.THIS,\n    'true': TokenType.TRUE,\n    'let': TokenType.LET,\n    'while': TokenType.WHILE,\n}",
  "metadata": {},
  "relative_path": "src\\core\\tokens.py",
  "id": "905332110f8a408b58932bcdb1323d5d"
}