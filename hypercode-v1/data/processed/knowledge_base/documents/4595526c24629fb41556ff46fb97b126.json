{
  "file_name": "hash.py",
  "file_path": "C:\\Users\\lyndz\\Downloads\\hypercode PROJECT\\hypercode\\venv_new\\Lib\\site-packages\\pip\\_internal\\commands\\hash.py",
  "file_size": 1703,
  "created": "2025-12-01T01:58:30.426668",
  "modified": "2025-12-01T01:58:30.436464",
  "file_type": "code",
  "content_hash": "0c3c6e30957a74e73c693e1069492566",
  "content_type": "text",
  "content": "import hashlib\nimport logging\nimport sys\nfrom optparse import Values\nfrom typing import List\n\nfrom pip._internal.cli.base_command import Command\nfrom pip._internal.cli.status_codes import ERROR, SUCCESS\nfrom pip._internal.utils.hashes import FAVORITE_HASH, STRONG_HASHES\nfrom pip._internal.utils.misc import read_chunks, write_output\n\nlogger = logging.getLogger(__name__)\n\n\nclass HashCommand(Command):\n    \"\"\"\n    Compute a hash of a local package archive.\n\n    These can be used with --hash in a requirements file to do repeatable\n    installs.\n    \"\"\"\n\n    usage = \"%prog [options] <file> ...\"\n    ignore_require_venv = True\n\n    def add_options(self) -> None:\n        self.cmd_opts.add_option(\n            \"-a\",\n            \"--algorithm\",\n            dest=\"algorithm\",\n            choices=STRONG_HASHES,\n            action=\"store\",\n            default=FAVORITE_HASH,\n            help=\"The hash algorithm to use: one of {}\".format(\n                \", \".join(STRONG_HASHES)\n            ),\n        )\n        self.parser.insert_option_group(0, self.cmd_opts)\n\n    def run(self, options: Values, args: List[str]) -> int:\n        if not args:\n            self.parser.print_usage(sys.stderr)\n            return ERROR\n\n        algorithm = options.algorithm\n        for path in args:\n            write_output(\n                \"%s:\\n--hash=%s:%s\", path, algorithm, _hash_of_file(path, algorithm)\n            )\n        return SUCCESS\n\n\ndef _hash_of_file(path: str, algorithm: str) -> str:\n    \"\"\"Return the hash digest of a file.\"\"\"\n    with open(path, \"rb\") as archive:\n        hash = hashlib.new(algorithm)\n        for chunk in read_chunks(archive):\n            hash.update(chunk)\n    return hash.hexdigest()\n",
  "metadata": {},
  "relative_path": "venv_new\\Lib\\site-packages\\pip\\_internal\\commands\\hash.py",
  "id": "4595526c24629fb41556ff46fb97b126"
}