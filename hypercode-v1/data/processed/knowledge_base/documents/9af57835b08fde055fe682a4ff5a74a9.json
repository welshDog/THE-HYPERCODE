{
  "file_name": "build-hyper-database.py",
  "file_path": "C:\\Users\\lyndz\\Downloads\\hypercode PROJECT\\hypercode\\scripts\\build-hyper-database.py",
  "file_size": 11381,
  "created": "2025-11-30T09:17:21.451650",
  "modified": "2025-11-30T20:25:34.799093",
  "file_type": "code",
  "content_hash": "ffd6b265d81642a11c40b66ca5d31ac7",
  "content_type": "text",
  "content": "#!/usr/bin/env python3\n\"\"\"\nHyper Database Builder - Scans HyperCode repo, builds knowledge graph.\n\nUsage:\n  python scripts/build-hyper-database.py\n\nOutput:\n  HYPER_DATABASE.md (living codebase inventory)\n  HYPER_DATABASE.json (machine-readable format)\n\"\"\"\n\nimport json\nimport ast\nfrom pathlib import Path\nfrom datetime import datetime\nfrom typing import Any\nfrom collections import defaultdict\n\n\nclass HyperDatabaseBuilder:\n    \"\"\"Scans codebase and builds semantic knowledge graph.\"\"\"\n\n    def __init__(self, repo_root: str = \".\") -> None:\n        \"\"\"Initialize builder with repo root path.\"\"\"\n        self.repo_root = Path(repo_root)\n        self.entities: list[dict[str, Any]] = []\n        self.relationships: dict[str, set[str]] = defaultdict(set)\n        self.files_scanned: int = 0\n        self.start_time = datetime.now()\n\n    def scan_python_file(self, file_path: Path) -> list[dict[str, Any]]:\n        \"\"\"Extract functions, classes from Python file.\"\"\"\n        entities: list[dict[str, Any]] = []\n        try:\n            with open(file_path, encoding='utf-8') as f:\n                content = f.read()\n                tree = ast.parse(content)\n        except (SyntaxError, UnicodeDecodeError):\n            return entities\n\n        for node in ast.walk(tree):\n            if isinstance(node, ast.FunctionDef):\n                docstring = ast.get_docstring(node)\n                entities.append({\n                    'id': f\"{file_path}:{node.name}\",\n                    'type': 'function',\n                    'name': node.name,\n                    'file': str(file_path),\n                    'lineno': node.lineno,\n                    'docstring': docstring,\n                    'args': [arg.arg for arg in node.args.args],\n                    'has_test': False,\n                    'has_doc': bool(docstring),\n                    'complexity': 'LOW',\n                })\n            elif isinstance(node, ast.ClassDef):\n                docstring = ast.get_docstring(node)\n                methods = [\n                    m.name for m in node.body\n                    if isinstance(m, ast.FunctionDef)\n                ]\n                entities.append({\n                    'id': f\"{file_path}:{node.name}\",\n                    'type': 'class',\n                    'name': node.name,\n                    'file': str(file_path),\n                    'lineno': node.lineno,\n                    'docstring': docstring,\n                    'methods': methods,\n                    'has_test': False,\n                    'has_doc': bool(docstring),\n                })\n\n        return entities\n\n    def scan_javascript_file(\n        self, file_path: Path\n    ) -> list[dict[str, Any]]:\n        \"\"\"Extract functions from JavaScript (regex-based).\"\"\"\n        entities: list[dict[str, Any]] = []\n        try:\n            with open(file_path, encoding='utf-8') as f:\n                lines = f.readlines()\n        except (UnicodeDecodeError, OSError):\n            return entities\n\n        for i, line in enumerate(lines):\n            line_stripped = line.strip()\n            # Match: function name() or const name = () =>\n            if line_stripped.startswith('function ') or '=>' in line_stripped:\n                has_doc = '/*' in line or '//' in line\n                entities.append({\n                    'id': f\"{file_path}:{i}\",\n                    'type': 'function',\n                    'file': str(file_path),\n                    'lineno': i + 1,\n                    'snippet': line_stripped[:80],\n                    'has_test': False,\n                    'has_doc': has_doc,\n                })\n\n        return entities\n\n    @staticmethod\n    def should_skip_directory(dirname: str) -> bool:\n        \"\"\"Check if directory should be skipped.\"\"\"\n        skip_dirs = {\n            'node_modules', '.git', '__pycache__', '.venv', 'venv',\n            '.pytest_cache', 'dist', 'build', '.egg-info', 'coverage',\n            '.nyc_output', '.DS_Store', '.idea', '.vscode'\n        }\n        return dirname in skip_dirs or dirname.startswith('.')\n\n    def build(self) -> list[dict[str, Any]]:\n        \"\"\"Scan entire repo and build database.\"\"\"\n        print(f\"ğŸ” Scanning HyperCode repo: {self.repo_root}\")\n        print()\n\n        for root, dirs, files in __import__('os').walk(self.repo_root):\n            # Skip ignored directories\n            dirs[:] = [\n                d for d in dirs\n                if not self.should_skip_directory(d)\n            ]\n\n            for file in files:\n                file_path = Path(root) / file\n                relative_path = file_path.relative_to(self.repo_root)\n\n                try:\n                    if file.endswith('.py'):\n                        entities = self.scan_python_file(file_path)\n                        self.entities.extend(entities)\n                        self.files_scanned += 1\n                        if entities:\n                            print(\n                                f\"  âœ… {relative_path}: \"\n                                f\"{len(entities)} entities\"\n                            )\n\n                    elif file.endswith(('.js', '.ts')):\n                        entities = self.scan_javascript_file(file_path)\n                        self.entities.extend(entities)\n                        self.files_scanned += 1\n                        if entities:\n                            print(\n                                f\"  âœ… {relative_path}: \"\n                                f\"{len(entities)} entities\"\n                            )\n\n                except Exception as e:\n                    print(f\"  âš ï¸  {relative_path}: {e}\")\n\n        print()\n        return self.entities\n\n    def generate_markdown_report(self) -> str:\n        \"\"\"Generate HYPER_DATABASE.md report.\"\"\"\n        elapsed = (datetime.now() - self.start_time).total_seconds()\n\n        functions = [\n            e for e in self.entities if e['type'] == 'function'\n        ]\n        classes = [e for e in self.entities if e['type'] == 'class']\n        documented = sum(\n            1 for e in self.entities if e.get('has_doc', False)\n        )\n\n        coverage_pct = (\n            100 * documented / len(self.entities)\n            if self.entities else 0\n        )\n\n        report = f\"\"\"# ğŸ§  HYPER DATABASE\n## Living Inventory of HyperCode Codebase\n\n**Generated**: {datetime.now().isoformat()}\n**Scan Time**: {elapsed:.1f}s\n**Files Scanned**: {self.files_scanned}\n**Total Entities**: {len(self.entities)}\n\n---\n\n## ğŸ“Š HEALTH SNAPSHOT\n\n| Metric | Value |\n|--------|-------|\n| **Functions** | {len(functions)} |\n| **Classes** | {len(classes)} |\n| **Files** | {self.files_scanned} |\n| **Documentation** | {documented}/{len(self.entities)} ({coverage_pct:.1f}%) |\n| **Status** | âœ… HEALTHY |\n\n---\n\n## ğŸ“‹ ALL FUNCTIONS\n\n\"\"\"\n\n        # Group by file\n        by_file: dict[str, list[dict[str, Any]]] = defaultdict(list)\n        for entity in self.entities:\n            if entity['type'] == 'function':\n                by_file[entity['file']].append(entity)\n\n        for file_path in sorted(by_file.keys()):\n            report += f\"### {file_path}\\n\\n\"\n            for func in sorted(by_file[file_path],\n                               key=lambda f: f.get('lineno', 0)): # closing bracket does not match visual indentation\n                func_name = func.get('name', 'unnamed_function')\n                line_no = func.get('lineno', 'N/A')\n                report += f\"#### `{func_name}()` (line {line_no})\\n\"\n                if func.get('docstring'):\n                    report += f\"_{func['docstring']}_\\n\\n\"\n                if func.get('args'):\n                    report += f\"**Args**: {', '.join(func['args'])}\\n\\n\"\n                report += \"\\n\"\n\n        report += \"---\\n\\n## ğŸ“¦ ALL CLASSES\\n\\n\"\n\n        by_file_classes: dict[str, list[dict[str, Any]]] = defaultdict(\n            list\n        )\n        for entity in self.entities:\n            if entity['type'] == 'class':\n                by_file_classes[entity['file']].append(entity)\n\n        for file_path in sorted(by_file_classes.keys()):\n            report += f\"### {file_path}\\n\\n\"\n            for cls in sorted(\n                by_file_classes[file_path], key=lambda c: c['lineno']\n            ):\n                report += f\"#### `{cls['name']}`\\n\"\n                if cls.get('docstring'):\n                    report += f\"_{cls['docstring']}_\\n\\n\"\n                if cls.get('methods'):\n                    methods_str = ', '.join(cls['methods'])\n                    report += f\"**Methods**: {methods_str}\\n\\n\"\n                report += \"\\n\"\n\n        report += \"\"\"---\n\n## ğŸ¯ NEXT STEPS\n\n1. Load HYPER_DATABASE.md into Windsurf Cascade\n2. Tell Cascade: \"Consulting HYPER_DATABASE before every task\"\n3. Add database queries to workflow:\n   - \"What functions are in X?\"\n   - \"What calls function Y?\"\n   - \"What tests cover Z?\"\n4. Auto-update daily\n\n**This database is TRUTH. Your code follows it.**\n\"\"\"\n\n        return report\n\n    def generate_json_report(self) -> dict[str, Any]:\n        \"\"\"Generate machine-readable HYPER_DATABASE.json.\"\"\"\n        return {\n            'generated': datetime.now().isoformat(),\n            'files_scanned': self.files_scanned,\n            'entities': self.entities,\n            'stats': {\n                'total_entities': len(self.entities),\n                'functions': sum(\n                    1 for e in self.entities if e['type'] == 'function'\n                ),\n                'classes': sum(\n                    1 for e in self.entities if e['type'] == 'class'\n                ),\n                'documented': sum(\n                    1 for e in self.entities if e.get('has_doc', False)\n                ),\n            }\n        }\n\n\ndef main() -> None:\n    \"\"\"Main entry point.\"\"\"\n    builder = HyperDatabaseBuilder('.')\n\n    print(\"=\" * 60)\n    print(\"ğŸš€ HYPER DATABASE BUILDER\")\n    print(\"=\" * 60)\n    print()\n\n    # Build\n    builder.build()\n\n    print(\"=\" * 60)\n    print(\"âœ… Scan complete!\")\n    print(f\"   - Files: {builder.files_scanned}\")\n    print(f\"   - Entities: {len(builder.entities)}\")\n    print(\"=\" * 60)\n    print()\n\n    # Generate reports\n    print(\"ğŸ“ Generating HYPER_DATABASE.md...\")\n    md_report = builder.generate_markdown_report()\n    with open('HYPER_DATABASE.md', 'w', encoding='utf-8') as f:\n        f.write(md_report)\n    print(\"   âœ… HYPER_DATABASE.md created\")\n\n    print(\"ğŸ“Š Generating HYPER_DATABASE.json...\")\n    json_report = builder.generate_json_report()\n    with open('HYPER_DATABASE.json', 'w', encoding='utf-8') as f:\n        json.dump(json_report, f, indent=2)\n    print(\"   âœ… HYPER_DATABASE.json created\")\n\n    print()\n    print(\"=\" * 60)\n    print(\"ğŸ‰ HYPER DATABASE READY!\")\n    print(\"=\" * 60)\n    print()\n    print(\"Next steps:\")\n    print(\"1. Open Windsurf\")\n    print(\"2. In Cascade Chat, paste:\")\n    print()\n    print('   Load HYPER_DATABASE.md into context')\n    print('   Ready for database-aware development')\n    print()\n    print(\"3. Watch Hyper Builder use it automatically!\")\n    print()\n\n\nif __name__ == '__main__':\n    main()\n",
  "metadata": {},
  "relative_path": "build-hyper-database.py",
  "id": "9af57835b08fde055fe682a4ff5a74a9"
}