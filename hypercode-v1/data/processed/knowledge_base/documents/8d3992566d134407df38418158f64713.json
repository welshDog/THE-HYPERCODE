{
  "file_name": "sync-space-to-main.py",
  "file_path": "C:\\Users\\lyndz\\Downloads\\hypercode PROJECT\\hypercode\\scripts\\sync-space-to-main.py",
  "file_size": 11456,
  "created": "2025-11-30T22:48:58.427007",
  "modified": "2025-12-03T00:46:08.555597",
  "file_type": "code",
  "content_hash": "e6e1ca9d9a7d7f28d4ac12e1a7a36f88",
  "content_type": "text",
  "content": "#!/usr/bin/env python3\n\"\"\"\nHyperCode Space-to-Main Sync Script\nMirrors Space export data (docs, data, assets) into main repo folders.\nOne-way sync with logging, conflict resolution, and dry-run mode.\n\nUsage:\n    python scripts/sync-space-to-main.py                  # Full sync\n    python scripts/sync-space-to-main.py --dry-run        # Preview changes\n    python scripts/sync-space-to-main.py --config custom.toml  # Custom config\n\"\"\"\n\nimport os\nimport sys\nimport json\nimport shutil  # type: ignore\nimport argparse\nfrom pathlib import Path\nfrom datetime import datetime\nimport toml\nfrom typing import Dict, List, Tuple\nimport traceback\n\n\ndef log_error(msg: str):\n    \"\"\"Error-level log with traceback.\"\"\"\n    print(f\"{Colors.RED}[ERROR]{Colors.RESET} {msg}\")\n    exc_type, exc_value, exc_traceback = sys.exc_info()\n    if exc_type:\n        print(f\"{Colors.RED}Exception Type: {exc_type.__name__}{Colors.RESET}\")\n        print(f\"{Colors.RED}Exception Value: {exc_value}{Colors.RESET}\")\n        print(f\"{Colors.YELLOW}Traceback:{Colors.RESET}\")\n        traceback.print_tb(exc_traceback)\n\n\n# ANSI colors for terminal output\nclass Colors:\n    GREEN = \"\\033[92m\"\n    RED = \"\\033[91m\"\n    YELLOW = \"\\033[93m\"\n    BLUE = \"\\033[94m\"\n    RESET = \"\\033[0m\"\n    BOLD = \"\\033[1m\"\n\n\ndef log_info(msg: str):\n    \"\"\"Info-level log.\"\"\"\n    print(f\"{Colors.BLUE}[INFO]{Colors.RESET} {msg}\")\n\n\ndef log_success(msg: str):\n    \"\"\"Success-level log.\"\"\"\n    print(f\"{Colors.GREEN}[✓]{Colors.RESET} {msg}\")\n\n\ndef log_warning(msg: str):\n    \"\"\"Warning-level log.\"\"\"\n    print(f\"{Colors.YELLOW}[⚠]{Colors.RESET} {msg}\")\n\n\ndef deep_merge(source: Dict, destination: Dict) -> Dict:\n    \"\"\"Recursively merge source dict into destination dict.\"\"\"\n    for key, value in source.items():\n        if isinstance(value, dict):\n            node = destination.setdefault(key, {})\n            deep_merge(value, node)\n        else:\n            destination[key] = value\n    return destination\n\n\ndef load_config(config_path: str = \".hypercode/sync.toml\") -> Dict:\n    \"\"\"\n    Load sync configuration from TOML file.\n    Fallback to defaults if file doesn't exist.\n    \"\"\"\n    default_config = {\n        \"sync\": {\n            \"source_root\": \"space_sync\",\n            \"target_root\": \".\",\n            \"mappings\": {\n                \"raw_docs\": \"docs\",\n                \"raw_data\": \"data\",\n                \"raw_assets\": \"assets\",\n            },\n            \"strict_mirror\": False,\n            \"delete_orphans\": False,\n            \"preserve_patterns\": [\".git\", \".gitignore\", \"*.md\", \"README*\"],\n            \"log_file\": \"logs/sync-space-to-main.log\",\n        },\n        \"filters\": {\n            \"exclude_extensions\": [\".tmp\", \".bak\", \".swp\"],\n            \"exclude_dirs\": [\"__pycache__\", \".pytest_cache\", \"node_modules\"],\n            \"exclude_names\": [\".DS_Store\", \"Thumbs.db\"],\n        },\n    }\n\n    if os.path.exists(config_path):\n        try:\n            user_config = toml.load(config_path)\n            deep_merge(user_config, default_config)\n            log_success(f\"Loaded config from {config_path}\")\n        except Exception as e:\n            log_error(f\"Failed to parse {config_path}: {e}\")\n            log_warning(\"Falling back to default configuration\")\n    else:\n        log_warning(f\"Config file {config_path} not found, using defaults\")\n\n    return default_config\n\n\ndef should_skip_file(filepath: Path, config: Dict) -> bool:\n    \"\"\"Check if file should be skipped based on filters.\"\"\"\n    filters = config.get(\"filters\", {})\n    exclude_ext = filters.get(\"exclude_extensions\", [])\n    exclude_dirs = filters.get(\"exclude_dirs\", [])\n    exclude_names = filters.get(\"exclude_names\", [])\n\n    # Check extension\n    if filepath.suffix in exclude_ext:\n        return True\n\n    # Check filename\n    if filepath.name in exclude_names:\n        return True\n\n    # Check if any parent dir is excluded\n    for part in filepath.parts:\n        if part in exclude_dirs:\n            return True\n\n    return False\n\n\ndef get_all_files(directory: Path) -> List[Path]:\n    \"\"\"Recursively get all files in directory.\"\"\"\n    files = []\n    if directory.exists():\n        for item in directory.rglob(\"*\"):\n            if item.is_file():\n                files.append(item)\n    return files\n\n\ndef copy_file(src: Path, dst: Path, dry_run: bool = False) -> bool:\n    \"\"\"Copy file with directory creation. Returns True if copied/would copy.\"\"\"\n    try:\n        dst.parent.mkdir(parents=True, exist_ok=True)\n        if not dry_run:\n            shutil.copy2(src, dst)\n        return True\n    except Exception as e:\n        log_error(f\"Failed to copy {src} → {dst}: {e}\")\n        return False\n\n\ndef remove_file(filepath: Path, dry_run: bool = False) -> bool:\n    \"\"\"Remove file. Returns True if removed/would remove.\"\"\"\n    try:\n        if not dry_run:\n            filepath.unlink()\n        return True\n    except Exception as e:\n        log_error(f\"Failed to delete {filepath}: {e}\")\n        return False\n\n\ndef sync_folder(\n    source: Path, target: Path, config: Dict, dry_run: bool = False\n) -> Tuple[int, int, int]:\n    \"\"\"\n    Sync source folder to target folder (one-way).\n    Returns (copied, updated, errors) counts.\n    \"\"\"\n    copied, updated, errors = 0, 0, 0\n\n    if not source.exists():\n        log_warning(f\"Source folder {source} doesn't exist, skipping\")\n        return copied, updated, errors\n\n    source_files = get_all_files(source)\n\n    for src_file in source_files:\n        if should_skip_file(src_file, config):\n            continue\n\n        # Calculate relative path and target location\n        rel_path = src_file.relative_to(source)\n        tgt_file = target / rel_path\n\n        # Check if target exists and is newer (update scenario)\n        if tgt_file.exists():\n            src_mtime = os.path.getmtime(src_file)\n            tgt_mtime = os.path.getmtime(tgt_file)\n\n            if src_mtime > tgt_mtime:\n                if copy_file(src_file, tgt_file, dry_run):\n                    log_info(f\"Updated: {rel_path}\")\n                    updated += 1\n                else:\n                    errors += 1\n        else:\n            if copy_file(src_file, tgt_file, dry_run):\n                log_info(f\"Copied: {rel_path}\")\n                copied += 1\n            else:\n                errors += 1\n\n    return copied, updated, errors\n\n\ndef delete_orphans(target: Path, source: Path, dry_run: bool = False) -> int:\n    \"\"\"Remove files from target that no longer exist in source.\"\"\"\n    deleted = 0\n    target_files = get_all_files(target)\n\n    for tgt_file in target_files:\n        rel_path = tgt_file.relative_to(target)\n        src_file = source / rel_path\n\n        if not src_file.exists():\n            if remove_file(tgt_file, dry_run):\n                log_info(f\"Deleted orphan: {rel_path}\")\n                deleted += 1\n\n    return deleted\n\n\ndef sync_all_mappings(config: Dict, dry_run: bool = False) -> Dict:\n    \"\"\"Execute all mappings from config.\"\"\"\n    sync_config = config.get(\"sync\", {})\n    source_root = Path(sync_config.get(\"source_root\", \"space_sync\")).resolve()\n    target_root = Path(sync_config.get(\"target_root\", \".\")).resolve()\n\n    # Only include string values in mappings (exclude boolean/list config values)\n    mappings = {\n        k: v for k, v in sync_config.get(\"mappings\", {}).items() if isinstance(v, str)\n    }\n    delete_orphans_flag = sync_config.get(\"delete_orphans\", False)\n\n    stats = {\n        \"total_copied\": 0,\n        \"total_updated\": 0,\n        \"total_deleted\": 0,\n        \"total_errors\": 0,\n        \"mappings\": {},\n    }\n\n    log_info(f\"Starting sync: {source_root} → {target_root}\")\n    if dry_run:\n        log_warning(\"DRY RUN MODE (no files will be modified)\")\n\n    for source_name, target_name in mappings.items():\n        source = source_root / str(source_name)\n        target = target_root / str(target_name)\n\n        if not source.exists():\n            log_warning(f\"Source folder {source} doesn't exist, skipping\")\n            continue\n\n        log_info(f\"Syncing: {source_name} → {target_name}\")\n\n        copied, updated, errors = sync_folder(source, target, config, dry_run)\n        stats[\"total_copied\"] += copied\n        stats[\"total_updated\"] += updated\n        stats[\"total_errors\"] += errors\n        stats[\"mappings\"][source_name] = {\n            \"target\": target_name,\n            \"copied\": copied,\n            \"updated\": updated,\n            \"errors\": errors,\n        }\n\n        if delete_orphans_flag:\n            deleted = delete_orphans(target, source, dry_run)\n            stats[\"total_deleted\"] += deleted\n\n    return stats\n\n\ndef write_log(log_file: str, stats: Dict, dry_run: bool = False):\n    \"\"\"Write sync results to log file.\"\"\"\n    log_dir = Path(log_file).parent\n    log_dir.mkdir(parents=True, exist_ok=True)\n\n    timestamp = datetime.now().isoformat()\n    mode = \"[DRY RUN]\" if dry_run else \"[LIVE]\"\n\n    try:\n        with open(log_file, \"a\") as f:\n            f.write(f\"\\n{'-' * 60}\\n\")\n            f.write(f\"{timestamp} {mode}\\n\")\n            f.write(\n                f\"Copied: {stats['total_copied']} | Updated: {stats['total_updated']} | \"\n                f\"Deleted: {stats['total_deleted']} | Errors: {stats['total_errors']}\\n\"\n            )\n            f.write(json.dumps(stats.get(\"mappings\", {}), indent=2) + \"\\n\")\n        log_success(f\"Log written to {log_file}\")\n    except Exception as e:\n        log_error(f\"Failed to write log: {e}\")\n\n\ndef print_summary(stats: Dict, dry_run: bool = False):\n    \"\"\"Print sync summary to console.\"\"\"\n    print(\"\\n\" + \"=\" * 80)\n    print(f\"{'SYNC SUMMARY' + (' (DRY RUN)' if dry_run else ''):^80}\")\n    print(\"=\" * 80)\n    print(f\"Copied: {stats['total_copied']}\")\n    print(f\"Updated: {stats['total_updated']}\")\n    print(f\"Deleted: {stats['total_deleted']}\")\n    print(f\"Errors: {stats['total_errors']}\\n\")\n\n    print(\"Mapping Details:\")\n    for src, details in stats[\"mappings\"].items():\n        tgt = details.get(\"target\", \"\")\n        print(\n            f\"  {str(src)[:20]:20} → {str(tgt)[:20]:20} (copied: {details['copied']}, \"\n            f\"updated: {details['updated']}, errors: {details['errors']}\"\n        )\n\n    if dry_run:\n        print(\"\\n\" + \"=\" * 80)\n        print(\"NOTE: This was a dry run. No files were actually modified.\")\n    print(\"=\" * 80)\n\n\ndef main():\n    try:\n        parser = argparse.ArgumentParser(\n            description=\"HyperCode Space-to-Main Sync: Mirror Space exports into repo folders.\"\n        )\n        parser.add_argument(\n            \"--dry-run\",\n            action=\"store_true\",\n            help=\"Preview changes without modifying files\",\n        )\n        parser.add_argument(\n            \"--config\",\n            default=\".hypercode/sync.toml\",\n            help=\"Path to sync config file (default: .hypercode/sync.toml)\",\n        )\n\n        args = parser.parse_args()\n\n        # Load configuration\n        config = load_config(args.config)\n\n        # Execute sync\n        stats = sync_all_mappings(config, dry_run=args.dry_run)\n\n        # Log results\n        log_file = config.get(\"sync\", {}).get(\"log_file\", \"logs/sync-space-to-main.log\")\n        write_log(log_file, stats, dry_run=args.dry_run)\n\n        # Print summary\n        print_summary(stats, dry_run=args.dry_run)\n\n        # Exit with error code if there were errors\n        sys.exit(1 if stats[\"total_errors\"] > 0 else 0)\n    except Exception as e:\n        log_error(f\"Fatal error during sync: {str(e)}\")\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n",
  "metadata": {},
  "relative_path": "scripts\\sync-space-to-main.py",
  "id": "8d3992566d134407df38418158f64713"
}