{
  "file_name": "req_file.py",
  "file_path": "C:\\Users\\lyndz\\Downloads\\hypercode PROJECT\\hypercode\\venv_new\\Lib\\site-packages\\pip\\_internal\\req\\req_file.py",
  "file_size": 20234,
  "created": "2025-12-01T01:58:31.267482",
  "modified": "2025-12-01T01:58:31.270018",
  "file_type": "code",
  "content_hash": "24e040d93fa1a4c639c647bc910f4075",
  "content_type": "text",
  "content": "\"\"\"\nRequirements file parsing\n\"\"\"\n\nimport codecs\nimport locale\nimport logging\nimport optparse\nimport os\nimport re\nimport shlex\nimport sys\nimport urllib.parse\nfrom dataclasses import dataclass\nfrom optparse import Values\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Callable,\n    Dict,\n    Generator,\n    Iterable,\n    List,\n    NoReturn,\n    Optional,\n    Tuple,\n)\n\nfrom pip._internal.cli import cmdoptions\nfrom pip._internal.exceptions import InstallationError, RequirementsFileParseError\nfrom pip._internal.models.search_scope import SearchScope\n\nif TYPE_CHECKING:\n    from pip._internal.index.package_finder import PackageFinder\n    from pip._internal.network.session import PipSession\n\n__all__ = [\"parse_requirements\"]\n\nReqFileLines = Iterable[Tuple[int, str]]\n\nLineParser = Callable[[str], Tuple[str, Values]]\n\nSCHEME_RE = re.compile(r\"^(http|https|file):\", re.I)\nCOMMENT_RE = re.compile(r\"(^|\\s+)#.*$\")\n\n# Matches environment variable-style values in '${MY_VARIABLE_1}' with the\n# variable name consisting of only uppercase letters, digits or the '_'\n# (underscore). This follows the POSIX standard defined in IEEE Std 1003.1,\n# 2013 Edition.\nENV_VAR_RE = re.compile(r\"(?P<var>\\$\\{(?P<name>[A-Z0-9_]+)\\})\")\n\nSUPPORTED_OPTIONS: List[Callable[..., optparse.Option]] = [\n    cmdoptions.index_url,\n    cmdoptions.extra_index_url,\n    cmdoptions.no_index,\n    cmdoptions.constraints,\n    cmdoptions.requirements,\n    cmdoptions.editable,\n    cmdoptions.find_links,\n    cmdoptions.no_binary,\n    cmdoptions.only_binary,\n    cmdoptions.prefer_binary,\n    cmdoptions.require_hashes,\n    cmdoptions.pre,\n    cmdoptions.trusted_host,\n    cmdoptions.use_new_feature,\n]\n\n# options to be passed to requirements\nSUPPORTED_OPTIONS_REQ: List[Callable[..., optparse.Option]] = [\n    cmdoptions.global_options,\n    cmdoptions.hash,\n    cmdoptions.config_settings,\n]\n\nSUPPORTED_OPTIONS_EDITABLE_REQ: List[Callable[..., optparse.Option]] = [\n    cmdoptions.config_settings,\n]\n\n\n# the 'dest' string values\nSUPPORTED_OPTIONS_REQ_DEST = [str(o().dest) for o in SUPPORTED_OPTIONS_REQ]\nSUPPORTED_OPTIONS_EDITABLE_REQ_DEST = [\n    str(o().dest) for o in SUPPORTED_OPTIONS_EDITABLE_REQ\n]\n\n# order of BOMS is important: codecs.BOM_UTF16_LE is a prefix of codecs.BOM_UTF32_LE\n# so data.startswith(BOM_UTF16_LE) would be true for UTF32_LE data\nBOMS: List[Tuple[bytes, str]] = [\n    (codecs.BOM_UTF8, \"utf-8\"),\n    (codecs.BOM_UTF32, \"utf-32\"),\n    (codecs.BOM_UTF32_BE, \"utf-32-be\"),\n    (codecs.BOM_UTF32_LE, \"utf-32-le\"),\n    (codecs.BOM_UTF16, \"utf-16\"),\n    (codecs.BOM_UTF16_BE, \"utf-16-be\"),\n    (codecs.BOM_UTF16_LE, \"utf-16-le\"),\n]\n\nPEP263_ENCODING_RE = re.compile(rb\"coding[:=]\\s*([-\\w.]+)\")\nDEFAULT_ENCODING = \"utf-8\"\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass(frozen=True)\nclass ParsedRequirement:\n    # TODO: replace this with slots=True when dropping Python 3.9 support.\n    __slots__ = (\n        \"requirement\",\n        \"is_editable\",\n        \"comes_from\",\n        \"constraint\",\n        \"options\",\n        \"line_source\",\n    )\n\n    requirement: str\n    is_editable: bool\n    comes_from: str\n    constraint: bool\n    options: Optional[Dict[str, Any]]\n    line_source: Optional[str]\n\n\n@dataclass(frozen=True)\nclass ParsedLine:\n    __slots__ = (\"filename\", \"lineno\", \"args\", \"opts\", \"constraint\")\n\n    filename: str\n    lineno: int\n    args: str\n    opts: Values\n    constraint: bool\n\n    @property\n    def is_editable(self) -> bool:\n        return bool(self.opts.editables)\n\n    @property\n    def requirement(self) -> Optional[str]:\n        if self.args:\n            return self.args\n        elif self.is_editable:\n            # We don't support multiple -e on one line\n            return self.opts.editables[0]\n        return None\n\n\ndef parse_requirements(\n    filename: str,\n    session: \"PipSession\",\n    finder: Optional[\"PackageFinder\"] = None,\n    options: Optional[optparse.Values] = None,\n    constraint: bool = False,\n) -> Generator[ParsedRequirement, None, None]:\n    \"\"\"Parse a requirements file and yield ParsedRequirement instances.\n\n    :param filename:    Path or url of requirements file.\n    :param session:     PipSession instance.\n    :param finder:      Instance of pip.index.PackageFinder.\n    :param options:     cli options.\n    :param constraint:  If true, parsing a constraint file rather than\n        requirements file.\n    \"\"\"\n    line_parser = get_line_parser(finder)\n    parser = RequirementsFileParser(session, line_parser)\n\n    for parsed_line in parser.parse(filename, constraint):\n        parsed_req = handle_line(\n            parsed_line, options=options, finder=finder, session=session\n        )\n        if parsed_req is not None:\n            yield parsed_req\n\n\ndef preprocess(content: str) -> ReqFileLines:\n    \"\"\"Split, filter, and join lines, and return a line iterator\n\n    :param content: the content of the requirements file\n    \"\"\"\n    lines_enum: ReqFileLines = enumerate(content.splitlines(), start=1)\n    lines_enum = join_lines(lines_enum)\n    lines_enum = ignore_comments(lines_enum)\n    lines_enum = expand_env_variables(lines_enum)\n    return lines_enum\n\n\ndef handle_requirement_line(\n    line: ParsedLine,\n    options: Optional[optparse.Values] = None,\n) -> ParsedRequirement:\n    # preserve for the nested code path\n    line_comes_from = \"{} {} (line {})\".format(\n        \"-c\" if line.constraint else \"-r\",\n        line.filename,\n        line.lineno,\n    )\n\n    assert line.requirement is not None\n\n    # get the options that apply to requirements\n    if line.is_editable:\n        supported_dest = SUPPORTED_OPTIONS_EDITABLE_REQ_DEST\n    else:\n        supported_dest = SUPPORTED_OPTIONS_REQ_DEST\n    req_options = {}\n    for dest in supported_dest:\n        if dest in line.opts.__dict__ and line.opts.__dict__[dest]:\n            req_options[dest] = line.opts.__dict__[dest]\n\n    line_source = f\"line {line.lineno} of {line.filename}\"\n    return ParsedRequirement(\n        requirement=line.requirement,\n        is_editable=line.is_editable,\n        comes_from=line_comes_from,\n        constraint=line.constraint,\n        options=req_options,\n        line_source=line_source,\n    )\n\n\ndef handle_option_line(\n    opts: Values,\n    filename: str,\n    lineno: int,\n    finder: Optional[\"PackageFinder\"] = None,\n    options: Optional[optparse.Values] = None,\n    session: Optional[\"PipSession\"] = None,\n) -> None:\n    if opts.hashes:\n        logger.warning(\n            \"%s line %s has --hash but no requirement, and will be ignored.\",\n            filename,\n            lineno,\n        )\n\n    if options:\n        # percolate options upward\n        if opts.require_hashes:\n            options.require_hashes = opts.require_hashes\n        if opts.features_enabled:\n            options.features_enabled.extend(\n                f for f in opts.features_enabled if f not in options.features_enabled\n            )\n\n    # set finder options\n    if finder:\n        find_links = finder.find_links\n        index_urls = finder.index_urls\n        no_index = finder.search_scope.no_index\n        if opts.no_index is True:\n            no_index = True\n            index_urls = []\n        if opts.index_url and not no_index:\n            index_urls = [opts.index_url]\n        if opts.extra_index_urls and not no_index:\n            index_urls.extend(opts.extra_index_urls)\n        if opts.find_links:\n            # FIXME: it would be nice to keep track of the source\n            # of the find_links: support a find-links local path\n            # relative to a requirements file.\n            value = opts.find_links[0]\n            req_dir = os.path.dirname(os.path.abspath(filename))\n            relative_to_reqs_file = os.path.join(req_dir, value)\n            if os.path.exists(relative_to_reqs_file):\n                value = relative_to_reqs_file\n            find_links.append(value)\n\n        if session:\n            # We need to update the auth urls in session\n            session.update_index_urls(index_urls)\n\n        search_scope = SearchScope(\n            find_links=find_links,\n            index_urls=index_urls,\n            no_index=no_index,\n        )\n        finder.search_scope = search_scope\n\n        if opts.pre:\n            finder.set_allow_all_prereleases()\n\n        if opts.prefer_binary:\n            finder.set_prefer_binary()\n\n        if session:\n            for host in opts.trusted_hosts or []:\n                source = f\"line {lineno} of {filename}\"\n                session.add_trusted_host(host, source=source)\n\n\ndef handle_line(\n    line: ParsedLine,\n    options: Optional[optparse.Values] = None,\n    finder: Optional[\"PackageFinder\"] = None,\n    session: Optional[\"PipSession\"] = None,\n) -> Optional[ParsedRequirement]:\n    \"\"\"Handle a single parsed requirements line; This can result in\n    creating/yielding requirements, or updating the finder.\n\n    :param line:        The parsed line to be processed.\n    :param options:     CLI options.\n    :param finder:      The finder - updated by non-requirement lines.\n    :param session:     The session - updated by non-requirement lines.\n\n    Returns a ParsedRequirement object if the line is a requirement line,\n    otherwise returns None.\n\n    For lines that contain requirements, the only options that have an effect\n    are from SUPPORTED_OPTIONS_REQ, and they are scoped to the\n    requirement. Other options from SUPPORTED_OPTIONS may be present, but are\n    ignored.\n\n    For lines that do not contain requirements, the only options that have an\n    effect are from SUPPORTED_OPTIONS. Options from SUPPORTED_OPTIONS_REQ may\n    be present, but are ignored. These lines may contain multiple options\n    (although our docs imply only one is supported), and all our parsed and\n    affect the finder.\n    \"\"\"\n\n    if line.requirement is not None:\n        parsed_req = handle_requirement_line(line, options)\n        return parsed_req\n    else:\n        handle_option_line(\n            line.opts,\n            line.filename,\n            line.lineno,\n            finder,\n            options,\n            session,\n        )\n        return None\n\n\nclass RequirementsFileParser:\n    def __init__(\n        self,\n        session: \"PipSession\",\n        line_parser: LineParser,\n    ) -> None:\n        self._session = session\n        self._line_parser = line_parser\n\n    def parse(\n        self, filename: str, constraint: bool\n    ) -> Generator[ParsedLine, None, None]:\n        \"\"\"Parse a given file, yielding parsed lines.\"\"\"\n        yield from self._parse_and_recurse(\n            filename, constraint, [{os.path.abspath(filename): None}]\n        )\n\n    def _parse_and_recurse(\n        self,\n        filename: str,\n        constraint: bool,\n        parsed_files_stack: List[Dict[str, Optional[str]]],\n    ) -> Generator[ParsedLine, None, None]:\n        for line in self._parse_file(filename, constraint):\n            if line.requirement is None and (\n                line.opts.requirements or line.opts.constraints\n            ):\n                # parse a nested requirements file\n                if line.opts.requirements:\n                    req_path = line.opts.requirements[0]\n                    nested_constraint = False\n                else:\n                    req_path = line.opts.constraints[0]\n                    nested_constraint = True\n\n                # original file is over http\n                if SCHEME_RE.search(filename):\n                    # do a url join so relative paths work\n                    req_path = urllib.parse.urljoin(filename, req_path)\n                # original file and nested file are paths\n                elif not SCHEME_RE.search(req_path):\n                    # do a join so relative paths work\n                    # and then abspath so that we can identify recursive references\n                    req_path = os.path.abspath(\n                        os.path.join(\n                            os.path.dirname(filename),\n                            req_path,\n                        )\n                    )\n                parsed_files = parsed_files_stack[0]\n                if req_path in parsed_files:\n                    initial_file = parsed_files[req_path]\n                    tail = (\n                        f\" and again in {initial_file}\"\n                        if initial_file is not None\n                        else \"\"\n                    )\n                    raise RequirementsFileParseError(\n                        f\"{req_path} recursively references itself in {filename}{tail}\"\n                    )\n                # Keeping a track where was each file first included in\n                new_parsed_files = parsed_files.copy()\n                new_parsed_files[req_path] = filename\n                yield from self._parse_and_recurse(\n                    req_path, nested_constraint, [new_parsed_files, *parsed_files_stack]\n                )\n            else:\n                yield line\n\n    def _parse_file(\n        self, filename: str, constraint: bool\n    ) -> Generator[ParsedLine, None, None]:\n        _, content = get_file_content(filename, self._session)\n\n        lines_enum = preprocess(content)\n\n        for line_number, line in lines_enum:\n            try:\n                args_str, opts = self._line_parser(line)\n            except OptionParsingError as e:\n                # add offending line\n                msg = f\"Invalid requirement: {line}\\n{e.msg}\"\n                raise RequirementsFileParseError(msg)\n\n            yield ParsedLine(\n                filename,\n                line_number,\n                args_str,\n                opts,\n                constraint,\n            )\n\n\ndef get_line_parser(finder: Optional[\"PackageFinder\"]) -> LineParser:\n    def parse_line(line: str) -> Tuple[str, Values]:\n        # Build new parser for each line since it accumulates appendable\n        # options.\n        parser = build_parser()\n        defaults = parser.get_default_values()\n        defaults.index_url = None\n        if finder:\n            defaults.format_control = finder.format_control\n\n        args_str, options_str = break_args_options(line)\n\n        try:\n            options = shlex.split(options_str)\n        except ValueError as e:\n            raise OptionParsingError(f\"Could not split options: {options_str}\") from e\n\n        opts, _ = parser.parse_args(options, defaults)\n\n        return args_str, opts\n\n    return parse_line\n\n\ndef break_args_options(line: str) -> Tuple[str, str]:\n    \"\"\"Break up the line into an args and options string.  We only want to shlex\n    (and then optparse) the options, not the args.  args can contain markers\n    which are corrupted by shlex.\n    \"\"\"\n    tokens = line.split(\" \")\n    args = []\n    options = tokens[:]\n    for token in tokens:\n        if token.startswith(\"-\") or token.startswith(\"--\"):\n            break\n        else:\n            args.append(token)\n            options.pop(0)\n    return \" \".join(args), \" \".join(options)\n\n\nclass OptionParsingError(Exception):\n    def __init__(self, msg: str) -> None:\n        self.msg = msg\n\n\ndef build_parser() -> optparse.OptionParser:\n    \"\"\"\n    Return a parser for parsing requirement lines\n    \"\"\"\n    parser = optparse.OptionParser(add_help_option=False)\n\n    option_factories = SUPPORTED_OPTIONS + SUPPORTED_OPTIONS_REQ\n    for option_factory in option_factories:\n        option = option_factory()\n        parser.add_option(option)\n\n    # By default optparse sys.exits on parsing errors. We want to wrap\n    # that in our own exception.\n    def parser_exit(self: Any, msg: str) -> \"NoReturn\":\n        raise OptionParsingError(msg)\n\n    # NOTE: mypy disallows assigning to a method\n    #       https://github.com/python/mypy/issues/2427\n    parser.exit = parser_exit  # type: ignore\n\n    return parser\n\n\ndef join_lines(lines_enum: ReqFileLines) -> ReqFileLines:\n    \"\"\"Joins a line ending in '\\' with the previous line (except when following\n    comments).  The joined line takes on the index of the first line.\n    \"\"\"\n    primary_line_number = None\n    new_line: List[str] = []\n    for line_number, line in lines_enum:\n        if not line.endswith(\"\\\\\") or COMMENT_RE.match(line):\n            if COMMENT_RE.match(line):\n                # this ensures comments are always matched later\n                line = \" \" + line\n            if new_line:\n                new_line.append(line)\n                assert primary_line_number is not None\n                yield primary_line_number, \"\".join(new_line)\n                new_line = []\n            else:\n                yield line_number, line\n        else:\n            if not new_line:\n                primary_line_number = line_number\n            new_line.append(line.strip(\"\\\\\"))\n\n    # last line contains \\\n    if new_line:\n        assert primary_line_number is not None\n        yield primary_line_number, \"\".join(new_line)\n\n    # TODO: handle space after '\\'.\n\n\ndef ignore_comments(lines_enum: ReqFileLines) -> ReqFileLines:\n    \"\"\"\n    Strips comments and filter empty lines.\n    \"\"\"\n    for line_number, line in lines_enum:\n        line = COMMENT_RE.sub(\"\", line)\n        line = line.strip()\n        if line:\n            yield line_number, line\n\n\ndef expand_env_variables(lines_enum: ReqFileLines) -> ReqFileLines:\n    \"\"\"Replace all environment variables that can be retrieved via `os.getenv`.\n\n    The only allowed format for environment variables defined in the\n    requirement file is `${MY_VARIABLE_1}` to ensure two things:\n\n    1. Strings that contain a `$` aren't accidentally (partially) expanded.\n    2. Ensure consistency across platforms for requirement files.\n\n    These points are the result of a discussion on the `github pull\n    request #3514 <https://github.com/pypa/pip/pull/3514>`_.\n\n    Valid characters in variable names follow the `POSIX standard\n    <http://pubs.opengroup.org/onlinepubs/9699919799/>`_ and are limited\n    to uppercase letter, digits and the `_` (underscore).\n    \"\"\"\n    for line_number, line in lines_enum:\n        for env_var, var_name in ENV_VAR_RE.findall(line):\n            value = os.getenv(var_name)\n            if not value:\n                continue\n\n            line = line.replace(env_var, value)\n\n        yield line_number, line\n\n\ndef get_file_content(url: str, session: \"PipSession\") -> Tuple[str, str]:\n    \"\"\"Gets the content of a file; it may be a filename, file: URL, or\n    http: URL.  Returns (location, content).  Content is unicode.\n    Respects # -*- coding: declarations on the retrieved files.\n\n    :param url:         File path or url.\n    :param session:     PipSession instance.\n    \"\"\"\n    scheme = urllib.parse.urlsplit(url).scheme\n    # Pip has special support for file:// URLs (LocalFSAdapter).\n    if scheme in [\"http\", \"https\", \"file\"]:\n        # Delay importing heavy network modules until absolutely necessary.\n        from pip._internal.network.utils import raise_for_status\n\n        resp = session.get(url)\n        raise_for_status(resp)\n        return resp.url, resp.text\n\n    # Assume this is a bare path.\n    try:\n        with open(url, \"rb\") as f:\n            raw_content = f.read()\n    except OSError as exc:\n        raise InstallationError(f\"Could not open requirements file: {exc}\")\n\n    content = _decode_req_file(raw_content, url)\n\n    return url, content\n\n\ndef _decode_req_file(data: bytes, url: str) -> str:\n    for bom, encoding in BOMS:\n        if data.startswith(bom):\n            return data[len(bom) :].decode(encoding)\n\n    for line in data.split(b\"\\n\")[:2]:\n        if line[0:1] == b\"#\":\n            result = PEP263_ENCODING_RE.search(line)\n            if result is not None:\n                encoding = result.groups()[0].decode(\"ascii\")\n                return data.decode(encoding)\n\n    try:\n        return data.decode(DEFAULT_ENCODING)\n    except UnicodeDecodeError:\n        locale_encoding = locale.getpreferredencoding(False) or sys.getdefaultencoding()\n        logging.warning(\n            \"unable to decode data from %s with default encoding %s, \"\n            \"falling back to encoding from locale: %s. \"\n            \"If this is intentional you should specify the encoding with a \"\n            \"PEP-263 style comment, e.g. '# -*- coding: %s -*-'\",\n            url,\n            DEFAULT_ENCODING,\n            locale_encoding,\n            locale_encoding,\n        )\n        return data.decode(locale_encoding)\n",
  "metadata": {},
  "relative_path": "venv_new\\Lib\\site-packages\\pip\\_internal\\req\\req_file.py",
  "id": "e5df27690768498792fbb6a9216d938c"
}