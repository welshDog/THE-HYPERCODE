{
  "file_name": "visual_syntax_parser.py",
  "file_path": "C:\\Users\\lyndz\\Downloads\\hypercode PROJECT\\hypercode\\hypercode\\src\\parser\\visual_syntax_parser.py",
  "file_size": 15981,
  "created": "2025-11-26T23:37:35.659180",
  "modified": "2025-11-26T23:37:35.659180",
  "file_type": "code",
  "content_hash": "5cea99c11017434d3bd28f9dc1855ca7",
  "content_type": "text",
  "content": "#!/usr/bin/env python3\n\"\"\"\nğŸ¨ Visual Syntax Parser for HyperCode V3\nThe first \"click moment\" for neurodivergent developers\n\nThis parser transforms emoji-based semantic markers into executable code\nwhile maintaining the visual clarity that makes neurodivergent developers\nthink \"Finally, a language that gets me!\"\n\"\"\"\n\nimport re\nfrom dataclasses import dataclass\nfrom enum import Enum\nfrom pathlib import Path\nfrom typing import Any, Dict, List\n\n\nclass SemanticMarker(Enum):\n    \"\"\"ğŸ¨ Semantic marker types with emoji representations\"\"\"\n\n    VERIFIABLE = \"ğŸ”\"  # Formal verification\n    ENSURES = \"ğŸ“\"  # Postconditions\n    REQUIRES = \"ğŸ“‹\"  # Preconditions\n    INTENT = \"ğŸ§ \"  # Function intent\n    ACCESSIBILITY = \"ğŸ¯\"  # Accessibility features\n    COMPUTATION = \"ğŸ¨\"  # Computation operations\n    OPERATION = \"âš¡\"  # Fast operations\n    RETURN = \"ğŸ”„\"  # Return values\n    DISTRIBUTED = \"ğŸ–¥ï¸\"  # Hardware placement\n    PROBABILISTIC = \"ğŸ“Š\"  # Uncertainty/Probability\n    DIFFERENTIABLE = \"ğŸ²\"  # Gradients/Differentiable\n    EVOLVABLE = \"ğŸ§¬\"  # Code evolution\n    UNIVERSAL = \"â™¿\"  # Universal accessibility\n\n\n@dataclass\nclass SemanticAnnotation:\n    \"\"\"ğŸ“‹ A single semantic annotation with its metadata\"\"\"\n\n    marker: SemanticMarker\n    params: Dict[str, Any]\n    line_number: int\n    column_number: int\n    raw_text: str\n\n    def __str__(self) -> str:\n        return f\"{self.marker.value} {self.raw_text}\"\n\n\n@dataclass\nclass ParsedFunction:\n    \"\"\"ğŸ” A fully parsed HyperCode function\"\"\"\n\n    name: str\n    annotations: List[SemanticAnnotation]\n    parameters: List[str]\n    return_type: str\n    body_lines: List[str]\n    line_start: int\n    line_end: int\n\n    def get_annotations_by_type(\n        self, marker_type: SemanticMarker\n    ) -> List[SemanticAnnotation]:\n        \"\"\"Get all annotations of a specific type\"\"\"\n        return [ann for ann in self.annotations if ann.marker == marker_type]\n\n\nclass VisualSyntaxParser:\n    \"\"\"ğŸ¨ Main parser for HyperCode's visual semantic syntax\"\"\"\n\n    def __init__(self) -> None:\n        self.semantic_patterns = self._build_semantic_patterns()\n        self.color_scheme = self._build_color_scheme()\n\n    def _build_semantic_patterns(self) -> Dict[str, Dict[str, Any]]:\n        \"\"\"ğŸ” Build regex patterns for all semantic markers\"\"\"\n        patterns = {}\n\n        # Map semantic markers to their annotation keywords\n        annotation_map = {\n            \"ğŸ”\": \"verifiable\",\n            \"ğŸ“\": \"ensures\",\n            \"ğŸ“‹\": \"requires\",\n            \"ğŸ§ \": \"intent\",\n            \"ğŸ¯\": \"accessibility\",\n            \"ğŸ¨\": \"computation\",\n            \"âš¡\": \"operation\",\n            \"ğŸ”„\": \"return\",\n            \"ğŸ–¥ï¸\": \"distributed\",\n            \"ğŸ“Š\": \"probabilistic\",\n            \"ğŸ²\": \"differentiable\",\n            \"ğŸ§¬\": \"evolvable\",\n            \"â™¿\": \"universal\",\n        }\n\n        for emoji, keyword in annotation_map.items():\n            # Match: emoji @keyword(\"param\") - the emoji is the marker,\n            # @keyword is the syntax\n            pattern = rf\"{emoji}\\s*@{keyword}\\s*\\((.*?)\\)\"\n            marker = next(m for m in SemanticMarker if m.value == emoji)\n            patterns[emoji] = {\"regex\": re.compile(pattern), \"marker\": marker}\n        return patterns\n\n    def _build_color_scheme(self) -> Dict[str, str]:\n        \"\"\"ğŸ¨ Build semantic color mapping for IDE highlighting\"\"\"\n        return {\n            \"ğŸ”\": \"#FF6B6B\",  # Verification - Red (attention)\n            \"ğŸ“\": \"#4ECDC4\",  # Ensures - Teal (calm, trustworthy)\n            \"ğŸ“‹\": \"#45B7D1\",  # Requires - Blue (informational)\n            \"ğŸ§ \": \"#96CEB4\",  # Intent - Green (growth, ideas)\n            \"ğŸ¯\": \"#FFEAA7\",  # Accessibility - Yellow (warm, inclusive)\n            \"ğŸ¨\": \"#DDA0DD\",  # Computation - Purple (creative)\n            \"âš¡\": \"#FFA500\",  # Operation - Orange (energy)\n            \"ğŸ”„\": \"#98D8C8\",  # Return - Mint (completion)\n            \"ğŸ–¥ï¸\": \"#74B9FF\",  # Hardware - Sky blue (tech)\n            \"ğŸ“Š\": \"#A29BFE\",  # Probabilistic - Lavender (uncertainty)\n            \"ğŸ²\": \"#FD79A8\",  # Differentiable - Pink (gradients)\n            \"ğŸ§¬\": \"#6C5CE7\",  # Evolvable - Violet (growth)\n            \"â™¿\": \"#00B894\",  # Universal - Emerald (accessibility)\n        }\n\n    def parse_file(self, file_path: str) -> List[ParsedFunction]:\n        \"\"\"ğŸ“„ Parse an entire HyperCode file\"\"\"\n        with Path(file_path).open(\"r\", encoding=\"utf-8\") as f:\n            content = f.read()\n\n        return self.parse_content(content)\n\n    def parse_content(self, content: str) -> List[ParsedFunction]:\n        \"\"\"ğŸ“ Parse HyperCode content string\"\"\"\n        lines = content.split(\"\\n\")\n        functions = []\n        current_function = None\n        pending_annotations: List[SemanticAnnotation] = []  # Store annotations\n\n        for line_num, line in enumerate(lines, 1):\n            line = line.strip()\n\n            # Parse semantic annotations on any line\n            annotations = self._parse_line_annotations(line, line_num)\n\n            # Check for function definition\n            if self._is_function_definition(line):\n                if current_function:\n                    functions.append(current_function)\n                current_function = self._start_new_function(line, line_num)\n                # Add pending annotations (found before function definition)\n                current_function.annotations.extend(pending_annotations)\n                # Add annotations found on the same line as function definition\n                current_function.annotations.extend(annotations)\n                pending_annotations = []  # Clear pending annotations\n            elif annotations and not current_function:\n                # Store annotations found before function definition\n                pending_annotations.extend(annotations)\n            elif annotations and current_function:\n                # Add annotations found after function definition\n                # (shouldn't happen in normal syntax)\n                current_function.annotations.extend(annotations)\n\n            # Add function body lines\n            if current_function and not self._is_function_definition(line):\n                current_function.body_lines.append(line)\n\n        if current_function:\n            functions.append(current_function)\n\n        return functions\n\n    def _is_function_definition(self, line: str) -> bool:\n        \"\"\"ğŸ” Check if line is a function definition\"\"\"\n        stripped = line.strip()\n        return (\n            stripped.startswith(\"function \")\n            or stripped.startswith(\"def \")\n            or \"function \" in stripped\n        )\n\n    def _start_new_function(self, line: str, line_num: int) -> ParsedFunction:\n        \"\"\"ğŸ†• Create new ParsedFunction from definition line\"\"\"\n        # Extract function name\n        name_match = re.search(r\"(?:function|def)\\s+(\\w+)\", line)\n        name = name_match.group(1) if name_match else \"unnamed\"\n\n        # Extract parameters and return type\n        params_match = re.search(r\"\\((.*?)\\)\", line)\n        params = params_match.group(1).split(\",\") if params_match else []\n        params = [p.strip() for p in params if p.strip()]\n\n        return_type = \"void\"  # Default, can be enhanced later\n\n        return ParsedFunction(\n            name=name,\n            annotations=[],\n            parameters=params,\n            return_type=return_type,\n            body_lines=[line],\n            line_start=line_num,\n            line_end=line_num,\n        )\n\n    def _parse_line_annotations(\n        self, line: str, line_num: int\n    ) -> List[SemanticAnnotation]:\n        \"\"\"ï¿½ Parse semantic annotations from a line\"\"\"\n        annotations = []\n\n        for _emoji, pattern_info in self.semantic_patterns.items():\n            matches = pattern_info[\"regex\"].findall(line)\n            for params_str in matches:\n                params = self._parse_annotation_params(params_str)\n                annotation = SemanticAnnotation(\n                    marker=pattern_info[\"marker\"],\n                    params=params,\n                    line_number=line_num,\n                    column_number=0,\n                    raw_text=line,\n                )\n                annotations.append(annotation)\n\n        return annotations\n\n    def _parse_annotation_params(self, params_str: str) -> Dict[str, Any]:\n        \"\"\"ğŸ”§ Parse annotation parameters from string\"\"\"\n        params = {}\n        params_str = params_str.strip()\n\n        # Handle empty parameters\n        if not params_str:\n            return {}\n\n        # Handle simple string parameters: @emoji(\"text\")\n        if params_str.startswith('\"') and params_str.endswith('\"'):\n            return {\"text\": params_str[1:-1]}\n\n        # Handle single word without quotes: @emoji(formal_proof)\n        if (\n            not params_str.startswith('\"')\n            and not params_str.endswith('\"')\n            and \"=\" not in params_str\n            and \",\" not in params_str\n        ):\n            return {\"text\": params_str}\n\n        # Handle key=value parameters: @emoji(key=value, other=\"text\")\n        parts = [part.strip() for part in params_str.split(\",\")]\n        for part in parts:\n            if \"=\" in part:\n                key, value = part.split(\"=\", 1)\n                key = key.strip()\n                value = value.strip()\n                # Remove quotes if present\n                if value.startswith('\"') and value.endswith('\"'):\n                    value = value[1:-1]\n                params[key] = value\n            else:\n                # Positional parameter\n                if part.startswith('\"') and part.endswith('\"'):\n                    params[f\"param_{len(params)}\"] = part[1:-1]\n                else:\n                    params[f\"param_{len(params)}\"] = part\n\n        return params\n\n    def generate_syntax_highlighting(self, content: str) -> str:\n        \"\"\"ğŸ¨ Generate HTML with syntax highlighting for visual markers\"\"\"\n        highlighted = content\n\n        # Apply semantic coloring\n        for emoji, color in self.color_scheme.items():\n            pattern = rf\"(@{emoji}\\([^)]*\\))\"\n            replacement = f'<span style=\"color: {color}; font-weight: bold;\">\\\\1</span>'\n            highlighted = re.sub(pattern, replacement, highlighted)\n\n        return highlighted\n\n    def extract_semantic_summary(\n        self, functions: List[ParsedFunction]\n    ) -> Dict[str, Any]:\n        \"\"\"ğŸ“Š Extract semantic summary for analysis\"\"\"\n        summary: Dict[str, Any] = {\n            \"total_functions\": len(functions),\n            \"marker_counts\": {},\n            \"accessibility_features\": [],\n            \"verification_level\": \"none\",\n            \"cognitive_load_score\": 0,\n        }\n\n        # Count markers\n        for marker in SemanticMarker:\n            summary[\"marker_counts\"][marker.value] = 0\n\n        for func in functions:\n            for annotation in func.annotations:\n                summary[\"marker_counts\"][annotation.marker.value] += 1\n\n                # Track accessibility features\n                if annotation.marker == SemanticMarker.ACCESSIBILITY:\n                    summary[\"accessibility_features\"].append(annotation.params)\n\n                # Check verification level\n                if annotation.marker == SemanticMarker.VERIFIABLE:\n                    summary[\"verification_level\"] = \"formal\"\n\n        # Calculate cognitive load score (lower is better)\n        total_annotations = sum(summary[\"marker_counts\"].values())\n        summary[\"cognitive_load_score\"] = total_annotations / max(len(functions), 1)\n\n        return summary\n\n    def validate_neurodiversity_compliance(\n        self, functions: List[ParsedFunction]\n    ) -> Dict[str, Any]:\n        \"\"\"ğŸ§  Validate neurodiversity-first design principles\"\"\"\n        compliance: Dict[str, Any] = {\n            \"score\": 0,\n            \"issues\": [],\n            \"recommendations\": [],\n            \"accessibility_coverage\": 0,\n        }\n\n        total_checks = 0\n        passed_checks = 0\n\n        for func in functions:\n            # Check 1: Has accessibility annotations\n            total_checks += 1\n            accessibility_annotations = func.get_annotations_by_type(\n                SemanticMarker.ACCESSIBILITY\n            )\n            if accessibility_annotations:\n                passed_checks += 1\n            else:\n                compliance[\"issues\"].append(\n                    f\"Function '{func.name}' lacks accessibility annotations\"\n                )\n                compliance[\"recommendations\"].append(\n                    f\"Add @ğŸ¯ annotations to '{func.name}'\"\n                )\n\n            # Check 2: Has intent annotations (reduces cognitive load)\n            total_checks += 1\n            intent_annotations = func.get_annotations_by_type(SemanticMarker.INTENT)\n            if intent_annotations:\n                passed_checks += 1\n            else:\n                compliance[\"issues\"].append(\n                    f\"Function '{func.name}' lacks intent annotations\"\n                )\n                compliance[\"recommendations\"].append(\n                    f\"Add @ğŸ§  intent annotation to '{func.name}'\"\n                )\n\n            # Check 3: Not too many annotations (cognitive overload)\n            total_checks += 1\n            if len(func.annotations) <= 5:  # Reasonable limit\n                passed_checks += 1\n            else:\n                compliance[\"issues\"].append(\n                    f\"Function '{func.name}' has too many annotations \"\n                    f\"({len(func.annotations)})\"\n                )\n                compliance[\"recommendations\"].append(\n                    f\"Consider reducing annotations in '{func.name}'\"\n                )\n\n        compliance[\"score\"] = (\n            (passed_checks / total_checks) * 100 if total_checks > 0 else 0\n        )\n        compliance[\"accessibility_coverage\"] = (\n            passed_checks / total_checks if total_checks > 0 else 0\n        )\n\n        return compliance\n\n\n# ğŸš€ Example usage and testing\nif __name__ == \"__main__\":\n    # Example HyperCode code\n    example_code = \"\"\"\nğŸ” @verifiable(\"formal_proof\")\nğŸ“ @ensures(\"output.shape == (batch, classes)\")\nğŸ“‹ @requires(\"input.shape[1] == features\")\nğŸ§  @intent(\"Classify input features\")\nğŸ¯ @accessibility(\"high_contrast\", \"dyslexia_font\")\nfunction classifier(input: Tensor[batch, features]) -> Tensor[batch, classes] {\n    ğŸ¨ weights = initialize(features, classes)\n    âš¡ logits = matmul(input, weights)\n    ğŸ”„ return softmax(logits)\n}\n\"\"\"\n\n    parser = VisualSyntaxParser()\n    functions = parser.parse_content(example_code)\n\n    print(\"ğŸ¨ Visual Syntax Parser Results:\")\n    print(f\"Found {len(functions)} functions\")\n\n    for func in functions:\n        print(f\"\\nğŸ” Function: {func.name}\")\n        print(f\"ğŸ“‹ Annotations: {len(func.annotations)}\")\n        for annotation in func.annotations:\n            print(f\"  {annotation}\")\n\n    # Generate summary\n    summary = parser.extract_semantic_summary(functions)\n    print(\"\\nğŸ“Š Semantic Summary:\")\n    print(f\"Total functions: {summary['total_functions']}\")\n    print(f\"Cognitive load score: {summary['cognitive_load_score']:.2f}\")\n\n    # Validate neurodiversity compliance\n    compliance = parser.validate_neurodiversity_compliance(functions)\n    print(f\"\\nğŸ§  Neurodiversity Compliance: {compliance['score']:.1f}%\")\n    if compliance[\"issues\"]:\n        print(\"âš ï¸  Issues:\")\n        for issue in compliance[\"issues\"]:\n            print(f\"  - {issue}\")\n\n    print(\"\\nâœ¨ First 'click moment' ready! ğŸ¯\")\n",
  "metadata": {},
  "relative_path": "hypercode\\src\\parser\\visual_syntax_parser.py",
  "id": "5b4e7c9486c35940ac5fbd67bfe4612e"
}