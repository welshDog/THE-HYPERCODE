# HYPER DATABASE
## Living Inventory of HyperCode Codebase

**Generated**: 2025-12-05T01:43:01.772235
**Scan Time**: 16.5s
**Files Scanned**: 967
**Total Entities**: 9657

---

## HEALTH SNAPSHOT

| Metric | Value |
|--------|-------|
| **Functions** | 8290 |
| **Classes** | 1367 |
| **Files** | 967 |
| **Documentation** | 4794/9657 (49.6%) |
| **Status** | OK |

---

## ALL FUNCTIONS

### 5 Core TypeScript Modules\code-analyzer.ts

#### `unnamed_function()` (line 56)

#### `unnamed_function()` (line 102)

#### `unnamed_function()` (line 103)

#### `unnamed_function()` (line 118)

#### `unnamed_function()` (line 164)

#### `unnamed_function()` (line 165)

#### `unnamed_function()` (line 180)

### 5 Core TypeScript Modules\extension.ts

#### `unnamed_function()` (line 19)

#### `unnamed_function()` (line 52)

#### `unnamed_function()` (line 59)

### 5 Core TypeScript Modules\spatial-visualizer.ts

#### `unnamed_function()` (line 77)

#### `unnamed_function()` (line 80)

#### `unnamed_function()` (line 141)

#### `unnamed_function()` (line 161)

#### `unnamed_function()` (line 162)

#### `unnamed_function()` (line 174)

#### `unnamed_function()` (line 176)

#### `unnamed_function()` (line 177)

#### `unnamed_function()` (line 187)

#### `unnamed_function()` (line 191)

#### `unnamed_function()` (line 195)

#### `unnamed_function()` (line 228)

#### `unnamed_function()` (line 263)

#### `unnamed_function()` (line 282)

### 5 Core TypeScript Modules\visualization-panel.ts

#### `unnamed_function()` (line 237)

#### `unnamed_function()` (line 254)

#### `unnamed_function()` (line 265)

#### `unnamed_function()` (line 269)

#### `unnamed_function()` (line 273)

### HyperCode showcase\src\__tests__\hypercode.test.ts

#### `unnamed_function()` (line 4)

#### `unnamed_function()` (line 7)

#### `unnamed_function()` (line 11)

#### `unnamed_function()` (line 17)

#### `unnamed_function()` (line 23)

#### `unnamed_function()` (line 29)

#### `unnamed_function()` (line 31)

### HyperCode showcase\src\index.ts

#### `unnamed_function()` (line 13)

#### `unnamed_function()` (line 29)

#### `unnamed_function()` (line 32)

#### `unnamed_function()` (line 33)

#### `unnamed_function()` (line 48)

#### `unnamed_function()` (line 84)

### benchmarks\__init__.py

#### `benchmark_lexer()` (line 12)
_Benchmark the lexer with the given source code._

**Args**: source, iterations


#### `print_benchmark_results()` (line 36)
_Print benchmark results in a readable format._

**Args**: results


### benchmarks\benchmarks_lexer.py

#### `benchmark_lexer()` (line 6)
_Benchmark the lexer with the given source code._

**Args**: source, iterations


#### `print_benchmark_results()` (line 30)
_Print benchmark results in a readable format._

**Args**: results


### code_insights.py

#### `analyze_code_patterns()` (line 8)
_Analyze function and class naming patterns._

**Args**: db


#### `find_undocumented_code()` (line 29)
_Find complex but undocumented code._

**Args**: db


#### `analyze_test_coverage()` (line 45)
_Analyze test coverage patterns.

Returns:
    Dictionary containing test coverage statistics_

**Args**: db


### code_quality_report.py

#### `get_undocumented_classes_priority()` (line 15)
_Get undocumented classes sorted by importance (more methods = higher priority)._

**Args**: db


#### `get_least_tested_files()` (line 33)
_Get files with most code but least test coverage.

Returns:
    List of dictionaries containing file test metrics, sorted by test ratio_

**Args**: db


#### `find_getter_methods()` (line 69)
_Find get_ methods that could be converted to properties.

Returns:
    List of dictionaries containing information about potential getter methods
    that could be converted to properties._

**Args**: db


#### `generate_code_quality_report()` (line 103)
_Generate a comprehensive code quality report._

**Args**: db_path


### htmlcov\coverage_html_cb_437fc316.js

#### `unnamed_function()` (line 11)

#### `unnamed_function()` (line 15)

#### `unnamed_function()` (line 21)

#### `unnamed_function()` (line 28)

#### `unnamed_function()` (line 36)

#### `unnamed_function()` (line 50)

#### `unnamed_function()` (line 59)

#### `unnamed_function()` (line 63)

#### `unnamed_function()` (line 80)

#### `unnamed_function()` (line 81)

#### `unnamed_function()` (line 114)

#### `unnamed_function()` (line 115)

#### `unnamed_function()` (line 144)

#### `unnamed_function()` (line 159)

#### `unnamed_function()` (line 263)

#### `unnamed_function()` (line 365)

#### `unnamed_function()` (line 389)

#### `unnamed_function()` (line 393)

#### `unnamed_function()` (line 619)

#### `unnamed_function()` (line 664)

#### `unnamed_function()` (line 697)

#### `unnamed_function()` (line 726)

### hypercode-proto\app.js

#### `unnamed_function()` (line 70)

#### `unnamed_function()` (line 85)

#### `unnamed_function()` (line 89)

#### `unnamed_function()` (line 92)

#### `unnamed_function()` (line 95)

#### `unnamed_function()` (line 101)

#### `unnamed_function()` (line 104)

#### `unnamed_function()` (line 109)

#### `unnamed_function()` (line 120)

#### `unnamed_function()` (line 121)

#### `unnamed_function()` (line 134)

#### `unnamed_function()` (line 145)

#### `unnamed_function()` (line 161)

#### `unnamed_function()` (line 166)

#### `unnamed_function()` (line 173)

#### `unnamed_function()` (line 187)

#### `unnamed_function()` (line 188)

#### `unnamed_function()` (line 195)

#### `unnamed_function()` (line 203)

#### `unnamed_function()` (line 214)

#### `unnamed_function()` (line 221)

#### `unnamed_function()` (line 242)

#### `unnamed_function()` (line 258)

#### `unnamed_function()` (line 260)

#### `unnamed_function()` (line 262)

#### `unnamed_function()` (line 270)

#### `unnamed_function()` (line 298)

#### `unnamed_function()` (line 304)

#### `unnamed_function()` (line 305)

#### `unnamed_function()` (line 314)

#### `unnamed_function()` (line 316)

#### `unnamed_function()` (line 322)

#### `unnamed_function()` (line 323)

#### `unnamed_function()` (line 325)

#### `unnamed_function()` (line 333)

#### `unnamed_function()` (line 344)

#### `unnamed_function()` (line 345)

#### `unnamed_function()` (line 352)

#### `unnamed_function()` (line 356)

#### `unnamed_function()` (line 384)

#### `unnamed_function()` (line 389)

#### `unnamed_function()` (line 403)

#### `unnamed_function()` (line 419)

#### `unnamed_function()` (line 429)

#### `unnamed_function()` (line 438)

#### `unnamed_function()` (line 439)

#### `unnamed_function()` (line 449)

#### `unnamed_function()` (line 450)

#### `unnamed_function()` (line 451)

#### `unnamed_function()` (line 462)

#### `unnamed_function()` (line 467)

#### `unnamed_function()` (line 472)

#### `unnamed_function()` (line 477)

#### `unnamed_function()` (line 481)

#### `unnamed_function()` (line 487)

#### `unnamed_function()` (line 495)

#### `unnamed_function()` (line 501)

#### `unnamed_function()` (line 502)

#### `unnamed_function()` (line 503)

#### `unnamed_function()` (line 517)

#### `unnamed_function()` (line 528)

#### `unnamed_function()` (line 532)

#### `unnamed_function()` (line 561)

#### `unnamed_function()` (line 562)

#### `unnamed_function()` (line 570)

#### `unnamed_function()` (line 592)

#### `unnamed_function()` (line 593)

#### `unnamed_function()` (line 600)

#### `unnamed_function()` (line 604)

#### `unnamed_function()` (line 610)

#### `unnamed_function()` (line 670)

#### `unnamed_function()` (line 681)

#### `unnamed_function()` (line 691)

#### `unnamed_function()` (line 696)

#### `unnamed_function()` (line 704)

#### `unnamed_function()` (line 714)

#### `unnamed_function()` (line 722)

#### `unnamed_function()` (line 761)

#### `unnamed_function()` (line 766)

### hypercode\5 Core TypeScript Modules\code-analyzer.ts

#### `unnamed_function()` (line 56)

#### `unnamed_function()` (line 102)

#### `unnamed_function()` (line 103)

#### `unnamed_function()` (line 118)

#### `unnamed_function()` (line 164)

#### `unnamed_function()` (line 165)

#### `unnamed_function()` (line 180)

### hypercode\5 Core TypeScript Modules\extension.ts

#### `unnamed_function()` (line 19)

#### `unnamed_function()` (line 52)

#### `unnamed_function()` (line 59)

### hypercode\5 Core TypeScript Modules\spatial-visualizer.ts

#### `unnamed_function()` (line 77)

#### `unnamed_function()` (line 80)

#### `unnamed_function()` (line 141)

#### `unnamed_function()` (line 161)

#### `unnamed_function()` (line 162)

#### `unnamed_function()` (line 174)

#### `unnamed_function()` (line 176)

#### `unnamed_function()` (line 177)

#### `unnamed_function()` (line 187)

#### `unnamed_function()` (line 191)

#### `unnamed_function()` (line 195)

#### `unnamed_function()` (line 228)

#### `unnamed_function()` (line 263)

#### `unnamed_function()` (line 282)

### hypercode\5 Core TypeScript Modules\visualization-panel.ts

#### `unnamed_function()` (line 237)

#### `unnamed_function()` (line 254)

#### `unnamed_function()` (line 265)

#### `unnamed_function()` (line 269)

#### `unnamed_function()` (line 273)

### hypercode\HyperCode showcase\src\__tests__\hypercode.test.ts

#### `unnamed_function()` (line 4)

#### `unnamed_function()` (line 7)

#### `unnamed_function()` (line 11)

#### `unnamed_function()` (line 17)

#### `unnamed_function()` (line 23)

#### `unnamed_function()` (line 29)

#### `unnamed_function()` (line 31)

### hypercode\HyperCode showcase\src\index.ts

#### `unnamed_function()` (line 13)

#### `unnamed_function()` (line 29)

#### `unnamed_function()` (line 32)

#### `unnamed_function()` (line 33)

#### `unnamed_function()` (line 48)

#### `unnamed_function()` (line 84)

### hypercode\benchmarks\__init__.py

#### `benchmark_lexer()` (line 13)
_Benchmark the lexer with the given source code._

**Args**: source, iterations


#### `print_benchmark_results()` (line 38)
_Print benchmark results in a readable format._

**Args**: results


### hypercode\benchmarks\benchmarks_lexer.py

#### `benchmark_lexer()` (line 7)
_Benchmark the lexer with the given source code._

**Args**: source, iterations


#### `print_benchmark_results()` (line 32)
_Print benchmark results in a readable format._

**Args**: results


### hypercode\build-hyper-database.py

#### `__init__()` (line 24)
_Initialize builder with repo root path._

**Args**: self, repo_root


#### `scan_python_file()` (line 32)
_Extract functions, classes from Python file._

**Args**: self, file_path


#### `scan_javascript_file()` (line 78)
_Extract functions from JavaScript (regex-based)._

**Args**: self, file_path


#### `should_skip_directory()` (line 107)
_Check if directory should be skipped._

**Args**: dirname


#### `build()` (line 127)
_Scan entire repo and build database._

**Args**: self


#### `generate_markdown_report()` (line 161)
_Generate HYPER_DATABASE.md report._

**Args**: self


#### `generate_json_report()` (line 248)
_Generate machine-readable HYPER_DATABASE.json._

**Args**: self


#### `main()` (line 263)
_Main entry point._


### hypercode\hypercode-proto\app.js

#### `unnamed_function()` (line 70)

#### `unnamed_function()` (line 85)

#### `unnamed_function()` (line 89)

#### `unnamed_function()` (line 92)

#### `unnamed_function()` (line 95)

#### `unnamed_function()` (line 101)

#### `unnamed_function()` (line 104)

#### `unnamed_function()` (line 109)

#### `unnamed_function()` (line 120)

#### `unnamed_function()` (line 121)

#### `unnamed_function()` (line 134)

#### `unnamed_function()` (line 145)

#### `unnamed_function()` (line 161)

#### `unnamed_function()` (line 166)

#### `unnamed_function()` (line 173)

#### `unnamed_function()` (line 187)

#### `unnamed_function()` (line 188)

#### `unnamed_function()` (line 195)

#### `unnamed_function()` (line 203)

#### `unnamed_function()` (line 214)

#### `unnamed_function()` (line 221)

#### `unnamed_function()` (line 242)

#### `unnamed_function()` (line 258)

#### `unnamed_function()` (line 260)

#### `unnamed_function()` (line 262)

#### `unnamed_function()` (line 270)

#### `unnamed_function()` (line 298)

#### `unnamed_function()` (line 304)

#### `unnamed_function()` (line 305)

#### `unnamed_function()` (line 314)

#### `unnamed_function()` (line 316)

#### `unnamed_function()` (line 322)

#### `unnamed_function()` (line 323)

#### `unnamed_function()` (line 325)

#### `unnamed_function()` (line 333)

#### `unnamed_function()` (line 344)

#### `unnamed_function()` (line 345)

#### `unnamed_function()` (line 352)

#### `unnamed_function()` (line 356)

#### `unnamed_function()` (line 384)

#### `unnamed_function()` (line 389)

#### `unnamed_function()` (line 403)

#### `unnamed_function()` (line 419)

#### `unnamed_function()` (line 429)

#### `unnamed_function()` (line 438)

#### `unnamed_function()` (line 439)

#### `unnamed_function()` (line 449)

#### `unnamed_function()` (line 450)

#### `unnamed_function()` (line 451)

#### `unnamed_function()` (line 462)

#### `unnamed_function()` (line 467)

#### `unnamed_function()` (line 472)

#### `unnamed_function()` (line 477)

#### `unnamed_function()` (line 481)

#### `unnamed_function()` (line 487)

#### `unnamed_function()` (line 495)

#### `unnamed_function()` (line 501)

#### `unnamed_function()` (line 502)

#### `unnamed_function()` (line 503)

#### `unnamed_function()` (line 517)

#### `unnamed_function()` (line 528)

#### `unnamed_function()` (line 532)

#### `unnamed_function()` (line 561)

#### `unnamed_function()` (line 562)

#### `unnamed_function()` (line 570)

#### `unnamed_function()` (line 592)

#### `unnamed_function()` (line 593)

#### `unnamed_function()` (line 600)

#### `unnamed_function()` (line 604)

#### `unnamed_function()` (line 610)

#### `unnamed_function()` (line 670)

#### `unnamed_function()` (line 681)

#### `unnamed_function()` (line 691)

#### `unnamed_function()` (line 696)

#### `unnamed_function()` (line 704)

#### `unnamed_function()` (line 714)

#### `unnamed_function()` (line 722)

#### `unnamed_function()` (line 761)

#### `unnamed_function()` (line 766)

### hypercode\mcp\servers\aws_cli.py

#### `main()` (line 4)

### hypercode\mcp\servers\aws_resource_manager.py

#### `main()` (line 4)

### hypercode\mcp\servers\code_analysis.py

#### `main()` (line 4)

### hypercode\mcp\servers\dataset_downloader.py

#### `main()` (line 4)

### hypercode\mcp\servers\file_system.py

#### `main()` (line 4)

### hypercode\mcp\servers\human_input.py

#### `main()` (line 4)

### hypercode\mcp\servers\hypercode_syntax.py

#### `__init__()` (line 31)
**Args**: self


#### `_initialize()` (line 56)
_Initialize the MCP server_

**Args**: self, _params


#### `_generate_diagnostics()` (line 216)
_Generate IDE diagnostics from parsed functions_

**Args**: self, functions


#### `_get_annotation_hover_info()` (line 266)
_Generate hover information for semantic annotations_

**Args**: self, annotation


### hypercode\mcp\servers\path_service.py

#### `main()` (line 4)

### hypercode\mcp\servers\user_profile_manager.py

#### `main()` (line 4)

### hypercode\mcp\servers\valkey_service.py

#### `main()` (line 144)
_Main function to run the Valkey Service MCP Server.
This function is called when the script is executed directly.
It starts the Uvicorn server, which in turn runs the FastAPI application._


### hypercode\mcp\servers\web_search.py

#### `main()` (line 4)

### hypercode\mcp\setup.py

#### `install_dependencies()` (line 16)
_Install required dependencies_


#### `verify_setup()` (line 31)
_Verify that MCP is properly set up_


#### `show_next_steps()` (line 54)
_Show next steps for using MCP_


#### `main()` (line 72)

### hypercode\mcp\start_servers.py

#### `start_server()` (line 34)
_Start a specific MCP server_

**Args**: server_name


#### `list_servers()` (line 59)
_List all available servers_


#### `main()` (line 66)

### hypercode\mcp\test_mcp.py

#### `test_server_imports()` (line 15)
_Test that all servers can be imported_


#### `main()` (line 47)

### hypercode\new files to check\backend\research\db.py

#### `_get_database_url()` (line 35)
_Return the database URL to connect to.

Checks the ``RESEARCH_DATABASE_URL`` environment variable first.  If
it isn't defined then falls back to a local SQLite file so that
development and testing can proceed without a PostgreSQL server._


### hypercode\new files to check\backend\research\models.py

#### `__repr__()` (line 52)
**Args**: self


#### `__repr__()` (line 81)
**Args**: self


#### `__repr__()` (line 102)
**Args**: self


#### `__repr__()` (line 124)
**Args**: self


#### `__repr__()` (line 144)
**Args**: self


#### `__repr__()` (line 169)
**Args**: self


#### `__repr__()` (line 193)
**Args**: self


#### `__repr__()` (line 221)
**Args**: self


### hypercode\new files to check\backend\research\scripts\import_sources_from_folder.py

#### `infer_kind()` (line 25)
**Args**: path


#### `main()` (line 36)
**Args**: data_dir


### hypercode\new files to check\backend\research\scripts\seed_basic_data.py

#### `main()` (line 25)

### hypercode\run_lexer.py

#### `run_lexer()` (line 13)
_Run the lexer on a source file and print the tokens._

**Args**: source_file


### hypercode\scripts\style_guide_collector.py

#### `__init__()` (line 21)
**Args**: self, repo_path


#### `_load_feedback()` (line 32)
_üìÇ Load existing feedback data_

**Args**: self


#### `_save_feedback()` (line 51)
_üíæ Save feedback data_

**Args**: self


#### `add_feedback()` (line 60)
_üìù Add new feedback entry

Args:
    feedback: Dictionary containing feedback data

Returns:
    bool: True if feedback was added successfully_

**Args**: self, feedback


#### `_update_analysis()` (line 102)
_üìä Update analysis based on new feedback

Args:
    entry: New feedback entry_

**Args**: self, entry


#### `analyze_feedback()` (line 151)
_üìä Generate comprehensive analysis of all feedback

Returns:
    Dict containing analysis results_

**Args**: self


#### `_get_top_items()` (line 189)
_üìä Get top items from a frequency dictionary

Args:
    items: Dictionary of item frequencies
    limit: Maximum number of items to return

Returns:
    List of top items with counts and percentages_

**Args**: self, items, limit


#### `_calculate_consensus()` (line 212)
_üìä Calculate consensus for preference categories

Args:
    preference_data: Nested dictionary of preferences

Returns:
    Dictionary with consensus analysis_

**Args**: self, preference_data


#### `_generate_recommendations()` (line 247)
_üí° Generate style guide recommendations based on feedback

Returns:
    List of recommendations with rationale_

**Args**: self


#### `import_github_issues()` (line 331)
_üì• Import feedback from GitHub issues

Args:
    github_token: GitHub API token (optional)

Returns:
    Number of issues imported_

**Args**: self, github_token


#### `generate_report()` (line 354)
_üìä Generate comprehensive feedback report

Args:
    output_file: Optional file to save report

Returns:
    Report content as string_

**Args**: self, output_file


#### `interactive_feedback()` (line 419)
_üéØ Interactive feedback collection from command line_

**Args**: self


#### `main()` (line 527)
_üöÄ Main entry point_


### hypercode\scripts\test_perplexity_api.py

#### `main()` (line 17)
_Test the Perplexity API connection and make a sample query._


### hypercode\server.js

#### `unnamed_function()` (line 13)

#### `unnamed_function()` (line 22)

#### `unnamed_function()` (line 24)

#### `unnamed_function()` (line 46)

#### `unnamed_function()` (line 47)

#### `unnamed_function()` (line 56)

#### `unnamed_function()` (line 70)

#### `unnamed_function()` (line 71)

#### `unnamed_function()` (line 80)

#### `unnamed_function()` (line 100)

### hypercode\src\ai_gateway\claude_adapter.py

#### `__init__()` (line 25)
**Args**: self, api_key


### hypercode\src\ai_gateway\mistral_adapter.py

#### `__init__()` (line 25)
**Args**: self, api_key


### hypercode\src\ai_gateway\ollama_adapter.py

#### `__init__()` (line 25)
**Args**: self, api_key


### hypercode\src\ai_gateway\openai_adapter.py

#### `__init__()` (line 25)
**Args**: self, api_key


### hypercode\src\build.py

#### `build()` (line 34)
_Builds a HyperCode source file to the target language.

Args:
    source_file: The path to the HyperCode source file (.hc).
    target: The target language for compilation._

**Args**: source_file, target


### hypercode\src\claude_adapter.py

#### `__init__()` (line 25)
**Args**: self, api_key


### hypercode\src\core\ast.py

#### `accept()` (line 10)
**Args**: self, visitor


### hypercode\src\core\hypercode-proto\app.js

#### `unnamed_function()` (line 70)

#### `unnamed_function()` (line 85)

#### `unnamed_function()` (line 89)

#### `unnamed_function()` (line 92)

#### `unnamed_function()` (line 95)

#### `unnamed_function()` (line 101)

#### `unnamed_function()` (line 104)

#### `unnamed_function()` (line 109)

#### `unnamed_function()` (line 120)

#### `unnamed_function()` (line 121)

#### `unnamed_function()` (line 134)

#### `unnamed_function()` (line 145)

#### `unnamed_function()` (line 161)

#### `unnamed_function()` (line 166)

#### `unnamed_function()` (line 173)

#### `unnamed_function()` (line 187)

#### `unnamed_function()` (line 188)

#### `unnamed_function()` (line 195)

#### `unnamed_function()` (line 203)

#### `unnamed_function()` (line 214)

#### `unnamed_function()` (line 221)

#### `unnamed_function()` (line 242)

#### `unnamed_function()` (line 258)

#### `unnamed_function()` (line 260)

#### `unnamed_function()` (line 262)

#### `unnamed_function()` (line 270)

#### `unnamed_function()` (line 298)

#### `unnamed_function()` (line 304)

#### `unnamed_function()` (line 305)

#### `unnamed_function()` (line 314)

#### `unnamed_function()` (line 316)

#### `unnamed_function()` (line 322)

#### `unnamed_function()` (line 323)

#### `unnamed_function()` (line 325)

#### `unnamed_function()` (line 333)

#### `unnamed_function()` (line 344)

#### `unnamed_function()` (line 345)

#### `unnamed_function()` (line 352)

#### `unnamed_function()` (line 356)

#### `unnamed_function()` (line 384)

#### `unnamed_function()` (line 389)

#### `unnamed_function()` (line 403)

#### `unnamed_function()` (line 419)

#### `unnamed_function()` (line 429)

#### `unnamed_function()` (line 438)

#### `unnamed_function()` (line 439)

#### `unnamed_function()` (line 449)

#### `unnamed_function()` (line 450)

#### `unnamed_function()` (line 451)

#### `unnamed_function()` (line 462)

#### `unnamed_function()` (line 467)

#### `unnamed_function()` (line 472)

#### `unnamed_function()` (line 477)

#### `unnamed_function()` (line 481)

#### `unnamed_function()` (line 487)

#### `unnamed_function()` (line 495)

#### `unnamed_function()` (line 501)

#### `unnamed_function()` (line 502)

#### `unnamed_function()` (line 503)

#### `unnamed_function()` (line 517)

#### `unnamed_function()` (line 528)

#### `unnamed_function()` (line 532)

#### `unnamed_function()` (line 561)

#### `unnamed_function()` (line 562)

#### `unnamed_function()` (line 570)

#### `unnamed_function()` (line 592)

#### `unnamed_function()` (line 593)

#### `unnamed_function()` (line 600)

#### `unnamed_function()` (line 604)

#### `unnamed_function()` (line 610)

#### `unnamed_function()` (line 670)

#### `unnamed_function()` (line 681)

#### `unnamed_function()` (line 691)

#### `unnamed_function()` (line 696)

#### `unnamed_function()` (line 704)

#### `unnamed_function()` (line 714)

#### `unnamed_function()` (line 722)

#### `unnamed_function()` (line 761)

#### `unnamed_function()` (line 766)

### hypercode\src\core\interpreter.py

#### `__init__()` (line 9)
**Args**: self, message, token


#### `__init__()` (line 16)
**Args**: self, enclosing


#### `define()` (line 20)
**Args**: self, name, value


#### `get()` (line 23)
**Args**: self, name


#### `assign()` (line 30)
**Args**: self, name, value


#### `arity()` (line 41)
**Args**: self


#### `call()` (line 44)
**Args**: self, interpreter, arguments


#### `__init__()` (line 49)
**Args**: self, declaration, closure


#### `call()` (line 53)
**Args**: self, interpreter, arguments


#### `arity()` (line 65)
**Args**: self


#### `__init__()` (line 70)
**Args**: self, value


#### `__init__()` (line 75)
**Args**: self


#### `arity()` (line 83)
**Args**: self


#### `call()` (line 86)
**Args**: self, interpreter, arguments


#### `__str__()` (line 89)
**Args**: self


#### `execute_block()` (line 94)
**Args**: self, statements, environment


#### `interpret()` (line 103)
**Args**: self, statements


#### `execute()` (line 112)
**Args**: self, stmt


#### `evaluate()` (line 115)
**Args**: self, expr


#### `visit_Expression()` (line 118)
**Args**: self, stmt


#### `visit_Print()` (line 122)
**Args**: self, stmt


#### `visit_Var()` (line 129)
**Args**: self, stmt


#### `visit_Block()` (line 136)
**Args**: self, stmt


#### `visit_Expression()` (line 140)
**Args**: self, stmt


#### `visit_Print()` (line 144)
**Args**: self, stmt


#### `visit_Intent()` (line 150)
**Args**: self, stmt


#### `visit_Function()` (line 155)
**Args**: self, stmt


#### `visit_Return()` (line 160)
**Args**: self, stmt


#### `visit_Literal()` (line 166)
**Args**: self, expr


#### `visit_Grouping()` (line 169)
**Args**: self, expr


#### `visit_Variable()` (line 172)
**Args**: self, expr


#### `visit_Assign()` (line 175)
**Args**: self, expr


#### `visit_Call()` (line 180)
**Args**: self, expr


#### `visit_Binary()` (line 198)
**Args**: self, expr


#### `visit_Unary()` (line 229)
**Args**: self, expr


#### `is_truthy()` (line 237)
**Args**: self, value


#### `stringify()` (line 244)
**Args**: self, value


#### `get_output()` (line 256)
**Args**: self


### hypercode\src\core\lexer.py

#### `__init__()` (line 42)
_Initialize the lexer with source code._

**Args**: self, source


#### `scan_tokens()` (line 99)
_Scan the source code and return a list of tokens._

**Args**: self


#### `scan_token()` (line 109)
_Scan a single token._

**Args**: self


#### `number()` (line 168)
_Lex a number literal._

**Args**: self


#### `string()` (line 203)
_Lex a string literal._

**Args**: self, interpolated


#### `docstring()` (line 252)
_Lex a docstring._

**Args**: self


#### `identifier()` (line 278)
_Lex an identifier or keyword._

**Args**: self


#### `error()` (line 288)
_Report a lexing error._

**Args**: self, message, line, column


#### `is_at_end()` (line 312)
_Check if we've reached the end of the source._

**Args**: self


#### `advance()` (line 316)
_Consume and return the next character._

**Args**: self


#### `match()` (line 325)
_Conditionally consume a character if it matches the expected value._

**Args**: self, expected


#### `peek()` (line 335)
_Look at the next character without consuming it._

**Args**: self


#### `peek_next()` (line 341)
_Look at the character after the next one without consuming it._

**Args**: self


#### `add_token()` (line 347)
_Add a new token to the token list._

**Args**: self, token_type, literal


### hypercode\src\core\parser.py

#### `__init__()` (line 12)
**Args**: self, tokens


#### `parse()` (line 16)
_Parse the entire program._

**Args**: self


#### `declaration()` (line 25)
**Args**: self


#### `var_declaration()` (line 36)
**Args**: self


#### `statement()` (line 61)
**Args**: self


#### `print_statement()` (line 72)
**Args**: self


#### `expression_statement()` (line 77)
**Args**: self


#### `block()` (line 82)
**Args**: self


#### `expression()` (line 91)
**Args**: self


#### `assignment()` (line 94)
**Args**: self


#### `equality()` (line 109)
**Args**: self


#### `comparison()` (line 119)
**Args**: self


#### `term()` (line 132)
**Args**: self


#### `factor()` (line 140)
**Args**: self


#### `unary()` (line 148)
**Args**: self


#### `primary()` (line 155)
**Args**: self


#### `function()` (line 177)
**Args**: self, kind


#### `if_statement()` (line 200)
**Args**: self


#### `return_statement()` (line 212)
**Args**: self


#### `match()` (line 222)
**Args**: self


#### `consume()` (line 229)
**Args**: self, type_, message


#### `error()` (line 239)
**Args**: self, token, message


#### `synchronize()` (line 245)
**Args**: self


#### `check()` (line 265)
**Args**: self, type_


#### `advance()` (line 270)
**Args**: self


#### `is_at_end()` (line 275)
**Args**: self


#### `peek()` (line 278)
**Args**: self


#### `previous()` (line 281)
**Args**: self


### hypercode\src\core\tokens.py

#### `__init__()` (line 84)
**Args**: self, type, lexeme, literal, line, column


#### `__str__()` (line 93)
**Args**: self


#### `__repr__()` (line 96)
**Args**: self


### hypercode\src\duelcode\duelcode_validator.py

#### `__init__()` (line 51)
**Args**: self, file_path


#### `_add_result()` (line 58)
_Add a validation result with proper line number._

**Args**: self, message, severity, line


#### `_find_lines()` (line 71)
_Find all lines matching the pattern with their line numbers._

**Args**: self, pattern


#### `validate()` (line 81)
_Run all validation checks._

**Args**: self


#### `validate_structure()` (line 93)
_Validate the overall document structure._

**Args**: self


#### `validate_headings()` (line 129)
_Validate heading hierarchy and formatting._

**Args**: self


#### `validate_code_blocks()` (line 171)
_Validate code blocks for proper formatting and language specification._

**Args**: self


#### `validate_checklists()` (line 210)
_Validate checklist items in the document._

**Args**: self


#### `validate_visual_elements()` (line 245)
_Validate visual elements like diagrams, images, etc._

**Args**: self


#### `validate_links()` (line 263)
_Validate internal and external links._

**Args**: self


#### `print_validation_results()` (line 283)
_Print validation results in a user-friendly format._

**Args**: validator


#### `main()` (line 316)
_Main entry point for the validator._


### hypercode\src\duelcode\enhanced_validator.py

#### `__init__()` (line 83)
**Args**: self, file_path


#### `_add_result()` (line 90)
_Add a validation result with proper line number._

**Args**: self, message, severity, line


#### `_find_lines()` (line 103)
_Find all lines matching the pattern with their line numbers._

**Args**: self, pattern


#### `validate_code_blocks_have_language()` (line 115)
_Ensure all code blocks have a specified language._

**Args**: self


#### `validate_has_visual_representation()` (line 128)
_Ensure each part has a visual representation._

**Args**: self


#### `validate_has_practical_exercise()` (line 140)
_Ensure each part has a practical exercise._

**Args**: self


#### `validate_has_learning_objectives()` (line 152)
_Ensure learning objectives are present and well-formed._

**Args**: self


#### `validate_has_checklist()` (line 174)
_Ensure a checklist is present and has items._

**Args**: self


#### `validate_has_conclusion()` (line 195)
_Ensure the document has a conclusion section._

**Args**: self


#### `validate_has_whats_next()` (line 204)
_Suggest adding a 'What's Next' section._

**Args**: self


#### `validate_code_quality()` (line 213)
_Check code quality in code blocks._

**Args**: self


#### `_analyze_code_block()` (line 234)
_Analyze a code block for quality issues._

**Args**: self, lines, lang, start_line


#### `_analyze_python_code()` (line 256)
_Python-specific code analysis._

**Args**: self, lines, _start_line


#### `_analyze_javascript_code()` (line 277)
_JavaScript/TypeScript-specific code analysis._

**Args**: self, lines, _start_line


#### `validate_has_glossary()` (line 291)
_Suggest adding a glossary for technical terms._

**Args**: self


#### `validate_has_see_also()` (line 325)
_Suggest adding a 'See Also' section with related resources._

**Args**: self


#### `validate_has_faq()` (line 334)
_Suggest adding an FAQ section._

**Args**: self


#### `validate_has_acknowledgments()` (line 344)
_Suggest adding an acknowledgments section._

**Args**: self


#### `validate_all()` (line 353)
_Run all validations._

**Args**: self


#### `print_validation_results()` (line 376)
_Print validation results in a user-friendly format._

**Args**: results


#### `main()` (line 407)
_Main entry point for the enhanced validator._


### hypercode\src\duelcode\test_framework.py

#### `__init__()` (line 45)
**Args**: self, duelcode_dir


#### `discover_tutorials()` (line 49)
_Find all tutorial markdown files._

**Args**: self


#### `run_validator()` (line 56)
_Run the ultra validator on a file._

**Args**: self, file_path


#### `parse_validator_output()` (line 71)
_Parse validator output to count issues by severity._

**Args**: self, output


#### `test_tutorial()` (line 99)
_Test a single tutorial file._

**Args**: self, tutorial_path


#### `test_validator_integrity()` (line 135)
_Test that validator itself is working correctly._

**Args**: self


#### `test_template_validity()` (line 176)
_Test that templates pass validation._

**Args**: self


#### `run_all_tests()` (line 221)
_Run the complete test suite._

**Args**: self


#### `generate_report()` (line 248)
_Generate a detailed test report._

**Args**: self


#### `main()` (line 295)
_Main entry point._


### hypercode\src\duelcode\test_validator.py

#### `test_valid_file()` (line 11)
_Test with a valid DuelCode file._


#### `test_invalid_file()` (line 65)
_Test with an invalid DuelCode file._


#### `main()` (line 90)
_Run the test suite._


### hypercode\src\duelcode\ultra_validator.py

#### `__init__()` (line 88)
**Args**: self, file_path


#### `_add_result()` (line 95)
**Args**: self, message, severity, line, suggestion


#### `_find_lines()` (line 106)
**Args**: self, pattern


#### `validate_code_blocks_have_language()` (line 118)
_Validate all code blocks have language specifications._

**Args**: self


#### `validate_has_visual_representation()` (line 152)
_Check for visual elements like diagrams, charts, or ASCII art._

**Args**: self


#### `validate_has_practical_exercise()` (line 171)
_Check for practical exercises or challenges._

**Args**: self


#### `validate_has_learning_objectives()` (line 192)
_Check for learning objectives section._

**Args**: self


#### `validate_has_checklist()` (line 215)
_Check for checklist elements._

**Args**: self


#### `validate_has_conclusion()` (line 234)
_Check for conclusion section._

**Args**: self


#### `validate_has_whats_next()` (line 257)
_Check for 'What's Next' section._

**Args**: self


#### `validate_code_quality()` (line 278)
_Validate code block quality and best practices._

**Args**: self


#### `_validate_code_block_content()` (line 305)
_Validate specific code block content based on language._

**Args**: self, block_lines, lang, start_line


#### `validate_has_glossary()` (line 340)
_Check for glossary section._

**Args**: self


#### `validate_has_see_also()` (line 360)
_Check for 'See Also' section._

**Args**: self


#### `validate_has_faq()` (line 380)
_Check for FAQ section._

**Args**: self


#### `validate_has_acknowledgments()` (line 402)
_Check for acknowledgments section._

**Args**: self


#### `validate_accessibility()` (line 422)
_Check for accessibility features._

**Args**: self


#### `validate_interactive_elements()` (line 443)
_Check for interactive elements._

**Args**: self


#### `validate_all()` (line 463)
_Run all validations and return results._

**Args**: self


#### `print_results()` (line 487)
_Print validation results in a formatted way._

**Args**: self


#### `main()` (line 537)

### hypercode\src\duelcode\validate_duelcode.py

#### `__init__()` (line 24)
**Args**: self, file_path


#### `validate_sections()` (line 30)
_Check if all required sections are present._

**Args**: self


#### `check_formatting()` (line 39)
_Check for common formatting issues._

**Args**: self


#### `check_visual_aids()` (line 55)
_Check for presence of visual aids._

**Args**: self


#### `validate()` (line 60)
_Run all validations and return results._

**Args**: self


#### `main()` (line 68)

### hypercode\src\duelcode_validator.py

#### `__init__()` (line 51)
**Args**: self, file_path


#### `_add_result()` (line 58)
_Add a validation result with proper line number._

**Args**: self, message, severity, line


#### `_find_lines()` (line 71)
_Find all lines matching the pattern with their line numbers._

**Args**: self, pattern


#### `validate()` (line 81)
_Run all validation checks._

**Args**: self


#### `validate_structure()` (line 93)
_Validate the overall document structure._

**Args**: self


#### `validate_headings()` (line 129)
_Validate heading hierarchy and formatting._

**Args**: self


#### `validate_code_blocks()` (line 171)
_Validate code blocks for proper formatting and language specification._

**Args**: self


#### `validate_checklists()` (line 210)
_Validate checklist items in the document._

**Args**: self


#### `validate_visual_elements()` (line 245)
_Validate visual elements like diagrams, images, etc._

**Args**: self


#### `validate_links()` (line 263)
_Validate internal and external links._

**Args**: self


#### `print_validation_results()` (line 283)
_Print validation results in a user-friendly format._

**Args**: validator


#### `main()` (line 316)
_Main entry point for the validator._


### hypercode\src\enhanced_validator.py

#### `__init__()` (line 83)
**Args**: self, file_path


#### `_add_result()` (line 90)
_Add a validation result with proper line number._

**Args**: self, message, severity, line


#### `_find_lines()` (line 103)
_Find all lines matching the pattern with their line numbers._

**Args**: self, pattern


#### `validate_code_blocks_have_language()` (line 115)
_Ensure all code blocks have a specified language._

**Args**: self


#### `validate_has_visual_representation()` (line 128)
_Ensure each part has a visual representation._

**Args**: self


#### `validate_has_practical_exercise()` (line 140)
_Ensure each part has a practical exercise._

**Args**: self


#### `validate_has_learning_objectives()` (line 152)
_Ensure learning objectives are present and well-formed._

**Args**: self


#### `validate_has_checklist()` (line 174)
_Ensure a checklist is present and has items._

**Args**: self


#### `validate_has_conclusion()` (line 195)
_Ensure the document has a conclusion section._

**Args**: self


#### `validate_has_whats_next()` (line 204)
_Suggest adding a 'What's Next' section._

**Args**: self


#### `validate_code_quality()` (line 213)
_Check code quality in code blocks._

**Args**: self


#### `_analyze_code_block()` (line 234)
_Analyze a code block for quality issues._

**Args**: self, lines, lang, start_line


#### `_analyze_python_code()` (line 256)
_Python-specific code analysis._

**Args**: self, lines, _start_line


#### `_analyze_javascript_code()` (line 277)
_JavaScript/TypeScript-specific code analysis._

**Args**: self, lines, _start_line


#### `validate_has_glossary()` (line 291)
_Suggest adding a glossary for technical terms._

**Args**: self


#### `validate_has_see_also()` (line 325)
_Suggest adding a 'See Also' section with related resources._

**Args**: self


#### `validate_has_faq()` (line 334)
_Suggest adding an FAQ section._

**Args**: self


#### `validate_has_acknowledgments()` (line 344)
_Suggest adding an acknowledgments section._

**Args**: self


#### `validate_all()` (line 353)
_Run all validations._

**Args**: self


#### `print_validation_results()` (line 376)
_Print validation results in a user-friendly format._

**Args**: results


#### `main()` (line 407)
_Main entry point for the enhanced validator._


### hypercode\src\hypercode-backend-js-COMPLETE.py

#### `__init__()` (line 30)
_Initialize compiler.

Args:
    ast: Root AST node (PROGRAM)
    optimize: Enable optimizations_

**Args**: self, ast, optimize


#### `compile()` (line 42)
_Compile AST to JavaScript.

Returns:
    JavaScript source code_

**Args**: self


#### `_generate_header()` (line 65)
_Generate JavaScript header_

**Args**: self


#### `_generate_setup()` (line 74)
_Generate setup code (memory tape, pointer, I/O)_

**Args**: self


#### `_generate_main()` (line 110)
_Generate JavaScript for AST node.

Args:
    node: AST node

Returns:
    JavaScript code_

**Args**: self, node


#### `_generate_footer()` (line 162)
_Generate JavaScript footer_

**Args**: self


#### `_indent()` (line 179)
_Get current indentation_

**Args**: self


#### `optimize_ast()` (line 183)
_Optimize AST (future: loop unrolling, dead code elimination).

Args:
    node: AST node

Returns:
    Optimized AST node_

**Args**: self, node


#### `main()` (line 200)
_CLI interface for JavaScript backend_


### hypercode\src\hypercode-launch-kit.py

#### `__init__()` (line 26)
**Args**: self


#### `create_readme()` (line 30)
_Create the ultimate README.md_

**Args**: self


#### `create_launch_checklist()` (line 367)
_Create launch day checklist_

**Args**: self


#### `create_launch_script()` (line 620)
_Create automated launch script_

**Args**: self


#### `create_first_30_days()` (line 718)
_Create 30-day success roadmap_

**Args**: self


#### `print_summary()` (line 974)
_Print beautiful summary_

**Args**: self


#### `main()` (line 1007)
_Run launch kit initialization_


### hypercode\src\hypercode-lexer-COMPLETE.py

#### `__repr__()` (line 54)
_Neurodivergent-friendly representation_

**Args**: self


#### `__init__()` (line 62)
**Args**: self, message, line, column


#### `__init__()` (line 95)
_Initialize lexer with source code.

Args:
    source: HyperCode source code
    filename: Source filename (for error reporting)_

**Args**: self, source, filename


#### `tokenize()` (line 110)
_Convert HyperCode source to token stream.

Returns:
    List of Token objects

Raises:
    LexerError: On invalid syntax_

**Args**: self


#### `_advance_position()` (line 169)
_Update position tracking after processing character_

**Args**: self, char


#### `_skip_comment()` (line 179)
_Skip characters until end of line_

**Args**: self


#### `get_tokens()` (line 184)
_Return current token list_

**Args**: self


#### `filter_tokens()` (line 188)
_Get tokens excluding certain types.

Args:
    exclude_types: Token types to exclude

Returns:
    Filtered token list_

**Args**: self, exclude_types


#### `print_tokens()` (line 205)
_Print tokens in readable format.

Args:
    colorize: Use ANSI colors (helps ADHD/dyslexia)_

**Args**: self, colorize


#### `get_statistics()` (line 236)
_Get token statistics (useful for analysis).

Returns:
    Dictionary with token counts_

**Args**: self


#### `main()` (line 250)
_CLI interface for the lexer_


### hypercode\src\hypercode-parser-COMPLETE.py

#### `__repr__()` (line 51)
_Pretty-print AST (neurodivergent-friendly)_

**Args**: self, indent


#### `__init__()` (line 71)
**Args**: self, message, token


#### `__init__()` (line 94)
_Initialize parser with token stream.

Args:
    tokens: List of tokens from lexer_

**Args**: self, tokens


#### `parse()` (line 105)
_Parse tokens into AST.

Returns:
    Root AST node (PROGRAM)

Raises:
    ParserError: On syntax errors_

**Args**: self


#### `_parse_statement()` (line 127)
_Parse a single statement_

**Args**: self


#### `_parse_loop()` (line 174)
_Parse loop structure: [ statements ]

Returns:
    Loop AST node_

**Args**: self


#### `_advance()` (line 209)
_Move to next token_

**Args**: self


#### `_is_at_end()` (line 215)
_Check if at end of token stream_

**Args**: self


#### `validate()` (line 222)
_Validate AST structure.

Returns:
    List of warnings (empty if no issues)_

**Args**: self


#### `print_ast()` (line 237)
_Print AST in readable format.

Args:
    node: AST node to print (defaults to root)
    indent: Indentation level_

**Args**: self, node, indent


#### `main()` (line 251)
_CLI interface for the parser_


### hypercode\src\hypercode\__main__.py

#### `main()` (line 6)

### hypercode\src\hypercode\config.py

#### `get_headers()` (line 27)
_Get headers for API requests_

**Args**: cls


### hypercode\src\hypercode\core\ast.py

#### `accept()` (line 10)
**Args**: self, visitor


### hypercode\src\hypercode\core\error_handler.py

#### `report_parse_error()` (line 5)
**Args**: token, message


#### `report()` (line 12)
**Args**: line, where, message


### hypercode\src\hypercode\core\interpreter.py

#### `__init__()` (line 9)
**Args**: self, value


#### `__init__()` (line 14)
**Args**: self, declaration, closure


#### `__str__()` (line 18)
**Args**: self


#### `arity()` (line 21)
**Args**: self


#### `call()` (line 24)
**Args**: self, interpreter, arguments


#### `__init__()` (line 38)
**Args**: self, enclosing


#### `define()` (line 42)
**Args**: self, name, value


#### `get()` (line 45)
**Args**: self, name


#### `assign()` (line 52)
**Args**: self, name, value


#### `__init__()` (line 63)
**Args**: self


#### `interpret()` (line 67)
**Args**: self, statements


#### `execute()` (line 74)
**Args**: self, stmt


#### `execute_block()` (line 77)
**Args**: self, statements, environment


#### `evaluate()` (line 86)
**Args**: self, expr


#### `visit_Expression()` (line 89)
**Args**: self, stmt


#### `visit_Print()` (line 92)
**Args**: self, stmt


#### `visit_Var()` (line 96)
**Args**: self, stmt


#### `visit_Block()` (line 102)
**Args**: self, stmt


#### `visit_Assign()` (line 105)
**Args**: self, expr


#### `visit_Binary()` (line 110)
**Args**: self, expr


#### `visit_Grouping()` (line 153)
**Args**: self, expr


#### `visit_Literal()` (line 156)
**Args**: self, expr


#### `visit_Unary()` (line 159)
**Args**: self, expr


#### `visit_Variable()` (line 172)
**Args**: self, expr


#### `visit_If()` (line 175)
**Args**: self, stmt


#### `is_truthy()` (line 181)
**Args**: self, obj


#### `visit_Fun()` (line 188)
**Args**: self, stmt


#### `visit_Return()` (line 192)
**Args**: self, stmt


#### `visit_Call()` (line 198)
**Args**: self, expr


#### `is_callable()` (line 216)
**Args**: self, obj


#### `visit_Expression()` (line 222)
**Args**: self, stmt


#### `visit_Print()` (line 225)
**Args**: self, stmt


#### `visit_Var()` (line 228)
**Args**: self, stmt


#### `visit_Block()` (line 231)
**Args**: self, stmt


#### `visit_If()` (line 234)
**Args**: self, stmt


#### `visit_Fun()` (line 237)
**Args**: self, stmt


#### `visit_Return()` (line 240)
**Args**: self, stmt


#### `visit_Assign()` (line 243)
**Args**: self, expr


#### `visit_Binary()` (line 246)
**Args**: self, expr


#### `visit_Grouping()` (line 249)
**Args**: self, expr


#### `visit_Literal()` (line 252)
**Args**: self, expr


#### `visit_Unary()` (line 255)
**Args**: self, expr


#### `visit_Variable()` (line 258)
**Args**: self, expr


#### `visit_Call()` (line 261)
**Args**: self, expr


### hypercode\src\hypercode\core\lexer.py

#### `__init__()` (line 35)
**Args**: self, message, line, column


#### `__init__()` (line 109)
_Initialize the lexer with source code.

Args:
    source: The source code to tokenize_

**Args**: self, source


#### `tokenize()` (line 126)
_Convert source code into a list of tokens.

Args:
    source: Optional source code to tokenize. If not provided, uses the source
           passed to the constructor.

Returns:
    List of Token objects

Raises:
    ValueError: If no source code is provided_

**Args**: self, source


#### `_match_patterns()` (line 161)
_Try to match the current position against all token patterns._

**Args**: self


#### `_update_position()` (line 187)
_Update line and column numbers based on the given text._

**Args**: self, text


#### `_add_token()` (line 206)
_Add a token to the token list.

Args:
    token_type: The type of the token.
    lexeme: The lexeme of the token (the actual text from the source)._

**Args**: self, token_type, lexeme


#### `_handle_unknown()` (line 270)
_Handle unknown characters in the source._

**Args**: self


### hypercode\src\hypercode\core\parser.py

#### `__init__()` (line 13)
**Args**: self, tokens


#### `parse()` (line 17)
_Parse the entire program._

**Args**: self


#### `declaration()` (line 26)
**Args**: self


#### `var_declaration()` (line 37)
**Args**: self


#### `statement()` (line 53)
**Args**: self


#### `print_statement()` (line 66)
**Args**: self


#### `return_statement()` (line 71)
**Args**: self


#### `intent_statement()` (line 79)
**Args**: self


#### `expression_statement()` (line 94)
**Args**: self


#### `if_statement()` (line 99)
**Args**: self


#### `function()` (line 111)
**Args**: self, kind


#### `block()` (line 130)
**Args**: self


#### `expression()` (line 137)
**Args**: self


#### `assignment()` (line 140)
**Args**: self


#### `equality()` (line 155)
**Args**: self


#### `comparison()` (line 165)
**Args**: self


#### `term()` (line 178)
**Args**: self


#### `factor()` (line 186)
**Args**: self


#### `unary()` (line 194)
**Args**: self


#### `primary()` (line 201)
**Args**: self


#### `_primary()` (line 218)
**Args**: self


#### `finish_call()` (line 249)
**Args**: self, callee


#### `match()` (line 262)
**Args**: self


#### `consume()` (line 269)
**Args**: self, type_, message


#### `error()` (line 276)
**Args**: self, token, message


#### `synchronize()` (line 282)
**Args**: self


#### `check()` (line 302)
**Args**: self, type_


#### `advance()` (line 307)
**Args**: self


#### `is_at_end()` (line 312)
**Args**: self


#### `peek()` (line 315)
**Args**: self


#### `previous()` (line 318)
**Args**: self


### hypercode\src\hypercode\core\sensory_profile.py

#### `to_dict()` (line 77)
_Convert the profile to a dictionary._

**Args**: self


#### `from_dict()` (line 85)
_Create a profile from a dictionary._

**Args**: cls, data


#### `save()` (line 107)
_Save the profile to a file._

**Args**: self, path


#### `load()` (line 113)
_Load a profile from a file._

**Args**: cls, path


#### `__init__()` (line 123)
_Initialize with optional custom profiles directory._

**Args**: self, profiles_dir


#### `_ensure_default_profiles()` (line 133)
_Ensure default profiles exist._

**Args**: self


#### `_create_minimal_profile()` (line 146)
_Create a minimal distraction-free profile._

**Args**: self


#### `_create_enhanced_profile()` (line 163)
_Create an enhanced profile with helpful visual cues._

**Args**: self


#### `_create_high_contrast_profile()` (line 190)
_Create a high-contrast profile for better readability._

**Args**: self


#### `list_profiles()` (line 216)
_List all available profile names._

**Args**: self


#### `get_profile()` (line 220)
_Get a profile by name._

**Args**: self, name


#### `save_profile()` (line 227)
_Save a profile._

**Args**: self, profile


#### `delete_profile()` (line 232)
_Delete a profile by name._

**Args**: self, name


#### `get_profile()` (line 243)
_Helper function to get a profile by name._

**Args**: name


#### `list_profiles()` (line 248)
_Helper function to list all available profiles._


### hypercode\src\hypercode\core\tokens.py

#### `__str__()` (line 68)
**Args**: self


### hypercode\src\hypercode\enhanced_perplexity_client.py

#### `__init__()` (line 21)
**Args**: self, kb_path


#### `query_with_context()` (line 25)
_Send a query with relevant knowledge base context_

**Args**: self, prompt, use_knowledge_base, model


#### `add_research_data()` (line 61)
_Add research data to the knowledge base_

**Args**: self, title, content, url, tags


#### `search_research_data()` (line 71)
_Search the knowledge base_

**Args**: self, query, limit


#### `list_research_documents()` (line 75)
_List all research documents_

**Args**: self


#### `get_document()` (line 79)
_Get a specific document_

**Args**: self, doc_id


#### `delete_document()` (line 83)
_Delete a document_

**Args**: self, doc_id


#### `import_from_perplexity_space()` (line 87)
_Import data from Perplexity Space export_

**Args**: self, space_data


#### `test_context_integration()` (line 123)
_Test the context integration_

**Args**: self


#### `create_perplexity_space_import_template()` (line 175)
_Create a template for importing Perplexity Space data_


### hypercode\src\hypercode\knowledge_base.py

#### `__post_init__()` (line 28)
**Args**: self


#### `generate_id()` (line 36)
_Generate unique ID from content hash_

**Args**: self


#### `validate()` (line 41)
_Validate document data_

**Args**: self


#### `update_timestamp()` (line 53)
_Update the last_updated timestamp_

**Args**: self


#### `__init__()` (line 103)
**Args**: self, kb_path


#### `load()` (line 109)
_Load knowledge base from file_

**Args**: self


#### `save()` (line 125)
_Save knowledge base to file_

**Args**: self


#### `add_document()` (line 135)
_Add a new research document_

**Args**: self, title, content, url, tags


#### `search_documents()` (line 163)
_Search documents by query_

**Args**: self, query, limit


#### `get_context_for_query()` (line 227)
_Get relevant context for a query_

**Args**: self, query, max_context_length


#### `list_documents()` (line 257)
_List all documents_

**Args**: self


#### `get_document()` (line 261)
_Get a specific document by ID_

**Args**: self, doc_id


#### `delete_document()` (line 265)
_Delete a document_

**Args**: self, doc_id


#### `update_document()` (line 273)
_Update an existing document_

**Args**: self, doc_id


#### `search_by_tags()` (line 287)
_Search documents by tags with AND/OR operators_

**Args**: self, tags, operator


#### `get_document_statistics()` (line 306)
_Get statistics about the knowledge base_

**Args**: self


#### `export_format()` (line 331)
_Export knowledge base in different formats_

**Args**: self, format_type


#### `validate_all_documents()` (line 353)
_Validate all documents and return list of errors_

**Args**: self


#### `cleanup_duplicates()` (line 363)
_Remove duplicate documents based on content hash_

**Args**: self


#### `initialize_sample_data()` (line 384)
_Initialize with sample HyperCode research data_


### hypercode\src\hypercode\perplexity_client.py

#### `__init__()` (line 15)
_Initialize the Perplexity client.

Args:
    api_key: Optional API key. If not provided, will use the one from config._

**Args**: self, api_key


#### `query()` (line 30)
_Send a query to the Perplexity API.

Args:
    prompt: The prompt to send to the API.
    model: The model to use for the query.

Returns:
    The API response as a dictionary._

**Args**: self, prompt, model


#### `test_connection()` (line 72)
_Test the connection to the Perplexity API_


### hypercode\src\hypercode\repl.py

#### `run_repl()` (line 12)

#### `run()` (line 33)
**Args**: source


#### `show_help()` (line 54)

### hypercode\src\hypercode_idea_generator.py

#### `__init__()` (line 439)
**Args**: self


#### `get_ideas_by_category()` (line 443)
_Get ideas by category and optionally by difficulty level.

Args:
    category: 'language_design', 'features_tooling',
             'community', 'accessibility'
    level: 'beginner', 'intermediate', 'advanced' (optional)

Returns:
    List of ideas_

**Args**: self, category, level


#### `get_top_ideas()` (line 468)
_Get most-voted ideas across all categories._

**Args**: self, category, limit


#### `vote_for_idea()` (line 487)
_Vote for an idea._

**Args**: self, idea_id


#### `get_trending_ideas()` (line 497)
_Get trending ideas (high votes + recent activity)._

**Args**: self


#### `format_idea_card()` (line 502)
_Format idea for display.

Returns:
    Formatted string for rendering_

**Args**: self, idea


#### `main()` (line 528)
_Interactive idea generator CLI_


### hypercode\src\hypercode_poc.py

#### `__init__()` (line 51)
**Args**: self


#### `tokenize()` (line 74)
**Args**: self, source


#### `handle_string()` (line 115)
**Args**: self, quote, errors


#### `handle_number()` (line 141)
**Args**: self


#### `handle_identifier()` (line 149)
**Args**: self


#### `advance()` (line 171)
**Args**: self


#### `__init__()` (line 179)
**Args**: self


#### `format_error()` (line 182)
**Args**: self, msg, line, col, level


#### `analyze()` (line 192)
**Args**: self, tokens


#### `__init__()` (line 212)
**Args**: self, level


#### `record()` (line 216)
**Args**: self, success


#### `__init__()` (line 225)
**Args**: self, level


#### `compile()` (line 232)
**Args**: self, code


### hypercode\src\mistral_adapter.py

#### `__init__()` (line 25)
**Args**: self, api_key


### hypercode\src\ollama_adapter.py

#### `__init__()` (line 25)
**Args**: self, api_key


### hypercode\src\openai_adapter.py

#### `__init__()` (line 25)
**Args**: self, api_key


### hypercode\src\parser\debug_ascii.py

#### `test_regex_patterns()` (line 14)
_Test regex patterns directly_


### hypercode\src\parser\debug_full.py

#### `debug_full_parsing()` (line 14)
_Debug the full parsing flow_


### hypercode\src\parser\debug_parser.py

#### `debug_annotation_detection()` (line 14)
_Debug why annotations aren't being detected_


### hypercode\src\parser\debug_simple.py

#### `debug_simple()` (line 14)
_Debug without emoji characters_


### hypercode\src\parser\test_parser.py

#### `test_first_click_moment()` (line 14)
_Test the parser with the first click moment example_


### hypercode\src\parser\visual_syntax_parser.py

#### `__str__()` (line 46)
**Args**: self


#### `get_annotations_by_type()` (line 62)
_Get all annotations of a specific type_

**Args**: self, marker_type


#### `__init__()` (line 72)
**Args**: self


#### `_build_semantic_patterns()` (line 76)
_üîç Build regex patterns for all semantic markers_

**Args**: self


#### `_build_color_scheme()` (line 105)
_üé® Build semantic color mapping for IDE highlighting_

**Args**: self


#### `parse_file()` (line 123)
_üìÑ Parse an entire HyperCode file_

**Args**: self, file_path


#### `parse_content()` (line 130)
_üìù Parse HyperCode content string_

**Args**: self, content


#### `_is_function_definition()` (line 170)
_üîç Check if line is a function definition_

**Args**: self, line


#### `_start_new_function()` (line 179)
_üÜï Create new ParsedFunction from definition line_

**Args**: self, line, line_num


#### `_parse_line_annotations()` (line 202)
_ÔøΩ Parse semantic annotations from a line_

**Args**: self, line, line_num


#### `_parse_annotation_params()` (line 223)
_üîß Parse annotation parameters from string_

**Args**: self, params_str


#### `generate_syntax_highlighting()` (line 265)
_üé® Generate HTML with syntax highlighting for visual markers_

**Args**: self, content


#### `extract_semantic_summary()` (line 277)
_üìä Extract semantic summary for analysis_

**Args**: self, functions


#### `validate_neurodiversity_compliance()` (line 311)
_üß† Validate neurodiversity-first design principles_

**Args**: self, functions


### hypercode\src\scaffold (1).py

#### `create_directories()` (line 141)
_Create all required directories._


#### `create_python_files()` (line 151)
_Create all Python files with proper __init__.py structure._


#### `create_example_files()` (line 165)
_Create example HyperCode files._


#### `create_root_files()` (line 202)
_Create root-level configuration files as empty placeholders._


#### `create_healthcheck()` (line 213)
_Create the healthcheck script for Docker._


#### `print_summary()` (line 234)
_Print summary of created structure._


#### `main()` (line 259)
_Main scaffolding function._


### hypercode\src\scaffold.py

#### `create_directories()` (line 153)
_Create all required directories._


#### `create_python_files()` (line 184)
_Create all Python files with proper docstrings and structure._


#### `create_example_files()` (line 254)
_Create example HyperCode files._


#### `create_root_files()` (line 291)
_Create root-level configuration files with appropriate content._


#### `create_healthcheck()` (line 541)
_Create the healthcheck script for Docker._


#### `print_summary()` (line 583)
_Print summary of created structure._


#### `main()` (line 621)
_Main scaffolding function._


### hypercode\src\spatial_visualizer\src\code-analyzer.ts

#### `unnamed_function()` (line 56)

#### `unnamed_function()` (line 102)

#### `unnamed_function()` (line 103)

#### `unnamed_function()` (line 118)

#### `unnamed_function()` (line 164)

#### `unnamed_function()` (line 165)

#### `unnamed_function()` (line 180)

### hypercode\src\spatial_visualizer\src\extension.ts

#### `unnamed_function()` (line 19)

#### `unnamed_function()` (line 52)

#### `unnamed_function()` (line 59)

### hypercode\src\spatial_visualizer\src\spatial-visualizer.ts

#### `unnamed_function()` (line 77)

#### `unnamed_function()` (line 80)

#### `unnamed_function()` (line 141)

#### `unnamed_function()` (line 161)

#### `unnamed_function()` (line 162)

#### `unnamed_function()` (line 174)

#### `unnamed_function()` (line 176)

#### `unnamed_function()` (line 177)

#### `unnamed_function()` (line 187)

#### `unnamed_function()` (line 191)

#### `unnamed_function()` (line 195)

#### `unnamed_function()` (line 228)

#### `unnamed_function()` (line 263)

#### `unnamed_function()` (line 282)

### hypercode\src\spatial_visualizer\src\visualization-panel.ts

#### `unnamed_function()` (line 237)

#### `unnamed_function()` (line 254)

#### `unnamed_function()` (line 265)

#### `unnamed_function()` (line 269)

#### `unnamed_function()` (line 273)

### hypercode\src\src\code-analyzer.ts

#### `unnamed_function()` (line 56)

#### `unnamed_function()` (line 102)

#### `unnamed_function()` (line 103)

#### `unnamed_function()` (line 118)

#### `unnamed_function()` (line 164)

#### `unnamed_function()` (line 165)

#### `unnamed_function()` (line 180)

### hypercode\src\src\extension.ts

#### `unnamed_function()` (line 19)

#### `unnamed_function()` (line 52)

#### `unnamed_function()` (line 59)

### hypercode\src\src\spatial-visualizer.ts

#### `unnamed_function()` (line 77)

#### `unnamed_function()` (line 80)

#### `unnamed_function()` (line 141)

#### `unnamed_function()` (line 161)

#### `unnamed_function()` (line 162)

#### `unnamed_function()` (line 174)

#### `unnamed_function()` (line 176)

#### `unnamed_function()` (line 177)

#### `unnamed_function()` (line 187)

#### `unnamed_function()` (line 191)

#### `unnamed_function()` (line 195)

#### `unnamed_function()` (line 228)

#### `unnamed_function()` (line 263)

#### `unnamed_function()` (line 282)

### hypercode\src\src\visualization-panel.ts

#### `unnamed_function()` (line 237)

#### `unnamed_function()` (line 254)

#### `unnamed_function()` (line 265)

#### `unnamed_function()` (line 269)

#### `unnamed_function()` (line 273)

### hypercode\src\test_framework.py

#### `__init__()` (line 45)
**Args**: self, duelcode_dir


#### `discover_tutorials()` (line 49)
_Find all tutorial markdown files._

**Args**: self


#### `run_validator()` (line 56)
_Run the ultra validator on a file._

**Args**: self, file_path


#### `parse_validator_output()` (line 71)
_Parse validator output to count issues by severity._

**Args**: self, output


#### `test_tutorial()` (line 99)
_Test a single tutorial file._

**Args**: self, tutorial_path


#### `test_validator_integrity()` (line 135)
_Test that validator itself is working correctly._

**Args**: self


#### `test_template_validity()` (line 176)
_Test that templates pass validation._

**Args**: self


#### `run_all_tests()` (line 221)
_Run the complete test suite._

**Args**: self


#### `generate_report()` (line 248)
_Generate a detailed test report._

**Args**: self


#### `main()` (line 295)
_Main entry point._


### hypercode\src\test_validator.py

#### `test_valid_file()` (line 11)
_Test with a valid DuelCode file._


#### `test_invalid_file()` (line 65)
_Test with an invalid DuelCode file._


#### `main()` (line 90)
_Run the test suite._


### hypercode\src\ultra_validator.py

#### `__init__()` (line 88)
**Args**: self, file_path


#### `_add_result()` (line 95)
**Args**: self, message, severity, line, suggestion


#### `_find_lines()` (line 106)
**Args**: self, pattern


#### `validate_code_blocks_have_language()` (line 118)
_Validate all code blocks have language specifications._

**Args**: self


#### `validate_has_visual_representation()` (line 152)
_Check for visual elements like diagrams, charts, or ASCII art._

**Args**: self


#### `validate_has_practical_exercise()` (line 171)
_Check for practical exercises or challenges._

**Args**: self


#### `validate_has_learning_objectives()` (line 192)
_Check for learning objectives section._

**Args**: self


#### `validate_has_checklist()` (line 215)
_Check for checklist elements._

**Args**: self


#### `validate_has_conclusion()` (line 234)
_Check for conclusion section._

**Args**: self


#### `validate_has_whats_next()` (line 257)
_Check for 'What's Next' section._

**Args**: self


#### `validate_code_quality()` (line 278)
_Validate code block quality and best practices._

**Args**: self


#### `_validate_code_block_content()` (line 305)
_Validate specific code block content based on language._

**Args**: self, block_lines, lang, start_line


#### `validate_has_glossary()` (line 340)
_Check for glossary section._

**Args**: self


#### `validate_has_see_also()` (line 360)
_Check for 'See Also' section._

**Args**: self


#### `validate_has_faq()` (line 380)
_Check for FAQ section._

**Args**: self


#### `validate_has_acknowledgments()` (line 402)
_Check for acknowledgments section._

**Args**: self


#### `validate_accessibility()` (line 422)
_Check for accessibility features._

**Args**: self


#### `validate_interactive_elements()` (line 443)
_Check for interactive elements._

**Args**: self


#### `validate_all()` (line 463)
_Run all validations and return results._

**Args**: self


#### `print_results()` (line 487)
_Print validation results in a formatted way._

**Args**: self


#### `main()` (line 537)

### hypercode\src\utils\code_analyzer_ai.py

#### `__init__()` (line 22)
**Args**: self


#### `analyze_file()` (line 25)
_Analyze a Python file with AI assistance_

**Args**: self, file_path


#### `_analyze_complexity()` (line 72)
_Analyze code complexity indicators_

**Args**: self, tree


#### `_check_docstrings()` (line 113)
_Check for docstring coverage_

**Args**: self, tree


#### `_get_ai_code_analysis()` (line 155)
_Get AI analysis of code from Perplexity_

**Args**: self, code, file_path


#### `analyze_project()` (line 183)
_Analyze entire project_

**Args**: self, project_path


#### `_get_project_ai_insights()` (line 230)
_Get AI insights for the entire project_

**Args**: self, analyses, stats


#### `save_analysis()` (line 262)
_Save analysis to file_

**Args**: self, analysis, filename


#### `print_summary()` (line 270)
_Print analysis summary_

**Args**: self, analysis


#### `main()` (line 288)
_Main function_


### hypercode\src\utils\debug_search.py

#### `debug_search()` (line 15)
_Debug why space data isn't being found_


### hypercode\src\utils\demo_ai_research.py

#### `demo_ai_research_queries()` (line 16)
_Demonstrate AI Research integration with Perplexity_


#### `test_document_specific_queries()` (line 90)
_Test queries specific to the HyperCode AI Research document_


### hypercode\src\utils\demo_enhanced_client.py

#### `demo_knowledge_base_integration()` (line 16)
_Demonstrate the knowledge base integration_


#### `demonstrate_memory_persistence()` (line 131)
_Demonstrate that the knowledge base persists between sessions_


### hypercode\src\utils\final_integration_test.py

#### `final_integration_test()` (line 15)
_Complete test of the Perplexity Space integration_


### hypercode\src\utils\health_scanner_ai.py

#### `__init__()` (line 21)
**Args**: self


#### `analyze_project_structure()` (line 25)
_Analyze project structure and identify health issues_

**Args**: self


#### `analyze_dependencies()` (line 68)
_Analyze dependency management_

**Args**: self


#### `analyze_security()` (line 110)
_Analyze security configuration_

**Args**: self


#### `get_ai_recommendations()` (line 143)
_Get AI-powered recommendations based on health scan_

**Args**: self, health_data


#### `run_full_scan()` (line 170)
_Run complete health scan with AI analysis_

**Args**: self


#### `save_report()` (line 221)
_Save health scan report to file_

**Args**: self, report, filename


#### `print_summary()` (line 227)
_Print a summary of the health scan_

**Args**: self, report


#### `main()` (line 247)
_Main function to run the health scanner_


### hypercode\src\utils\import-helper.py

#### `__init__()` (line 16)
**Args**: self, output_dir


#### `validate_document()` (line 21)
_Validate a document structure
Returns (is_valid, error_message)_

**Args**: self, doc


#### `load_template()` (line 63)
_Load documents from JSON template file_

**Args**: self, filepath


#### `validate_all()` (line 83)
_Validate all loaded documents_

**Args**: self


#### `generate_report()` (line 95)
_Generate a validation report_

**Args**: self


#### `create_import_script()` (line 141)
_Generate a Python script to import the data_

**Args**: self, output_file


#### `create_template_instructions()` (line 193)
_Generate detailed instructions for filling the template_

**Args**: self, output_file


#### `main()` (line 264)
_CLI interface for the import helper_


### hypercode\src\utils\import_all_space_data.py

#### `format_content()` (line 16)
_Recursively format nested data into readable text_

**Args**: data, indent


#### `import_all_hypercode_data()` (line 41)
_Import all sections of your HyperCode Space data_


### hypercode\src\utils\import_hypercode_data.py

#### `import_hypercode_space_data()` (line 16)
_Import your actual HyperCode Space data_


### hypercode\src\utils\import_perplexity_space.py

#### `create_manual_import_script()` (line 17)
_Create a script for manual data entry from Perplexity Space_


#### `create_json_import_template()` (line 86)
_Create a JSON template for importing data_


#### `import_from_json()` (line 115)
_Import data from JSON file_


#### `test_imported_data()` (line 153)
_Test the imported data with context-aware queries_


#### `show_import_menu()` (line 188)
_Show the import menu_


### hypercode\src\utils\local_health_scanner.py

#### `__init__()` (line 23)
**Args**: self


#### `scan_project()` (line 35)
_Scan the entire project and return health metrics_

**Args**: self


#### `_scan_directory()` (line 43)
_Recursively scan a directory for Python files_

**Args**: self, directory


#### `_analyze_file()` (line 52)
_Analyze a single Python file_

**Args**: self, file_path


#### `_analyze_ast()` (line 77)
_Analyze Python AST for code quality metrics_

**Args**: self, node


#### `_check_documentation()` (line 97)
_Check documentation coverage_

**Args**: self


#### `_check_tests()` (line 109)
_Check test coverage_

**Args**: self


#### `_calculate_metrics()` (line 120)
_Calculate final metrics_

**Args**: self


#### `print_health_report()` (line 132)
_Print a formatted health report_

**Args**: metrics


#### `main()` (line 163)
_Main function to run the health scanner_


### hypercode\src\utils\perplexity_space_collector.py

#### `quick_copy_paste_collector()` (line 18)
_Quick collector for copy-paste workflow_


#### `create_structured_template()` (line 117)
_Create a structured JSON template for bulk import_


#### `show_bro_hacks()` (line 167)
_Show BROski's pro tips_


#### `main_menu()` (line 207)
_Main menu for the collector_


### hypercode\src\utils\perplexity_space_integration.py

#### `main()` (line 16)

### hypercode\src\utils\run_lexer.py

#### `run_lexer()` (line 13)
_Run the lexer on a source file and print the tokens._

**Args**: source_file


### hypercode\src\validate_duelcode.py

#### `__init__()` (line 24)
**Args**: self, file_path


#### `validate_sections()` (line 30)
_Check if all required sections are present._

**Args**: self


#### `check_formatting()` (line 39)
_Check for common formatting issues._

**Args**: self


#### `check_visual_aids()` (line 55)
_Check for presence of visual aids._

**Args**: self


#### `validate()` (line 60)
_Run all validations and return results._

**Args**: self


#### `main()` (line 68)

### hypercode\test_mcp_connection.py

#### `check_port()` (line 26)
_Check if a port is open on the given host._

**Args**: host, port, timeout


#### `find_running_servers()` (line 36)
_Scan common ports to find running servers._

**Args**: host


#### `test_server_connection()` (line 49)
_Test connection to a single MCP server._

**Args**: server_name, base_url, port


#### `test_all_servers()` (line 90)
_Test connection to all MCP servers and print results._


#### `check_dependencies()` (line 139)
_Check if required dependencies are installed._


### hypercode\tests\benchmark_knowledge_base.py

#### `__init__()` (line 27)
**Args**: self


#### `_get_system_info()` (line 34)
_Get system information for benchmark context_

**Args**: self


#### `generate_test_data()` (line 43)
_Generate test data of specified size_

**Args**: self, size


#### `benchmark_operation()` (line 93)
_Benchmark a single operation_

**Args**: self, operation_name, operation_func


#### `run_benchmark_suite()` (line 118)
_Run complete benchmark suite_

**Args**: self, size


#### `_calculate_summary()` (line 274)
_Calculate summary statistics_

**Args**: self


#### `_generate_recommendations()` (line 296)
_Generate performance recommendations_

**Args**: self


#### `generate_markdown_report()` (line 338)
_Generate beautiful markdown report_

**Args**: self, output_file


#### `save_json_results()` (line 467)
_Save results as JSON_

**Args**: self, output_file


#### `main()` (line 474)
_Main benchmark runner_


### hypercode\tests\test_core.py

#### `run_test()` (line 30)
_Test the lexer, parser, and interpreter with the given source code._

**Args**: source_code


### hypercode\tests\test_direct_access.py

#### `test_direct_implementation_access()` (line 15)
_Test direct access to implementation guide content_


### hypercode\tests\test_implementation_guide.py

#### `test_search_functionality()` (line 15)
_Test search for implementation guide terms_


#### `test_implementation_guide_content()` (line 37)
_Test the implementation guide document directly_


#### `test_context_queries()` (line 82)
_Test context-aware queries_


### hypercode\tests\test_intent_blocks.py

#### `test_intent_block()` (line 13)
_Test parsing of intent blocks_


### hypercode\tests\test_interpreter.py

#### `run_code()` (line 10)
_A helper function to run code and capture stdout._

**Args**: source


#### `test_if_statement_then()` (line 30)
**Args**: self


#### `test_if_statement_else()` (line 42)
**Args**: self


#### `test_function_call()` (line 54)
**Args**: self


#### `test_function_with_parameters()` (line 64)
**Args**: self


#### `test_function_with_return()` (line 74)
**Args**: self


#### `test_recursive_function_call()` (line 85)
**Args**: self


#### `test_scoping()` (line 99)
**Args**: self


### hypercode\tests\test_knowledge_base.py

#### `sample_documents()` (line 16)
_Create sample documents for testing._

**Args**: self


#### `knowledge_base()` (line 40)
_Create a knowledge base instance with sample documents._

**Args**: self, sample_documents


#### `test_basic_search()` (line 48)
_Test basic search functionality._

**Args**: self, knowledge_base, sample_documents


#### `test_search_with_exact_match()` (line 54)
_Test search with exact phrase matching._

**Args**: self, knowledge_base


#### `test_search_case_insensitive()` (line 59)
_Test that search is case-insensitive._

**Args**: self, knowledge_base


#### `test_search_empty_query()` (line 65)
_Test search with empty query returns all or no documents._

**Args**: self, knowledge_base


#### `test_search_no_matches()` (line 71)
_Test search with no matching documents._

**Args**: self, knowledge_base


#### `test_search_ranking()` (line 77)
_Test that search results are ranked by relevance._

**Args**: self, knowledge_base, sample_documents


#### `test_query_normalization()` (line 90)
_Test query normalization (typos, spacing, punctuation)._

**Args**: self, knowledge_base


#### `test_multi_word_query()` (line 98)
_Test search with multiple keywords._

**Args**: self, knowledge_base


#### `test_tag_based_search()` (line 103)
_Test search that includes tag matching._

**Args**: self, knowledge_base, sample_documents


#### `knowledge_base()` (line 116)
**Args**: self


#### `test_very_short_query()` (line 121)
_Test search with very short query (1-2 chars)._

**Args**: self, knowledge_base


#### `test_very_long_query()` (line 126)
_Test search with very long query (paragraph length)._

**Args**: self, knowledge_base


#### `test_special_characters_in_query()` (line 136)
_Test search with special characters._

**Args**: self, knowledge_base


#### `test_unicode_in_query()` (line 141)
_Test search with unicode characters._

**Args**: self, knowledge_base


#### `test_sql_injection_attempt()` (line 146)
_Test that search is safe from SQL injection-style attacks._

**Args**: self, knowledge_base


#### `test_repeated_queries()` (line 151)
_Test that repeated queries return consistent results._

**Args**: self, knowledge_base


#### `large_knowledge_base()` (line 163)
_Create a knowledge base with many documents._

**Args**: self


#### `test_search_response_time()` (line 179)
_Test that search completes within acceptable time._

**Args**: self, large_knowledge_base


#### `test_concurrent_searches()` (line 189)
_Test multiple concurrent search operations._

**Args**: self, large_knowledge_base


#### `test_memory_usage()` (line 207)
_Test memory usage during search operations._

**Args**: self, large_knowledge_base


#### `mock_perplexity_client()` (line 217)
_Create a mock Perplexity client._

**Args**: self


#### `mock_knowledge_base()` (line 229)
_Create a mock knowledge base._

**Args**: self


#### `test_enhanced_query_with_context()` (line 243)
_Test that queries are enhanced with knowledge base context._

**Args**: self, mock_perplexity_client, mock_knowledge_base


#### `test_fallback_to_perplexity_api()` (line 259)
_Test fallback to Perplexity API when no local context found._

**Args**: self, mock_perplexity_client, mock_knowledge_base


#### `test_context_ranking_and_selection()` (line 273)
_Test that best context is selected for query enhancement._

**Args**: self, mock_knowledge_base


#### `knowledge_base()` (line 292)
**Args**: self


#### `test_add_document()` (line 300)
_Test adding a new document to knowledge base._

**Args**: self, knowledge_base


#### `test_update_document()` (line 310)
_Test updating an existing document._

**Args**: self, knowledge_base


#### `test_remove_document()` (line 315)
_Test removing a document._

**Args**: self, knowledge_base


### hypercode\tests\test_knowledge_base_comprehensive.py

#### `temp_kb()` (line 24)
_Create a temporary knowledge base for testing_

**Args**: self


#### `sample_docs()` (line 36)
_Sample documents for testing_

**Args**: self


#### `test_init_empty_kb()` (line 59)
_Test knowledge base initialization_

**Args**: self, temp_kb


#### `test_add_single_document()` (line 65)
_Test adding a single document_

**Args**: self, temp_kb, sample_docs


#### `test_add_multiple_documents()` (line 74)
_Test adding multiple documents_

**Args**: self, temp_kb, sample_docs


#### `test_save_and_load()` (line 84)
_Test saving and loading knowledge base_

**Args**: self, temp_kb, sample_docs


#### `test_search_exact_match()` (line 102)
_Test exact search matching_

**Args**: self, temp_kb, sample_docs


#### `test_search_partial_match()` (line 113)
_Test partial search matching_

**Args**: self, temp_kb, sample_docs


#### `test_search_tag_matching()` (line 124)
_Test tag-based search_

**Args**: self, temp_kb, sample_docs


#### `test_search_case_insensitive()` (line 135)
_Test case insensitive search_

**Args**: self, temp_kb, sample_docs


#### `test_empty_search()` (line 147)
_Test empty search query_

**Args**: self, temp_kb


#### `test_nonexistent_search()` (line 155)
_Test search for nonexistent terms_

**Args**: self, temp_kb, sample_docs


#### `test_get_context_for_query()` (line 165)
_Test context extraction_

**Args**: self, temp_kb, sample_docs


#### `test_context_length_limit()` (line 176)
_Test context length limiting_

**Args**: self, temp_kb, sample_docs


#### `test_document_update()` (line 186)
_Test updating existing documents_

**Args**: self, temp_kb, sample_docs


#### `test_list_documents()` (line 202)
_Test listing all documents_

**Args**: self, temp_kb, sample_docs


#### `test_delete_document()` (line 213)
_Test document deletion_

**Args**: self, temp_kb, sample_docs


#### `populated_kb()` (line 233)
_Create a populated knowledge base for integration testing_

**Args**: self


#### `test_complex_search_queries()` (line 277)
_Test complex search scenarios_

**Args**: self, populated_kb


#### `test_search_ranking_quality()` (line 291)
_Test that search results are properly ranked_

**Args**: self, populated_kb


#### `test_related_term_expansion()` (line 301)
_Test that related terms are properly expanded_

**Args**: self, populated_kb


#### `test_performance_with_large_dataset()` (line 313)
_Test performance with larger dataset_

**Args**: self, populated_kb


#### `test_concurrent_access_simulation()` (line 332)
_Test simulated concurrent access_

**Args**: self, populated_kb


#### `large_kb()` (line 360)
_Create a large knowledge base for performance testing_

**Args**: self


#### `test_search_performance_large_dataset()` (line 382)
_Test search performance with large dataset_

**Args**: self, large_kb


#### `test_save_performance_large_dataset()` (line 396)
_Test save performance with large dataset_

**Args**: self, large_kb


#### `test_load_performance_large_dataset()` (line 409)
_Test load performance with large dataset_

**Args**: self, large_kb


#### `test_memory_usage_large_dataset()` (line 423)
_Test memory usage with large dataset_

**Args**: self, large_kb


#### `edge_case_kb()` (line 450)
_Create knowledge base for edge case testing_

**Args**: self


#### `test_empty_title_handling()` (line 494)
_Test handling of documents with empty titles_

**Args**: self, edge_case_kb


#### `test_special_characters_handling()` (line 499)
_Test handling of special characters and unicode_

**Args**: self, edge_case_kb


#### `test_very_long_titles()` (line 507)
_Test handling of very long titles_

**Args**: self, edge_case_kb


#### `test_empty_content_handling()` (line 512)
_Test handling of documents with empty content_

**Args**: self, edge_case_kb


#### `test_none_tags_handling()` (line 517)
_Test handling of None tags_

**Args**: self, edge_case_kb


#### `test_malformed_json_handling()` (line 531)
_Test handling of malformed JSON files_

**Args**: self


#### `test_file_permission_handling()` (line 544)
_Test handling of file permission issues_

**Args**: self


### hypercode\tests\test_lexer.py

#### `test_lexer_basic_tokens()` (line 5)

#### `test_lexer_strings()` (line 23)

#### `test_lexer_operators()` (line 48)
**Args**: source, expected_type


### hypercode\tests\test_lexer_extended.py

#### `test_lexer_escaped_strings()` (line 5)
_Test handling of strings with escaped characters._


#### `test_lexer_numbers()` (line 18)
_Test various number formats._


#### `test_lexer_operators()` (line 39)
_Test all operators._


#### `test_lexer_comments()` (line 86)
_Test handling of single-line and multi-line comments._


#### `test_lexer_whitespace()` (line 115)
_Test handling of various whitespace characters._


#### `test_lexer_error_handling()` (line 130)
_Test error handling for invalid tokens._


#### `test_lexer_hex_numbers()` (line 139)
_Test hexadecimal number literals._


#### `test_lexer_binary_numbers()` (line 157)
_Test binary number literals._


#### `test_lexer_scientific_notation()` (line 169)
_Test scientific notation numbers._


#### `test_lexer_string_escapes()` (line 180)
_Test string escape sequences._


#### `test_lexer_keywords()` (line 197)
_Test all language keywords._


#### `test_lexer_position_tracking()` (line 223)
_Test that line and column numbers are tracked correctly._


#### `test_lexer_error_recovery()` (line 243)
_Test that the lexer raises errors on invalid characters._


#### `test_lexer_error_messages()` (line 252)
_Test that lexer error messages are informative._


### hypercode\tests\test_parser.py

#### `test_parse_literal()` (line 12)

#### `test_parse_variable_declaration()` (line 24)

#### `test_parse_binary_expression()` (line 37)

### hypercode\tests\test_perplexity.py

#### `test_perplexity_connection()` (line 16)
_Test Perplexity API with detailed logging_


#### `test_ai_research_integration()` (line 66)
_Test integration with AI Research document content_


### hypercode\tests\test_real_data.py

#### `test_enhanced_knowledge_base()` (line 16)
_Test enhanced KnowledgeBase functionality_


#### `test_real_perplexity_data_simulation()` (line 185)
_Simulate testing with real Perplexity Space data_


### hypercode\tests\test_real_space_data.py

#### `test_real_space_data()` (line 15)
_Test queries that use your actual Perplexity Space data_


### hypercode\tests\test_sensory_profiles.py

#### `test_visual_settings_creation()` (line 21)
_Test creating visual settings._


#### `test_audio_settings_creation()` (line 35)
_Test creating audio settings._


#### `test_animation_settings_creation()` (line 44)
_Test creating animation settings._


#### `test_sensory_profile_creation()` (line 55)
_Test creating a complete sensory profile._


#### `test_profile_serialization()` (line 71)
_Test serializing AND deserializing a profile._


#### `test_profile_file_io()` (line 92)
_Test saving and loading a profile to/from a file._

**Args**: tmp_path


#### `test_profile_manager_initialization()` (line 115)
_Test initializing the profile manager and checking default profiles._

**Args**: tmp_path


#### `test_profile_manager_get_profile()` (line 129)
_Test getting a profile by name._

**Args**: tmp_path


#### `test_profile_manager_save_custom_profile()` (line 142)
_Test saving a custom profile._

**Args**: tmp_path


#### `test_profile_manager_delete_profile()` (line 169)
_Test deleting a profile._

**Args**: tmp_path


### hypercode\tests\tests\test_lexer_enhanced.py

#### `test_lexer_edge_cases()` (line 7)

#### `test_lexer_error_handling()` (line 28)

#### `test_lexer_number_literals()` (line 43)

#### `test_lexer_string_interpolation()` (line 65)

#### `test_lexer_docstrings()` (line 79)

### hypercode\tests\unit\test_direct_access.py

#### `test_direct_implementation_access()` (line 15)
_Test direct access to implementation guide content_


### hypercode\tests\unit\test_implementation_guide.py

#### `test_search_functionality()` (line 15)
_Test search for implementation guide terms_


#### `test_implementation_guide_content()` (line 37)
_Test the implementation guide document directly_


#### `test_context_queries()` (line 82)
_Test context-aware queries_


### hypercode\tests\unit\test_intent_blocks.py

#### `test_intent_block()` (line 13)
_Test parsing of intent blocks_


### hypercode\tests\unit\test_knowledge_base.py

#### `temp_kb()` (line 24)
_Create a temporary knowledge base for testing_

**Args**: self


#### `sample_documents()` (line 33)
_Sample documents for testing_

**Args**: self


#### `test_init_empty_kb()` (line 56)
_Test knowledge base initialization_

**Args**: self, temp_kb


#### `test_add_document()` (line 61)
_Test adding a single document_

**Args**: self, temp_kb, sample_documents


#### `test_add_multiple_documents()` (line 82)
_Test adding multiple documents_

**Args**: self, temp_kb, sample_documents


#### `test_save_and_load()` (line 92)
_Test saving and loading knowledge base_

**Args**: self, temp_kb, sample_documents


#### `test_search_exact_match()` (line 113)
_Test exact term matching in search_

**Args**: self, temp_kb, sample_documents


#### `test_search_tag_matching()` (line 126)
_Test tag-based search_

**Args**: self, temp_kb, sample_documents


#### `test_search_related_terms()` (line 139)
_Test related term expansion_

**Args**: self, temp_kb, sample_documents


#### `test_search_space_data_boost()` (line 153)
_Test that space data gets boosted in search_

**Args**: self, temp_kb


#### `test_get_context_for_query()` (line 180)
_Test context extraction for queries_

**Args**: self, temp_kb, sample_documents


#### `test_context_length_limit()` (line 192)
_Test context length limiting_

**Args**: self, temp_kb, sample_documents


#### `test_list_documents()` (line 203)
_Test listing all documents_

**Args**: self, temp_kb, sample_documents


#### `test_empty_search()` (line 216)
_Test search with empty query_

**Args**: self, temp_kb


#### `test_search_nonexistent_term()` (line 221)
_Test search for term that doesn't exist_

**Args**: self, temp_kb, sample_documents


#### `test_document_update()` (line 231)
_Test updating existing document_

**Args**: self, temp_kb, sample_documents


#### `test_document_creation()` (line 253)
_Test creating a research document_

**Args**: self


#### `test_document_optional_fields()` (line 273)
_Test document with optional fields_

**Args**: self


### hypercode\tests\unit\test_lexer.py

#### `test_lexer()` (line 12)
_Test the lexer with the given source code and print the results.

Args:
    source: The source code to tokenize
    description: A description of what this test is checking_

**Args**: source, description


#### `run_tests()` (line 42)
_Run a series of test cases for the lexer._


### hypercode\tests\unit\test_mcp_connection.py

#### `check_port()` (line 26)
_Check if a port is open on the given host._

**Args**: host, port, timeout


#### `find_running_servers()` (line 36)
_Scan common ports to find running servers._

**Args**: host


#### `test_server_connection()` (line 49)
_Test connection to a single MCP server._

**Args**: server_name, base_url, port


#### `test_all_servers()` (line 90)
_Test connection to all MCP servers and print results._


#### `check_dependencies()` (line 139)
_Check if required dependencies are installed._


### hypercode\tests\unit\test_perplexity.py

#### `test_perplexity_connection()` (line 16)
_Test Perplexity API with detailed logging_


#### `test_ai_research_integration()` (line 66)
_Test integration with AI Research document content_


### hypercode\tests\unit\test_real_data.py

#### `test_enhanced_knowledge_base()` (line 16)
_Test enhanced KnowledgeBase functionality_


#### `test_real_perplexity_data_simulation()` (line 185)
_Simulate testing with real Perplexity Space data_


### hypercode\tests\unit\test_real_space_data.py

#### `test_real_space_data()` (line 15)
_Test queries that use your actual Perplexity Space data_


### hypercode\tests\unit\test_search_algorithm.py

#### `populated_kb()` (line 24)
_Create a knowledge base with test documents_

**Args**: self


#### `test_exact_title_match_highest_score()` (line 80)
_Test that exact title matches get highest priority_

**Args**: self, populated_kb


#### `test_space_data_boosting()` (line 92)
_Test that space data gets boosted in search results_

**Args**: self, populated_kb


#### `test_related_term_expansion()` (line 105)
_Test related term matching functionality_

**Args**: self, populated_kb


#### `test_tag_matching_scoring()` (line 126)
_Test that tag matches contribute to scoring_

**Args**: self, populated_kb


#### `test_content_frequency_scoring()` (line 136)
_Test that multiple content occurrences increase score_

**Args**: self, populated_kb


#### `test_partial_word_matching()` (line 149)
_Test partial word matching for longer terms_

**Args**: self, populated_kb


#### `test_query_word_ordering()` (line 167)
_Test that query words are properly processed_

**Args**: self, populated_kb


#### `test_case_insensitive_search()` (line 179)
_Test that search is case insensitive_

**Args**: self, populated_kb


#### `test_empty_query_returns_no_results()` (line 202)
_Test that empty queries return no results_

**Args**: self, populated_kb


#### `test_limit_parameter_respected()` (line 210)
_Test that search limit parameter works correctly_

**Args**: self, populated_kb


#### `test_no_results_for_nonexistent_terms()` (line 219)
_Test search for terms that don't exist_

**Args**: self, populated_kb


#### `test_special_characters_in_query()` (line 227)
_Test search with special characters_

**Args**: self, populated_kb


#### `test_unicode_characters()` (line 237)
_Test search with unicode characters_

**Args**: self, populated_kb


#### `test_search_performance_with_large_kb()` (line 256)
_Test search performance with larger knowledge base_

**Args**: self, populated_kb


#### `test_search_result_consistency()` (line 277)
_Test that search results are consistent across multiple calls_

**Args**: self, populated_kb


#### `scoring_kb()` (line 296)
_Create KB for detailed scoring tests_

**Args**: self


#### `test_title_match_beats_content_match()` (line 324)
_Test that title matches score higher than content matches_

**Args**: self, scoring_kb


#### `test_space_data_boosting_works()` (line 332)
_Test that space data gets boosted_

**Args**: self, scoring_kb


#### `test_frequency_scoring()` (line 340)
_Test that content frequency affects scoring_

**Args**: self, scoring_kb


### hypercode\vscode-extension\out\extension.js

#### `unnamed_function()` (line 6)

#### `unnamed_function()` (line 21)

#### `unnamed_function()` (line 48)

#### `unnamed_function()` (line 66)

### hypercode\vscode-extension\src\extension.ts

#### `unnamed_function()` (line 22)

#### `unnamed_function()` (line 61)

### hypercode\vscode-extension\src\test\suite\extension.test.ts

#### `unnamed_function()` (line 5)

#### `unnamed_function()` (line 6)

### hypercode_db.py

#### `__post_init__()` (line 23)
_Validate the entity after initialization._

**Args**: self


#### `__init__()` (line 35)
_Initialize the database with the given JSON file.

Args:
    db_path: Path to the JSON database file_

**Args**: self, db_path


#### `_load_database()` (line 46)
_Load the database from a JSON file.

Args:
    db_path: Path to the JSON database file_

**Args**: self, db_path


#### `get_entities_by_type()` (line 93)
_Get all entities of a specific type.

Args:
    entity_type: The type of entities to retrieve (e.g., 'function', 'class')

Returns:
    List of matching CodeEntity objects_

**Args**: self, entity_type


#### `get_entities_in_file()` (line 104)
_Get all entities in a specific file.

Args:
    file_path: Path to the file

Returns:
    List of CodeEntity objects in the file_

**Args**: self, file_path


#### `print_analysis()` (line 116)
_Print a detailed analysis of the codebase.

Args:
    db: Initialized HypercodeDB instance_

**Args**: db


### live_research\cli.py

#### `print_entry()` (line 10)
_Print a research entry in a readable format._

**Args**: entry, detailed


#### `search_entries()` (line 38)
_Search for research entries._

**Args**: args


#### `view_entry()` (line 59)
_View a specific research entry by ID._

**Args**: args


#### `add_entry()` (line 71)
_Add a new research entry._

**Args**: args


#### `import_entries()` (line 94)
_Import entries from a JSON file._

**Args**: args


#### `export_entries()` (line 126)
_Export all entries to a JSON file._

**Args**: args


#### `main()` (line 150)
_Main CLI entry point._


### live_research\database.py

#### `__init__()` (line 8)
_Initialize the database connection and create tables if they don't exist._

**Args**: self, db_path


#### `_get_connection()` (line 13)
_Create and return a database connection._

**Args**: self


#### `_create_tables()` (line 17)
_Create the necessary tables if they don't exist._

**Args**: self


#### `add_research_entry()` (line 68)
_Add a new research entry to the database._

**Args**: self, entry_data


#### `get_research_entry()` (line 128)
_Retrieve a research entry by its ID._

**Args**: self, entry_id


#### `search_entries()` (line 159)
_Search research entries by content or tags._

**Args**: self, query, tag, limit


#### `import_from_json()` (line 220)
_Import research entries from a JSON file._

**Args**: self, json_path


#### `setup_database()` (line 241)
_Initialize and return a configured ResearchDatabase instance._


### live_research\import_research.py

#### `import_research_data()` (line 18)
_Import all JSON research files into the database._


### live_research\web\app.py

#### `get_db_connection()` (line 35)
_Create and return a database connection._


#### `index()` (line 43)
_Home page showing recent research entries._


#### `view_entry()` (line 79)
_View a specific research entry._

**Args**: entry_id


#### `search()` (line 121)
_Search for research entries._


#### `list_tags()` (line 194)
_List all tags with counts._


#### `api_entries()` (line 219)
_API endpoint to get all entries in JSON format._


#### `page_not_found()` (line 246)
_Handle 404 errors._

**Args**: e


#### `server_error()` (line 252)
_Handle 500 errors._

**Args**: e


#### `format_date_filter()` (line 258)
_Format a date string._

**Args**: date_str, format


### mcp\servers\aws_cli.py

#### `main()` (line 4)

### mcp\servers\aws_resource_manager.py

#### `main()` (line 4)

### mcp\servers\code_analysis.py

#### `main()` (line 4)

### mcp\servers\dataset_downloader.py

#### `main()` (line 4)

### mcp\servers\file_system.py

#### `main()` (line 4)

### mcp\servers\human_input.py

#### `main()` (line 4)

### mcp\servers\hypercode_syntax.py

#### `__init__()` (line 31)
**Args**: self


#### `_initialize()` (line 56)
_Initialize the MCP server_

**Args**: self, _params


#### `_generate_diagnostics()` (line 216)
_Generate IDE diagnostics from parsed functions_

**Args**: self, functions


#### `_get_annotation_hover_info()` (line 266)
_Generate hover information for semantic annotations_

**Args**: self, annotation


### mcp\servers\path_service.py

#### `main()` (line 4)

### mcp\servers\user_profile_manager.py

#### `main()` (line 4)

### mcp\servers\valkey_service.py

#### `main()` (line 124)
_Main function to run the Valkey Service MCP Server.
This function is called when the script is executed directly.
It starts the Uvicorn server, which in turn runs the FastAPI application._


### mcp\servers\web_search.py

#### `main()` (line 4)

### mcp\setup.py

#### `install_dependencies()` (line 15)
_Install required dependencies_


#### `verify_setup()` (line 27)
_Verify that MCP is properly set up_


#### `show_next_steps()` (line 45)
_Show next steps for using MCP_


#### `main()` (line 62)

### mcp\start_servers.py

#### `start_server()` (line 33)
_Start a specific MCP server_

**Args**: server_name


#### `list_servers()` (line 55)
_List all available servers_


#### `main()` (line 61)

### mcp\test_mcp.py

#### `test_server_imports()` (line 14)
_Test that all servers can be imported_


#### `main()` (line 48)

### new files to check\backend\research\db.py

#### `_get_database_url()` (line 35)
_Return the database URL to connect to.

Checks the ``RESEARCH_DATABASE_URL`` environment variable first.  If
it isn't defined then falls back to a local SQLite file so that
development and testing can proceed without a PostgreSQL server._


### new files to check\backend\research\models.py

#### `__repr__()` (line 52)
**Args**: self


#### `__repr__()` (line 81)
**Args**: self


#### `__repr__()` (line 102)
**Args**: self


#### `__repr__()` (line 124)
**Args**: self


#### `__repr__()` (line 144)
**Args**: self


#### `__repr__()` (line 169)
**Args**: self


#### `__repr__()` (line 193)
**Args**: self


#### `__repr__()` (line 219)
**Args**: self


### new files to check\backend\research\scripts\import_sources_from_folder.py

#### `infer_kind()` (line 25)
**Args**: path


#### `main()` (line 36)
**Args**: data_dir


### new files to check\backend\research\scripts\seed_basic_data.py

#### `main()` (line 25)

### scripts\build-hyper-database.py

#### `__init__()` (line 24)
_Initialize builder with repo root path._

**Args**: self, repo_root


#### `scan_python_file()` (line 32)
_Extract functions, classes from Python file._

**Args**: self, file_path


#### `scan_javascript_file()` (line 78)
_Extract functions from JavaScript (regex-based)._

**Args**: self, file_path


#### `should_skip_directory()` (line 107)
_Check if directory should be skipped._

**Args**: dirname


#### `build()` (line 127)
_Scan entire repo and build database._

**Args**: self


#### `generate_markdown_report()` (line 161)
_Generate HYPER_DATABASE.md report._

**Args**: self


#### `generate_json_report()` (line 250)
_Generate machine-readable HYPER_DATABASE.json._

**Args**: self


#### `main()` (line 265)
_Main entry point with proper encoding handling._


### scripts\build_knowledge_base.py

#### `__init__()` (line 38)
_Initialize the knowledge base builder.

Args:
    repo_root: Root directory of the HyperCode repository
    output_dir: Directory to store the generated knowledge base_

**Args**: self, repo_root, output_dir


#### `should_skip()` (line 79)
_Check if a path should be skipped during processing._

**Args**: self, path


#### `get_file_type()` (line 162)
_Get the file type category._

**Args**: self, path


#### `process_file()` (line 244)
_Process a single file and return its metadata._

**Args**: self, file_path


#### `build_index()` (line 287)
_Build the knowledge base index._

**Args**: self


#### `main()` (line 376)
_Main entry point for the script._


### scripts\document_processor.py

#### `get_file_hash()` (line 19)
_Generate a hash for file content._

**Args**: file_path


#### `extract_metadata()` (line 29)
_Extract basic metadata from any file._

**Args**: file_path


#### `extract_pdf_content()` (line 43)
_Extract text content from PDF files._

**Args**: file_path


#### `extract_markdown_content()` (line 74)
_Extract content from Markdown files with frontmatter support._

**Args**: file_path


#### `extract_docx_content()` (line 99)
_Extract text content from DOCX files._

**Args**: file_path


#### `extract_csv_content()` (line 133)
_Extract content from CSV files._

**Args**: file_path


#### `extract_text_content()` (line 154)
_Extract content from plain text files._

**Args**: file_path


#### `process_document()` (line 167)
_Process a document based on its file type._

**Args**: cls, file_path


### scripts\generate_directory_readmes.py

#### `create_readme()` (line 9)
_Create or update a README.md file with the given content._

**Args**: directory, content


#### `main()` (line 20)

### scripts\organize_docs.py

#### `setup_directories()` (line 131)
_Create the new documentation directory structure._


#### `move_files()` (line 138)
_Move files to their new locations based on the mapping._


#### `generate_report()` (line 172)
_Generate a migration report._

**Args**: moved_files, skipped_files


#### `main()` (line 204)

### scripts\run_lexer.py

#### `setUp()` (line 21)
_Create a fresh lexer instance for each test._

**Args**: self


#### `test_empty_source()` (line 25)
_Test that an empty source returns only an EOF token._

**Args**: self


#### `test_basic_tokens()` (line 31)
_Test basic token types are correctly identified._

**Args**: self


#### `test_string_literals()` (line 44)
_Test string literals with various contents._

**Args**: self


#### `test_numbers()` (line 58)
_Test different number formats._

**Args**: self


#### `test_arithmetic_expressions()` (line 83)
_Test complex arithmetic expressions._

**Args**: self


#### `test_comments()` (line 107)
_Test different types of comments are properly ignored._

**Args**: self


#### `test_error_handling()` (line 121)
_Test that the lexer properly handles and reports errors._

**Args**: self


#### `test_error_recovery()` (line 153)
_Test that the lexer can recover from invalid tokens and continue parsing._

**Args**: self


#### `_assert_token_types()` (line 179)
_Helper to assert token types match expected types.

Args:
    tokens: List of tokens to check
    expected_types: List of expected token types
    msg: Optional message to include in assertion errors_

**Args**: self, tokens, expected_types, msg


#### `test_lexer_error_class()` (line 201)
_Test that LexerError is properly defined and can be instantiated._

**Args**: self


### scripts\run_tests.py

#### `run_tests()` (line 16)
_Run pytest with the given arguments and coverage reporting._

**Args**: args


#### `main()` (line 49)
_Parse command line arguments and run tests._


### scripts\style_guide_collector.py

#### `__init__()` (line 20)
**Args**: self, repo_path


#### `_load_feedback()` (line 31)
_üìÇ Load existing feedback data_

**Args**: self


#### `_save_feedback()` (line 50)
_üíæ Save feedback data_

**Args**: self


#### `add_feedback()` (line 59)
_üìù Add new feedback entry

Args:
    feedback: Dictionary containing feedback data
    
Returns:
    bool: True if feedback was added successfully_

**Args**: self, feedback


#### `_update_analysis()` (line 101)
_üìä Update analysis based on new feedback

Args:
    entry: New feedback entry_

**Args**: self, entry


#### `analyze_feedback()` (line 150)
_üìä Generate comprehensive analysis of all feedback

Returns:
    Dict containing analysis results_

**Args**: self


#### `_get_top_items()` (line 176)
_üìä Get top items from a frequency dictionary

Args:
    items: Dictionary of item frequencies
    limit: Maximum number of items to return
    
Returns:
    List of top items with counts and percentages_

**Args**: self, items, limit


#### `_calculate_consensus()` (line 201)
_üìä Calculate consensus for preference categories

Args:
    preference_data: Nested dictionary of preferences
    
Returns:
    Dictionary with consensus analysis_

**Args**: self, preference_data


#### `_generate_recommendations()` (line 230)
_üí° Generate style guide recommendations based on feedback

Returns:
    List of recommendations with rationale_

**Args**: self


#### `import_github_issues()` (line 288)
_üì• Import feedback from GitHub issues

Args:
    github_token: GitHub API token (optional)
    
Returns:
    Number of issues imported_

**Args**: self, github_token


#### `generate_report()` (line 309)
_üìä Generate comprehensive feedback report

Args:
    output_file: Optional file to save report
    
Returns:
    Report content as string_

**Args**: self, output_file


#### `interactive_feedback()` (line 370)
_üéØ Interactive feedback collection from command line_

**Args**: self


#### `main()` (line 469)
_üöÄ Main entry point_


### scripts\sync-space-to-main.py

#### `log_error()` (line 25)
_Error-level log with traceback._

**Args**: msg


#### `log_info()` (line 46)
_Info-level log._

**Args**: msg


#### `log_success()` (line 51)
_Success-level log._

**Args**: msg


#### `log_warning()` (line 56)
_Warning-level log._

**Args**: msg


#### `deep_merge()` (line 61)
_Recursively merge source dict into destination dict._

**Args**: source, destination


#### `load_config()` (line 72)
_Load sync configuration from TOML file.
Fallback to defaults if file doesn't exist._

**Args**: config_path


#### `should_skip_file()` (line 112)
_Check if file should be skipped based on filters._

**Args**: filepath, config


#### `get_all_files()` (line 135)
_Recursively get all files in directory._

**Args**: directory


#### `copy_file()` (line 145)
_Copy file with directory creation. Returns True if copied/would copy._

**Args**: src, dst, dry_run


#### `remove_file()` (line 157)
_Remove file. Returns True if removed/would remove._

**Args**: filepath, dry_run


#### `sync_folder()` (line 168)
_Sync source folder to target folder (one-way).
Returns (copied, updated, errors) counts._

**Args**: source, target, config, dry_run


#### `delete_orphans()` (line 212)
_Remove files from target that no longer exist in source._

**Args**: target, source, dry_run


#### `sync_all_mappings()` (line 229)
_Execute all mappings from config._

**Args**: config, dry_run


#### `write_log()` (line 281)
_Write sync results to log file._

**Args**: log_file, stats, dry_run


#### `print_summary()` (line 303)
_Print sync summary to console._

**Args**: stats, dry_run


#### `main()` (line 327)

### scripts\test_mcp_connection.py

#### `check_port()` (line 25)
_Check if a port is open on the given host._

**Args**: host, port, timeout


#### `find_running_servers()` (line 34)
_Scan common ports to find running servers._

**Args**: host


#### `test_server_connection()` (line 46)
_Test connection to a single MCP server._

**Args**: server_name, base_url, port


#### `test_all_servers()` (line 82)
_Test connection to all MCP servers and print results._


#### `check_dependencies()` (line 124)
_Check if required dependencies are installed._


### scripts\test_perplexity_api.py

#### `main()` (line 17)
_Test the Perplexity API connection and make a sample query._


### scripts\update_doc_links.py

#### `update_links_in_file()` (line 27)
_Update links in a single file._

**Args**: file_path


#### `replace_link()` (line 39)
**Args**: match


#### `main()` (line 63)

### scripts\web_interface.py

#### `load_index()` (line 18)

#### `search_documents()` (line 24)
**Args**: query, limit


#### `index()` (line 58)

#### `search()` (line 63)

#### `get_document()` (line 71)
**Args**: doc_id


#### `serve_static()` (line 80)
**Args**: filename


#### `create_template_if_not_exists()` (line 84)
_Create the template directory and index.html if they don't exist_


### server.js

#### `unnamed_function()` (line 13)

#### `unnamed_function()` (line 22)

#### `unnamed_function()` (line 24)

#### `unnamed_function()` (line 46)

#### `unnamed_function()` (line 47)

#### `unnamed_function()` (line 56)

#### `unnamed_function()` (line 70)

#### `unnamed_function()` (line 71)

#### `unnamed_function()` (line 80)

#### `unnamed_function()` (line 100)

### src\ai_gateway\claude_adapter.py

#### `__init__()` (line 25)
**Args**: self, api_key


### src\ai_gateway\mistral_adapter.py

#### `__init__()` (line 25)
**Args**: self, api_key


### src\ai_gateway\ollama_adapter.py

#### `__init__()` (line 25)
**Args**: self, api_key


### src\ai_gateway\openai_adapter.py

#### `__init__()` (line 25)
**Args**: self, api_key


### src\build.py

#### `build()` (line 34)
_Builds a HyperCode source file to the target language.

Args:
    source_file: The path to the HyperCode source file (.hc).
    target: The target language for compilation._

**Args**: source_file, target


### src\claude_adapter.py

#### `__init__()` (line 25)
**Args**: self, api_key


### src\core\hypercode-\5 Core TypeScript Modules\code-analyzer.ts

#### `unnamed_function()` (line 56)

#### `unnamed_function()` (line 102)

#### `unnamed_function()` (line 103)

#### `unnamed_function()` (line 118)

#### `unnamed_function()` (line 164)

#### `unnamed_function()` (line 165)

#### `unnamed_function()` (line 180)

### src\core\hypercode-\5 Core TypeScript Modules\extension.ts

#### `unnamed_function()` (line 19)

#### `unnamed_function()` (line 52)

#### `unnamed_function()` (line 59)

### src\core\hypercode-\5 Core TypeScript Modules\spatial-visualizer.ts

#### `unnamed_function()` (line 77)

#### `unnamed_function()` (line 80)

#### `unnamed_function()` (line 141)

#### `unnamed_function()` (line 161)

#### `unnamed_function()` (line 162)

#### `unnamed_function()` (line 174)

#### `unnamed_function()` (line 176)

#### `unnamed_function()` (line 177)

#### `unnamed_function()` (line 187)

#### `unnamed_function()` (line 191)

#### `unnamed_function()` (line 195)

#### `unnamed_function()` (line 228)

#### `unnamed_function()` (line 263)

#### `unnamed_function()` (line 282)

### src\core\hypercode-\5 Core TypeScript Modules\visualization-panel.ts

#### `unnamed_function()` (line 237)

#### `unnamed_function()` (line 254)

#### `unnamed_function()` (line 265)

#### `unnamed_function()` (line 269)

#### `unnamed_function()` (line 273)

### src\core\hypercode-\DuelCode\duelcode_validator.py

#### `__init__()` (line 51)
**Args**: self, file_path


#### `_add_result()` (line 58)
_Add a validation result with proper line number._

**Args**: self, message, severity, line


#### `_find_lines()` (line 71)
_Find all lines matching the pattern with their line numbers._

**Args**: self, pattern


#### `validate()` (line 81)
_Run all validation checks._

**Args**: self


#### `validate_structure()` (line 93)
_Validate the overall document structure._

**Args**: self


#### `validate_headings()` (line 129)
_Validate heading hierarchy and formatting._

**Args**: self


#### `validate_code_blocks()` (line 171)
_Validate code blocks for proper formatting and language specification._

**Args**: self


#### `validate_checklists()` (line 210)
_Validate checklist items in the document._

**Args**: self


#### `validate_visual_elements()` (line 245)
_Validate visual elements like diagrams, images, etc._

**Args**: self


#### `validate_links()` (line 263)
_Validate internal and external links._

**Args**: self


#### `print_validation_results()` (line 283)
_Print validation results in a user-friendly format._

**Args**: validator


#### `main()` (line 316)
_Main entry point for the validator._


### src\core\hypercode-\DuelCode\enhanced_validator.py

#### `__init__()` (line 83)
**Args**: self, file_path


#### `_add_result()` (line 90)
_Add a validation result with proper line number._

**Args**: self, message, severity, line


#### `_find_lines()` (line 103)
_Find all lines matching the pattern with their line numbers._

**Args**: self, pattern


#### `validate_code_blocks_have_language()` (line 115)
_Ensure all code blocks have a specified language._

**Args**: self


#### `validate_has_visual_representation()` (line 128)
_Ensure each part has a visual representation._

**Args**: self


#### `validate_has_practical_exercise()` (line 140)
_Ensure each part has a practical exercise._

**Args**: self


#### `validate_has_learning_objectives()` (line 152)
_Ensure learning objectives are present and well-formed._

**Args**: self


#### `validate_has_checklist()` (line 174)
_Ensure a checklist is present and has items._

**Args**: self


#### `validate_has_conclusion()` (line 195)
_Ensure the document has a conclusion section._

**Args**: self


#### `validate_has_whats_next()` (line 204)
_Suggest adding a 'What's Next' section._

**Args**: self


#### `validate_code_quality()` (line 213)
_Check code quality in code blocks._

**Args**: self


#### `_analyze_code_block()` (line 234)
_Analyze a code block for quality issues._

**Args**: self, lines, lang, start_line


#### `_analyze_python_code()` (line 256)
_Python-specific code analysis._

**Args**: self, lines, _start_line


#### `_analyze_javascript_code()` (line 277)
_JavaScript/TypeScript-specific code analysis._

**Args**: self, lines, _start_line


#### `validate_has_glossary()` (line 291)
_Suggest adding a glossary for technical terms._

**Args**: self


#### `validate_has_see_also()` (line 325)
_Suggest adding a 'See Also' section with related resources._

**Args**: self


#### `validate_has_faq()` (line 334)
_Suggest adding an FAQ section._

**Args**: self


#### `validate_has_acknowledgments()` (line 344)
_Suggest adding an acknowledgments section._

**Args**: self


#### `validate_all()` (line 353)
_Run all validations._

**Args**: self


#### `print_validation_results()` (line 376)
_Print validation results in a user-friendly format._

**Args**: results


#### `main()` (line 407)
_Main entry point for the enhanced validator._


### src\core\hypercode-\DuelCode\test_framework.py

#### `__init__()` (line 45)
**Args**: self, duelcode_dir


#### `discover_tutorials()` (line 49)
_Find all tutorial markdown files._

**Args**: self


#### `run_validator()` (line 56)
_Run the ultra validator on a file._

**Args**: self, file_path


#### `parse_validator_output()` (line 71)
_Parse validator output to count issues by severity._

**Args**: self, output


#### `test_tutorial()` (line 99)
_Test a single tutorial file._

**Args**: self, tutorial_path


#### `test_validator_integrity()` (line 135)
_Test that validator itself is working correctly._

**Args**: self


#### `test_template_validity()` (line 176)
_Test that templates pass validation._

**Args**: self


#### `run_all_tests()` (line 221)
_Run the complete test suite._

**Args**: self


#### `generate_report()` (line 248)
_Generate a detailed test report._

**Args**: self


#### `main()` (line 295)
_Main entry point._


### src\core\hypercode-\DuelCode\test_validator.py

#### `test_valid_file()` (line 11)
_Test with a valid DuelCode file._


#### `test_invalid_file()` (line 65)
_Test with an invalid DuelCode file._


#### `main()` (line 90)
_Run the test suite._


### src\core\hypercode-\DuelCode\ultra_validator.py

#### `__init__()` (line 88)
**Args**: self, file_path


#### `_add_result()` (line 95)
**Args**: self, message, severity, line, suggestion


#### `_find_lines()` (line 106)
**Args**: self, pattern


#### `validate_code_blocks_have_language()` (line 118)
_Validate all code blocks have language specifications._

**Args**: self


#### `validate_has_visual_representation()` (line 152)
_Check for visual elements like diagrams, charts, or ASCII art._

**Args**: self


#### `validate_has_practical_exercise()` (line 171)
_Check for practical exercises or challenges._

**Args**: self


#### `validate_has_learning_objectives()` (line 192)
_Check for learning objectives section._

**Args**: self


#### `validate_has_checklist()` (line 215)
_Check for checklist elements._

**Args**: self


#### `validate_has_conclusion()` (line 234)
_Check for conclusion section._

**Args**: self


#### `validate_has_whats_next()` (line 257)
_Check for 'What's Next' section._

**Args**: self


#### `validate_code_quality()` (line 278)
_Validate code block quality and best practices._

**Args**: self


#### `_validate_code_block_content()` (line 305)
_Validate specific code block content based on language._

**Args**: self, block_lines, lang, start_line


#### `validate_has_glossary()` (line 340)
_Check for glossary section._

**Args**: self


#### `validate_has_see_also()` (line 360)
_Check for 'See Also' section._

**Args**: self


#### `validate_has_faq()` (line 380)
_Check for FAQ section._

**Args**: self


#### `validate_has_acknowledgments()` (line 402)
_Check for acknowledgments section._

**Args**: self


#### `validate_accessibility()` (line 422)
_Check for accessibility features._

**Args**: self


#### `validate_interactive_elements()` (line 443)
_Check for interactive elements._

**Args**: self


#### `validate_all()` (line 463)
_Run all validations and return results._

**Args**: self


#### `print_results()` (line 487)
_Print validation results in a formatted way._

**Args**: self


#### `main()` (line 537)

### src\core\hypercode-\DuelCode\validate_duelcode.py

#### `__init__()` (line 24)
**Args**: self, file_path


#### `validate_sections()` (line 30)
_Check if all required sections are present._

**Args**: self


#### `check_formatting()` (line 39)
_Check for common formatting issues._

**Args**: self


#### `check_visual_aids()` (line 55)
_Check for presence of visual aids._

**Args**: self


#### `validate()` (line 60)
_Run all validations and return results._

**Args**: self


#### `main()` (line 68)

### src\core\hypercode-\HyperCode showcase\src\__tests__\hypercode.test.ts

#### `unnamed_function()` (line 4)

#### `unnamed_function()` (line 7)

#### `unnamed_function()` (line 11)

#### `unnamed_function()` (line 17)

#### `unnamed_function()` (line 23)

#### `unnamed_function()` (line 29)

#### `unnamed_function()` (line 31)

### src\core\hypercode-\HyperCode showcase\src\index.ts

#### `unnamed_function()` (line 13)

#### `unnamed_function()` (line 29)

#### `unnamed_function()` (line 32)

#### `unnamed_function()` (line 33)

#### `unnamed_function()` (line 48)

#### `unnamed_function()` (line 84)

### src\core\hypercode-\ai_gateway\claude_adapter.py

#### `__init__()` (line 25)
**Args**: self, api_key


### src\core\hypercode-\ai_gateway\mistral_adapter.py

#### `__init__()` (line 25)
**Args**: self, api_key


### src\core\hypercode-\ai_gateway\ollama_adapter.py

#### `__init__()` (line 25)
**Args**: self, api_key


### src\core\hypercode-\ai_gateway\openai_adapter.py

#### `__init__()` (line 25)
**Args**: self, api_key


### src\core\hypercode-\code_analyzer_ai.py

#### `__init__()` (line 23)
**Args**: self


#### `analyze_file()` (line 26)
_Analyze a Python file with AI assistance_

**Args**: self, file_path


#### `_analyze_complexity()` (line 73)
_Analyze code complexity indicators_

**Args**: self, tree


#### `_check_docstrings()` (line 114)
_Check for docstring coverage_

**Args**: self, tree


#### `_get_ai_code_analysis()` (line 156)
_Get AI analysis of code from Perplexity_

**Args**: self, code, file_path


#### `analyze_project()` (line 184)
_Analyze entire project_

**Args**: self, project_path


#### `_get_project_ai_insights()` (line 231)
_Get AI insights for the entire project_

**Args**: self, analyses, stats


#### `save_analysis()` (line 263)
_Save analysis to file_

**Args**: self, analysis, filename


#### `print_summary()` (line 271)
_Print analysis summary_

**Args**: self, analysis


#### `main()` (line 289)
_Main function_


### src\core\hypercode-\debug_search.py

#### `debug_search()` (line 15)
_Debug why space data isn't being found_


### src\core\hypercode-\demo_ai_research.py

#### `demo_ai_research_queries()` (line 16)
_Demonstrate AI Research integration with Perplexity_


#### `test_document_specific_queries()` (line 90)
_Test queries specific to the HyperCode AI Research document_


### src\core\hypercode-\demo_enhanced_client.py

#### `demo_knowledge_base_integration()` (line 16)
_Demonstrate the knowledge base integration_


#### `demonstrate_memory_persistence()` (line 131)
_Demonstrate that the knowledge base persists between sessions_


### src\core\hypercode-\final_integration_test.py

#### `final_integration_test()` (line 15)
_Complete test of the Perplexity Space integration_


### src\core\hypercode-\health_scanner_ai.py

#### `__init__()` (line 22)
**Args**: self


#### `analyze_project_structure()` (line 26)
_Analyze project structure and identify health issues_

**Args**: self


#### `analyze_dependencies()` (line 69)
_Analyze dependency management_

**Args**: self


#### `analyze_security()` (line 111)
_Analyze security configuration_

**Args**: self


#### `get_ai_recommendations()` (line 144)
_Get AI-powered recommendations based on health scan_

**Args**: self, health_data


#### `run_full_scan()` (line 171)
_Run complete health scan with AI analysis_

**Args**: self


#### `save_report()` (line 222)
_Save health scan report to file_

**Args**: self, report, filename


#### `print_summary()` (line 228)
_Print a summary of the health scan_

**Args**: self, report


#### `main()` (line 248)
_Main function to run the health scanner_


### src\core\hypercode-\hypercode-proto\app.js

#### `unnamed_function()` (line 70)

#### `unnamed_function()` (line 85)

#### `unnamed_function()` (line 89)

#### `unnamed_function()` (line 92)

#### `unnamed_function()` (line 95)

#### `unnamed_function()` (line 101)

#### `unnamed_function()` (line 104)

#### `unnamed_function()` (line 109)

#### `unnamed_function()` (line 120)

#### `unnamed_function()` (line 121)

#### `unnamed_function()` (line 134)

#### `unnamed_function()` (line 145)

#### `unnamed_function()` (line 161)

#### `unnamed_function()` (line 166)

#### `unnamed_function()` (line 173)

#### `unnamed_function()` (line 187)

#### `unnamed_function()` (line 188)

#### `unnamed_function()` (line 195)

#### `unnamed_function()` (line 203)

#### `unnamed_function()` (line 214)

#### `unnamed_function()` (line 221)

#### `unnamed_function()` (line 242)

#### `unnamed_function()` (line 258)

#### `unnamed_function()` (line 260)

#### `unnamed_function()` (line 262)

#### `unnamed_function()` (line 270)

#### `unnamed_function()` (line 298)

#### `unnamed_function()` (line 304)

#### `unnamed_function()` (line 305)

#### `unnamed_function()` (line 314)

#### `unnamed_function()` (line 316)

#### `unnamed_function()` (line 322)

#### `unnamed_function()` (line 323)

#### `unnamed_function()` (line 325)

#### `unnamed_function()` (line 333)

#### `unnamed_function()` (line 344)

#### `unnamed_function()` (line 345)

#### `unnamed_function()` (line 352)

#### `unnamed_function()` (line 356)

#### `unnamed_function()` (line 384)

#### `unnamed_function()` (line 389)

#### `unnamed_function()` (line 403)

#### `unnamed_function()` (line 419)

#### `unnamed_function()` (line 429)

#### `unnamed_function()` (line 438)

#### `unnamed_function()` (line 439)

#### `unnamed_function()` (line 449)

#### `unnamed_function()` (line 450)

#### `unnamed_function()` (line 451)

#### `unnamed_function()` (line 462)

#### `unnamed_function()` (line 467)

#### `unnamed_function()` (line 472)

#### `unnamed_function()` (line 477)

#### `unnamed_function()` (line 481)

#### `unnamed_function()` (line 487)

#### `unnamed_function()` (line 495)

#### `unnamed_function()` (line 501)

#### `unnamed_function()` (line 502)

#### `unnamed_function()` (line 503)

#### `unnamed_function()` (line 517)

#### `unnamed_function()` (line 528)

#### `unnamed_function()` (line 532)

#### `unnamed_function()` (line 561)

#### `unnamed_function()` (line 562)

#### `unnamed_function()` (line 570)

#### `unnamed_function()` (line 592)

#### `unnamed_function()` (line 593)

#### `unnamed_function()` (line 600)

#### `unnamed_function()` (line 604)

#### `unnamed_function()` (line 610)

#### `unnamed_function()` (line 670)

#### `unnamed_function()` (line 681)

#### `unnamed_function()` (line 691)

#### `unnamed_function()` (line 696)

#### `unnamed_function()` (line 704)

#### `unnamed_function()` (line 714)

#### `unnamed_function()` (line 722)

#### `unnamed_function()` (line 761)

#### `unnamed_function()` (line 766)

### src\core\hypercode-\import-helper.py

#### `__init__()` (line 16)
**Args**: self, output_dir


#### `validate_document()` (line 21)
_Validate a document structure
Returns (is_valid, error_message)_

**Args**: self, doc


#### `load_template()` (line 63)
_Load documents from JSON template file_

**Args**: self, filepath


#### `validate_all()` (line 83)
_Validate all loaded documents_

**Args**: self


#### `generate_report()` (line 95)
_Generate a validation report_

**Args**: self


#### `create_import_script()` (line 141)
_Generate a Python script to import the data_

**Args**: self, output_file


#### `create_template_instructions()` (line 193)
_Generate detailed instructions for filling the template_

**Args**: self, output_file


#### `main()` (line 264)
_CLI interface for the import helper_


### src\core\hypercode-\import_all_space_data.py

#### `format_content()` (line 16)
_Recursively format nested data into readable text_

**Args**: data, indent


#### `import_all_hypercode_data()` (line 41)
_Import all sections of your HyperCode Space data_


### src\core\hypercode-\import_hypercode_data.py

#### `import_hypercode_space_data()` (line 16)
_Import your actual HyperCode Space data_


### src\core\hypercode-\import_perplexity_space.py

#### `create_manual_import_script()` (line 17)
_Create a script for manual data entry from Perplexity Space_


#### `create_json_import_template()` (line 86)
_Create a JSON template for importing data_


#### `import_from_json()` (line 115)
_Import data from JSON file_


#### `test_imported_data()` (line 153)
_Test the imported data with context-aware queries_


#### `show_import_menu()` (line 188)
_Show the import menu_


### src\core\hypercode-\mcp\servers\aws_cli.py

#### `main()` (line 4)

### src\core\hypercode-\mcp\servers\aws_resource_manager.py

#### `main()` (line 4)

### src\core\hypercode-\mcp\servers\code_analysis.py

#### `main()` (line 4)

### src\core\hypercode-\mcp\servers\dataset_downloader.py

#### `main()` (line 4)

### src\core\hypercode-\mcp\servers\file_system.py

#### `main()` (line 4)

### src\core\hypercode-\mcp\servers\human_input.py

#### `main()` (line 4)

### src\core\hypercode-\mcp\servers\hypercode_syntax.py

#### `__init__()` (line 31)
**Args**: self


#### `_initialize()` (line 56)
_Initialize the MCP server_

**Args**: self, _params


#### `_generate_diagnostics()` (line 216)
_Generate IDE diagnostics from parsed functions_

**Args**: self, functions


#### `_get_annotation_hover_info()` (line 266)
_Generate hover information for semantic annotations_

**Args**: self, annotation


### src\core\hypercode-\mcp\servers\path_service.py

#### `main()` (line 4)

### src\core\hypercode-\mcp\servers\user_profile_manager.py

#### `main()` (line 4)

### src\core\hypercode-\mcp\servers\valkey_service.py

#### `main()` (line 144)
_Main function to run the Valkey Service MCP Server.
This function is called when the script is executed directly.
It starts the Uvicorn server, which in turn runs the FastAPI application._


### src\core\hypercode-\mcp\servers\web_search.py

#### `main()` (line 4)

### src\core\hypercode-\mcp\setup.py

#### `install_dependencies()` (line 16)
_Install required dependencies_


#### `verify_setup()` (line 31)
_Verify that MCP is properly set up_


#### `show_next_steps()` (line 54)
_Show next steps for using MCP_


#### `main()` (line 72)

### src\core\hypercode-\mcp\start_servers.py

#### `start_server()` (line 34)
_Start a specific MCP server_

**Args**: server_name


#### `list_servers()` (line 59)
_List all available servers_


#### `main()` (line 66)

### src\core\hypercode-\mcp\test_mcp.py

#### `test_server_imports()` (line 15)
_Test that all servers can be imported_


#### `main()` (line 47)

### src\core\hypercode-\perplexity_space_collector.py

#### `quick_copy_paste_collector()` (line 18)
_Quick collector for copy-paste workflow_


#### `create_structured_template()` (line 117)
_Create a structured JSON template for bulk import_


#### `show_bro_hacks()` (line 167)
_Show BROski's pro tips_


#### `main_menu()` (line 207)
_Main menu for the collector_


### src\core\hypercode-\perplexity_space_integration.py

#### `main()` (line 16)

### src\core\hypercode-\scripts\style_guide_collector.py

#### `__init__()` (line 19)
**Args**: self, repo_path


#### `_load_feedback()` (line 30)
_üìÇ Load existing feedback data_

**Args**: self


#### `_save_feedback()` (line 49)
_üíæ Save feedback data_

**Args**: self


#### `add_feedback()` (line 58)
_üìù Add new feedback entry

Args:
    feedback: Dictionary containing feedback data

Returns:
    bool: True if feedback was added successfully_

**Args**: self, feedback


#### `_update_analysis()` (line 100)
_üìä Update analysis based on new feedback

Args:
    entry: New feedback entry_

**Args**: self, entry


#### `analyze_feedback()` (line 149)
_üìä Generate comprehensive analysis of all feedback

Returns:
    Dict containing analysis results_

**Args**: self


#### `_get_top_items()` (line 187)
_üìä Get top items from a frequency dictionary

Args:
    items: Dictionary of item frequencies
    limit: Maximum number of items to return

Returns:
    List of top items with counts and percentages_

**Args**: self, items, limit


#### `_calculate_consensus()` (line 210)
_üìä Calculate consensus for preference categories

Args:
    preference_data: Nested dictionary of preferences

Returns:
    Dictionary with consensus analysis_

**Args**: self, preference_data


#### `_generate_recommendations()` (line 243)
_üí° Generate style guide recommendations based on feedback

Returns:
    List of recommendations with rationale_

**Args**: self


#### `import_github_issues()` (line 323)
_üì• Import feedback from GitHub issues

Args:
    github_token: GitHub API token (optional)

Returns:
    Number of issues imported_

**Args**: self, github_token


#### `generate_report()` (line 346)
_üìä Generate comprehensive feedback report

Args:
    output_file: Optional file to save report

Returns:
    Report content as string_

**Args**: self, output_file


#### `interactive_feedback()` (line 413)
_üéØ Interactive feedback collection from command line_

**Args**: self


#### `main()` (line 521)
_üöÄ Main entry point_


### src\core\hypercode-\scripts\test_perplexity_api.py

#### `main()` (line 17)
_Test the Perplexity API connection and make a sample query._


### src\core\hypercode-\spatial_visualizer\src\code-analyzer.ts

#### `unnamed_function()` (line 56)

#### `unnamed_function()` (line 102)

#### `unnamed_function()` (line 103)

#### `unnamed_function()` (line 118)

#### `unnamed_function()` (line 164)

#### `unnamed_function()` (line 165)

#### `unnamed_function()` (line 180)

### src\core\hypercode-\spatial_visualizer\src\extension.ts

#### `unnamed_function()` (line 19)

#### `unnamed_function()` (line 52)

#### `unnamed_function()` (line 59)

### src\core\hypercode-\spatial_visualizer\src\spatial-visualizer.ts

#### `unnamed_function()` (line 77)

#### `unnamed_function()` (line 80)

#### `unnamed_function()` (line 141)

#### `unnamed_function()` (line 161)

#### `unnamed_function()` (line 162)

#### `unnamed_function()` (line 174)

#### `unnamed_function()` (line 176)

#### `unnamed_function()` (line 177)

#### `unnamed_function()` (line 187)

#### `unnamed_function()` (line 191)

#### `unnamed_function()` (line 195)

#### `unnamed_function()` (line 228)

#### `unnamed_function()` (line 263)

#### `unnamed_function()` (line 282)

### src\core\hypercode-\spatial_visualizer\src\visualization-panel.ts

#### `unnamed_function()` (line 237)

#### `unnamed_function()` (line 254)

#### `unnamed_function()` (line 265)

#### `unnamed_function()` (line 269)

#### `unnamed_function()` (line 273)

### src\core\hypercode-\src\build.py

#### `build()` (line 34)
_Builds a HyperCode source file to the target language.

Args:
    source_file: The path to the HyperCode source file (.hc).
    target: The target language for compilation._

**Args**: source_file, target


### src\core\hypercode-\src\core\lexer.py

#### `__init__()` (line 49)
_Initialize the lexer with source code.

Args:
    source: The source code string to tokenize_

**Args**: self, source


#### `tokenize()` (line 110)
_Convert the source code into a list of tokens.

Returns:
    List of tokens representing the source code.

Example:
    >>> lexer = Lexer("let x = 42")
    >>> tokens = lexer.tokenize()
    >>> [t.type for t in tokens]
    [TokenType.LET, TokenType.IDENTIFIER, TokenType.EQUAL, TokenType.NUMBER, TokenType.EOF]_

**Args**: self


#### `is_at_end()` (line 134)
**Args**: self


#### `scan_token()` (line 137)
_Scan the next token from the source code.

This method processes a single token and adds it to the tokens list.
It handles all token types including keywords, identifiers, literals,
and operators.

Raises:
    ValueError: If an unexpected character is encountered_

**Args**: self


#### `advance()` (line 228)
**Args**: self


#### `add_token()` (line 233)
_Add a new token to the tokens list.

Args:
    type: The token type
    literal: The literal value (for numbers, strings, etc.)_

**Args**: self, type, literal


#### `error()` (line 246)
_Record a lexing error.

Args:
    message: Error message_

**Args**: self, message


#### `synchronize()` (line 262)
_Synchronize after an error by skipping tokens until we find a statement boundary._

**Args**: self


#### `previous()` (line 274)
_Return the previous character._

**Args**: self


#### `peek_next()` (line 280)
_Look ahead two characters._

**Args**: self


#### `match()` (line 286)
**Args**: self, expected


#### `peek()` (line 295)
**Args**: self


#### `string()` (line 300)
_Parse a string literal._

**Args**: self


#### `is_digit()` (line 362)
_Check if a character is a digit (0-9)._

**Args**: self, char


#### `number()` (line 366)
_Parse a number literal (integer or float)._

**Args**: self


#### `is_alpha()` (line 421)
_Check if a character is alphabetic or underscore._

**Args**: self, char


#### `is_alphanumeric()` (line 425)
_Check if a character is alphanumeric or underscore._

**Args**: self, char


#### `is_hex_digit()` (line 429)
_Check if a character is a valid hexadecimal digit._

**Args**: self, char


#### `identifier()` (line 433)
_Parse an identifier or keyword._

**Args**: self


### src\core\hypercode-\src\core\parser.py

#### `__init__()` (line 13)
**Args**: self, tokens


#### `parse()` (line 17)
_Parse the entire program._

**Args**: self


#### `declaration()` (line 26)
**Args**: self


#### `var_declaration()` (line 39)
**Args**: self


#### `statement()` (line 64)
**Args**: self


#### `print_statement()` (line 71)
**Args**: self


#### `expression_statement()` (line 76)
**Args**: self


#### `block()` (line 81)
**Args**: self


#### `expression()` (line 88)
**Args**: self


#### `assignment()` (line 91)
**Args**: self


#### `equality()` (line 106)
**Args**: self


#### `comparison()` (line 116)
**Args**: self


#### `term()` (line 129)
**Args**: self


#### `factor()` (line 137)
**Args**: self


#### `unary()` (line 145)
**Args**: self


#### `primary()` (line 152)
**Args**: self


#### `match()` (line 184)
**Args**: self


#### `consume()` (line 191)
**Args**: self, type_, message


#### `error()` (line 201)
**Args**: self, token, message


#### `synchronize()` (line 207)
**Args**: self


#### `check()` (line 227)
**Args**: self, type_


#### `advance()` (line 232)
**Args**: self


#### `is_at_end()` (line 237)
**Args**: self


#### `peek()` (line 240)
**Args**: self


#### `previous()` (line 243)
**Args**: self


### src\core\hypercode-\src\hypercode-backend-js-COMPLETE.py

#### `__init__()` (line 30)
_Initialize compiler.

Args:
    ast: Root AST node (PROGRAM)
    optimize: Enable optimizations_

**Args**: self, ast, optimize


#### `compile()` (line 42)
_Compile AST to JavaScript.

Returns:
    JavaScript source code_

**Args**: self


#### `_generate_header()` (line 65)
_Generate JavaScript header_

**Args**: self


#### `_generate_setup()` (line 74)
_Generate setup code (memory tape, pointer, I/O)_

**Args**: self


#### `_generate_main()` (line 110)
_Generate JavaScript for AST node.

Args:
    node: AST node

Returns:
    JavaScript code_

**Args**: self, node


#### `_generate_footer()` (line 162)
_Generate JavaScript footer_

**Args**: self


#### `_indent()` (line 179)
_Get current indentation_

**Args**: self


#### `optimize_ast()` (line 183)
_Optimize AST (future: loop unrolling, dead code elimination).

Args:
    node: AST node

Returns:
    Optimized AST node_

**Args**: self, node


#### `main()` (line 200)
_CLI interface for JavaScript backend_


### src\core\hypercode-\src\hypercode-launch-kit.py

#### `__init__()` (line 26)
**Args**: self


#### `create_readme()` (line 30)
_Create the ultimate README.md_

**Args**: self


#### `create_launch_checklist()` (line 367)
_Create launch day checklist_

**Args**: self


#### `create_launch_script()` (line 620)
_Create automated launch script_

**Args**: self


#### `create_first_30_days()` (line 718)
_Create 30-day success roadmap_

**Args**: self


#### `print_summary()` (line 974)
_Print beautiful summary_

**Args**: self


#### `main()` (line 1007)
_Run launch kit initialization_


### src\core\hypercode-\src\hypercode-lexer-COMPLETE.py

#### `__repr__()` (line 54)
_Neurodivergent-friendly representation_

**Args**: self


#### `__init__()` (line 62)
**Args**: self, message, line, column


#### `__init__()` (line 95)
_Initialize lexer with source code.

Args:
    source: HyperCode source code
    filename: Source filename (for error reporting)_

**Args**: self, source, filename


#### `tokenize()` (line 110)
_Convert HyperCode source to token stream.

Returns:
    List of Token objects

Raises:
    LexerError: On invalid syntax_

**Args**: self


#### `_advance_position()` (line 169)
_Update position tracking after processing character_

**Args**: self, char


#### `_skip_comment()` (line 179)
_Skip characters until end of line_

**Args**: self


#### `get_tokens()` (line 184)
_Return current token list_

**Args**: self


#### `filter_tokens()` (line 188)
_Get tokens excluding certain types.

Args:
    exclude_types: Token types to exclude

Returns:
    Filtered token list_

**Args**: self, exclude_types


#### `print_tokens()` (line 205)
_Print tokens in readable format.

Args:
    colorize: Use ANSI colors (helps ADHD/dyslexia)_

**Args**: self, colorize


#### `get_statistics()` (line 236)
_Get token statistics (useful for analysis).

Returns:
    Dictionary with token counts_

**Args**: self


#### `main()` (line 250)
_CLI interface for the lexer_


### src\core\hypercode-\src\hypercode-parser-COMPLETE.py

#### `__repr__()` (line 51)
_Pretty-print AST (neurodivergent-friendly)_

**Args**: self, indent


#### `__init__()` (line 71)
**Args**: self, message, token


#### `__init__()` (line 94)
_Initialize parser with token stream.

Args:
    tokens: List of tokens from lexer_

**Args**: self, tokens


#### `parse()` (line 105)
_Parse tokens into AST.

Returns:
    Root AST node (PROGRAM)

Raises:
    ParserError: On syntax errors_

**Args**: self


#### `_parse_statement()` (line 127)
_Parse a single statement_

**Args**: self


#### `_parse_loop()` (line 174)
_Parse loop structure: [ statements ]

Returns:
    Loop AST node_

**Args**: self


#### `_advance()` (line 209)
_Move to next token_

**Args**: self


#### `_is_at_end()` (line 215)
_Check if at end of token stream_

**Args**: self


#### `validate()` (line 222)
_Validate AST structure.

Returns:
    List of warnings (empty if no issues)_

**Args**: self


#### `print_ast()` (line 237)
_Print AST in readable format.

Args:
    node: AST node to print (defaults to root)
    indent: Indentation level_

**Args**: self, node, indent


#### `main()` (line 251)
_CLI interface for the parser_


### src\core\hypercode-\src\hypercode\__main__.py

#### `main()` (line 6)

### src\core\hypercode-\src\hypercode\config.py

#### `get_headers()` (line 27)
_Get headers for API requests_

**Args**: cls


### src\core\hypercode-\src\hypercode\core\ast.py

#### `accept()` (line 10)
**Args**: self, visitor


### src\core\hypercode-\src\hypercode\core\error_handler.py

#### `report_parse_error()` (line 5)
**Args**: token, message


#### `report()` (line 12)
**Args**: line, where, message


### src\core\hypercode-\src\hypercode\core\lexer.py

#### `__init__()` (line 35)
**Args**: self, message, line, column


#### `__init__()` (line 109)
_Initialize the lexer with source code.

Args:
    source: The source code to tokenize_

**Args**: self, source


#### `tokenize()` (line 126)
_Convert source code into a list of tokens.

Args:
    source: Optional source code to tokenize. If not provided, uses the source
           passed to the constructor.

Returns:
    List of Token objects

Raises:
    ValueError: If no source code is provided_

**Args**: self, source


#### `_match_patterns()` (line 161)
_Try to match the current position against all token patterns._

**Args**: self


#### `_update_position()` (line 187)
_Update line and column numbers based on the given text._

**Args**: self, text


#### `_add_token()` (line 206)
_Add a token to the token list.

Args:
    token_type: The type of the token.
    lexeme: The lexeme of the token (the actual text from the source)._

**Args**: self, token_type, lexeme


#### `_handle_unknown()` (line 270)
_Handle unknown characters in the source._

**Args**: self


### src\core\hypercode-\src\hypercode\core\parser.py

#### `__init__()` (line 29)
**Args**: self, tokens


#### `parse()` (line 33)
_Parse the entire program._

**Args**: self


#### `declaration()` (line 42)
**Args**: self


#### `var_declaration()` (line 51)
**Args**: self


#### `statement()` (line 67)
**Args**: self


#### `print_statement()` (line 76)
**Args**: self


#### `intent_statement()` (line 81)
**Args**: self


#### `expression_statement()` (line 96)
**Args**: self


#### `block()` (line 101)
**Args**: self


#### `expression()` (line 108)
**Args**: self


#### `assignment()` (line 111)
**Args**: self


#### `equality()` (line 126)
**Args**: self


#### `comparison()` (line 136)
**Args**: self


#### `term()` (line 149)
**Args**: self


#### `factor()` (line 157)
**Args**: self


#### `unary()` (line 165)
**Args**: self


#### `primary()` (line 172)
**Args**: self


#### `_primary()` (line 189)
**Args**: self


#### `finish_call()` (line 220)
**Args**: self, callee


#### `match()` (line 233)
**Args**: self


#### `consume()` (line 240)
**Args**: self, type_, message


#### `error()` (line 247)
**Args**: self, token, message


#### `synchronize()` (line 253)
**Args**: self


#### `check()` (line 273)
**Args**: self, type_


#### `advance()` (line 278)
**Args**: self


#### `is_at_end()` (line 283)
**Args**: self


#### `peek()` (line 286)
**Args**: self


#### `previous()` (line 289)
**Args**: self


### src\core\hypercode-\src\hypercode\core\tokens.py

#### `__str__()` (line 68)
**Args**: self


### src\core\hypercode-\src\hypercode\enhanced_perplexity_client.py

#### `__init__()` (line 21)
**Args**: self, kb_path


#### `query_with_context()` (line 25)
_Send a query with relevant knowledge base context_

**Args**: self, prompt, use_knowledge_base, model


#### `add_research_data()` (line 61)
_Add research data to the knowledge base_

**Args**: self, title, content, url, tags


#### `search_research_data()` (line 71)
_Search the knowledge base_

**Args**: self, query, limit


#### `list_research_documents()` (line 75)
_List all research documents_

**Args**: self


#### `get_document()` (line 79)
_Get a specific document_

**Args**: self, doc_id


#### `delete_document()` (line 83)
_Delete a document_

**Args**: self, doc_id


#### `import_from_perplexity_space()` (line 87)
_Import data from Perplexity Space export_

**Args**: self, space_data


#### `test_context_integration()` (line 123)
_Test the context integration_

**Args**: self


#### `create_perplexity_space_import_template()` (line 175)
_Create a template for importing Perplexity Space data_


### src\core\hypercode-\src\hypercode\knowledge_base.py

#### `__post_init__()` (line 28)
**Args**: self


#### `generate_id()` (line 36)
_Generate unique ID from content hash_

**Args**: self


#### `validate()` (line 41)
_Validate document data_

**Args**: self


#### `update_timestamp()` (line 53)
_Update the last_updated timestamp_

**Args**: self


#### `__init__()` (line 103)
**Args**: self, kb_path


#### `load()` (line 109)
_Load knowledge base from file_

**Args**: self


#### `save()` (line 125)
_Save knowledge base to file_

**Args**: self


#### `add_document()` (line 135)
_Add a new research document_

**Args**: self, title, content, url, tags


#### `search_documents()` (line 163)
_Search documents by query_

**Args**: self, query, limit


#### `get_context_for_query()` (line 226)
_Get relevant context for a query_

**Args**: self, query, max_context_length


#### `list_documents()` (line 256)
_List all documents_

**Args**: self


#### `get_document()` (line 260)
_Get a specific document by ID_

**Args**: self, doc_id


#### `delete_document()` (line 264)
_Delete a document_

**Args**: self, doc_id


#### `update_document()` (line 272)
_Update an existing document_

**Args**: self, doc_id


#### `search_by_tags()` (line 286)
_Search documents by tags with AND/OR operators_

**Args**: self, tags, operator


#### `get_document_statistics()` (line 305)
_Get statistics about the knowledge base_

**Args**: self


#### `export_format()` (line 330)
_Export knowledge base in different formats_

**Args**: self, format_type


#### `validate_all_documents()` (line 352)
_Validate all documents and return list of errors_

**Args**: self


#### `cleanup_duplicates()` (line 362)
_Remove duplicate documents based on content hash_

**Args**: self


#### `initialize_sample_data()` (line 383)
_Initialize with sample HyperCode research data_


### src\core\hypercode-\src\hypercode\perplexity_client.py

#### `__init__()` (line 15)
_Initialize the Perplexity client.

Args:
    api_key: Optional API key. If not provided, will use the one from config._

**Args**: self, api_key


#### `query()` (line 30)
_Send a query to the Perplexity API.

Args:
    prompt: The prompt to send to the API.
    model: The model to use for the query.

Returns:
    The API response as a dictionary._

**Args**: self, prompt, model


#### `test_connection()` (line 72)
_Test the connection to the Perplexity API_


### src\core\hypercode-\src\hypercode\repl.py

#### `run_repl()` (line 7)

#### `run()` (line 22)
**Args**: source


### src\core\hypercode-\src\hypercode_idea_generator.py

#### `__init__()` (line 439)
**Args**: self


#### `get_ideas_by_category()` (line 443)
_Get ideas by category and optionally by difficulty level.

Args:
    category: 'language_design', 'features_tooling',
             'community', 'accessibility'
    level: 'beginner', 'intermediate', 'advanced' (optional)

Returns:
    List of ideas_

**Args**: self, category, level


#### `get_top_ideas()` (line 468)
_Get most-voted ideas across all categories._

**Args**: self, category, limit


#### `vote_for_idea()` (line 487)
_Vote for an idea._

**Args**: self, idea_id


#### `get_trending_ideas()` (line 497)
_Get trending ideas (high votes + recent activity)._

**Args**: self


#### `format_idea_card()` (line 502)
_Format idea for display.

Returns:
    Formatted string for rendering_

**Args**: self, idea


#### `main()` (line 528)
_Interactive idea generator CLI_


### src\core\hypercode-\src\hypercode_lexer_fixed.py

#### `__repr__()` (line 54)
_Readable representation_

**Args**: self


#### `__init__()` (line 71)
**Args**: self, message, line, column, context


#### `__init__()` (line 125)
_Initialize lexer.

Args:
    source: Source code
    filename: Filename for error reporting
    preserve_escapes: If True, keep escapes in output (e.g., "hello\"world")
                    If False, convert to actual chars (e.g., "hello"world")_

**Args**: self, source, filename, preserve_escapes


#### `tokenize()` (line 145)
_Convert source to token stream.

Returns:
    List of tokens

Raises:
    LexerError: On invalid syntax_

**Args**: self


#### `_parse_string()` (line 217)
_Parse string literal with escape sequence handling.

Args:
    quote_char: Quote character (" or ')

Raises:
    LexerError: If string is unterminated or contains invalid escapes_

**Args**: self, quote_char


#### `_skip_comment()` (line 300)
_Skip comment until end of line_

**Args**: self


#### `_advance()` (line 305)
_Update position after processing character_

**Args**: self, char


#### `print_tokens()` (line 315)
_Print tokens in readable format_

**Args**: self, verbose


#### `run_tests()` (line 329)
_Comprehensive test suite_


#### `main()` (line 446)
_Main entry point_


### src\core\hypercode-\src\hypercode_poc.py

#### `__init__()` (line 51)
**Args**: self


#### `tokenize()` (line 74)
**Args**: self, source


#### `handle_string()` (line 115)
**Args**: self, quote, errors


#### `handle_number()` (line 141)
**Args**: self


#### `handle_identifier()` (line 149)
**Args**: self


#### `advance()` (line 171)
**Args**: self


#### `__init__()` (line 179)
**Args**: self


#### `format_error()` (line 182)
**Args**: self, msg, line, col, level


#### `analyze()` (line 192)
**Args**: self, tokens


#### `__init__()` (line 212)
**Args**: self, level


#### `record()` (line 216)
**Args**: self, success


#### `__init__()` (line 225)
**Args**: self, level


#### `compile()` (line 232)
**Args**: self, code


### src\core\hypercode-\src\parser\debug_ascii.py

#### `test_regex_patterns()` (line 14)
_Test regex patterns directly_


### src\core\hypercode-\src\parser\debug_full.py

#### `debug_full_parsing()` (line 14)
_Debug the full parsing flow_


### src\core\hypercode-\src\parser\debug_parser.py

#### `debug_annotation_detection()` (line 14)
_Debug why annotations aren't being detected_


### src\core\hypercode-\src\parser\debug_simple.py

#### `debug_simple()` (line 14)
_Debug without emoji characters_


### src\core\hypercode-\src\parser\test_parser.py

#### `test_first_click_moment()` (line 14)
_Test the parser with the first click moment example_


### src\core\hypercode-\src\parser\visual_syntax_parser.py

#### `__str__()` (line 46)
**Args**: self


#### `get_annotations_by_type()` (line 62)
_Get all annotations of a specific type_

**Args**: self, marker_type


#### `__init__()` (line 72)
**Args**: self


#### `_build_semantic_patterns()` (line 76)
_üîç Build regex patterns for all semantic markers_

**Args**: self


#### `_build_color_scheme()` (line 105)
_üé® Build semantic color mapping for IDE highlighting_

**Args**: self


#### `parse_file()` (line 123)
_üìÑ Parse an entire HyperCode file_

**Args**: self, file_path


#### `parse_content()` (line 130)
_üìù Parse HyperCode content string_

**Args**: self, content


#### `_is_function_definition()` (line 170)
_üîç Check if line is a function definition_

**Args**: self, line


#### `_start_new_function()` (line 179)
_üÜï Create new ParsedFunction from definition line_

**Args**: self, line, line_num


#### `_parse_line_annotations()` (line 202)
_ÔøΩ Parse semantic annotations from a line_

**Args**: self, line, line_num


#### `_parse_annotation_params()` (line 223)
_üîß Parse annotation parameters from string_

**Args**: self, params_str


#### `generate_syntax_highlighting()` (line 265)
_üé® Generate HTML with syntax highlighting for visual markers_

**Args**: self, content


#### `extract_semantic_summary()` (line 277)
_üìä Extract semantic summary for analysis_

**Args**: self, functions


#### `validate_neurodiversity_compliance()` (line 311)
_üß† Validate neurodiversity-first design principles_

**Args**: self, functions


### src\core\hypercode-\src\scaffold (1).py

#### `create_directories()` (line 141)
_Create all required directories._


#### `create_python_files()` (line 151)
_Create all Python files with proper __init__.py structure._


#### `create_example_files()` (line 165)
_Create example HyperCode files._


#### `create_root_files()` (line 202)
_Create root-level configuration files as empty placeholders._


#### `create_healthcheck()` (line 213)
_Create the healthcheck script for Docker._


#### `print_summary()` (line 234)
_Print summary of created structure._


#### `main()` (line 259)
_Main scaffolding function._


### src\core\hypercode-\src\scaffold.py

#### `create_directories()` (line 153)
_Create all required directories._


#### `create_python_files()` (line 184)
_Create all Python files with proper docstrings and structure._


#### `create_example_files()` (line 254)
_Create example HyperCode files._


#### `create_root_files()` (line 291)
_Create root-level configuration files with appropriate content._


#### `create_healthcheck()` (line 541)
_Create the healthcheck script for Docker._


#### `print_summary()` (line 583)
_Print summary of created structure._


#### `main()` (line 621)
_Main scaffolding function._


### src\core\hypercode-\test_direct_access.py

#### `test_direct_implementation_access()` (line 15)
_Test direct access to implementation guide content_


### src\core\hypercode-\test_implementation_guide.py

#### `test_search_functionality()` (line 15)
_Test search for implementation guide terms_


#### `test_implementation_guide_content()` (line 37)
_Test the implementation guide document directly_


#### `test_context_queries()` (line 82)
_Test context-aware queries_


### src\core\hypercode-\test_intent_blocks.py

#### `test_intent_block()` (line 13)
_Test parsing of intent blocks_


### src\core\hypercode-\test_perplexity.py

#### `test_perplexity_connection()` (line 16)
_Test Perplexity API with detailed logging_


#### `test_ai_research_integration()` (line 66)
_Test integration with AI Research document content_


### src\core\hypercode-\test_real_data.py

#### `test_enhanced_knowledge_base()` (line 16)
_Test enhanced KnowledgeBase functionality_


#### `test_real_perplexity_data_simulation()` (line 183)
_Simulate testing with real Perplexity Space data_


### src\core\hypercode-\test_real_space_data.py

#### `test_real_space_data()` (line 15)
_Test queries that use your actual Perplexity Space data_


### src\core\hypercode-\tests\benchmark_knowledge_base.py

#### `__init__()` (line 27)
**Args**: self


#### `_get_system_info()` (line 34)
_Get system information for benchmark context_

**Args**: self


#### `generate_test_data()` (line 43)
_Generate test data of specified size_

**Args**: self, size


#### `benchmark_operation()` (line 93)
_Benchmark a single operation_

**Args**: self, operation_name, operation_func


#### `run_benchmark_suite()` (line 118)
_Run complete benchmark suite_

**Args**: self, size


#### `_calculate_summary()` (line 274)
_Calculate summary statistics_

**Args**: self


#### `_generate_recommendations()` (line 296)
_Generate performance recommendations_

**Args**: self


#### `generate_markdown_report()` (line 338)
_Generate beautiful markdown report_

**Args**: self, output_file


#### `save_json_results()` (line 467)
_Save results as JSON_

**Args**: self, output_file


#### `main()` (line 474)
_Main benchmark runner_


### src\core\hypercode-\tests\test_core.py

#### `run_test()` (line 29)
_Test the lexer and parser with the given source code._

**Args**: source_code


### src\core\hypercode-\tests\test_knowledge_base.py

#### `sample_documents()` (line 16)
_Create sample documents for testing._

**Args**: self


#### `knowledge_base()` (line 40)
_Create a knowledge base instance with sample documents._

**Args**: self, sample_documents


#### `test_basic_search()` (line 48)
_Test basic search functionality._

**Args**: self, knowledge_base, sample_documents


#### `test_search_with_exact_match()` (line 54)
_Test search with exact phrase matching._

**Args**: self, knowledge_base


#### `test_search_case_insensitive()` (line 59)
_Test that search is case-insensitive._

**Args**: self, knowledge_base


#### `test_search_empty_query()` (line 65)
_Test search with empty query returns all or no documents._

**Args**: self, knowledge_base


#### `test_search_no_matches()` (line 71)
_Test search with no matching documents._

**Args**: self, knowledge_base


#### `test_search_ranking()` (line 77)
_Test that search results are ranked by relevance._

**Args**: self, knowledge_base, sample_documents


#### `test_query_normalization()` (line 90)
_Test query normalization (typos, spacing, punctuation)._

**Args**: self, knowledge_base


#### `test_multi_word_query()` (line 98)
_Test search with multiple keywords._

**Args**: self, knowledge_base


#### `test_tag_based_search()` (line 103)
_Test search that includes tag matching._

**Args**: self, knowledge_base, sample_documents


#### `knowledge_base()` (line 116)
**Args**: self


#### `test_very_short_query()` (line 121)
_Test search with very short query (1-2 chars)._

**Args**: self, knowledge_base


#### `test_very_long_query()` (line 126)
_Test search with very long query (paragraph length)._

**Args**: self, knowledge_base


#### `test_special_characters_in_query()` (line 136)
_Test search with special characters._

**Args**: self, knowledge_base


#### `test_unicode_in_query()` (line 141)
_Test search with unicode characters._

**Args**: self, knowledge_base


#### `test_sql_injection_attempt()` (line 146)
_Test that search is safe from SQL injection-style attacks._

**Args**: self, knowledge_base


#### `test_repeated_queries()` (line 151)
_Test that repeated queries return consistent results._

**Args**: self, knowledge_base


#### `large_knowledge_base()` (line 163)
_Create a knowledge base with many documents._

**Args**: self


#### `test_search_response_time()` (line 179)
_Test that search completes within acceptable time._

**Args**: self, large_knowledge_base


#### `test_concurrent_searches()` (line 189)
_Test multiple concurrent search operations._

**Args**: self, large_knowledge_base


#### `test_memory_usage()` (line 207)
_Test memory usage during search operations._

**Args**: self, large_knowledge_base


#### `mock_perplexity_client()` (line 217)
_Create a mock Perplexity client._

**Args**: self


#### `mock_knowledge_base()` (line 229)
_Create a mock knowledge base._

**Args**: self


#### `test_enhanced_query_with_context()` (line 243)
_Test that queries are enhanced with knowledge base context._

**Args**: self, mock_perplexity_client, mock_knowledge_base


#### `test_fallback_to_perplexity_api()` (line 259)
_Test fallback to Perplexity API when no local context found._

**Args**: self, mock_perplexity_client, mock_knowledge_base


#### `test_context_ranking_and_selection()` (line 273)
_Test that best context is selected for query enhancement._

**Args**: self, mock_knowledge_base


#### `knowledge_base()` (line 292)
**Args**: self


#### `test_add_document()` (line 300)
_Test adding a new document to knowledge base._

**Args**: self, knowledge_base


#### `test_update_document()` (line 310)
_Test updating an existing document._

**Args**: self, knowledge_base


#### `test_remove_document()` (line 315)
_Test removing a document._

**Args**: self, knowledge_base


### src\core\hypercode-\tests\test_knowledge_base_comprehensive.py

#### `temp_kb()` (line 24)
_Create a temporary knowledge base for testing_

**Args**: self


#### `sample_docs()` (line 36)
_Sample documents for testing_

**Args**: self


#### `test_init_empty_kb()` (line 59)
_Test knowledge base initialization_

**Args**: self, temp_kb


#### `test_add_single_document()` (line 65)
_Test adding a single document_

**Args**: self, temp_kb, sample_docs


#### `test_add_multiple_documents()` (line 74)
_Test adding multiple documents_

**Args**: self, temp_kb, sample_docs


#### `test_save_and_load()` (line 84)
_Test saving and loading knowledge base_

**Args**: self, temp_kb, sample_docs


#### `test_search_exact_match()` (line 102)
_Test exact search matching_

**Args**: self, temp_kb, sample_docs


#### `test_search_partial_match()` (line 113)
_Test partial search matching_

**Args**: self, temp_kb, sample_docs


#### `test_search_tag_matching()` (line 124)
_Test tag-based search_

**Args**: self, temp_kb, sample_docs


#### `test_search_case_insensitive()` (line 135)
_Test case insensitive search_

**Args**: self, temp_kb, sample_docs


#### `test_empty_search()` (line 147)
_Test empty search query_

**Args**: self, temp_kb


#### `test_nonexistent_search()` (line 155)
_Test search for nonexistent terms_

**Args**: self, temp_kb, sample_docs


#### `test_get_context_for_query()` (line 165)
_Test context extraction_

**Args**: self, temp_kb, sample_docs


#### `test_context_length_limit()` (line 176)
_Test context length limiting_

**Args**: self, temp_kb, sample_docs


#### `test_document_update()` (line 186)
_Test updating existing documents_

**Args**: self, temp_kb, sample_docs


#### `test_list_documents()` (line 202)
_Test listing all documents_

**Args**: self, temp_kb, sample_docs


#### `test_delete_document()` (line 213)
_Test document deletion_

**Args**: self, temp_kb, sample_docs


#### `populated_kb()` (line 233)
_Create a populated knowledge base for integration testing_

**Args**: self


#### `test_complex_search_queries()` (line 277)
_Test complex search scenarios_

**Args**: self, populated_kb


#### `test_search_ranking_quality()` (line 291)
_Test that search results are properly ranked_

**Args**: self, populated_kb


#### `test_related_term_expansion()` (line 301)
_Test that related terms are properly expanded_

**Args**: self, populated_kb


#### `test_performance_with_large_dataset()` (line 313)
_Test performance with larger dataset_

**Args**: self, populated_kb


#### `test_concurrent_access_simulation()` (line 332)
_Test simulated concurrent access_

**Args**: self, populated_kb


#### `large_kb()` (line 360)
_Create a large knowledge base for performance testing_

**Args**: self


#### `test_search_performance_large_dataset()` (line 382)
_Test search performance with large dataset_

**Args**: self, large_kb


#### `test_save_performance_large_dataset()` (line 396)
_Test save performance with large dataset_

**Args**: self, large_kb


#### `test_load_performance_large_dataset()` (line 409)
_Test load performance with large dataset_

**Args**: self, large_kb


#### `test_memory_usage_large_dataset()` (line 423)
_Test memory usage with large dataset_

**Args**: self, large_kb


#### `edge_case_kb()` (line 450)
_Create knowledge base for edge case testing_

**Args**: self


#### `test_empty_title_handling()` (line 494)
_Test handling of documents with empty titles_

**Args**: self, edge_case_kb


#### `test_special_characters_handling()` (line 499)
_Test handling of special characters and unicode_

**Args**: self, edge_case_kb


#### `test_very_long_titles()` (line 507)
_Test handling of very long titles_

**Args**: self, edge_case_kb


#### `test_empty_content_handling()` (line 512)
_Test handling of documents with empty content_

**Args**: self, edge_case_kb


#### `test_none_tags_handling()` (line 517)
_Test handling of None tags_

**Args**: self, edge_case_kb


#### `test_malformed_json_handling()` (line 531)
_Test handling of malformed JSON files_

**Args**: self


#### `test_file_permission_handling()` (line 544)
_Test handling of file permission issues_

**Args**: self


### src\core\hypercode-\tests\test_lexer.py

#### `test_lexer_basic_tokens()` (line 5)

#### `test_lexer_strings()` (line 23)

#### `test_lexer_operators()` (line 48)
**Args**: source, expected_type


### src\core\hypercode-\tests\test_lexer_extended.py

#### `test_lexer_escaped_strings()` (line 5)
_Test handling of strings with escaped characters._


#### `test_lexer_numbers()` (line 18)
_Test various number formats._


#### `test_lexer_operators()` (line 39)
_Test all operators._


#### `test_lexer_comments()` (line 86)
_Test handling of single-line and multi-line comments._


#### `test_lexer_whitespace()` (line 115)
_Test handling of various whitespace characters._


#### `test_lexer_error_handling()` (line 130)
_Test error handling for invalid tokens._


#### `test_lexer_hex_numbers()` (line 139)
_Test hexadecimal number literals._


#### `test_lexer_binary_numbers()` (line 157)
_Test binary number literals._


#### `test_lexer_scientific_notation()` (line 169)
_Test scientific notation numbers._


#### `test_lexer_string_escapes()` (line 180)
_Test string escape sequences._


#### `test_lexer_keywords()` (line 197)
_Test all language keywords._


#### `test_lexer_position_tracking()` (line 223)
_Test that line and column numbers are tracked correctly._


#### `test_lexer_error_recovery()` (line 243)
_Test that the lexer raises errors on invalid characters._


#### `test_lexer_error_messages()` (line 252)
_Test that lexer error messages are informative._


### src\core\hypercode-\tests\test_parser.py

#### `test_parse_literal()` (line 12)

#### `test_parse_variable_declaration()` (line 24)

#### `test_parse_binary_expression()` (line 37)

### src\core\hypercode-\tests\unit\test_knowledge_base.py

#### `temp_kb()` (line 24)
_Create a temporary knowledge base for testing_

**Args**: self


#### `sample_documents()` (line 33)
_Sample documents for testing_

**Args**: self


#### `test_init_empty_kb()` (line 56)
_Test knowledge base initialization_

**Args**: self, temp_kb


#### `test_add_document()` (line 61)
_Test adding a single document_

**Args**: self, temp_kb, sample_documents


#### `test_add_multiple_documents()` (line 82)
_Test adding multiple documents_

**Args**: self, temp_kb, sample_documents


#### `test_save_and_load()` (line 92)
_Test saving and loading knowledge base_

**Args**: self, temp_kb, sample_documents


#### `test_search_exact_match()` (line 113)
_Test exact term matching in search_

**Args**: self, temp_kb, sample_documents


#### `test_search_tag_matching()` (line 126)
_Test tag-based search_

**Args**: self, temp_kb, sample_documents


#### `test_search_related_terms()` (line 139)
_Test related term expansion_

**Args**: self, temp_kb, sample_documents


#### `test_search_space_data_boost()` (line 153)
_Test that space data gets boosted in search_

**Args**: self, temp_kb


#### `test_get_context_for_query()` (line 180)
_Test context extraction for queries_

**Args**: self, temp_kb, sample_documents


#### `test_context_length_limit()` (line 192)
_Test context length limiting_

**Args**: self, temp_kb, sample_documents


#### `test_list_documents()` (line 203)
_Test listing all documents_

**Args**: self, temp_kb, sample_documents


#### `test_empty_search()` (line 216)
_Test search with empty query_

**Args**: self, temp_kb


#### `test_search_nonexistent_term()` (line 221)
_Test search for term that doesn't exist_

**Args**: self, temp_kb, sample_documents


#### `test_document_update()` (line 231)
_Test updating existing document_

**Args**: self, temp_kb, sample_documents


#### `test_document_creation()` (line 253)
_Test creating a research document_

**Args**: self


#### `test_document_optional_fields()` (line 273)
_Test document with optional fields_

**Args**: self


### src\core\hypercode-\tests\unit\test_search_algorithm.py

#### `populated_kb()` (line 24)
_Create a knowledge base with test documents_

**Args**: self


#### `test_exact_title_match_highest_score()` (line 80)
_Test that exact title matches get highest priority_

**Args**: self, populated_kb


#### `test_space_data_boosting()` (line 92)
_Test that space data gets boosted in search results_

**Args**: self, populated_kb


#### `test_related_term_expansion()` (line 105)
_Test related term matching functionality_

**Args**: self, populated_kb


#### `test_tag_matching_scoring()` (line 126)
_Test that tag matches contribute to scoring_

**Args**: self, populated_kb


#### `test_content_frequency_scoring()` (line 136)
_Test that multiple content occurrences increase score_

**Args**: self, populated_kb


#### `test_partial_word_matching()` (line 149)
_Test partial word matching for longer terms_

**Args**: self, populated_kb


#### `test_query_word_ordering()` (line 167)
_Test that query words are properly processed_

**Args**: self, populated_kb


#### `test_case_insensitive_search()` (line 179)
_Test that search is case insensitive_

**Args**: self, populated_kb


#### `test_empty_query_returns_no_results()` (line 202)
_Test that empty queries return no results_

**Args**: self, populated_kb


#### `test_limit_parameter_respected()` (line 210)
_Test that search limit parameter works correctly_

**Args**: self, populated_kb


#### `test_no_results_for_nonexistent_terms()` (line 219)
_Test search for terms that don't exist_

**Args**: self, populated_kb


#### `test_special_characters_in_query()` (line 227)
_Test search with special characters_

**Args**: self, populated_kb


#### `test_unicode_characters()` (line 237)
_Test search with unicode characters_

**Args**: self, populated_kb


#### `test_search_performance_with_large_kb()` (line 256)
_Test search performance with larger knowledge base_

**Args**: self, populated_kb


#### `test_search_result_consistency()` (line 277)
_Test that search results are consistent across multiple calls_

**Args**: self, populated_kb


#### `scoring_kb()` (line 296)
_Create KB for detailed scoring tests_

**Args**: self


#### `test_title_match_beats_content_match()` (line 324)
_Test that title matches score higher than content matches_

**Args**: self, scoring_kb


#### `test_space_data_boosting_works()` (line 332)
_Test that space data gets boosted_

**Args**: self, scoring_kb


#### `test_frequency_scoring()` (line 340)
_Test that content frequency affects scoring_

**Args**: self, scoring_kb


### src\core\hypercode-\vscode-extension\out\extension.js

#### `unnamed_function()` (line 6)

#### `unnamed_function()` (line 23)

#### `unnamed_function()` (line 60)

#### `unnamed_function()` (line 78)

### src\core\hypercode-\vscode-extension\src\extension.ts

#### `unnamed_function()` (line 22)

#### `unnamed_function()` (line 61)

### src\core\hypercode-proto\app.js

#### `unnamed_function()` (line 70)

#### `unnamed_function()` (line 85)

#### `unnamed_function()` (line 89)

#### `unnamed_function()` (line 92)

#### `unnamed_function()` (line 95)

#### `unnamed_function()` (line 101)

#### `unnamed_function()` (line 104)

#### `unnamed_function()` (line 109)

#### `unnamed_function()` (line 120)

#### `unnamed_function()` (line 121)

#### `unnamed_function()` (line 134)

#### `unnamed_function()` (line 145)

#### `unnamed_function()` (line 161)

#### `unnamed_function()` (line 166)

#### `unnamed_function()` (line 173)

#### `unnamed_function()` (line 187)

#### `unnamed_function()` (line 188)

#### `unnamed_function()` (line 195)

#### `unnamed_function()` (line 203)

#### `unnamed_function()` (line 214)

#### `unnamed_function()` (line 221)

#### `unnamed_function()` (line 242)

#### `unnamed_function()` (line 258)

#### `unnamed_function()` (line 260)

#### `unnamed_function()` (line 262)

#### `unnamed_function()` (line 270)

#### `unnamed_function()` (line 298)

#### `unnamed_function()` (line 304)

#### `unnamed_function()` (line 305)

#### `unnamed_function()` (line 314)

#### `unnamed_function()` (line 316)

#### `unnamed_function()` (line 322)

#### `unnamed_function()` (line 323)

#### `unnamed_function()` (line 325)

#### `unnamed_function()` (line 333)

#### `unnamed_function()` (line 344)

#### `unnamed_function()` (line 345)

#### `unnamed_function()` (line 352)

#### `unnamed_function()` (line 356)

#### `unnamed_function()` (line 384)

#### `unnamed_function()` (line 389)

#### `unnamed_function()` (line 403)

#### `unnamed_function()` (line 419)

#### `unnamed_function()` (line 429)

#### `unnamed_function()` (line 438)

#### `unnamed_function()` (line 439)

#### `unnamed_function()` (line 449)

#### `unnamed_function()` (line 450)

#### `unnamed_function()` (line 451)

#### `unnamed_function()` (line 462)

#### `unnamed_function()` (line 467)

#### `unnamed_function()` (line 472)

#### `unnamed_function()` (line 477)

#### `unnamed_function()` (line 481)

#### `unnamed_function()` (line 487)

#### `unnamed_function()` (line 495)

#### `unnamed_function()` (line 501)

#### `unnamed_function()` (line 502)

#### `unnamed_function()` (line 503)

#### `unnamed_function()` (line 517)

#### `unnamed_function()` (line 528)

#### `unnamed_function()` (line 532)

#### `unnamed_function()` (line 561)

#### `unnamed_function()` (line 562)

#### `unnamed_function()` (line 570)

#### `unnamed_function()` (line 592)

#### `unnamed_function()` (line 593)

#### `unnamed_function()` (line 600)

#### `unnamed_function()` (line 604)

#### `unnamed_function()` (line 610)

#### `unnamed_function()` (line 670)

#### `unnamed_function()` (line 681)

#### `unnamed_function()` (line 691)

#### `unnamed_function()` (line 696)

#### `unnamed_function()` (line 704)

#### `unnamed_function()` (line 714)

#### `unnamed_function()` (line 722)

#### `unnamed_function()` (line 761)

#### `unnamed_function()` (line 766)

### src\core\interpreter.py

#### `__init__()` (line 9)
**Args**: self, message, token


#### `__init__()` (line 16)
**Args**: self, enclosing


#### `define()` (line 20)
**Args**: self, name, value


#### `get()` (line 23)
**Args**: self, name


#### `assign()` (line 30)
**Args**: self, name, value


#### `arity()` (line 41)
**Args**: self


#### `call()` (line 44)
**Args**: self, interpreter, arguments


#### `__init__()` (line 49)
**Args**: self, declaration, closure


#### `call()` (line 53)
**Args**: self, interpreter, arguments


#### `arity()` (line 65)
**Args**: self


#### `__init__()` (line 70)
**Args**: self, value


#### `__init__()` (line 75)
**Args**: self


#### `arity()` (line 83)
**Args**: self


#### `call()` (line 86)
**Args**: self, interpreter, arguments


#### `__str__()` (line 89)
**Args**: self


#### `arity()` (line 93)
**Args**: self


#### `call()` (line 96)
**Args**: self, interpreter, arguments


#### `__str__()` (line 101)
**Args**: self


#### `arity()` (line 105)
**Args**: self


#### `call()` (line 108)
**Args**: self, interpreter, arguments


#### `__str__()` (line 113)
**Args**: self


#### `execute_block()` (line 120)
**Args**: self, statements, environment


#### `interpret()` (line 129)
**Args**: self, statements


#### `execute()` (line 141)
**Args**: self, stmt


#### `evaluate()` (line 144)
**Args**: self, expr


#### `visit_Expression()` (line 147)
**Args**: self, stmt


#### `visit_Print()` (line 151)
**Args**: self, stmt


#### `visit_Let()` (line 158)
**Args**: self, stmt


#### `visit_Block()` (line 165)
**Args**: self, stmt


#### `visit_BlockDecl()` (line 169)
**Args**: self, stmt


#### `visit_Intent()` (line 175)
**Args**: self, stmt


#### `visit_Function()` (line 180)
**Args**: self, stmt


#### `visit_Return()` (line 185)
**Args**: self, stmt


#### `visit_Literal()` (line 191)
**Args**: self, expr


#### `visit_Grouping()` (line 194)
**Args**: self, expr


#### `visit_Variable()` (line 197)
**Args**: self, expr


#### `visit_Assign()` (line 200)
**Args**: self, expr


#### `visit_Pipe()` (line 205)
**Args**: self, expr


#### `visit_State()` (line 234)
**Args**: self, expr


#### `visit_Call()` (line 244)
**Args**: self, expr


#### `visit_Binary()` (line 262)
**Args**: self, expr


#### `visit_Unary()` (line 293)
**Args**: self, expr


#### `is_truthy()` (line 301)
**Args**: self, value


#### `stringify()` (line 308)
**Args**: self, value


#### `get_output()` (line 322)
**Args**: self


### src\core\lexer.py

#### `__init__()` (line 41)
_Initialize the lexer with source code._

**Args**: self, source


#### `scan_tokens()` (line 77)
_Scan the source code and return a list of tokens._

**Args**: self


#### `scan_token()` (line 87)
_Scan a single token._

**Args**: self


#### `number()` (line 164)
_Lex a number literal._

**Args**: self


#### `string()` (line 197)
_Lex a string literal._

**Args**: self, interpolated


#### `docstring()` (line 242)
_Lex a docstring._

**Args**: self


#### `identifier()` (line 268)
_Lex an identifier or keyword._

**Args**: self


#### `error()` (line 278)
_Report a lexing error._

**Args**: self, message, line, column


#### `is_at_end()` (line 294)
_Check if we've reached the end of the source._

**Args**: self


#### `advance()` (line 298)
_Consume and return the next character._

**Args**: self


#### `match()` (line 307)
_Conditionally consume a character if it matches the expected value._

**Args**: self, expected


#### `peek()` (line 317)
_Look at the next character without consuming it._

**Args**: self


#### `peek_next()` (line 323)
_Look at the character after the next one without consuming it._

**Args**: self


#### `add_token()` (line 329)
_Add a new token to the token list._

**Args**: self, token_type, literal


### src\core\parser.py

#### `__init__()` (line 12)
**Args**: self, tokens


#### `parse()` (line 16)
_Parse the entire program._

**Args**: self


#### `declaration()` (line 25)
**Args**: self


#### `let_declaration()` (line 38)
**Args**: self


#### `block_declaration()` (line 48)
**Args**: self


#### `statement()` (line 54)
**Args**: self


#### `print_statement()` (line 65)
**Args**: self


#### `expression_statement()` (line 70)
**Args**: self


#### `block()` (line 75)
**Args**: self


#### `expression()` (line 84)
**Args**: self


#### `pipe()` (line 87)
**Args**: self


#### `assignment()` (line 103)
**Args**: self


#### `equality()` (line 118)
**Args**: self


#### `comparison()` (line 128)
**Args**: self


#### `term()` (line 141)
**Args**: self


#### `factor()` (line 149)
**Args**: self


#### `unary()` (line 157)
**Args**: self


#### `primary()` (line 164)
**Args**: self


#### `function()` (line 194)
**Args**: self, kind


#### `if_statement()` (line 215)
**Args**: self


#### `return_statement()` (line 227)
**Args**: self


#### `match()` (line 237)
**Args**: self


#### `consume()` (line 244)
**Args**: self, type_, message


#### `error()` (line 249)
**Args**: self, token, message


#### `synchronize()` (line 255)
**Args**: self


#### `check()` (line 276)
**Args**: self, type_


#### `advance()` (line 281)
**Args**: self


#### `is_at_end()` (line 286)
**Args**: self


#### `peek()` (line 289)
**Args**: self


#### `previous()` (line 292)
**Args**: self


### src\core\tokens.py

#### `__init__()` (line 83)
**Args**: self, type, lexeme, literal, line, column


#### `__str__()` (line 97)
**Args**: self


#### `__repr__()` (line 100)
**Args**: self


### src\duelcode\duelcode_validator.py

#### `__init__()` (line 51)
**Args**: self, file_path


#### `_add_result()` (line 58)
_Add a validation result with proper line number._

**Args**: self, message, severity, line


#### `_find_lines()` (line 71)
_Find all lines matching the pattern with their line numbers._

**Args**: self, pattern


#### `validate()` (line 81)
_Run all validation checks._

**Args**: self


#### `validate_structure()` (line 93)
_Validate the overall document structure._

**Args**: self


#### `validate_headings()` (line 129)
_Validate heading hierarchy and formatting._

**Args**: self


#### `validate_code_blocks()` (line 171)
_Validate code blocks for proper formatting and language specification._

**Args**: self


#### `validate_checklists()` (line 210)
_Validate checklist items in the document._

**Args**: self


#### `validate_visual_elements()` (line 245)
_Validate visual elements like diagrams, images, etc._

**Args**: self


#### `validate_links()` (line 263)
_Validate internal and external links._

**Args**: self


#### `print_validation_results()` (line 283)
_Print validation results in a user-friendly format._

**Args**: validator


#### `main()` (line 316)
_Main entry point for the validator._


### src\duelcode\enhanced_validator.py

#### `__init__()` (line 83)
**Args**: self, file_path


#### `_add_result()` (line 90)
_Add a validation result with proper line number._

**Args**: self, message, severity, line


#### `_find_lines()` (line 103)
_Find all lines matching the pattern with their line numbers._

**Args**: self, pattern


#### `validate_code_blocks_have_language()` (line 115)
_Ensure all code blocks have a specified language._

**Args**: self


#### `validate_has_visual_representation()` (line 128)
_Ensure each part has a visual representation._

**Args**: self


#### `validate_has_practical_exercise()` (line 140)
_Ensure each part has a practical exercise._

**Args**: self


#### `validate_has_learning_objectives()` (line 152)
_Ensure learning objectives are present and well-formed._

**Args**: self


#### `validate_has_checklist()` (line 174)
_Ensure a checklist is present and has items._

**Args**: self


#### `validate_has_conclusion()` (line 195)
_Ensure the document has a conclusion section._

**Args**: self


#### `validate_has_whats_next()` (line 204)
_Suggest adding a 'What's Next' section._

**Args**: self


#### `validate_code_quality()` (line 213)
_Check code quality in code blocks._

**Args**: self


#### `_analyze_code_block()` (line 234)
_Analyze a code block for quality issues._

**Args**: self, lines, lang, start_line


#### `_analyze_python_code()` (line 256)
_Python-specific code analysis._

**Args**: self, lines, _start_line


#### `_analyze_javascript_code()` (line 277)
_JavaScript/TypeScript-specific code analysis._

**Args**: self, lines, _start_line


#### `validate_has_glossary()` (line 291)
_Suggest adding a glossary for technical terms._

**Args**: self


#### `validate_has_see_also()` (line 325)
_Suggest adding a 'See Also' section with related resources._

**Args**: self


#### `validate_has_faq()` (line 334)
_Suggest adding an FAQ section._

**Args**: self


#### `validate_has_acknowledgments()` (line 344)
_Suggest adding an acknowledgments section._

**Args**: self


#### `validate_all()` (line 353)
_Run all validations._

**Args**: self


#### `print_validation_results()` (line 376)
_Print validation results in a user-friendly format._

**Args**: results


#### `main()` (line 407)
_Main entry point for the enhanced validator._


### src\duelcode\test_framework.py

#### `__init__()` (line 45)
**Args**: self, duelcode_dir


#### `discover_tutorials()` (line 49)
_Find all tutorial markdown files._

**Args**: self


#### `run_validator()` (line 56)
_Run the ultra validator on a file._

**Args**: self, file_path


#### `parse_validator_output()` (line 71)
_Parse validator output to count issues by severity._

**Args**: self, output


#### `test_tutorial()` (line 99)
_Test a single tutorial file._

**Args**: self, tutorial_path


#### `test_validator_integrity()` (line 135)
_Test that validator itself is working correctly._

**Args**: self


#### `test_template_validity()` (line 176)
_Test that templates pass validation._

**Args**: self


#### `run_all_tests()` (line 221)
_Run the complete test suite._

**Args**: self


#### `generate_report()` (line 248)
_Generate a detailed test report._

**Args**: self


#### `main()` (line 295)
_Main entry point._


### src\duelcode\test_validator.py

#### `test_valid_file()` (line 11)
_Test with a valid DuelCode file._


#### `test_invalid_file()` (line 65)
_Test with an invalid DuelCode file._


#### `main()` (line 90)
_Run the test suite._


### src\duelcode\ultra_validator.py

#### `__init__()` (line 88)
**Args**: self, file_path


#### `_add_result()` (line 95)
**Args**: self, message, severity, line, suggestion


#### `_find_lines()` (line 106)
**Args**: self, pattern


#### `validate_code_blocks_have_language()` (line 118)
_Validate all code blocks have language specifications._

**Args**: self


#### `validate_has_visual_representation()` (line 152)
_Check for visual elements like diagrams, charts, or ASCII art._

**Args**: self


#### `validate_has_practical_exercise()` (line 171)
_Check for practical exercises or challenges._

**Args**: self


#### `validate_has_learning_objectives()` (line 192)
_Check for learning objectives section._

**Args**: self


#### `validate_has_checklist()` (line 215)
_Check for checklist elements._

**Args**: self


#### `validate_has_conclusion()` (line 234)
_Check for conclusion section._

**Args**: self


#### `validate_has_whats_next()` (line 257)
_Check for 'What's Next' section._

**Args**: self


#### `validate_code_quality()` (line 278)
_Validate code block quality and best practices._

**Args**: self


#### `_validate_code_block_content()` (line 305)
_Validate specific code block content based on language._

**Args**: self, block_lines, lang, start_line


#### `validate_has_glossary()` (line 340)
_Check for glossary section._

**Args**: self


#### `validate_has_see_also()` (line 360)
_Check for 'See Also' section._

**Args**: self


#### `validate_has_faq()` (line 380)
_Check for FAQ section._

**Args**: self


#### `validate_has_acknowledgments()` (line 402)
_Check for acknowledgments section._

**Args**: self


#### `validate_accessibility()` (line 422)
_Check for accessibility features._

**Args**: self


#### `validate_interactive_elements()` (line 443)
_Check for interactive elements._

**Args**: self


#### `validate_all()` (line 463)
_Run all validations and return results._

**Args**: self


#### `print_results()` (line 487)
_Print validation results in a formatted way._

**Args**: self


#### `main()` (line 537)

### src\duelcode\validate_duelcode.py

#### `__init__()` (line 24)
**Args**: self, file_path


#### `validate_sections()` (line 30)
_Check if all required sections are present._

**Args**: self


#### `check_formatting()` (line 39)
_Check for common formatting issues._

**Args**: self


#### `check_visual_aids()` (line 55)
_Check for presence of visual aids._

**Args**: self


#### `validate()` (line 60)
_Run all validations and return results._

**Args**: self


#### `main()` (line 68)

### src\duelcode_validator.py

#### `__init__()` (line 51)
**Args**: self, file_path


#### `_add_result()` (line 58)
_Add a validation result with proper line number._

**Args**: self, message, severity, line


#### `_find_lines()` (line 71)
_Find all lines matching the pattern with their line numbers._

**Args**: self, pattern


#### `validate()` (line 81)
_Run all validation checks._

**Args**: self


#### `validate_structure()` (line 93)
_Validate the overall document structure._

**Args**: self


#### `validate_headings()` (line 129)
_Validate heading hierarchy and formatting._

**Args**: self


#### `validate_code_blocks()` (line 171)
_Validate code blocks for proper formatting and language specification._

**Args**: self


#### `validate_checklists()` (line 210)
_Validate checklist items in the document._

**Args**: self


#### `validate_visual_elements()` (line 245)
_Validate visual elements like diagrams, images, etc._

**Args**: self


#### `validate_links()` (line 263)
_Validate internal and external links._

**Args**: self


#### `print_validation_results()` (line 283)
_Print validation results in a user-friendly format._

**Args**: validator


#### `main()` (line 316)
_Main entry point for the validator._


### src\enhanced_validator.py

#### `__init__()` (line 83)
**Args**: self, file_path


#### `_add_result()` (line 90)
_Add a validation result with proper line number._

**Args**: self, message, severity, line


#### `_find_lines()` (line 103)
_Find all lines matching the pattern with their line numbers._

**Args**: self, pattern


#### `validate_code_blocks_have_language()` (line 115)
_Ensure all code blocks have a specified language._

**Args**: self


#### `validate_has_visual_representation()` (line 128)
_Ensure each part has a visual representation._

**Args**: self


#### `validate_has_practical_exercise()` (line 140)
_Ensure each part has a practical exercise._

**Args**: self


#### `validate_has_learning_objectives()` (line 152)
_Ensure learning objectives are present and well-formed._

**Args**: self


#### `validate_has_checklist()` (line 174)
_Ensure a checklist is present and has items._

**Args**: self


#### `validate_has_conclusion()` (line 195)
_Ensure the document has a conclusion section._

**Args**: self


#### `validate_has_whats_next()` (line 204)
_Suggest adding a 'What's Next' section._

**Args**: self


#### `validate_code_quality()` (line 213)
_Check code quality in code blocks._

**Args**: self


#### `_analyze_code_block()` (line 234)
_Analyze a code block for quality issues._

**Args**: self, lines, lang, start_line


#### `_analyze_python_code()` (line 256)
_Python-specific code analysis._

**Args**: self, lines, _start_line


#### `_analyze_javascript_code()` (line 277)
_JavaScript/TypeScript-specific code analysis._

**Args**: self, lines, _start_line


#### `validate_has_glossary()` (line 291)
_Suggest adding a glossary for technical terms._

**Args**: self


#### `validate_has_see_also()` (line 325)
_Suggest adding a 'See Also' section with related resources._

**Args**: self


#### `validate_has_faq()` (line 334)
_Suggest adding an FAQ section._

**Args**: self


#### `validate_has_acknowledgments()` (line 344)
_Suggest adding an acknowledgments section._

**Args**: self


#### `validate_all()` (line 353)
_Run all validations._

**Args**: self


#### `print_validation_results()` (line 376)
_Print validation results in a user-friendly format._

**Args**: results


#### `main()` (line 407)
_Main entry point for the enhanced validator._


### src\hypercode-backend-js-COMPLETE.py

#### `__init__()` (line 30)
_Initialize compiler.

Args:
    ast: Root AST node (PROGRAM)
    optimize: Enable optimizations_

**Args**: self, ast, optimize


#### `compile()` (line 42)
_Compile AST to JavaScript.

Returns:
    JavaScript source code_

**Args**: self


#### `_generate_header()` (line 65)
_Generate JavaScript header_

**Args**: self


#### `_generate_setup()` (line 74)
_Generate setup code (memory tape, pointer, I/O)_

**Args**: self


#### `_generate_main()` (line 110)
_Generate JavaScript for AST node.

Args:
    node: AST node

Returns:
    JavaScript code_

**Args**: self, node


#### `_generate_footer()` (line 162)
_Generate JavaScript footer_

**Args**: self


#### `_indent()` (line 179)
_Get current indentation_

**Args**: self


#### `optimize_ast()` (line 183)
_Optimize AST (future: loop unrolling, dead code elimination).

Args:
    node: AST node

Returns:
    Optimized AST node_

**Args**: self, node


#### `main()` (line 200)
_CLI interface for JavaScript backend_


### src\hypercode-launch-kit.py

#### `__init__()` (line 26)
**Args**: self


#### `create_readme()` (line 30)
_Create the ultimate README.md_

**Args**: self


#### `create_launch_checklist()` (line 367)
_Create launch day checklist_

**Args**: self


#### `create_launch_script()` (line 620)
_Create automated launch script_

**Args**: self


#### `create_first_30_days()` (line 718)
_Create 30-day success roadmap_

**Args**: self


#### `print_summary()` (line 974)
_Print beautiful summary_

**Args**: self


#### `main()` (line 1007)
_Run launch kit initialization_


### src\hypercode-lexer-COMPLETE.py

#### `__repr__()` (line 54)
_Neurodivergent-friendly representation_

**Args**: self


#### `__init__()` (line 62)
**Args**: self, message, line, column


#### `__init__()` (line 95)
_Initialize lexer with source code.

Args:
    source: HyperCode source code
    filename: Source filename (for error reporting)_

**Args**: self, source, filename


#### `tokenize()` (line 110)
_Convert HyperCode source to token stream.

Returns:
    List of Token objects

Raises:
    LexerError: On invalid syntax_

**Args**: self


#### `_advance_position()` (line 169)
_Update position tracking after processing character_

**Args**: self, char


#### `_skip_comment()` (line 179)
_Skip characters until end of line_

**Args**: self


#### `get_tokens()` (line 184)
_Return current token list_

**Args**: self


#### `filter_tokens()` (line 188)
_Get tokens excluding certain types.

Args:
    exclude_types: Token types to exclude

Returns:
    Filtered token list_

**Args**: self, exclude_types


#### `print_tokens()` (line 205)
_Print tokens in readable format.

Args:
    colorize: Use ANSI colors (helps ADHD/dyslexia)_

**Args**: self, colorize


#### `get_statistics()` (line 236)
_Get token statistics (useful for analysis).

Returns:
    Dictionary with token counts_

**Args**: self


#### `main()` (line 250)
_CLI interface for the lexer_


### src\hypercode-parser-COMPLETE.py

#### `__repr__()` (line 51)
_Pretty-print AST (neurodivergent-friendly)_

**Args**: self, indent


#### `__init__()` (line 71)
**Args**: self, message, token


#### `__init__()` (line 94)
_Initialize parser with token stream.

Args:
    tokens: List of tokens from lexer_

**Args**: self, tokens


#### `parse()` (line 105)
_Parse tokens into AST.

Returns:
    Root AST node (PROGRAM)

Raises:
    ParserError: On syntax errors_

**Args**: self


#### `_parse_statement()` (line 127)
_Parse a single statement_

**Args**: self


#### `_parse_loop()` (line 174)
_Parse loop structure: [ statements ]

Returns:
    Loop AST node_

**Args**: self


#### `_advance()` (line 209)
_Move to next token_

**Args**: self


#### `_is_at_end()` (line 215)
_Check if at end of token stream_

**Args**: self


#### `validate()` (line 222)
_Validate AST structure.

Returns:
    List of warnings (empty if no issues)_

**Args**: self


#### `print_ast()` (line 237)
_Print AST in readable format.

Args:
    node: AST node to print (defaults to root)
    indent: Indentation level_

**Args**: self, node, indent


#### `main()` (line 251)
_CLI interface for the parser_


### src\hypercode\__main__.py

#### `main()` (line 6)

### src\hypercode\cli\__init__.py

#### `main()` (line 14)
_Run the HyperCode lexer from the command line.

Args:
    args: Command line arguments (defaults to sys.argv[1:])

Returns:
    int: Exit code (0 for success, non-zero for errors)_

**Args**: args


### src\hypercode\config.py

#### `get_headers()` (line 27)
_Get headers for API requests_

**Args**: cls


### src\hypercode\core\error_handler.py

#### `report_parse_error()` (line 5)
**Args**: token, message


#### `report()` (line 12)
**Args**: line, where, message


### src\hypercode\core\hypercode_ast.py

#### `accept()` (line 10)
**Args**: self, visitor


### src\hypercode\core\interpreter.py

#### `__init__()` (line 7)
**Args**: self, value


#### `__init__()` (line 12)
**Args**: self, declaration, closure


#### `__str__()` (line 16)
**Args**: self


#### `arity()` (line 19)
**Args**: self


#### `call()` (line 22)
**Args**: self, interpreter, arguments


#### `__init__()` (line 36)
**Args**: self, enclosing


#### `define()` (line 40)
**Args**: self, name, value


#### `get()` (line 43)
**Args**: self, name


#### `assign()` (line 50)
**Args**: self, name, value


#### `__init__()` (line 61)
**Args**: self


#### `interpret()` (line 65)
**Args**: self, statements


#### `execute()` (line 72)
**Args**: self, stmt


#### `execute_block()` (line 75)
**Args**: self, statements, environment


#### `evaluate()` (line 84)
**Args**: self, expr


#### `visit_Expression()` (line 87)
**Args**: self, stmt


#### `visit_Print()` (line 90)
**Args**: self, stmt


#### `visit_Var()` (line 94)
**Args**: self, stmt


#### `visit_Block()` (line 100)
**Args**: self, stmt


#### `visit_Assign()` (line 103)
**Args**: self, expr


#### `visit_Binary()` (line 108)
**Args**: self, expr


#### `visit_Grouping()` (line 151)
**Args**: self, expr


#### `visit_Literal()` (line 154)
**Args**: self, expr


#### `visit_Unary()` (line 157)
**Args**: self, expr


#### `visit_Variable()` (line 170)
**Args**: self, expr


#### `visit_If()` (line 173)
**Args**: self, stmt


#### `is_truthy()` (line 179)
**Args**: self, obj


#### `visit_Fun()` (line 186)
**Args**: self, stmt


#### `visit_Return()` (line 190)
**Args**: self, stmt


#### `visit_Call()` (line 196)
**Args**: self, expr


#### `is_callable()` (line 214)
**Args**: self, obj


#### `visit_Expression()` (line 220)
**Args**: self, stmt


#### `visit_Print()` (line 223)
**Args**: self, stmt


#### `visit_Var()` (line 226)
**Args**: self, stmt


#### `visit_Block()` (line 229)
**Args**: self, stmt


#### `visit_If()` (line 232)
**Args**: self, stmt


#### `visit_Fun()` (line 235)
**Args**: self, stmt


#### `visit_Return()` (line 238)
**Args**: self, stmt


#### `visit_Assign()` (line 241)
**Args**: self, expr


#### `visit_Binary()` (line 244)
**Args**: self, expr


#### `visit_Grouping()` (line 247)
**Args**: self, expr


#### `visit_Literal()` (line 250)
**Args**: self, expr


#### `visit_Unary()` (line 253)
**Args**: self, expr


#### `visit_Variable()` (line 256)
**Args**: self, expr


#### `visit_Call()` (line 259)
**Args**: self, expr


### src\hypercode\core\lexer.py

#### `__init__()` (line 35)
**Args**: self, message, line, column


#### `__init__()` (line 45)
_Initialize the lexer with source code.

Args:
    source: The source code to tokenize_

**Args**: self, source


#### `tokenize()` (line 59)
_Convert source code into a list of tokens.

Args:
    source: Optional source code to tokenize. If not provided,
           uses the source passed to the constructor.

Returns:
    List of Token objects, always ending with an EOF token_

**Args**: self, source


#### `is_at_end()` (line 89)
_Check if we've consumed all characters._

**Args**: self


#### `__init__()` (line 105)
**Args**: self, message, line, column


#### `__init__()` (line 122)
_Initialize the lexer with source code.

Args:
    source: The source code to tokenize_

**Args**: self, source


#### `tokenize()` (line 136)
_Convert source code into a list of tokens.

Args:
    source: Optional source code to tokenize. If not provided,
           uses the source passed to the constructor.

Returns:
    List of Token objects, always ending with an EOF token_

**Args**: self, source


#### `scan_token()` (line 164)
_Scan the next token from the source._

**Args**: self


#### `string()` (line 251)
_Scan a string literal._

**Args**: self, quote


#### `number()` (line 273)
_Scan a number literal._

**Args**: self


#### `identifier()` (line 306)
_Scan an identifier or keyword._

**Args**: self


#### `match()` (line 316)
_Match the next character if it matches the expected character._

**Args**: self, expected


#### `peek()` (line 327)
_Look at the next character without consuming it._

**Args**: self


#### `peek_next()` (line 333)
_Look at the character after the next one without consuming it._

**Args**: self


#### `advance()` (line 339)
_Consume and return the next character._

**Args**: self


#### `add_token()` (line 349)
_Add a new token to the tokens list._

**Args**: self, token_type, literal


#### `error()` (line 357)
_Record a lexer error.

Args:
    message: The error message
    line: The line number where the error occurred (defaults to current line)
    column: The column number where the error occurred (defaults to current column)_

**Args**: self, message, line, column


#### `is_at_end()` (line 371)
_Check if we've consumed all characters._

**Args**: self


### src\hypercode\core\parser.py

#### `__init__()` (line 13)
**Args**: self, tokens


#### `parse()` (line 17)
_Parse the entire program._

**Args**: self


#### `declaration()` (line 26)
**Args**: self


#### `var_declaration()` (line 37)
**Args**: self


#### `statement()` (line 53)
**Args**: self


#### `print_statement()` (line 66)
**Args**: self


#### `return_statement()` (line 71)
**Args**: self


#### `intent_statement()` (line 79)
**Args**: self


#### `expression_statement()` (line 92)
**Args**: self


#### `if_statement()` (line 97)
**Args**: self


#### `function()` (line 109)
**Args**: self, kind


#### `block()` (line 128)
**Args**: self


#### `expression()` (line 135)
**Args**: self


#### `assignment()` (line 138)
**Args**: self


#### `equality()` (line 153)
**Args**: self


#### `comparison()` (line 163)
**Args**: self


#### `term()` (line 176)
**Args**: self


#### `factor()` (line 184)
**Args**: self


#### `unary()` (line 192)
**Args**: self


#### `primary()` (line 199)
**Args**: self


#### `_primary()` (line 214)
**Args**: self


#### `finish_call()` (line 245)
**Args**: self, callee


#### `match()` (line 258)
**Args**: self


#### `consume()` (line 265)
**Args**: self, type_, message


#### `error()` (line 272)
**Args**: self, token, message


#### `synchronize()` (line 278)
**Args**: self


#### `check()` (line 298)
**Args**: self, type_


#### `advance()` (line 303)
**Args**: self


#### `is_at_end()` (line 308)
**Args**: self


#### `peek()` (line 311)
**Args**: self


#### `previous()` (line 314)
**Args**: self


### src\hypercode\core\sensory_profile.py

#### `to_dict()` (line 77)
_Convert the profile to a dictionary.

Returns:
    Dict containing the profile data_

**Args**: self


#### `from_dict()` (line 93)
_Create a profile from a dictionary._

**Args**: cls, data


#### `save()` (line 115)
_Save the profile to a file._

**Args**: self, path


#### `load()` (line 121)
_Load a profile from a file._

**Args**: cls, path


#### `__init__()` (line 131)
_Initialize with optional custom profiles directory._

**Args**: self, profiles_dir


#### `_ensure_default_profiles()` (line 141)
_Ensure default profiles exist._

**Args**: self


#### `_create_minimal_profile()` (line 154)
_Create a minimal distraction-free profile._

**Args**: self


#### `_create_enhanced_profile()` (line 171)
_Create an enhanced profile with helpful visual cues._

**Args**: self


#### `_create_high_contrast_profile()` (line 198)
_Create a high-contrast profile for better readability._

**Args**: self


#### `list_profiles()` (line 224)
_List all available profile names._

**Args**: self


#### `get_profile()` (line 228)
_Get a profile by name._

**Args**: self, name


#### `save_profile()` (line 235)
_Save a profile._

**Args**: self, profile


#### `delete_profile()` (line 240)
_Delete a profile by name._

**Args**: self, name


#### `get_profile()` (line 251)
_Helper function to get a profile by name.

Args:
    name: Name of the profile to retrieve

Returns:
    The requested SensoryProfile or None if not found_

**Args**: name


#### `list_profiles()` (line 263)
_Helper function to list all available profiles.

Returns:
    List of available profile names_


### src\hypercode\core\tokens.py

#### `__str__()` (line 103)
**Args**: self


### src\hypercode\enhanced_perplexity_client.py

#### `__init__()` (line 21)
**Args**: self, kb_path


#### `query_with_context()` (line 25)
_Send a query with relevant knowledge base context_

**Args**: self, prompt, use_knowledge_base, model


#### `add_research_data()` (line 61)
_Add research data to the knowledge base_

**Args**: self, title, content, url, tags


#### `search_research_data()` (line 71)
_Search the knowledge base_

**Args**: self, query, limit


#### `list_research_documents()` (line 75)
_List all research documents_

**Args**: self


#### `get_document()` (line 79)
_Get a specific document_

**Args**: self, doc_id


#### `delete_document()` (line 83)
_Delete a document_

**Args**: self, doc_id


#### `import_from_perplexity_space()` (line 87)
_Import data from Perplexity Space export_

**Args**: self, space_data


#### `test_context_integration()` (line 123)
_Test the context integration_

**Args**: self


#### `create_perplexity_space_import_template()` (line 175)
_Create a template for importing Perplexity Space data_


### src\hypercode\knowledge_base.py

#### `__post_init__()` (line 28)
**Args**: self


#### `generate_id()` (line 36)
_Generate unique ID from content hash_

**Args**: self


#### `validate()` (line 41)
_Validate document data_

**Args**: self


#### `update_timestamp()` (line 53)
_Update the last_updated timestamp_

**Args**: self


#### `__init__()` (line 103)
**Args**: self, kb_path


#### `load()` (line 109)
_Load knowledge base from file_

**Args**: self


#### `save()` (line 125)
_Save knowledge base to file_

**Args**: self


#### `add_document()` (line 135)
_Add a new research document_

**Args**: self, title, content, url, tags


#### `search_documents()` (line 163)
_Search documents by query_

**Args**: self, query, limit


#### `get_context_for_query()` (line 227)
_Get relevant context for a query_

**Args**: self, query, max_context_length


#### `list_documents()` (line 257)
_List all documents_

**Args**: self


#### `get_document()` (line 261)
_Get a specific document by ID_

**Args**: self, doc_id


#### `delete_document()` (line 265)
_Delete a document_

**Args**: self, doc_id


#### `update_document()` (line 273)
_Update an existing document_

**Args**: self, doc_id


#### `search_by_tags()` (line 287)
_Search documents by tags with AND/OR operators_

**Args**: self, tags, operator


#### `get_document_statistics()` (line 306)
_Get statistics about the knowledge base_

**Args**: self


#### `export_format()` (line 331)
_Export knowledge base in different formats_

**Args**: self, format_type


#### `validate_all_documents()` (line 353)
_Validate all documents and return list of errors_

**Args**: self


#### `cleanup_duplicates()` (line 363)
_Remove duplicate documents based on content hash_

**Args**: self


#### `initialize_sample_data()` (line 384)
_Initialize with sample HyperCode research data_


### src\hypercode\perplexity_client.py

#### `__init__()` (line 15)
_Initialize the Perplexity client.

Args:
    api_key: Optional API key. If not provided, will use the one from config._

**Args**: self, api_key


#### `query()` (line 30)
_Send a query to the Perplexity API.

Args:
    prompt: The prompt to send to the API.
    model: The model to use for the query.

Returns:
    The API response as a dictionary._

**Args**: self, prompt, model


#### `test_connection()` (line 72)
_Test the connection to the Perplexity API_


### src\hypercode\repl.py

#### `run_repl()` (line 11)

#### `run()` (line 32)
**Args**: source


#### `show_help()` (line 51)

### src\hypercode_idea_generator.py

#### `__init__()` (line 439)
**Args**: self


#### `get_ideas_by_category()` (line 443)
_Get ideas by category and optionally by difficulty level.

Args:
    category: 'language_design', 'features_tooling',
             'community', 'accessibility'
    level: 'beginner', 'intermediate', 'advanced' (optional)

Returns:
    List of ideas_

**Args**: self, category, level


#### `get_top_ideas()` (line 468)
_Get most-voted ideas across all categories._

**Args**: self, category, limit


#### `vote_for_idea()` (line 487)
_Vote for an idea._

**Args**: self, idea_id


#### `get_trending_ideas()` (line 497)
_Get trending ideas (high votes + recent activity)._

**Args**: self


#### `format_idea_card()` (line 502)
_Format idea for display.

Returns:
    Formatted string for rendering_

**Args**: self, idea


#### `main()` (line 528)
_Interactive idea generator CLI_


### src\hypercode_poc.py

#### `__init__()` (line 51)
**Args**: self


#### `tokenize()` (line 74)
**Args**: self, source


#### `handle_string()` (line 115)
**Args**: self, quote, errors


#### `handle_number()` (line 141)
**Args**: self


#### `handle_identifier()` (line 149)
**Args**: self


#### `advance()` (line 171)
**Args**: self


#### `__init__()` (line 179)
**Args**: self


#### `format_error()` (line 182)
**Args**: self, msg, line, col, level


#### `analyze()` (line 192)
**Args**: self, tokens


#### `__init__()` (line 212)
**Args**: self, level


#### `record()` (line 216)
**Args**: self, success


#### `__init__()` (line 225)
**Args**: self, level


#### `compile()` (line 232)
**Args**: self, code


### src\mistral_adapter.py

#### `__init__()` (line 25)
**Args**: self, api_key


### src\ollama_adapter.py

#### `__init__()` (line 25)
**Args**: self, api_key


### src\openai_adapter.py

#### `__init__()` (line 25)
**Args**: self, api_key


### src\parser\debug_ascii.py

#### `test_regex_patterns()` (line 14)
_Test regex patterns directly_


### src\parser\debug_full.py

#### `debug_full_parsing()` (line 14)
_Debug the full parsing flow_


### src\parser\debug_parser.py

#### `debug_annotation_detection()` (line 14)
_Debug why annotations aren't being detected_


### src\parser\debug_simple.py

#### `debug_simple()` (line 14)
_Debug without emoji characters_


### src\parser\test_parser.py

#### `test_first_click_moment()` (line 14)
_Test the parser with the first click moment example_


### src\parser\visual_syntax_parser.py

#### `__str__()` (line 46)
**Args**: self


#### `get_annotations_by_type()` (line 62)
_Get all annotations of a specific type_

**Args**: self, marker_type


#### `__init__()` (line 72)
**Args**: self


#### `_build_semantic_patterns()` (line 76)
_üîç Build regex patterns for all semantic markers_

**Args**: self


#### `_build_color_scheme()` (line 105)
_üé® Build semantic color mapping for IDE highlighting_

**Args**: self


#### `parse_file()` (line 123)
_üìÑ Parse an entire HyperCode file_

**Args**: self, file_path


#### `parse_content()` (line 130)
_üìù Parse HyperCode content string_

**Args**: self, content


#### `_is_function_definition()` (line 170)
_üîç Check if line is a function definition_

**Args**: self, line


#### `_start_new_function()` (line 179)
_üÜï Create new ParsedFunction from definition line_

**Args**: self, line, line_num


#### `_parse_line_annotations()` (line 202)
_ÔøΩ Parse semantic annotations from a line_

**Args**: self, line, line_num


#### `_parse_annotation_params()` (line 223)
_üîß Parse annotation parameters from string_

**Args**: self, params_str


#### `generate_syntax_highlighting()` (line 265)
_üé® Generate HTML with syntax highlighting for visual markers_

**Args**: self, content


#### `extract_semantic_summary()` (line 277)
_üìä Extract semantic summary for analysis_

**Args**: self, functions


#### `validate_neurodiversity_compliance()` (line 311)
_üß† Validate neurodiversity-first design principles_

**Args**: self, functions


### src\scaffold (1).py

#### `create_directories()` (line 141)
_Create all required directories._


#### `create_python_files()` (line 151)
_Create all Python files with proper __init__.py structure._


#### `create_example_files()` (line 165)
_Create example HyperCode files._


#### `create_root_files()` (line 202)
_Create root-level configuration files as empty placeholders._


#### `create_healthcheck()` (line 213)
_Create the healthcheck script for Docker._


#### `print_summary()` (line 234)
_Print summary of created structure._


#### `main()` (line 259)
_Main scaffolding function._


### src\scaffold.py

#### `create_directories()` (line 153)
_Create all required directories._


#### `create_python_files()` (line 184)
_Create all Python files with proper docstrings and structure._


#### `create_example_files()` (line 254)
_Create example HyperCode files._


#### `create_root_files()` (line 291)
_Create root-level configuration files with appropriate content._


#### `create_healthcheck()` (line 541)
_Create the healthcheck script for Docker._


#### `print_summary()` (line 583)
_Print summary of created structure._


#### `main()` (line 621)
_Main scaffolding function._


### src\spatial_visualizer\src\code-analyzer.ts

#### `unnamed_function()` (line 56)

#### `unnamed_function()` (line 102)

#### `unnamed_function()` (line 103)

#### `unnamed_function()` (line 118)

#### `unnamed_function()` (line 164)

#### `unnamed_function()` (line 165)

#### `unnamed_function()` (line 180)

### src\spatial_visualizer\src\extension.ts

#### `unnamed_function()` (line 19)

#### `unnamed_function()` (line 52)

#### `unnamed_function()` (line 59)

### src\spatial_visualizer\src\spatial-visualizer.ts

#### `unnamed_function()` (line 77)

#### `unnamed_function()` (line 80)

#### `unnamed_function()` (line 141)

#### `unnamed_function()` (line 161)

#### `unnamed_function()` (line 162)

#### `unnamed_function()` (line 174)

#### `unnamed_function()` (line 176)

#### `unnamed_function()` (line 177)

#### `unnamed_function()` (line 187)

#### `unnamed_function()` (line 191)

#### `unnamed_function()` (line 195)

#### `unnamed_function()` (line 228)

#### `unnamed_function()` (line 263)

#### `unnamed_function()` (line 282)

### src\spatial_visualizer\src\visualization-panel.ts

#### `unnamed_function()` (line 237)

#### `unnamed_function()` (line 254)

#### `unnamed_function()` (line 265)

#### `unnamed_function()` (line 269)

#### `unnamed_function()` (line 273)

### src\src\code-analyzer.ts

#### `unnamed_function()` (line 56)

#### `unnamed_function()` (line 102)

#### `unnamed_function()` (line 103)

#### `unnamed_function()` (line 118)

#### `unnamed_function()` (line 164)

#### `unnamed_function()` (line 165)

#### `unnamed_function()` (line 180)

### src\src\extension.ts

#### `unnamed_function()` (line 19)

#### `unnamed_function()` (line 52)

#### `unnamed_function()` (line 59)

### src\src\spatial-visualizer.ts

#### `unnamed_function()` (line 77)

#### `unnamed_function()` (line 80)

#### `unnamed_function()` (line 141)

#### `unnamed_function()` (line 161)

#### `unnamed_function()` (line 162)

#### `unnamed_function()` (line 174)

#### `unnamed_function()` (line 176)

#### `unnamed_function()` (line 177)

#### `unnamed_function()` (line 187)

#### `unnamed_function()` (line 191)

#### `unnamed_function()` (line 195)

#### `unnamed_function()` (line 228)

#### `unnamed_function()` (line 263)

#### `unnamed_function()` (line 282)

### src\src\visualization-panel.ts

#### `unnamed_function()` (line 237)

#### `unnamed_function()` (line 254)

#### `unnamed_function()` (line 265)

#### `unnamed_function()` (line 269)

#### `unnamed_function()` (line 273)

### src\test_framework.py

#### `__init__()` (line 45)
**Args**: self, duelcode_dir


#### `discover_tutorials()` (line 49)
_Find all tutorial markdown files._

**Args**: self


#### `run_validator()` (line 56)
_Run the ultra validator on a file._

**Args**: self, file_path


#### `parse_validator_output()` (line 71)
_Parse validator output to count issues by severity._

**Args**: self, output


#### `test_tutorial()` (line 99)
_Test a single tutorial file._

**Args**: self, tutorial_path


#### `test_validator_integrity()` (line 135)
_Test that validator itself is working correctly._

**Args**: self


#### `test_template_validity()` (line 176)
_Test that templates pass validation._

**Args**: self


#### `run_all_tests()` (line 221)
_Run the complete test suite._

**Args**: self


#### `generate_report()` (line 248)
_Generate a detailed test report._

**Args**: self


#### `main()` (line 295)
_Main entry point._


### src\test_validator.py

#### `test_valid_file()` (line 11)
_Test with a valid DuelCode file._


#### `test_invalid_file()` (line 65)
_Test with an invalid DuelCode file._


#### `main()` (line 90)
_Run the test suite._


### src\ultra_validator.py

#### `__init__()` (line 88)
**Args**: self, file_path


#### `_add_result()` (line 95)
**Args**: self, message, severity, line, suggestion


#### `_find_lines()` (line 106)
**Args**: self, pattern


#### `validate_code_blocks_have_language()` (line 118)
_Validate all code blocks have language specifications._

**Args**: self


#### `validate_has_visual_representation()` (line 152)
_Check for visual elements like diagrams, charts, or ASCII art._

**Args**: self


#### `validate_has_practical_exercise()` (line 171)
_Check for practical exercises or challenges._

**Args**: self


#### `validate_has_learning_objectives()` (line 192)
_Check for learning objectives section._

**Args**: self


#### `validate_has_checklist()` (line 215)
_Check for checklist elements._

**Args**: self


#### `validate_has_conclusion()` (line 234)
_Check for conclusion section._

**Args**: self


#### `validate_has_whats_next()` (line 257)
_Check for 'What's Next' section._

**Args**: self


#### `validate_code_quality()` (line 278)
_Validate code block quality and best practices._

**Args**: self


#### `_validate_code_block_content()` (line 305)
_Validate specific code block content based on language._

**Args**: self, block_lines, lang, start_line


#### `validate_has_glossary()` (line 340)
_Check for glossary section._

**Args**: self


#### `validate_has_see_also()` (line 360)
_Check for 'See Also' section._

**Args**: self


#### `validate_has_faq()` (line 380)
_Check for FAQ section._

**Args**: self


#### `validate_has_acknowledgments()` (line 402)
_Check for acknowledgments section._

**Args**: self


#### `validate_accessibility()` (line 422)
_Check for accessibility features._

**Args**: self


#### `validate_interactive_elements()` (line 443)
_Check for interactive elements._

**Args**: self


#### `validate_all()` (line 463)
_Run all validations and return results._

**Args**: self


#### `print_results()` (line 487)
_Print validation results in a formatted way._

**Args**: self


#### `main()` (line 537)

### src\utils\code_analyzer_ai.py

#### `__init__()` (line 22)
**Args**: self


#### `analyze_file()` (line 25)
_Analyze a Python file with AI assistance_

**Args**: self, file_path


#### `_analyze_complexity()` (line 61)
_Analyze code complexity indicators_

**Args**: self, tree


#### `_check_docstrings()` (line 98)
_Check for docstring coverage_

**Args**: self, tree


#### `_get_ai_code_analysis()` (line 134)
_Get AI analysis of code from Perplexity_

**Args**: self, code, file_path


#### `analyze_project()` (line 162)
_Analyze entire project_

**Args**: self, project_path


#### `_get_project_ai_insights()` (line 206)
_Get AI insights for the entire project_

**Args**: self, analyses, stats


#### `save_analysis()` (line 238)
_Save analysis to file_

**Args**: self, analysis, filename


#### `print_summary()` (line 244)
_Print analysis summary_

**Args**: self, analysis


#### `main()` (line 262)
_Main function_


### src\utils\debug_search.py

#### `debug_search()` (line 15)
_Debug why space data isn't being found_


### src\utils\demo_ai_research.py

#### `demo_ai_research_queries()` (line 16)
_Demonstrate AI Research integration with Perplexity_


#### `test_document_specific_queries()` (line 90)
_Test queries specific to the HyperCode AI Research document_


### src\utils\demo_enhanced_client.py

#### `demo_knowledge_base_integration()` (line 16)
_Demonstrate the knowledge base integration_


#### `demonstrate_memory_persistence()` (line 131)
_Demonstrate that the knowledge base persists between sessions_


### src\utils\final_integration_test.py

#### `final_integration_test()` (line 15)
_Complete test of the Perplexity Space integration_


### src\utils\health_scanner_ai.py

#### `__init__()` (line 21)
**Args**: self


#### `analyze_project_structure()` (line 25)
_Analyze project structure and identify health issues_

**Args**: self


#### `analyze_dependencies()` (line 64)
_Analyze dependency management_

**Args**: self


#### `analyze_security()` (line 100)
_Analyze security configuration_

**Args**: self


#### `get_ai_recommendations()` (line 137)
_Get AI-powered recommendations based on health scan_

**Args**: self, health_data


#### `run_full_scan()` (line 164)
_Run complete health scan with AI analysis_

**Args**: self


#### `save_report()` (line 215)
_Save health scan report to file_

**Args**: self, report, filename


#### `print_summary()` (line 221)
_Print a summary of the health scan_

**Args**: self, report


#### `main()` (line 241)
_Main function to run the health scanner_


### src\utils\import-helper.py

#### `__init__()` (line 16)
**Args**: self, output_dir


#### `validate_document()` (line 21)
_Validate a document structure
Returns (is_valid, error_message)_

**Args**: self, doc


#### `load_template()` (line 63)
_Load documents from JSON template file_

**Args**: self, filepath


#### `validate_all()` (line 83)
_Validate all loaded documents_

**Args**: self


#### `generate_report()` (line 95)
_Generate a validation report_

**Args**: self


#### `create_import_script()` (line 141)
_Generate a Python script to import the data_

**Args**: self, output_file


#### `create_template_instructions()` (line 193)
_Generate detailed instructions for filling the template_

**Args**: self, output_file


#### `main()` (line 264)
_CLI interface for the import helper_


### src\utils\import_all_space_data.py

#### `format_content()` (line 16)
_Recursively format nested data into readable text_

**Args**: data, indent


#### `import_all_hypercode_data()` (line 41)
_Import all sections of your HyperCode Space data_


### src\utils\import_hypercode_data.py

#### `import_hypercode_space_data()` (line 16)
_Import your actual HyperCode Space data_


### src\utils\import_perplexity_space.py

#### `create_manual_import_script()` (line 17)
_Create a script for manual data entry from Perplexity Space_


#### `create_json_import_template()` (line 86)
_Create a JSON template for importing data_


#### `import_from_json()` (line 115)
_Import data from JSON file_


#### `test_imported_data()` (line 153)
_Test the imported data with context-aware queries_


#### `show_import_menu()` (line 188)
_Show the import menu_


### src\utils\local_health_scanner.py

#### `__init__()` (line 22)
**Args**: self


#### `scan_project()` (line 34)
_Scan the entire project and return health metrics_

**Args**: self


#### `_scan_directory()` (line 42)
_Recursively scan a directory for Python files_

**Args**: self, directory


#### `_analyze_file()` (line 51)
_Analyze a single Python file_

**Args**: self, file_path


#### `_analyze_ast()` (line 74)
_Analyze Python AST for code quality metrics_

**Args**: self, node


#### `_check_documentation()` (line 94)
_Check documentation coverage_

**Args**: self


#### `_check_tests()` (line 106)
_Check test coverage_

**Args**: self


#### `_calculate_metrics()` (line 117)
_Calculate final metrics_

**Args**: self


#### `print_health_report()` (line 128)
_Print a formatted health report_

**Args**: metrics


#### `main()` (line 158)
_Main function to run the health scanner_


### src\utils\perplexity_space_collector.py

#### `quick_copy_paste_collector()` (line 18)
_Quick collector for copy-paste workflow_


#### `create_structured_template()` (line 117)
_Create a structured JSON template for bulk import_


#### `show_bro_hacks()` (line 167)
_Show BROski's pro tips_


#### `main_menu()` (line 207)
_Main menu for the collector_


### src\utils\perplexity_space_integration.py

#### `main()` (line 16)

### src\utils\run_lexer.py

#### `run_lexer()` (line 12)
_Run the lexer on a source file and print the tokens._

**Args**: source_file


### src\validate_duelcode.py

#### `__init__()` (line 24)
**Args**: self, file_path


#### `validate_sections()` (line 30)
_Check if all required sections are present._

**Args**: self


#### `check_formatting()` (line 39)
_Check for common formatting issues._

**Args**: self


#### `check_visual_aids()` (line 55)
_Check for presence of visual aids._

**Args**: self


#### `validate()` (line 60)
_Run all validations and return results._

**Args**: self


#### `main()` (line 68)

### tests\benchmark_knowledge_base.py

#### `__init__()` (line 27)
**Args**: self


#### `_get_system_info()` (line 34)
_Get system information for benchmark context_

**Args**: self


#### `generate_test_data()` (line 43)
_Generate test data of specified size_

**Args**: self, size


#### `benchmark_operation()` (line 93)
_Benchmark a single operation_

**Args**: self, operation_name, operation_func


#### `run_benchmark_suite()` (line 118)
_Run complete benchmark suite_

**Args**: self, size


#### `_calculate_summary()` (line 274)
_Calculate summary statistics_

**Args**: self


#### `_generate_recommendations()` (line 296)
_Generate performance recommendations_

**Args**: self


#### `generate_markdown_report()` (line 338)
_Generate beautiful markdown report_

**Args**: self, output_file


#### `save_json_results()` (line 467)
_Save results as JSON_

**Args**: self, output_file


#### `main()` (line 474)
_Main benchmark runner_


### tests\conftest.py

#### `sample_hypercode()` (line 16)

#### `sample_lexer_tokens()` (line 27)

### tests\test_core.py

#### `run_test()` (line 30)
_Test the lexer, parser, and interpreter with the given source code._

**Args**: source_code


### tests\test_direct_access.py

#### `test_direct_implementation_access()` (line 15)
_Test direct access to implementation guide content_


### tests\test_implementation_guide.py

#### `test_search_functionality()` (line 15)
_Test search for implementation guide terms_


#### `test_implementation_guide_content()` (line 37)
_Test the implementation guide document directly_


#### `test_context_queries()` (line 82)
_Test context-aware queries_


### tests\test_intent_blocks.py

#### `test_intent_block()` (line 13)
_Test parsing of intent blocks_


### tests\test_interpreter.py

#### `run_code()` (line 10)
_A helper function to run code and capture stdout._

**Args**: source


#### `test_if_statement_then()` (line 30)
**Args**: self


#### `test_if_statement_else()` (line 42)
**Args**: self


#### `test_function_call()` (line 54)
**Args**: self


#### `test_function_with_parameters()` (line 64)
**Args**: self


#### `test_function_with_return()` (line 74)
**Args**: self


#### `test_recursive_function_call()` (line 85)
**Args**: self


#### `test_scoping()` (line 99)
**Args**: self


### tests\test_knowledge_base.py

#### `sample_documents()` (line 16)
_Create sample documents for testing._

**Args**: self


#### `knowledge_base()` (line 40)
_Create a knowledge base instance with sample documents._

**Args**: self, sample_documents


#### `test_basic_search()` (line 48)
_Test basic search functionality._

**Args**: self, knowledge_base, sample_documents


#### `test_search_with_exact_match()` (line 54)
_Test search with exact phrase matching._

**Args**: self, knowledge_base


#### `test_search_case_insensitive()` (line 59)
_Test that search is case-insensitive._

**Args**: self, knowledge_base


#### `test_search_empty_query()` (line 65)
_Test search with empty query returns all or no documents._

**Args**: self, knowledge_base


#### `test_search_no_matches()` (line 71)
_Test search with no matching documents._

**Args**: self, knowledge_base


#### `test_search_ranking()` (line 77)
_Test that search results are ranked by relevance._

**Args**: self, knowledge_base, sample_documents


#### `test_query_normalization()` (line 90)
_Test query normalization (typos, spacing, punctuation)._

**Args**: self, knowledge_base


#### `test_multi_word_query()` (line 98)
_Test search with multiple keywords._

**Args**: self, knowledge_base


#### `test_tag_based_search()` (line 103)
_Test search that includes tag matching._

**Args**: self, knowledge_base, sample_documents


#### `knowledge_base()` (line 116)
**Args**: self


#### `test_very_short_query()` (line 121)
_Test search with very short query (1-2 chars)._

**Args**: self, knowledge_base


#### `test_very_long_query()` (line 126)
_Test search with very long query (paragraph length)._

**Args**: self, knowledge_base


#### `test_special_characters_in_query()` (line 136)
_Test search with special characters._

**Args**: self, knowledge_base


#### `test_unicode_in_query()` (line 141)
_Test search with unicode characters._

**Args**: self, knowledge_base


#### `test_sql_injection_attempt()` (line 146)
_Test that search is safe from SQL injection-style attacks._

**Args**: self, knowledge_base


#### `test_repeated_queries()` (line 151)
_Test that repeated queries return consistent results._

**Args**: self, knowledge_base


#### `large_knowledge_base()` (line 163)
_Create a knowledge base with many documents._

**Args**: self


#### `test_search_response_time()` (line 179)
_Test that search completes within acceptable time._

**Args**: self, large_knowledge_base


#### `test_concurrent_searches()` (line 189)
_Test multiple concurrent search operations._

**Args**: self, large_knowledge_base


#### `test_memory_usage()` (line 207)
_Test memory usage during search operations._

**Args**: self, large_knowledge_base


#### `mock_perplexity_client()` (line 217)
_Create a mock Perplexity client._

**Args**: self


#### `mock_knowledge_base()` (line 229)
_Create a mock knowledge base._

**Args**: self


#### `test_enhanced_query_with_context()` (line 243)
_Test that queries are enhanced with knowledge base context._

**Args**: self, mock_perplexity_client, mock_knowledge_base


#### `test_fallback_to_perplexity_api()` (line 259)
_Test fallback to Perplexity API when no local context found._

**Args**: self, mock_perplexity_client, mock_knowledge_base


#### `test_context_ranking_and_selection()` (line 273)
_Test that best context is selected for query enhancement._

**Args**: self, mock_knowledge_base


#### `knowledge_base()` (line 292)
**Args**: self


#### `test_add_document()` (line 300)
_Test adding a new document to knowledge base._

**Args**: self, knowledge_base


#### `test_update_document()` (line 310)
_Test updating an existing document._

**Args**: self, knowledge_base


#### `test_remove_document()` (line 315)
_Test removing a document._

**Args**: self, knowledge_base


### tests\test_knowledge_base_comprehensive.py

#### `temp_kb()` (line 24)
_Create a temporary knowledge base for testing_

**Args**: self


#### `sample_docs()` (line 36)
_Sample documents for testing_

**Args**: self


#### `test_init_empty_kb()` (line 59)
_Test knowledge base initialization_

**Args**: self, temp_kb


#### `test_add_single_document()` (line 65)
_Test adding a single document_

**Args**: self, temp_kb, sample_docs


#### `test_add_multiple_documents()` (line 74)
_Test adding multiple documents_

**Args**: self, temp_kb, sample_docs


#### `test_save_and_load()` (line 84)
_Test saving and loading knowledge base_

**Args**: self, temp_kb, sample_docs


#### `test_search_exact_match()` (line 102)
_Test exact search matching_

**Args**: self, temp_kb, sample_docs


#### `test_search_partial_match()` (line 113)
_Test partial search matching_

**Args**: self, temp_kb, sample_docs


#### `test_search_tag_matching()` (line 124)
_Test tag-based search_

**Args**: self, temp_kb, sample_docs


#### `test_search_case_insensitive()` (line 135)
_Test case insensitive search_

**Args**: self, temp_kb, sample_docs


#### `test_empty_search()` (line 147)
_Test empty search query_

**Args**: self, temp_kb


#### `test_nonexistent_search()` (line 155)
_Test search for nonexistent terms_

**Args**: self, temp_kb, sample_docs


#### `test_get_context_for_query()` (line 165)
_Test context extraction_

**Args**: self, temp_kb, sample_docs


#### `test_context_length_limit()` (line 176)
_Test context length limiting_

**Args**: self, temp_kb, sample_docs


#### `test_document_update()` (line 186)
_Test updating existing documents_

**Args**: self, temp_kb, sample_docs


#### `test_list_documents()` (line 202)
_Test listing all documents_

**Args**: self, temp_kb, sample_docs


#### `test_delete_document()` (line 213)
_Test document deletion_

**Args**: self, temp_kb, sample_docs


#### `populated_kb()` (line 233)
_Create a populated knowledge base for integration testing_

**Args**: self


#### `test_complex_search_queries()` (line 277)
_Test complex search scenarios_

**Args**: self, populated_kb


#### `test_search_ranking_quality()` (line 291)
_Test that search results are properly ranked_

**Args**: self, populated_kb


#### `test_related_term_expansion()` (line 301)
_Test that related terms are properly expanded_

**Args**: self, populated_kb


#### `test_performance_with_large_dataset()` (line 313)
_Test performance with larger dataset_

**Args**: self, populated_kb


#### `test_concurrent_access_simulation()` (line 332)
_Test simulated concurrent access_

**Args**: self, populated_kb


#### `large_kb()` (line 360)
_Create a large knowledge base for performance testing_

**Args**: self


#### `test_search_performance_large_dataset()` (line 382)
_Test search performance with large dataset_

**Args**: self, large_kb


#### `test_save_performance_large_dataset()` (line 396)
_Test save performance with large dataset_

**Args**: self, large_kb


#### `test_load_performance_large_dataset()` (line 409)
_Test load performance with large dataset_

**Args**: self, large_kb


#### `test_memory_usage_large_dataset()` (line 423)
_Test memory usage with large dataset_

**Args**: self, large_kb


#### `edge_case_kb()` (line 450)
_Create knowledge base for edge case testing_

**Args**: self


#### `test_empty_title_handling()` (line 494)
_Test handling of documents with empty titles_

**Args**: self, edge_case_kb


#### `test_special_characters_handling()` (line 499)
_Test handling of special characters and unicode_

**Args**: self, edge_case_kb


#### `test_very_long_titles()` (line 507)
_Test handling of very long titles_

**Args**: self, edge_case_kb


#### `test_empty_content_handling()` (line 512)
_Test handling of documents with empty content_

**Args**: self, edge_case_kb


#### `test_none_tags_handling()` (line 517)
_Test handling of None tags_

**Args**: self, edge_case_kb


#### `test_malformed_json_handling()` (line 531)
_Test handling of malformed JSON files_

**Args**: self


#### `test_file_permission_handling()` (line 544)
_Test handling of file permission issues_

**Args**: self


### tests\test_lexer.py

#### `test_lexer_basic_tokens()` (line 5)

#### `test_lexer_strings()` (line 23)

#### `test_lexer_operators()` (line 48)
**Args**: source, expected_type


### tests\test_lexer_extended.py

#### `test_lexer_escaped_strings()` (line 5)
_Test handling of strings with escaped characters._


#### `test_lexer_numbers()` (line 18)
_Test various number formats._


#### `test_lexer_operators()` (line 39)
_Test all operators._


#### `test_lexer_comments()` (line 86)
_Test handling of single-line and multi-line comments._


#### `test_lexer_whitespace()` (line 115)
_Test handling of various whitespace characters._


#### `test_lexer_error_handling()` (line 130)
_Test error handling for invalid tokens._


#### `test_lexer_hex_numbers()` (line 139)
_Test hexadecimal number literals._


#### `test_lexer_binary_numbers()` (line 157)
_Test binary number literals._


#### `test_lexer_scientific_notation()` (line 169)
_Test scientific notation numbers._


#### `test_lexer_string_escapes()` (line 180)
_Test string escape sequences._


#### `test_lexer_keywords()` (line 197)
_Test all language keywords._


#### `test_lexer_position_tracking()` (line 223)
_Test that line and column numbers are tracked correctly._


#### `test_lexer_error_recovery()` (line 243)
_Test that the lexer raises errors on invalid characters._


#### `test_lexer_error_messages()` (line 252)
_Test that lexer error messages are informative._


### tests\test_parser.py

#### `test_parse_literal()` (line 12)

#### `test_parse_variable_declaration()` (line 24)

#### `test_parse_binary_expression()` (line 37)

### tests\test_perplexity.py

#### `test_perplexity_connection()` (line 16)
_Test Perplexity API with detailed logging_


#### `test_ai_research_integration()` (line 66)
_Test integration with AI Research document content_


### tests\test_real_data.py

#### `test_enhanced_knowledge_base()` (line 16)
_Test enhanced KnowledgeBase functionality_


#### `test_real_perplexity_data_simulation()` (line 185)
_Simulate testing with real Perplexity Space data_


### tests\test_real_space_data.py

#### `test_real_space_data()` (line 15)
_Test queries that use your actual Perplexity Space data_


### tests\test_sensory_profiles.py

#### `test_visual_settings_creation()` (line 21)
_Test creating visual settings._


#### `test_audio_settings_creation()` (line 35)
_Test creating audio settings._


#### `test_animation_settings_creation()` (line 44)
_Test creating animation settings._


#### `test_sensory_profile_creation()` (line 55)
_Test creating a complete sensory profile._


#### `test_profile_serialization()` (line 71)
_Test serializing AND deserializing a profile._


#### `test_profile_file_io()` (line 92)
_Test saving and loading a profile to/from a file._

**Args**: tmp_path


#### `test_profile_manager_initialization()` (line 115)
_Test initializing the profile manager and checking default profiles._

**Args**: tmp_path


#### `test_profile_manager_get_profile()` (line 129)
_Test getting a profile by name._

**Args**: tmp_path


#### `test_profile_manager_save_custom_profile()` (line 142)
_Test saving a custom profile._

**Args**: tmp_path


#### `test_profile_manager_delete_profile()` (line 169)
_Test deleting a profile._

**Args**: tmp_path


### tests\test_syntax.py

#### `test_program_structure()` (line 8)
_Test basic program structure and entry point._


#### `test_function_definition()` (line 26)
_Test function definition syntax._


#### `test_io_operations()` (line 49)
_Test input/output operations._


#### `test_variables()` (line 73)
_Test variable declarations and assignments._


#### `test_loops()` (line 96)
_Test loop constructs._


#### `test_conditionals()` (line 117)
_Test if/else conditionals._


#### `test_goto()` (line 142)
_Test goto and labels._


#### `test_comments()` (line 167)
_Test that comments are properly ignored._


### tests\tests\test_lexer_enhanced.py

#### `test_lexer_edge_cases()` (line 7)

#### `test_lexer_error_handling()` (line 28)

#### `test_lexer_number_literals()` (line 43)

#### `test_lexer_string_interpolation()` (line 65)

#### `test_lexer_docstrings()` (line 79)

### tests\unit\lexer\test_lexer_basic.py

#### `test_empty_source()` (line 12)
_Test that an empty source returns only EOF token._

**Args**: self


#### `test_whitespace_handling()` (line 19)
_Test that whitespace is properly handled and ignored._

**Args**: self


#### `test_single_character_tokens()` (line 27)
_Test recognition of single-character tokens._

**Args**: self


#### `test_comments_are_ignored()` (line 52)
_Test that comments are properly ignored._

**Args**: self


#### `test_string_literals()` (line 72)
_Test string literal tokenization._

**Args**: self


#### `test_number_literals()` (line 87)
_Test number literal tokenization._

**Args**: self


#### `test_identifiers_and_keywords()` (line 103)
_Test identifier and keyword recognition._

**Args**: self


#### `test_error_handling()` (line 139)
_Test error handling for invalid tokens._

**Args**: self


### tests\unit\test_direct_access.py

#### `test_direct_implementation_access()` (line 15)
_Test direct access to implementation guide content_


### tests\unit\test_implementation_guide.py

#### `test_search_functionality()` (line 15)
_Test search for implementation guide terms_


#### `test_implementation_guide_content()` (line 37)
_Test the implementation guide document directly_


#### `test_context_queries()` (line 82)
_Test context-aware queries_


### tests\unit\test_intent_blocks.py

#### `test_intent_block()` (line 13)
_Test parsing of intent blocks_


### tests\unit\test_knowledge_base.py

#### `temp_kb()` (line 24)
_Create a temporary knowledge base for testing_

**Args**: self


#### `sample_documents()` (line 33)
_Sample documents for testing_

**Args**: self


#### `test_init_empty_kb()` (line 56)
_Test knowledge base initialization_

**Args**: self, temp_kb


#### `test_add_document()` (line 61)
_Test adding a single document_

**Args**: self, temp_kb, sample_documents


#### `test_add_multiple_documents()` (line 82)
_Test adding multiple documents_

**Args**: self, temp_kb, sample_documents


#### `test_save_and_load()` (line 92)
_Test saving and loading knowledge base_

**Args**: self, temp_kb, sample_documents


#### `test_search_exact_match()` (line 113)
_Test exact term matching in search_

**Args**: self, temp_kb, sample_documents


#### `test_search_tag_matching()` (line 126)
_Test tag-based search_

**Args**: self, temp_kb, sample_documents


#### `test_search_related_terms()` (line 139)
_Test related term expansion_

**Args**: self, temp_kb, sample_documents


#### `test_search_space_data_boost()` (line 153)
_Test that space data gets boosted in search_

**Args**: self, temp_kb


#### `test_get_context_for_query()` (line 180)
_Test context extraction for queries_

**Args**: self, temp_kb, sample_documents


#### `test_context_length_limit()` (line 192)
_Test context length limiting_

**Args**: self, temp_kb, sample_documents


#### `test_list_documents()` (line 203)
_Test listing all documents_

**Args**: self, temp_kb, sample_documents


#### `test_empty_search()` (line 216)
_Test search with empty query_

**Args**: self, temp_kb


#### `test_search_nonexistent_term()` (line 221)
_Test search for term that doesn't exist_

**Args**: self, temp_kb, sample_documents


#### `test_document_update()` (line 231)
_Test updating existing document_

**Args**: self, temp_kb, sample_documents


#### `test_document_creation()` (line 253)
_Test creating a research document_

**Args**: self


#### `test_document_optional_fields()` (line 273)
_Test document with optional fields_

**Args**: self


### tests\unit\test_lexer.py

#### `test_lexer()` (line 12)
_Test the lexer with the given source code and print the results.

Args:
    source: The source code to tokenize
    description: A description of what this test is checking_

**Args**: source, description


#### `run_tests()` (line 42)
_Run a series of test cases for the lexer._


### tests\unit\test_lexer_pytest.py

#### `test_basic_arithmetic()` (line 9)
_Test basic arithmetic expressions._


#### `test_variable_declaration()` (line 25)
_Test variable declarations._


#### `test_string_literals()` (line 40)
_Test string literals._


### tests\unit\test_mcp_connection.py

#### `check_port()` (line 26)
_Check if a port is open on the given host._

**Args**: host, port, timeout


#### `find_running_servers()` (line 36)
_Scan common ports to find running servers._

**Args**: host


#### `test_server_connection()` (line 49)
_Test connection to a single MCP server._

**Args**: server_name, base_url, port


#### `test_all_servers()` (line 90)
_Test connection to all MCP servers and print results._


#### `check_dependencies()` (line 139)
_Check if required dependencies are installed._


### tests\unit\test_perplexity.py

#### `test_perplexity_connection()` (line 16)
_Test Perplexity API with detailed logging_


#### `test_ai_research_integration()` (line 66)
_Test integration with AI Research document content_


### tests\unit\test_real_data.py

#### `test_enhanced_knowledge_base()` (line 16)
_Test enhanced KnowledgeBase functionality_


#### `test_real_perplexity_data_simulation()` (line 185)
_Simulate testing with real Perplexity Space data_


### tests\unit\test_real_space_data.py

#### `test_real_space_data()` (line 15)
_Test queries that use your actual Perplexity Space data_


### tests\unit\test_search_algorithm.py

#### `populated_kb()` (line 24)
_Create a knowledge base with test documents_

**Args**: self


#### `test_exact_title_match_highest_score()` (line 80)
_Test that exact title matches get highest priority_

**Args**: self, populated_kb


#### `test_space_data_boosting()` (line 92)
_Test that space data gets boosted in search results_

**Args**: self, populated_kb


#### `test_related_term_expansion()` (line 105)
_Test related term matching functionality_

**Args**: self, populated_kb


#### `test_tag_matching_scoring()` (line 126)
_Test that tag matches contribute to scoring_

**Args**: self, populated_kb


#### `test_content_frequency_scoring()` (line 136)
_Test that multiple content occurrences increase score_

**Args**: self, populated_kb


#### `test_partial_word_matching()` (line 149)
_Test partial word matching for longer terms_

**Args**: self, populated_kb


#### `test_query_word_ordering()` (line 167)
_Test that query words are properly processed_

**Args**: self, populated_kb


#### `test_case_insensitive_search()` (line 179)
_Test that search is case insensitive_

**Args**: self, populated_kb


#### `test_empty_query_returns_no_results()` (line 202)
_Test that empty queries return no results_

**Args**: self, populated_kb


#### `test_limit_parameter_respected()` (line 210)
_Test that search limit parameter works correctly_

**Args**: self, populated_kb


#### `test_no_results_for_nonexistent_terms()` (line 219)
_Test search for terms that don't exist_

**Args**: self, populated_kb


#### `test_special_characters_in_query()` (line 227)
_Test search with special characters_

**Args**: self, populated_kb


#### `test_unicode_characters()` (line 237)
_Test search with unicode characters_

**Args**: self, populated_kb


#### `test_search_performance_with_large_kb()` (line 256)
_Test search performance with larger knowledge base_

**Args**: self, populated_kb


#### `test_search_result_consistency()` (line 277)
_Test that search results are consistent across multiple calls_

**Args**: self, populated_kb


#### `scoring_kb()` (line 296)
_Create KB for detailed scoring tests_

**Args**: self


#### `test_title_match_beats_content_match()` (line 324)
_Test that title matches score higher than content matches_

**Args**: self, scoring_kb


#### `test_space_data_boosting_works()` (line 332)
_Test that space data gets boosted_

**Args**: self, scoring_kb


#### `test_frequency_scoring()` (line 340)
_Test that content frequency affects scoring_

**Args**: self, scoring_kb


### venv_new\Lib\site-packages\pip\__init__.py

#### `main()` (line 6)
_This is an internal API only meant for use by pip's own console scripts.

For additional details, see https://github.com/pypa/pip/issues/7498._

**Args**: args


### venv_new\Lib\site-packages\pip\__pip-runner__.py

#### `version_str()` (line 15)
**Args**: version


#### `find_spec()` (line 38)
**Args**: self, fullname, path, target


### venv_new\Lib\site-packages\pip\_internal\__init__.py

#### `main()` (line 10)
_This is preserved for old console scripts that may still be referencing
it.

For additional details, see https://github.com/pypa/pip/issues/7498._

**Args**: args


### venv_new\Lib\site-packages\pip\_internal\build_env.py

#### `_dedup()` (line 31)
**Args**: a, b


#### `__init__()` (line 36)
**Args**: self, path


#### `get_runnable_pip()` (line 44)
_Get a file to pass to a Python executable, to run the currently-running pip.

This is used to run a pip subprocess, for installing requirements into the build
environment._


#### `_get_system_sitepackages()` (line 60)
_Get system site packages

Usually from site.getsitepackages,
but fallback on `get_purelib()/get_platlib()` if unavailable
(e.g. in a virtualenv created by virtualenv<20)

Returns normalized set of strings._


#### `__init__()` (line 83)
**Args**: self


#### `__enter__()` (line 137)
**Args**: self


#### `__exit__()` (line 158)
**Args**: self, exc_type, exc_val, exc_tb


#### `check_requirements()` (line 170)
_Return 2 sets:
- conflicting requirements: set of (installed, wanted) reqs tuples
- missing requirements: set of reqs_

**Args**: self, reqs


#### `install_requirements()` (line 204)
**Args**: self, finder, requirements, prefix_as_string


#### `_install_requirements()` (line 226)
**Args**: pip_runnable, finder, requirements, prefix


#### `__init__()` (line 297)
**Args**: self


#### `__enter__()` (line 300)
**Args**: self


#### `__exit__()` (line 303)
**Args**: self, exc_type, exc_val, exc_tb


#### `cleanup()` (line 311)
**Args**: self


#### `install_requirements()` (line 314)
**Args**: self, finder, requirements, prefix_as_string


### venv_new\Lib\site-packages\pip\_internal\cache.py

#### `_hash_dict()` (line 26)
_Return a stable sha224 of a dictionary._

**Args**: d


#### `__init__()` (line 38)
**Args**: self, cache_dir


#### `_get_cache_path_parts()` (line 43)
_Get parts of part that must be os.path.joined with cache_dir_

**Args**: self, link


#### `_get_candidates()` (line 76)
**Args**: self, link, canonical_package_name


#### `get_path_for_link()` (line 86)
_Return a directory to store cached items in for link._

**Args**: self, link


#### `get()` (line 90)
_Returns a link to a cached item if it exists, otherwise returns the
passed link._

**Args**: self, link, package_name, supported_tags


#### `__init__()` (line 105)
**Args**: self, cache_dir


#### `get_path_for_link()` (line 108)
_Return a directory to store cached wheels for link

Because there are M wheels for any one sdist, we provide a directory
to cache them in, and then consult that directory when looking up
cache hits.

We only insert things into the cache if they have plausible version
numbers, so that we don't contaminate the cache with things that were
not unique. E.g. ./package might have dozens of installs done for it
and build a version of 0.0...and if we built and cached a wheel, we'd
end up using the same wheel even if the source has been edited.

:param link: The link of the sdist for which this will cache wheels._

**Args**: self, link


#### `get()` (line 128)
**Args**: self, link, package_name, supported_tags


#### `__init__()` (line 175)
**Args**: self


#### `__init__()` (line 185)
**Args**: self, link, persistent


#### `__init__()` (line 215)
**Args**: self, cache_dir


#### `get_path_for_link()` (line 220)
**Args**: self, link


#### `get_ephem_path_for_link()` (line 223)
**Args**: self, link


#### `get()` (line 226)
**Args**: self, link, package_name, supported_tags


#### `get_cache_entry()` (line 237)
_Returns a CacheEntry with a link to a cached item if it exists or
None. The cache entry indicates if the item was found in the persistent
or ephemeral cache._

**Args**: self, link, package_name, supported_tags


#### `record_download_origin()` (line 266)
**Args**: cache_dir, download_info


### venv_new\Lib\site-packages\pip\_internal\cli\autocompletion.py

#### `autocomplete()` (line 15)
_Entry Point for completion of main and subcommand options._


#### `get_path_completion_type()` (line 124)
_Get the type of path completion (``file``, ``dir``, ``path`` or None)

:param cwords: same as the environmental variable ``COMP_WORDS``
:param cword: same as the environmental variable ``COMP_CWORD``
:param opts: The available options to check
:return: path completion type (``file``, ``dir``, ``path`` or None)_

**Args**: cwords, cword, opts


#### `auto_complete_paths()` (line 148)
_If ``completion_type`` is ``file`` or ``path``, list all regular files
and directories starting with ``current``; otherwise only list directories
starting with ``current``.

:param current: The word to be completed
:param completion_type: path completion type(``file``, ``path`` or ``dir``)
:return: A generator of regular files and/or directories_

**Args**: current, completion_type


### venv_new\Lib\site-packages\pip\_internal\cli\base_command.py

#### `__init__()` (line 49)
**Args**: self, name, summary, isolated


#### `add_options()` (line 79)
**Args**: self


#### `handle_pip_version_check()` (line 82)
_This is a no-op so that commands by default do not do the pip version
check._

**Args**: self, options


#### `run()` (line 91)
**Args**: self, options, args


#### `_run_wrapper()` (line 94)
**Args**: self, level_number, options, args


#### `_inner_run()` (line 95)

#### `parse_args()` (line 151)
**Args**: self, args


#### `main()` (line 155)
**Args**: self, args


#### `_main()` (line 162)
**Args**: self, args


### venv_new\Lib\site-packages\pip\_internal\cli\cmdoptions.py

#### `raise_option_error()` (line 36)
_Raise an option parsing error using parser.error().

Args:
  parser: an OptionParser instance.
  option: an Option instance.
  msg: the error text._

**Args**: parser, option, msg


#### `make_option_group()` (line 50)
_Return an OptionGroup object
group  -- assumed to be dict with 'name' and 'options' keys
parser -- an optparse Parser_

**Args**: group, parser


#### `check_dist_restriction()` (line 62)
_Function for determining if custom platform options are allowed.

:param options: The OptionParser options.
:param check_target: Whether or not to check if --target is being used._

**Args**: options, check_target


#### `_path_option_check()` (line 102)
**Args**: option, opt, value


#### `_package_name_option_check()` (line 106)
**Args**: option, opt, value


#### `exists_action()` (line 299)

#### `extra_index_url()` (line 354)

#### `find_links()` (line 377)

#### `trusted_host()` (line 393)

#### `constraints()` (line 405)

#### `requirements()` (line 418)

#### `editable()` (line 431)

#### `_handle_src()` (line 446)
**Args**: option, opt_str, value, parser


#### `_get_format_control()` (line 469)
_Get a format_control object._

**Args**: values, option


#### `_handle_no_binary()` (line 474)
**Args**: option, opt_str, value, parser


#### `_handle_only_binary()` (line 485)
**Args**: option, opt_str, value, parser


#### `no_binary()` (line 496)

#### `only_binary()` (line 514)

#### `_convert_python_version()` (line 548)
_Convert a version string like "3", "37", or "3.7.3" into a tuple of ints.

:return: A 2-tuple (version_info, error_msg), where `error_msg` is
    non-None if and only if there was a parsing error._

**Args**: value


#### `_handle_python_version()` (line 577)
_Handle a provided --python-version value._

**Args**: option, opt_str, value, parser


#### `add_target_python_options()` (line 646)
**Args**: cmd_opts


#### `make_target_python()` (line 653)
**Args**: options


#### `prefer_binary()` (line 664)

#### `_handle_no_cache_dir()` (line 688)
_Process a value provided for the --no-cache-dir option.

This is an optparse.Option callback for the --no-cache-dir option._

**Args**: option, opt, value, parser


#### `_handle_no_use_pep517()` (line 765)
_Process a value provided for the --no-use-pep517 option.

This is an optparse.Option callback for the no_use_pep517 option._

**Args**: option, opt, value, parser


#### `_handle_config_settings()` (line 821)
**Args**: option, opt_str, value, parser


#### `_handle_merge_hash()` (line 910)
_Given a value spelled "algo:digest", append the digest to a list
pointed to in a dict by the algo name._

**Args**: option, opt_str, value, parser


#### `check_list_path_option()` (line 971)
**Args**: options


### venv_new\Lib\site-packages\pip\_internal\cli\command_context.py

#### `__init__()` (line 8)
**Args**: self


#### `main_context()` (line 14)
**Args**: self


#### `enter_context()` (line 24)
**Args**: self, context_provider


### venv_new\Lib\site-packages\pip\_internal\cli\index_command.py

#### `_create_truststore_ssl_context()` (line 28)

#### `__init__()` (line 55)
**Args**: self


#### `_get_index_urls()` (line 60)
_Return a list of index urls from user-provided options._

**Args**: cls, options


#### `get_default_session()` (line 73)
_Get a default-managed session._

**Args**: self, options


#### `_build_session()` (line 83)
**Args**: self, options, retries, timeout


#### `_pip_self_version_check()` (line 135)
**Args**: session, options


#### `handle_pip_version_check()` (line 148)
_Do the pip version check if not disabled.

This overrides the default behavior of not doing the check._

**Args**: self, options


### venv_new\Lib\site-packages\pip\_internal\cli\main.py

#### `main()` (line 47)
**Args**: args


### venv_new\Lib\site-packages\pip\_internal\cli\main_parser.py

#### `create_main_parser()` (line 19)
_Creates and returns the main parser for pip's CLI_


#### `identify_python_interpreter()` (line 50)
**Args**: python


#### `parse_command()` (line 69)
**Args**: args


### venv_new\Lib\site-packages\pip\_internal\cli\parser.py

#### `__init__()` (line 21)
**Args**: self


#### `format_option_strings()` (line 28)
**Args**: self, option


#### `_format_option_strings()` (line 31)
_Return a comma-separated list of option strings and metavars.

:param option:  tuple of (short opt, long opt), e.g: ('-f', '--format')
:param mvarfmt: metavar format string
:param optsep:  separator_

**Args**: self, option, mvarfmt, optsep


#### `format_heading()` (line 57)
**Args**: self, heading


#### `format_usage()` (line 62)
_Ensure there is only one newline between usage and the first heading
if there is no description._

**Args**: self, usage


#### `format_description()` (line 70)
**Args**: self, description


#### `format_epilog()` (line 88)
**Args**: self, epilog


#### `indent_lines()` (line 95)
**Args**: self, text, indent


#### `expand_default()` (line 109)
**Args**: self, option


#### `insert_option_group()` (line 133)
_Insert an OptionGroup at a given position._

**Args**: self, idx


#### `option_list_all()` (line 145)
_Get a list of all options, including those in option groups._

**Args**: self


#### `__init__()` (line 158)
**Args**: self


#### `check_default()` (line 171)
**Args**: self, option, key, val


#### `_get_ordered_configuration_items()` (line 178)
**Args**: self


#### `_update_defaults()` (line 206)
_Updates the given defaults with values from the config files and
the environ. Does a little special handling for certain types of
options (lists)._

**Args**: self, defaults


#### `get_default_values()` (line 270)
_Overriding to make updating the defaults after instantiation of
the option parser possible, _update_defaults() does the dirty work._

**Args**: self


#### `error()` (line 292)
**Args**: self, msg


### venv_new\Lib\site-packages\pip\_internal\cli\progress_bars.py

#### `_rich_progress_bar()` (line 24)
**Args**: iterable


#### `_raw_progress_bar()` (line 60)
**Args**: iterable


#### `write_progress()` (line 65)
**Args**: current, total


#### `get_download_progress_renderer()` (line 82)
_Get an object that can be used to render the download progress.

Returns a callable, that takes an iterable to "wrap"._


### venv_new\Lib\site-packages\pip\_internal\cli\req_command.py

#### `with_cleanup()` (line 50)
_Decorator for common logic related to managing temporary
directories._

**Args**: func


#### `configure_tempdir_registry()` (line 55)
**Args**: registry


#### `wrapper()` (line 59)
**Args**: self, options, args


#### `__init__()` (line 79)
**Args**: self


#### `determine_resolver_variant()` (line 85)
_Determines which resolver should be used, based on the given options._

**Args**: options


#### `make_requirement_preparer()` (line 93)
_Create a RequirementPreparer instance for the given parameters._

**Args**: cls, temp_build_dir, options, build_tracker, session, finder, use_user_site, download_dir, verbosity


#### `make_resolver()` (line 148)
_Create a Resolver instance for the given parameters._

**Args**: cls, preparer, finder, options, wheel_cache, use_user_site, ignore_installed, ignore_requires_python, force_reinstall, upgrade_strategy, use_pep517, py_version_info


#### `get_requirements()` (line 206)
_Parse command-line arguments into the corresponding requirements._

**Args**: self, args, options, finder, session


#### `trace_basic_info()` (line 293)
_Trace basic information about the provided objects._

**Args**: finder


#### `_build_package_finder()` (line 303)
_Create a package finder appropriate to this requirement command.

:param ignore_requires_python: Whether to ignore incompatible
    "Requires-Python" values in links. Defaults to False._

**Args**: self, options, session, target_python, ignore_requires_python


### venv_new\Lib\site-packages\pip\_internal\cli\spinners.py

#### `spin()` (line 15)
**Args**: self


#### `finish()` (line 18)
**Args**: self, final_status


#### `__init__()` (line 23)
**Args**: self, message, file, spin_chars, min_update_interval_seconds


#### `_write()` (line 43)
**Args**: self, status


#### `spin()` (line 55)
**Args**: self


#### `finish()` (line 62)
**Args**: self, final_status


#### `__init__()` (line 76)
**Args**: self, message, min_update_interval_seconds


#### `_update()` (line 82)
**Args**: self, status


#### `spin()` (line 87)
**Args**: self


#### `finish()` (line 94)
**Args**: self, final_status


#### `__init__()` (line 102)
**Args**: self, min_update_interval_seconds


#### `ready()` (line 106)
**Args**: self


#### `reset()` (line 111)
**Args**: self


#### `open_spinner()` (line 116)
**Args**: message


#### `hidden_cursor()` (line 144)
**Args**: file


### venv_new\Lib\site-packages\pip\_internal\commands\__init__.py

#### `create_command()` (line 109)
_Create an instance of the Command class with the given name._

**Args**: name


#### `get_similar_commands()` (line 121)
_Command name auto-correct._

**Args**: name


### venv_new\Lib\site-packages\pip\_internal\commands\cache.py

#### `add_options()` (line 40)
**Args**: self


#### `run()` (line 52)
**Args**: self, options, args


#### `get_cache_dir()` (line 84)
**Args**: self, options, args


#### `get_cache_info()` (line 90)
**Args**: self, options, args


#### `list_cache_items()` (line 132)
**Args**: self, options, args


#### `format_for_human()` (line 147)
**Args**: self, files


#### `format_for_abspath()` (line 160)
**Args**: self, files


#### `remove_cache_items()` (line 164)
**Args**: self, options, args


#### `purge_cache()` (line 191)
**Args**: self, options, args


#### `_cache_dir()` (line 197)
**Args**: self, options, subdir


#### `_find_http_files()` (line 200)
**Args**: self, options


#### `_find_wheels()` (line 207)
**Args**: self, options, pattern


### venv_new\Lib\site-packages\pip\_internal\commands\check.py

#### `run()` (line 26)
**Args**: self, options, args


### venv_new\Lib\site-packages\pip\_internal\commands\completion.py

#### `add_options()` (line 80)
**Args**: self


#### `run()` (line 116)
_Prints the completion code of the given shell_

**Args**: self, options, args


### venv_new\Lib\site-packages\pip\_internal\commands\configuration.py

#### `add_options()` (line 58)
**Args**: self


#### `run()` (line 96)
**Args**: self, options, args


#### `_determine_file()` (line 141)
**Args**: self, options, need_value


#### `list_values()` (line 171)
**Args**: self, options, args


#### `get_name()` (line 177)
**Args**: self, options, args


#### `set_name_value()` (line 183)
**Args**: self, options, args


#### `unset_name()` (line 189)
**Args**: self, options, args


#### `list_config_values()` (line 195)
_List config key-value pairs across different config files_

**Args**: self, options, args


#### `print_config_file_values()` (line 211)
_Get key-value pairs from the file of a variant_

**Args**: self, variant


#### `print_env_var_values()` (line 217)
_Get key-values pairs present as environment variables_

**Args**: self


#### `open_in_editor()` (line 225)
**Args**: self, options, args


#### `_get_n_args()` (line 247)
_Helper to make sure the command got the right number of arguments_

**Args**: self, args, example, n


#### `_save_configuration()` (line 261)
**Args**: self


#### `_determine_editor()` (line 272)
**Args**: self, options


### venv_new\Lib\site-packages\pip\_internal\commands\debug.py

#### `show_value()` (line 26)
**Args**: name, value


#### `show_sys_implementation()` (line 30)

#### `create_vendor_txt_map()` (line 37)

#### `get_module_from_module_name()` (line 49)
**Args**: module_name


#### `get_vendor_version_from_module()` (line 67)
**Args**: module_name


#### `show_actual_vendor_versions()` (line 82)
_Log the actual version and print extra info if there is
a conflict or if the actual version could not be imported._

**Args**: vendor_txt_versions


#### `show_vendor_versions()` (line 103)

#### `show_tags()` (line 111)
**Args**: options


#### `ca_bundle_info()` (line 141)
**Args**: config


#### `add_options()` (line 167)
**Args**: self


#### `run()` (line 172)
**Args**: self, options, args


### venv_new\Lib\site-packages\pip\_internal\commands\download.py

#### `add_options()` (line 38)
**Args**: self


#### `run()` (line 78)
**Args**: self, options, args


### venv_new\Lib\site-packages\pip\_internal\commands\freeze.py

#### `_should_suppress_build_backends()` (line 12)

#### `_dev_pkgs()` (line 16)

#### `add_options()` (line 37)
**Args**: self


#### `run()` (line 89)
**Args**: self, options, args


### venv_new\Lib\site-packages\pip\_internal\commands\hash.py

#### `add_options()` (line 26)
**Args**: self


#### `run()` (line 40)
**Args**: self, options, args


#### `_hash_of_file()` (line 53)
_Return the hash digest of a file._

**Args**: path, algorithm


### venv_new\Lib\site-packages\pip\_internal\commands\help.py

#### `run()` (line 16)
**Args**: self, options, args


### venv_new\Lib\site-packages\pip\_internal\commands\index.py

#### `add_options()` (line 32)
**Args**: self


#### `run()` (line 48)
**Args**: self, options, args


#### `_build_package_finder()` (line 78)
_Create a package finder appropriate to the index command._

**Args**: self, options, session, target_python, ignore_requires_python


#### `get_available_package_versions()` (line 103)
**Args**: self, options, args


### venv_new\Lib\site-packages\pip\_internal\commands\inspect.py

#### `add_options()` (line 28)
**Args**: self


#### `run()` (line 48)
**Args**: self, options, args


#### `_dist_to_dict()` (line 65)
**Args**: self, dist


### venv_new\Lib\site-packages\pip\_internal\commands\install.py

#### `add_options()` (line 80)
**Args**: self


#### `run()` (line 274)
**Args**: self, options, args


#### `_handle_target_dir()` (line 527)
**Args**: self, target_dir, target_temp_dir, upgrade


#### `_determine_conflicts()` (line 581)
**Args**: self, to_install


#### `_warn_about_conflicts()` (line 593)
**Args**: self, conflict_details, resolver_variant


#### `get_lib_location_guesses()` (line 644)
**Args**: user, home, root, isolated, prefix


#### `site_packages_writable()` (line 662)
**Args**: root, isolated


#### `decide_user_install()` (line 669)
_Determine whether to do a user install based on the input options.

If use_user_site is False, no additional checks are done.
If use_user_site is True, it is checked for compatibility with other
options.
If use_user_site is None, the default behaviour depends on the environment,
which is provided by the other arguments._

**Args**: use_user_site, prefix_path, target_dir, root_path, isolated_mode


#### `create_os_error_message()` (line 730)
_Format an error message for an OSError

It may occur anytime during the execution of the install command._

**Args**: error, show_traceback, using_user_site


### venv_new\Lib\site-packages\pip\_internal\commands\list.py

#### `add_options()` (line 49)
**Args**: self


#### `handle_pip_version_check()` (line 137)
**Args**: self, options


#### `_build_package_finder()` (line 141)
_Create a package finder appropriate to this list command._

**Args**: self, options, session


#### `run()` (line 164)
**Args**: self, options, args


#### `get_outdated()` (line 205)
**Args**: self, packages, options


#### `get_uptodate()` (line 214)
**Args**: self, packages, options


#### `get_not_required()` (line 223)
**Args**: self, packages, options


#### `iter_packages_latest_infos()` (line 237)
**Args**: self, packages, options


#### `latest_info()` (line 243)
**Args**: dist


#### `output_package_listing()` (line 275)
**Args**: self, packages, options


#### `output_package_listing_columns()` (line 296)
**Args**: self, data, header


#### `format_for_columns()` (line 313)
_Convert the package data into something usable
by output_package_listing_columns._

**Args**: pkgs, options


#### `format_for_json()` (line 358)
**Args**: packages, options


### venv_new\Lib\site-packages\pip\_internal\commands\search.py

#### `add_options()` (line 40)
**Args**: self


#### `run()` (line 52)
**Args**: self, options, args


#### `search()` (line 68)
**Args**: self, query, options


#### `transform_hits()` (line 86)
_The list from pypi is really a list of versions. We want a list of
packages with the list of versions stored inline. This converts the
list from pypi into one we can use._

**Args**: hits


#### `print_dist_installation_info()` (line 114)
**Args**: name, latest


#### `print_results()` (line 133)
**Args**: hits, name_column_width, terminal_width


#### `highest_version()` (line 171)
**Args**: versions


### venv_new\Lib\site-packages\pip\_internal\commands\show.py

#### `add_options()` (line 27)
**Args**: self


#### `run()` (line 39)
**Args**: self, options, args


#### `search_packages_info()` (line 74)
_Gather details from installed distributions. Print distribution name,
version, location, and installed files. Installed files requires a
pip generated 'installed-files.txt' in the distributions '.egg-info'
directory._

**Args**: query


#### `_get_requiring_packages()` (line 91)
**Args**: current_dist


#### `print_results()` (line 171)
_Print the information from installed distributions found._

**Args**: distributions, list_files, verbose


### venv_new\Lib\site-packages\pip\_internal\commands\uninstall.py

#### `add_options()` (line 41)
**Args**: self


#### `run()` (line 65)
**Args**: self, options, args


### venv_new\Lib\site-packages\pip\_internal\commands\wheel.py

#### `add_options()` (line 44)
**Args**: self


#### `run()` (line 104)
**Args**: self, options, args


### venv_new\Lib\site-packages\pip\_internal\configuration.py

#### `_normalize_name()` (line 50)
_Make a name consistent regardless of source (environment or file)_

**Args**: name


#### `_disassemble_key()` (line 58)
**Args**: name


#### `get_configuration_files()` (line 68)

#### `__init__()` (line 101)
**Args**: self, isolated, load_only


#### `load()` (line 122)
_Loads configuration from configuration files and environment_

**Args**: self


#### `get_file_to_edit()` (line 128)
_Returns the file with highest priority in configuration_

**Args**: self


#### `items()` (line 137)
_Returns key-value pairs like dict.items() representing the loaded
configuration_

**Args**: self


#### `get_value()` (line 143)
_Get a value from the configuration._

**Args**: self, key


#### `set_value()` (line 155)
_Modify a value in the configuration._

**Args**: self, key, value


#### `unset_value()` (line 174)
_Unset a value in the configuration._

**Args**: self, key


#### `save()` (line 203)
_Save the current in-memory state._

**Args**: self


#### `_ensure_have_load_only()` (line 227)
**Args**: self


#### `_dictionary()` (line 233)
_A dictionary representing the loaded configuration._

**Args**: self


#### `_load_config_files()` (line 244)
_Loads configuration from configuration files_

**Args**: self


#### `_load_file()` (line 267)
**Args**: self, variant, fname


#### `_construct_parser()` (line 277)
**Args**: self, fname


#### `_load_environment_vars()` (line 298)
_Loads configuration from environment variables_

**Args**: self


#### `_normalized_keys()` (line 304)
_Normalizes items to construct a dictionary with normalized keys.

This routine is where the names become keys and are made the same
regardless of source - configuration files or environment._

**Args**: self, section, items


#### `get_environ_vars()` (line 318)
_Returns a generator with all environmental vars with prefix PIP__

**Args**: self


#### `iter_config_files()` (line 327)
_Yields variant and configuration files associated with it.

This should be treated like items of a dictionary. The order
here doesn't affect what gets overridden. That is controlled
by OVERRIDE_ORDER. However this does control the order they are
displayed to the user. It's probably most ergonomic to display
things in the same order as OVERRIDE_ORDER_

**Args**: self


#### `get_values_in_config()` (line 359)
_Get values present in a config file_

**Args**: self, variant


#### `_get_parser_to_modify()` (line 363)
**Args**: self


#### `_mark_as_modified()` (line 377)
**Args**: self, fname, parser


#### `__repr__()` (line 382)
**Args**: self


### venv_new\Lib\site-packages\pip\_internal\distributions\__init__.py

#### `make_distribution_for_install_requirement()` (line 7)
_Returns a Distribution for the given InstallRequirement_

**Args**: install_req


### venv_new\Lib\site-packages\pip\_internal\distributions\base.py

#### `__init__()` (line 30)
**Args**: self, req


#### `build_tracker_id()` (line 35)
_A string that uniquely identifies this requirement to the build tracker.

If None, then this dist has no work to do in the build tracker, and
``.prepare_distribution_metadata()`` will not be called._

**Args**: self


#### `get_metadata_distribution()` (line 43)
**Args**: self


#### `prepare_distribution_metadata()` (line 47)
**Args**: self, finder, build_isolation, check_build_deps


### venv_new\Lib\site-packages\pip\_internal\distributions\installed.py

#### `build_tracker_id()` (line 16)
**Args**: self


#### `get_metadata_distribution()` (line 19)
**Args**: self


#### `prepare_distribution_metadata()` (line 23)
**Args**: self, finder, build_isolation, check_build_deps


### venv_new\Lib\site-packages\pip\_internal\distributions\sdist.py

#### `build_tracker_id()` (line 24)
_Identify this requirement uniquely by its link._

**Args**: self


#### `get_metadata_distribution()` (line 29)
**Args**: self


#### `prepare_distribution_metadata()` (line 32)
**Args**: self, finder, build_isolation, check_build_deps


#### `_prepare_build_backend()` (line 71)
**Args**: self, finder


#### `_get_build_requires_wheel()` (line 97)
**Args**: self


#### `_get_build_requires_editable()` (line 105)
**Args**: self


#### `_install_build_reqs()` (line 115)
**Args**: self, finder


#### `_raise_conflicts()` (line 134)
**Args**: self, conflicting_with, conflicting_reqs


#### `_raise_missing_reqs()` (line 151)
**Args**: self, missing


### venv_new\Lib\site-packages\pip\_internal\distributions\wheel.py

#### `build_tracker_id()` (line 23)
**Args**: self


#### `get_metadata_distribution()` (line 26)
_Loads the metadata from the wheel file into memory and returns a
Distribution that uses it, not relying on the wheel file or
requirement._

**Args**: self


#### `prepare_distribution_metadata()` (line 36)
**Args**: self, finder, build_isolation, check_build_deps


### venv_new\Lib\site-packages\pip\_internal\exceptions.py

#### `_is_kebab_case()` (line 38)
**Args**: s


#### `_prefix_with_indent()` (line 42)
**Args**: s, console


#### `__init__()` (line 76)
**Args**: self


#### `__repr__()` (line 106)
**Args**: self


#### `__rich_console__()` (line 117)
**Args**: self, console, options


#### `__init__()` (line 194)
**Args**: self


#### `__init__()` (line 211)
**Args**: self


#### `__init__()` (line 232)
_:param dist: A Distribution object.
:param metadata_name: The name of the metadata being accessed
    (can be "METADATA" or "PKG-INFO")._

**Args**: self, dist, metadata_name


#### `__str__()` (line 245)
**Args**: self


#### `__str__()` (line 254)
**Args**: self


#### `__str__()` (line 259)
**Args**: self


#### `__init__()` (line 292)
_Initialize NetworkConnectionError with  `request` and `response`
objects._

**Args**: self, error_msg, response, request


#### `__str__()` (line 313)
**Args**: self


#### `__init__()` (line 328)
**Args**: self, location, name


#### `__str__()` (line 332)
**Args**: self


#### `__init__()` (line 344)
**Args**: self, ireq, field, f_val, m_val


#### `__str__()` (line 352)
**Args**: self


#### `__init__()` (line 362)
**Args**: self, ireq, error


#### `__str__()` (line 366)
**Args**: self


#### `__init__()` (line 375)
**Args**: self


#### `__str__()` (line 407)
**Args**: self


#### `__init__()` (line 414)
**Args**: self


#### `__str__()` (line 426)
**Args**: self


#### `__init__()` (line 433)
**Args**: self


#### `append()` (line 436)
**Args**: self, error


#### `__str__()` (line 439)
**Args**: self


#### `__bool__()` (line 449)
**Args**: self


#### `body()` (line 474)
_Return a summary of me for display under the heading.

This default implementation simply prints a description of the
triggering requirement.

:param req: The InstallRequirement that provoked this error, with
    its link already populated by the resolver's _populate_link()._

**Args**: self


#### `__str__()` (line 486)
**Args**: self


#### `_requirement_name()` (line 489)
_Return a description of the requirement that triggered me.

This default implementation returns long description of the req, with
line numbers_

**Args**: self


#### `__init__()` (line 535)
_:param gotten_hash: The hash of the (possibly malicious) archive we
    just downloaded_

**Args**: self, gotten_hash


#### `body()` (line 542)
**Args**: self


#### `__init__()` (line 592)
_:param allowed: A dict of algorithm names pointing to lists of allowed
    hex digests
:param gots: A dict of algorithm names pointing to hashes we
    actually got from the files under suspicion_

**Args**: self, allowed, gots


#### `body()` (line 602)
**Args**: self


#### `_hash_comparison()` (line 605)
_Return a comparison of actual and expected hash values.

Example::

       Expected sha256 abcdeabcdeabcdeabcdeabcdeabcdeabcdeabcdeabcde
                    or 123451234512345123451234512345123451234512345
            Got        bcdefbcdefbcdefbcdefbcdefbcdefbcdefbcdefbcdef_

**Args**: self


#### `hash_then_or()` (line 617)
**Args**: hash_name


#### `__init__()` (line 640)
**Args**: self, reason, fname, error


#### `__str__()` (line 651)
**Args**: self


#### `__init__()` (line 679)
**Args**: self, error


#### `_iter_externally_managed_error_keys()` (line 697)

#### `from_config()` (line 719)
**Args**: cls, config


#### `__init__()` (line 743)
**Args**: self


#### `__init__()` (line 770)
**Args**: self


#### `__init__()` (line 785)
**Args**: self


### venv_new\Lib\site-packages\pip\_internal\index\collector.py

#### `_match_vcs_scheme()` (line 51)
_Look for VCS schemes in the URL.

Returns the matched VCS scheme, or None if there's no match._

**Args**: url


#### `__init__()` (line 63)
**Args**: self, content_type, request_desc


#### `_ensure_api_header()` (line 69)
_Check the Content-Type header to ensure the response contains a Simple
API Response.

Raises `_NotAPIContent` if the content type is not a valid content-type._

**Args**: response


#### `_ensure_api_response()` (line 95)
_Send a HEAD request to the URL, and ensure the response contains a simple
API Response.

Raises `_NotHTTP` if the URL is not available for a HEAD request, or
`_NotAPIContent` if the content type is not a valid content type._

**Args**: url, session


#### `_get_simple_response()` (line 113)
_Access an Simple API response with GET, and return the response.

This consists of three parts:

1. If the URL looks suspiciously like an archive, send a HEAD first to
   check the Content-Type is HTML or Simple API, to avoid downloading a
   large file. Raise `_NotHTTP` if the content type cannot be determined, or
   `_NotAPIContent` if it is not HTML or a Simple API.
2. Actually perform the request. Raise HTTP exceptions on network failures.
3. Check the Content-Type header to make sure we got a Simple API response,
   and raise `_NotAPIContent` otherwise._

**Args**: url, session


#### `_get_encoding_from_headers()` (line 176)
_Determine if we have any encoding information in our headers._

**Args**: headers


#### `__init__()` (line 188)
**Args**: self, page


#### `__eq__()` (line 192)
**Args**: self, other


#### `__hash__()` (line 195)
**Args**: self


#### `__call__()` (line 200)
**Args**: self, page


#### `with_cached_index_content()` (line 203)
_Given a function that parses an Iterable[Link] from an IndexContent, cache the
function's result (keyed by CacheablePageContent), unless the IndexContent
`page` has `page.cache_link_parsing == False`._

**Args**: fn


#### `wrapper()` (line 211)
**Args**: cacheable_page


#### `wrapper_wrapper()` (line 215)
**Args**: page


#### `parse_links()` (line 224)
_Parse a Simple API's Index Content, and yield its anchor elements as Link objects._

**Args**: page


#### `__str__()` (line 269)
**Args**: self


#### `__init__()` (line 279)
**Args**: self, url


#### `handle_starttag()` (line 286)
**Args**: self, tag, attrs


#### `get_href()` (line 294)
**Args**: self, attrs


#### `_handle_get_simple_fail()` (line 301)
**Args**: link, reason, meth


#### `_make_index_content()` (line 311)
**Args**: response, cache_link_parsing


#### `_get_index_content()` (line 324)
**Args**: link


#### `__init__()` (line 398)
**Args**: self, session, search_scope


#### `create()` (line 407)
_:param session: The Session to use to make requests.
:param suppress_no_index: Whether to ignore the --no-index option
    when constructing the SearchScope object._

**Args**: cls, session, options, suppress_no_index


#### `find_links()` (line 441)
**Args**: self


#### `fetch_response()` (line 444)
_Fetch an HTML page containing package links._

**Args**: self, location


#### `collect_sources()` (line 450)
**Args**: self, project_name, candidates_from_page


### venv_new\Lib\site-packages\pip\_internal\index\package_finder.py

#### `_check_link_requires_python()` (line 52)
_Return whether the given Python version is compatible with a link's
"Requires-Python" value.

:param version_info: A 3-tuple of ints representing the Python
    major-minor-micro version to check.
:param ignore_requires_python: Whether to ignore the "Requires-Python"
    value if the given Python version isn't compatible._

**Args**: link, version_info, ignore_requires_python


#### `__init__()` (line 120)
_:param project_name: The user supplied package name.
:param canonical_name: The canonical package name.
:param formats: The formats allowed for this package. Should be a set
    with 'binary' or 'source' or both in it.
:param target_python: The target Python interpreter to use when
    evaluating link compatibility. This is used, for example, to
    check wheel compatibility, as well as when checking the Python
    version, e.g. the Python version embedded in a link filename
    (or egg fragment) and against an HTML link's optional PEP 503
    "data-requires-python" attribute.
:param allow_yanked: Whether files marked as yanked (in the sense
    of PEP 592) are permitted to be candidates for install.
:param ignore_requires_python: Whether to ignore incompatible
    PEP 503 "data-requires-python" values in HTML links. Defaults
    to False._

**Args**: self, project_name, canonical_name, formats, target_python, allow_yanked, ignore_requires_python


#### `evaluate_link()` (line 157)
_Determine whether a link is a candidate for installation.

:return: A tuple (result, detail), where *result* is an enum
    representing whether the evaluation found a candidate, or the reason
    why one is not found. If a candidate is found, *detail* will be the
    candidate's version string; if one is not found, it contains the
    reason the link fails to qualify._

**Args**: self, link


#### `filter_unallowed_hashes()` (line 252)
_Filter out candidates whose hashes aren't allowed, and return a new
list of candidates.

If at least one candidate has an allowed hash, then all candidates with
either an allowed hash or no hash specified are returned.  Otherwise,
the given candidates are returned.

Including the candidates with no hash specified when there is a match
allows a warning to be logged if there is a more preferred candidate
with no hash specified.  Returning all candidates in the case of no
matches lets pip report the hash of the candidate that would otherwise
have been installed (e.g. permitting the user to more easily update
their requirements file with the desired hash)._

**Args**: candidates, hashes, project_name


#### `__post_init__()` (line 354)
**Args**: self


#### `create()` (line 370)
_Create a CandidateEvaluator object.

:param target_python: The target Python interpreter to use when
    checking compatibility. If None (the default), a TargetPython
    object will be constructed from the running Python.
:param specifier: An optional object implementing `filter`
    (e.g. `packaging.specifiers.SpecifierSet`) to filter applicable
    versions.
:param hashes: An optional collection of allowed hashes._

**Args**: cls, project_name, target_python, prefer_binary, allow_all_prereleases, specifier, hashes


#### `__init__()` (line 405)
_:param supported_tags: The PEP 425 tags supported by the target
    Python in order of preference (most preferred first)._

**Args**: self, project_name, supported_tags, specifier, prefer_binary, allow_all_prereleases, hashes


#### `get_applicable_candidates()` (line 431)
_Return the applicable candidates from a list of candidates._

**Args**: self, candidates


#### `_sort_key()` (line 466)
_Function to pass as the `key` argument to a call to sorted() to sort
InstallationCandidates by preference.

Returns a tuple such that tuples sorting as greater using Python's
default comparison operator are more preferred.

The preference is as follows:

First and foremost, candidates with allowed (matching) hashes are
always preferred over candidates without matching hashes. This is
because e.g. if the only candidate with an allowed hash is yanked,
we still want to use that candidate.

Second, excepting hash considerations, candidates that have been
yanked (in the sense of PEP 592) are always less preferred than
candidates that haven't been yanked. Then:

If not finding wheels, they are sorted by version only.
If finding wheels, then the sort order is by version, then:
  1. existing installs
  2. wheels ordered via Wheel.support_index_min(self._supported_tags)
  3. source archives
If prefer_binary was set, then all wheels are sorted above sources.

Note: it was considered to embed this logic into the Link
      comparison operators, but then different sdist links
      with the same version, would have to be considered equal_

**Args**: self, candidate


#### `sort_best_candidate()` (line 535)
_Return the best candidate per the instance's sort order, or None if
no candidate is acceptable._

**Args**: self, candidates


#### `compute_best_candidate()` (line 548)
_Compute and return a `BestCandidateResult` instance._

**Args**: self, candidates


#### `__init__()` (line 573)
_This constructor is primarily meant to be used by the create() class
method and from tests.

:param format_control: A FormatControl object, used to control
    the selection of source packages / binary packages when consulting
    the index and links.
:param candidate_prefs: Options to use when creating a
    CandidateEvaluator object._

**Args**: self, link_collector, target_python, allow_yanked, format_control, candidate_prefs, ignore_requires_python


#### `create()` (line 613)
_Create a PackageFinder.

:param selection_prefs: The candidate selection preferences, as a
    SelectionPreferences object.
:param target_python: The target Python interpreter to use when
    checking compatibility. If None (the default), a TargetPython
    object will be constructed from the running Python._

**Args**: cls, link_collector, selection_prefs, target_python


#### `target_python()` (line 645)
**Args**: self


#### `search_scope()` (line 649)
**Args**: self


#### `search_scope()` (line 653)
**Args**: self, search_scope


#### `find_links()` (line 657)
**Args**: self


#### `index_urls()` (line 661)
**Args**: self


#### `proxy()` (line 665)
**Args**: self


#### `trusted_hosts()` (line 669)
**Args**: self


#### `custom_cert()` (line 674)
**Args**: self


#### `client_cert()` (line 682)
**Args**: self


#### `allow_all_prereleases()` (line 688)
**Args**: self


#### `set_allow_all_prereleases()` (line 691)
**Args**: self


#### `prefer_binary()` (line 695)
**Args**: self


#### `set_prefer_binary()` (line 698)
**Args**: self


#### `requires_python_skipped_reasons()` (line 701)
**Args**: self


#### `make_link_evaluator()` (line 709)
**Args**: self, project_name


#### `_sort_links()` (line 722)
_Returns elements of links in order, non-egg links first, egg links
second, while eliminating duplicates_

**Args**: self, links


#### `_log_skipped_link()` (line 738)
**Args**: self, link, result, detail


#### `get_install_candidate()` (line 751)
_If the link is a candidate for install, convert it to an
InstallationCandidate and return it. Otherwise, return None._

**Args**: self, link_evaluator, link


#### `evaluate_links()` (line 772)
_Convert links that are candidates to InstallationCandidate objects._

**Args**: self, link_evaluator, links


#### `process_project_url()` (line 786)
**Args**: self, project_url, link_evaluator


#### `find_all_candidates()` (line 808)
_Find all available InstallationCandidate for project_name

This checks index_urls and find_links.
All versions found are returned as an InstallationCandidate list.

See LinkEvaluator.evaluate_link() for details on which files
are accepted._

**Args**: self, project_name


#### `make_candidate_evaluator()` (line 860)
_Create a CandidateEvaluator object to use._

**Args**: self, project_name, specifier, hashes


#### `find_best_candidate()` (line 878)
_Find matches for the given project and specifier.

:param specifier: An optional object implementing `filter`
    (e.g. `packaging.specifiers.SpecifierSet`) to filter applicable
    versions.

:return: A `BestCandidateResult` instance._

**Args**: self, project_name, specifier, hashes


#### `find_requirement()` (line 900)
_Try to find a Link matching req

Expects req, an InstallRequirement and upgrade, a boolean
Returns a InstallationCandidate if found,
Raises DistributionNotFound or BestVersionAlreadyInstalled otherwise_

**Args**: self, req, upgrade


#### `_format_versions()` (line 921)
**Args**: cand_iter


#### `_should_install_candidate()` (line 946)
**Args**: candidate


#### `_find_name_version_sep()` (line 988)
_Find the separator's index based on the package's canonical name.

:param fragment: A <package>+<version> filename "fragment" (stem) or
    egg fragment.
:param canonical_name: The package's canonical name.

This function is needed since the canonicalized name does not necessarily
have the same length as the egg info's name part. An example::

>>> fragment = 'foo__bar-1.0'
>>> canonical_name = 'foo-bar'
>>> _find_name_version_sep(fragment, canonical_name)
8_

**Args**: fragment, canonical_name


#### `_extract_version_from_fragment()` (line 1014)
_Parse the version string from a <package>+<version> filename
"fragment" (stem) or egg fragment.

:param fragment: The string to parse. E.g. foo-2.1
:param canonical_name: The canonicalized name of the package this
    belongs to._

**Args**: fragment, canonical_name


### venv_new\Lib\site-packages\pip\_internal\index\sources.py

#### `link()` (line 30)
_Returns the underlying link, if there's one._

**Args**: self


#### `page_candidates()` (line 34)
_Candidates found by parsing an archive listing HTML file._

**Args**: self


#### `file_links()` (line 38)
_Links found by specifying archives directly._

**Args**: self


#### `_is_html_file()` (line 43)
**Args**: file_url


#### `__init__()` (line 50)
**Args**: self, path


#### `_scan_directory()` (line 56)
_Scans directory once and populates both page_candidates
and project_name_to_urls at the same time_

**Args**: self


#### `page_candidates()` (line 80)
**Args**: self


#### `project_name_to_urls()` (line 87)
**Args**: self


#### `__init__()` (line 105)
**Args**: self, candidates_from_page, path, project_name


#### `link()` (line 122)
**Args**: self


#### `page_candidates()` (line 125)
**Args**: self


#### `file_links()` (line 129)
**Args**: self


#### `__init__()` (line 144)
**Args**: self, candidates_from_page, link


#### `link()` (line 153)
**Args**: self


#### `page_candidates()` (line 156)
**Args**: self


#### `file_links()` (line 161)
**Args**: self


#### `__init__()` (line 176)
**Args**: self, candidates_from_page, page_validator, link


#### `link()` (line 187)
**Args**: self


#### `page_candidates()` (line 190)
**Args**: self


#### `file_links()` (line 195)
**Args**: self


#### `__init__()` (line 206)
**Args**: self, candidates_from_page, link


#### `link()` (line 215)
**Args**: self


#### `page_candidates()` (line 218)
**Args**: self


#### `file_links()` (line 221)
**Args**: self


#### `build_source()` (line 225)
**Args**: location


### venv_new\Lib\site-packages\pip\_internal\locations\__init__.py

#### `_should_use_sysconfig()` (line 46)
_This function determines the value of _USE_SYSCONFIG.

By default, pip uses sysconfig on Python 3.10+.
But Python distributors can override this decision by setting:
    sysconfig._PIP_USE_SYSCONFIG = True / False
Rationale in https://github.com/pypa/pip/issues/10647

This is a function for testability, but should be constant during any one
run._


#### `_looks_like_bpo_44860()` (line 76)
_The resolution to bpo-44860 will change this incorrect platlib.

See <https://bugs.python.org/issue44860>._


#### `_looks_like_red_hat_patched_platlib_purelib()` (line 90)
**Args**: scheme


#### `_looks_like_red_hat_lib()` (line 101)
_Red Hat patches platlib in unix_prefix and unix_home, but not purelib.

This is the only way I can see to tell a Red Hat-patched Python._


#### `_looks_like_debian_scheme()` (line 116)
_Debian adds two additional schemes._


#### `_looks_like_red_hat_scheme()` (line 124)
_Red Hat patches ``sys.prefix`` and ``sys.exec_prefix``.

Red Hat's ``00251-change-user-install-location.patch`` changes the install
command's ``prefix`` and ``exec_prefix`` to append ``"/local"``. This is
(fortunately?) done quite unconditionally, so we create a default command
object without any configuration to detect this._


#### `_looks_like_slackware_scheme()` (line 144)
_Slackware patches sysconfig but fails to patch distutils and site.

Slackware changes sysconfig's user scheme to use ``"lib64"`` for the lib
path, but does not do the same to the site module._


#### `_looks_like_msys2_mingw_scheme()` (line 160)
_MSYS2 patches distutils and sysconfig to use a UNIX-like scheme.

However, MSYS2 incorrectly patches sysconfig ``nt`` scheme. The fix is
likely going to be included in their 3.10 release, so we ignore the warning.
See msys2/MINGW-packages#9319.

MSYS2 MINGW's patch uses lowercase ``"lib"`` instead of the usual uppercase,
and is missing the final ``"site-packages"``._


#### `_fix_abiflags()` (line 177)
**Args**: parts


#### `_warn_mismatched()` (line 194)
**Args**: old, new


#### `_warn_if_mismatch()` (line 204)
**Args**: old, new


#### `_log_context()` (line 212)

#### `get_scheme()` (line 230)
**Args**: dist_name, user, home, root, isolated, prefix


#### `get_bin_prefix()` (line 397)

#### `get_bin_user()` (line 408)

#### `_looks_like_deb_system_dist_packages()` (line 412)
_Check if the value is Debian's APT-controlled dist-packages.

Debian's ``distutils.sysconfig.get_python_lib()`` implementation returns the
default package path controlled by APT, but does not patch ``sysconfig`` to
do the same. This is similar to the bug worked around in ``get_scheme()``,
but here the default is ``deb_system`` instead of ``unix_local``. Ultimately
we can't do anything about this Debian bug, and this detection allows us to
skip the warning when needed._

**Args**: value


#### `get_purelib()` (line 429)
_Return the default pure-Python lib location._


#### `get_platlib()` (line 443)
_Return the default platform-shared lib location._


### venv_new\Lib\site-packages\pip\_internal\locations\_distutils.py

#### `distutils_scheme()` (line 35)
_Return a distutils install scheme_

**Args**: dist_name, user, home, root, isolated, prefix


#### `get_scheme()` (line 115)
_Get the "scheme" corresponding to the input parameters. The distutils
documentation provides the context for the available schemes:
https://docs.python.org/3/install/index.html#alternate-installation

:param dist_name: the name of the package to retrieve the scheme for, used
    in the headers scheme path
:param user: indicates to use the "user" scheme
:param home: indicates to use the "home" scheme and provides the base
    directory for the same
:param root: root under which other directories are re-based
:param isolated: equivalent to --no-user-cfg, i.e. do not consider
    ~/.pydistutils.cfg (posix) or ~/pydistutils.cfg (non-posix) for
    scheme paths
:param prefix: indicates to use the "prefix" scheme and provides the
    base directory for the same_

**Args**: dist_name, user, home, root, isolated, prefix


#### `get_bin_prefix()` (line 150)

#### `get_purelib()` (line 167)

#### `get_platlib()` (line 171)

### venv_new\Lib\site-packages\pip\_internal\locations\_sysconfig.py

#### `_should_use_osx_framework_prefix()` (line 29)
_Check for Apple's ``osx_framework_library`` scheme.

Python distributed by Apple's Command Line Tools has this special scheme
that's used when:

* This is a framework build.
* We are installing into the system prefix.

This does not account for ``pip install --prefix`` (also means we're not
installing to the system prefix), which should use ``posix_prefix``, but
logic here means ``_infer_prefix()`` outputs ``osx_framework_library``. But
since ``prefix`` is not available for ``sysconfig.get_default_scheme()``,
which is the stdlib replacement for ``_infer_prefix()``, presumably Apple
wouldn't be able to magically switch between ``osx_framework_library`` and
``posix_prefix``. ``_infer_prefix()`` returning ``osx_framework_library``
means its behavior is consistent whether we use the stdlib implementation
or our own, and we deal with this special case in ``get_scheme()`` instead._


#### `_infer_prefix()` (line 55)
_Try to find a prefix scheme for the current platform.

This tries:

* A special ``osx_framework_library`` for Python distributed by Apple's
  Command Line Tools, when not running in a virtual environment.
* Implementation + OS, used by PyPy on Windows (``pypy_nt``).
* Implementation without OS, used by PyPy on POSIX (``pypy``).
* OS + "prefix", used by CPython on POSIX (``posix_prefix``).
* Just the OS name, used by CPython on Windows (``nt``).

If none of the above works, fall back to ``posix_prefix``._


#### `_infer_user()` (line 86)
_Try to find a user scheme for the current platform._


#### `_infer_home()` (line 101)
_Try to find a home for the current platform._


#### `get_scheme()` (line 124)
_Get the "scheme" corresponding to the input parameters.

:param dist_name: the name of the package to retrieve the scheme for, used
    in the headers scheme path
:param user: indicates to use the "user" scheme
:param home: indicates to use the "home" scheme
:param root: root under which other directories are re-based
:param isolated: ignored, but kept for distutils compatibility (where
    this controls whether the user-site pydistutils.cfg is honored)
:param prefix: indicates to use the "prefix" scheme and provides the
    base directory for the same_

**Args**: dist_name, user, home, root, isolated, prefix


#### `get_bin_prefix()` (line 202)

#### `get_purelib()` (line 209)

#### `get_platlib()` (line 213)

### venv_new\Lib\site-packages\pip\_internal\locations\base.py

#### `get_major_minor_version()` (line 19)
_Return the major-minor version of the current Python as a string, e.g.
"3.7" or "3.10"._


#### `change_root()` (line 27)
_Return 'pathname' with 'new_root' prepended.

If 'pathname' is relative, this is equivalent to os.path.join(new_root, pathname).
Otherwise, it requires making 'pathname' relative and then joining the
two, which is tricky on DOS/Windows and Mac OS.

This is borrowed from Python's standard library's distutils module._

**Args**: new_root, pathname


#### `get_src_prefix()` (line 55)

#### `is_osx_framework()` (line 80)

### venv_new\Lib\site-packages\pip\_internal\main.py

#### `main()` (line 4)
_This is preserved for old console scripts that may still be referencing
it.

For additional details, see https://github.com/pypa/pip/issues/7498._

**Args**: args


### venv_new\Lib\site-packages\pip\_internal\metadata\__init__.py

#### `_should_use_importlib_metadata()` (line 29)
_Whether to use the ``importlib.metadata`` or ``pkg_resources`` backend.

By default, pip uses ``importlib.metadata`` on Python 3.11+, and
``pkg_resources`` otherwise. This can be overridden by a couple of ways:

* If environment variable ``_PIP_USE_IMPORTLIB_METADATA`` is set, it
  dictates whether ``importlib.metadata`` is used, regardless of Python
  version.
* On Python 3.11+, Python distributors can patch ``importlib.metadata``
  to add a global constant ``_PIP_USE_IMPORTLIB_METADATA = False``. This
  makes pip use ``pkg_resources`` (unless the user set the aforementioned
  environment variable to *True*)._


#### `select_backend()` (line 59)

#### `get_default_environment()` (line 69)
_Get the default representation for the current environment.

This returns an Environment instance from the chosen backend. The default
Environment instance should be built from ``sys.path`` and may use caching
to share instance state across calls._


#### `get_environment()` (line 79)
_Get a representation of the environment specified by ``paths``.

This returns an Environment instance from the chosen backend based on the
given import paths. The backend must build a fresh instance representing
the state of installed distributions when this function is called._

**Args**: paths


#### `get_directory_distribution()` (line 89)
_Get the distribution metadata representation in the specified directory.

This returns a Distribution instance from the chosen backend based on
the given on-disk ``.dist-info`` directory._

**Args**: directory


#### `get_wheel_distribution()` (line 98)
_Get the representation of the specified wheel's distribution metadata.

This returns a Distribution instance from the chosen backend based on
the given wheel's ``.dist-info`` directory.

:param canonical_name: Normalized project name of the given wheel._

**Args**: wheel, canonical_name


#### `get_metadata_distribution()` (line 109)
_Get the dist representation of the specified METADATA file contents.

This returns a Distribution instance from the chosen backend sourced from the data
in `metadata_contents`.

:param metadata_contents: Contents of a METADATA file within a dist, or one served
                          via PEP 658.
:param filename: Filename for the dist this metadata represents.
:param canonical_name: Normalized project name of the given dist._

**Args**: metadata_contents, filename, canonical_name


### venv_new\Lib\site-packages\pip\_internal\metadata\_json.py

#### `json_name()` (line 39)
**Args**: field


#### `msg_to_json()` (line 43)
_Convert a Message object into a JSON-compatible dictionary._

**Args**: msg


#### `sanitise_header()` (line 46)
**Args**: h


### venv_new\Lib\site-packages\pip\_internal\metadata\base.py

#### `name()` (line 51)
**Args**: self


#### `value()` (line 55)
**Args**: self


#### `group()` (line 59)
**Args**: self


#### `_convert_installed_files_path()` (line 63)
_Convert a legacy installed-files.txt path into modern RECORD path.

The legacy format stores paths relative to the info directory, while the
modern format stores paths relative to the package root, e.g. the
site-packages directory.

:param entry: Path parts of the installed-files.txt entry.
:param info: Path parts of the egg-info directory relative to package root.
:returns: The converted entry.

For best compatibility with symlinks, this does not use ``abspath()`` or
``Path.resolve()``, but tries to work with path parts:

1. While ``entry`` starts with ``..``, remove the equal amounts of parts
   from ``info``; if ``info`` is empty, start appending ``..`` instead.
2. Join the two directly._

**Args**: entry, info


#### `from_directory()` (line 101)
_Load the distribution from a metadata directory.

:param directory: Path to a metadata directory, e.g. ``.dist-info``._

**Args**: cls, directory


#### `from_metadata_file_contents()` (line 109)
_Load the distribution from the contents of a METADATA file.

This is used to implement PEP 658 by generating a "shallow" dist object that can
be used for resolution without downloading or building the actual dist yet.

:param metadata_contents: The contents of a METADATA file.
:param filename: File name for the dist with this metadata.
:param project_name: Name of the project this dist represents._

**Args**: cls, metadata_contents, filename, project_name


#### `from_wheel()` (line 127)
_Load the distribution from a given wheel.

:param wheel: A concrete wheel definition.
:param name: File name of the wheel.

:raises InvalidWheel: Whenever loading of the wheel causes a
    :py:exc:`zipfile.BadZipFile` exception to be thrown.
:raises UnsupportedWheel: If the wheel is a valid zip, but malformed
    internally._

**Args**: cls, wheel, name


#### `__repr__()` (line 140)
**Args**: self


#### `__str__()` (line 143)
**Args**: self


#### `location()` (line 147)
_Where the distribution is loaded from.

A string value is not necessarily a filesystem path, since distributions
can be loaded from other sources, e.g. arbitrary zip archives. ``None``
means the distribution is created in-memory.

Do not canonicalize this value with e.g. ``pathlib.Path.resolve()``. If
this is a symbolic link, we want to preserve the relative path between
it and files in the distribution._

**Args**: self


#### `editable_project_location()` (line 161)
_The project location for editable distributions.

This is the directory where pyproject.toml or setup.py is located.
None if the distribution is not installed in editable mode._

**Args**: self


#### `installed_location()` (line 183)
_The distribution's "installed" location.

This should generally be a ``site-packages`` directory. This is
usually ``dist.location``, except for legacy develop-installed packages,
where ``dist.location`` is the source code location, and this is where
the ``.egg-link`` file is.

The returned location is normalized (in particular, with symlinks removed)._

**Args**: self


#### `info_location()` (line 196)
_Location of the .[egg|dist]-info directory or file.

Similarly to ``location``, a string value is not necessarily a
filesystem path. ``None`` means the distribution is created in-memory.

For a modern .dist-info installation on disk, this should be something
like ``{location}/{raw_name}-{version}.dist-info``.

Do not canonicalize this value with e.g. ``pathlib.Path.resolve()``. If
this is a symbolic link, we want to preserve the relative path between
it and other files in the distribution._

**Args**: self


#### `installed_by_distutils()` (line 212)
_Whether this distribution is installed with legacy distutils format.

A distribution installed with "raw" distutils not patched by setuptools
uses one single file at ``info_location`` to store metadata. We need to
treat this specially on uninstallation._

**Args**: self


#### `installed_as_egg()` (line 225)
_Whether this distribution is installed as an egg.

This usually indicates the distribution was installed by (older versions
of) easy_install._

**Args**: self


#### `installed_with_setuptools_egg_info()` (line 237)
_Whether this distribution is installed with the ``.egg-info`` format.

This usually indicates the distribution was installed with setuptools
with an old pip version or with ``single-version-externally-managed``.

Note that this ensure the metadata store is a directory. distutils can
also installs an ``.egg-info``, but as a file, not a directory. This
property is *False* for that case. Also see ``installed_by_distutils``._

**Args**: self


#### `installed_with_dist_info()` (line 255)
_Whether this distribution is installed with the "modern format".

This indicates a "modern" installation, e.g. storing metadata in the
``.dist-info`` directory. This applies to installations made by
setuptools (but through pip, not directly), or anything using the
standardized build backend interface (PEP 517)._

**Args**: self


#### `canonical_name()` (line 271)
**Args**: self


#### `version()` (line 275)
**Args**: self


#### `raw_version()` (line 279)
**Args**: self


#### `setuptools_filename()` (line 283)
_Convert a project name to its setuptools-compatible filename.

This is a copy of ``pkg_resources.to_filename()`` for compatibility._

**Args**: self


#### `direct_url()` (line 291)
_Obtain a DirectUrl from this distribution.

Returns None if the distribution has no `direct_url.json` metadata,
or if `direct_url.json` is invalid._

**Args**: self


#### `installer()` (line 317)
**Args**: self


#### `requested()` (line 329)
**Args**: self


#### `editable()` (line 333)
**Args**: self


#### `local()` (line 337)
_If distribution is installed in the current virtual environment.

Always True if we're not in a virtualenv._

**Args**: self


#### `in_usersite()` (line 347)
**Args**: self


#### `in_site_packages()` (line 353)
**Args**: self


#### `is_file()` (line 358)
_Check whether an entry in the info directory is a file._

**Args**: self, path


#### `iter_distutils_script_names()` (line 362)
_Find distutils 'scripts' entries metadata.

If 'scripts' is supplied in ``setup.py``, distutils records those in the
installed distribution's ``scripts`` directory, a file for each script._

**Args**: self


#### `read_text()` (line 370)
_Read a file in the info directory.

:raise FileNotFoundError: If ``path`` does not exist in the directory.
:raise NoneMetadataError: If ``path`` exists in the info directory, but
    cannot be read._

**Args**: self, path


#### `iter_entry_points()` (line 379)
**Args**: self


#### `_metadata_impl()` (line 382)
**Args**: self


#### `metadata()` (line 386)
_Metadata of distribution parsed from e.g. METADATA or PKG-INFO.

This should return an empty message if the metadata file is unavailable.

:raises NoneMetadataError: If the metadata file is available, but does
    not contain valid metadata._

**Args**: self


#### `metadata_dict()` (line 399)
_PEP 566 compliant JSON-serializable representation of METADATA or PKG-INFO.

This should return an empty dict if the metadata file is unavailable.

:raises NoneMetadataError: If the metadata file is available, but does
    not contain valid metadata._

**Args**: self


#### `metadata_version()` (line 410)
_Value of "Metadata-Version:" in distribution metadata, if available._

**Args**: self


#### `raw_name()` (line 415)
_Value of "Name:" in distribution metadata._

**Args**: self


#### `requires_python()` (line 422)
_Value of "Requires-Python:" in distribution metadata.

If the key does not exist or contains an invalid value, an empty
SpecifierSet should be returned._

**Args**: self


#### `iter_dependencies()` (line 440)
_Dependencies of this distribution.

For modern .dist-info distributions, this is the collection of
"Requires-Dist:" entries in distribution metadata._

**Args**: self, extras


#### `iter_raw_dependencies()` (line 448)
_Raw Requires-Dist metadata._

**Args**: self


#### `iter_provided_extras()` (line 452)
_Extras provided by this distribution.

For modern .dist-info distributions, this is the collection of
"Provides-Extra:" entries in distribution metadata.

The return value of this function is expected to be normalised names,
per PEP 685, with the returned value being handled appropriately by
`iter_dependencies`._

**Args**: self


#### `_iter_declared_entries_from_record()` (line 464)
**Args**: self


#### `_iter_declared_entries_from_legacy()` (line 472)
**Args**: self


#### `iter_declared_entries()` (line 493)
_Iterate through file entries declared in this distribution.

For modern .dist-info distributions, this is the files listed in the
``RECORD`` metadata file. For legacy setuptools distributions, this
comes from ``installed-files.txt``, with entries normalized to be
compatible with the format used by ``RECORD``.

:return: An iterator for listed entries, or None if the distribution
    contains neither ``RECORD`` nor ``installed-files.txt``._

**Args**: self


#### `_iter_requires_txt_entries()` (line 509)
_Parse a ``requires.txt`` in an egg-info directory.

This is an INI-ish format where an egg-info stores dependencies. A
section name describes extra other environment markers, while each entry
is an arbitrary string (not a key-value pair) representing a dependency
as a requirement string (no markers).

There is a construct in ``importlib.metadata`` called ``Sectioned`` that
does mostly the same, but the format is currently considered private._

**Args**: self


#### `_iter_egg_info_extras()` (line 534)
_Get extras from the egg-info directory._

**Args**: self


#### `_iter_egg_info_dependencies()` (line 544)
_Get distribution dependencies from the egg-info directory.

To ease parsing, this converts a legacy dependency entry into a PEP 508
requirement string. Like ``_iter_requires_txt_entries()``, there is code
in ``importlib.metadata`` that does mostly the same, but not do exactly
what we need.

Namely, ``importlib.metadata`` does not normalize the extra name before
putting it into the requirement string, which causes marker comparison
to fail because the dist-info format do normalize. This is consistent in
all currently available PEP 517 backends, although not standardized._

**Args**: self


#### `_add_egg_info_requires()` (line 572)
_Add egg-info requires.txt information to the metadata._

**Args**: self, metadata


#### `default()` (line 586)
**Args**: cls


#### `from_paths()` (line 590)
**Args**: cls, paths


#### `get_distribution()` (line 593)
_Given a requirement name, return the installed distributions.

The name may not be normalized. The implementation must canonicalize
it for lookup._

**Args**: self, name


#### `_iter_distributions()` (line 601)
_Iterate through installed distributions.

This function should be implemented by subclass, but never called
directly. Use the public ``iter_distribution()`` instead, which
implements additional logic to make sure the distributions are valid._

**Args**: self


#### `iter_all_distributions()` (line 610)
_Iterate through all installed distributions without any filtering._

**Args**: self


#### `iter_installed_distributions()` (line 631)
_Return a list of installed distributions.

This is based on ``iter_all_distributions()`` with additional filtering
options. Note that ``iter_installed_distributions()`` without arguments
is *not* equal to ``iter_all_distributions()``, since some of the
configurations exclude packages by default.

:param local_only: If True (default), only return installations
local to the current virtualenv, if in a virtualenv.
:param skip: An iterable of canonicalized project names to ignore;
    defaults to ``stdlib_pkgs``.
:param include_editables: If False, don't report editables.
:param editables_only: If True, only report editables.
:param user_only: If True, only report installations in the user
site directory._

**Args**: self, local_only, skip, include_editables, editables_only, user_only


#### `as_zipfile()` (line 670)
**Args**: self


#### `__init__()` (line 675)
**Args**: self, location


#### `as_zipfile()` (line 678)
**Args**: self


#### `__init__()` (line 683)
**Args**: self, location, stream


#### `as_zipfile()` (line 687)
**Args**: self


### venv_new\Lib\site-packages\pip\_internal\metadata\importlib\_compat.py

#### `__init__()` (line 9)
**Args**: self, dist


#### `__str__()` (line 13)
**Args**: self


#### `name()` (line 29)
**Args**: self


#### `parent()` (line 33)
**Args**: self


#### `get_info_location()` (line 37)
_Find the path to the distribution's metadata directory.

HACK: This relies on importlib.metadata's private ``_path`` attribute. Not
all distributions exist on disk, so importlib.metadata is correct to not
expose the attribute as public. But pip's code base is old and not as clean,
so we do this to avoid having to rewrite too many things. Hopefully we can
eliminate this some day._

**Args**: d


#### `parse_name_and_version_from_info_directory()` (line 49)
_Get a name and version from the metadata directory name.

This is much faster than reading distribution metadata._

**Args**: dist


#### `get_dist_canonical_name()` (line 73)
_Get the distribution's normalized name.

The ``name`` attribute is only available in Python 3.10 or later. We are
targeting exactly that, but Mypy does not know this._

**Args**: dist


### venv_new\Lib\site-packages\pip\_internal\metadata\importlib\_dists.py

#### `__init__()` (line 53)
**Args**: self, files, info_location


#### `from_zipfile()` (line 62)
**Args**: cls, zf, name, location


#### `iterdir()` (line 81)
**Args**: self, path


#### `read_text()` (line 87)
**Args**: self, filename


#### `locate_file()` (line 100)
**Args**: self, path


#### `__init__()` (line 107)
**Args**: self, dist, info_location, installed_location


#### `from_directory()` (line 118)
**Args**: cls, directory


#### `from_metadata_file_contents()` (line 124)
**Args**: cls, metadata_contents, filename, project_name


#### `from_wheel()` (line 141)
**Args**: cls, wheel, name


#### `location()` (line 150)
**Args**: self


#### `info_location()` (line 156)
**Args**: self


#### `installed_location()` (line 162)
**Args**: self


#### `canonical_name()` (line 168)
**Args**: self


#### `version()` (line 172)
**Args**: self


#### `raw_version()` (line 178)
**Args**: self


#### `is_file()` (line 181)
**Args**: self, path


#### `iter_distutils_script_names()` (line 184)
**Args**: self


#### `read_text()` (line 193)
**Args**: self, path


#### `iter_entry_points()` (line 199)
**Args**: self


#### `_metadata_impl()` (line 203)
**Args**: self


#### `iter_provided_extras()` (line 211)
**Args**: self


#### `iter_dependencies()` (line 217)
**Args**: self, extras


### venv_new\Lib\site-packages\pip\_internal\metadata\importlib\_envs.py

#### `_looks_like_wheel()` (line 24)
**Args**: location


#### `__init__()` (line 49)
**Args**: self


#### `_find_impl()` (line 52)
_Find distributions in a location._

**Args**: self, location


#### `find()` (line 73)
_Find distributions in a location.

The path can be either a directory, or a ZIP archive._

**Args**: self, location


#### `find_linked()` (line 85)
_Read location in egg-link files and return distributions in there.

The path should be a directory; otherwise this returns nothing. This
follows how setuptools does this for compatibility. The first non-empty
line in the egg-link is read as a path (resolved against the egg-link's
containing directory if relative). Distributions found at that linked
location are returned._

**Args**: self, location


#### `_find_eggs_in_dir()` (line 109)
**Args**: self, location


#### `_find_eggs_in_zip()` (line 121)
**Args**: self, location


#### `find_eggs()` (line 133)
_Find eggs in a location.

This actually uses the old *pkg_resources* backend. We likely want to
deprecate this so we can eventually remove the *pkg_resources*
dependency entirely. Before that, this should first emit a deprecation
warning for some versions when using the fallback since importing
*pkg_resources* is slow for those who don't need it._

**Args**: self, location


#### `_emit_egg_deprecation()` (line 149)
**Args**: location


#### `__init__()` (line 159)
**Args**: self, paths


#### `default()` (line 163)
**Args**: cls


#### `from_paths()` (line 167)
**Args**: cls, paths


#### `_iter_distributions()` (line 172)
**Args**: self


#### `get_distribution()` (line 182)
**Args**: self, name


### venv_new\Lib\site-packages\pip\_internal\metadata\pkg_resources.py

#### `__init__()` (line 54)
**Args**: self, metadata, wheel_name


#### `has_metadata()` (line 58)
**Args**: self, name


#### `get_metadata()` (line 61)
**Args**: self, name


#### `get_metadata_lines()` (line 70)
**Args**: self, name


#### `metadata_isdir()` (line 73)
**Args**: self, name


#### `metadata_listdir()` (line 76)
**Args**: self, name


#### `run_script()` (line 79)
**Args**: self, script_name, namespace


#### `__init__()` (line 84)
**Args**: self, dist


#### `_extra_mapping()` (line 91)
**Args**: self


#### `from_directory()` (line 100)
**Args**: cls, directory


#### `from_metadata_file_contents()` (line 120)
**Args**: cls, metadata_contents, filename, project_name


#### `from_wheel()` (line 137)
**Args**: cls, wheel, name


#### `location()` (line 158)
**Args**: self


#### `installed_location()` (line 162)
**Args**: self


#### `info_location()` (line 173)
**Args**: self


#### `installed_by_distutils()` (line 177)
**Args**: self


#### `canonical_name()` (line 187)
**Args**: self


#### `version()` (line 191)
**Args**: self


#### `raw_version()` (line 195)
**Args**: self


#### `is_file()` (line 198)
**Args**: self, path


#### `iter_distutils_script_names()` (line 201)
**Args**: self


#### `read_text()` (line 204)
**Args**: self, path


#### `iter_entry_points()` (line 213)
**Args**: self


#### `_metadata_impl()` (line 219)
_:raises NoneMetadataError: if the distribution reports `has_metadata()`
    True but `get_metadata()` returns None._

**Args**: self


#### `iter_dependencies()` (line 241)
**Args**: self, extras


#### `iter_provided_extras()` (line 249)
**Args**: self


#### `__init__()` (line 254)
**Args**: self, ws


#### `default()` (line 258)
**Args**: cls


#### `from_paths()` (line 262)
**Args**: cls, paths


#### `_iter_distributions()` (line 265)
**Args**: self


#### `_search_distribution()` (line 269)
_Find a distribution matching the ``name`` in the environment.

This searches from *all* distributions available in the environment, to
match the behavior of ``pkg_resources.get_distribution()``._

**Args**: self, name


#### `get_distribution()` (line 281)
**Args**: self, name


### venv_new\Lib\site-packages\pip\_internal\models\candidate.py

#### `__init__()` (line 19)
**Args**: self, name, version, link


#### `__str__()` (line 24)
**Args**: self


### venv_new\Lib\site-packages\pip\_internal\models\direct_url.py

#### `_get()` (line 27)
_Get value from dictionary and verify expected type._

**Args**: d, expected_type, key, default


#### `_get_required()` (line 41)
**Args**: d, expected_type, key, default


#### `_exactly_one_of()` (line 50)
**Args**: infos


#### `_filter_none()` (line 64)
_Make dict excluding None values._


#### `_from_dict()` (line 78)
**Args**: cls, d


#### `_to_dict()` (line 87)
**Args**: self


#### `__init__()` (line 98)
**Args**: self, hash, hashes


#### `hash()` (line 108)
**Args**: self


#### `hash()` (line 112)
**Args**: self, value


#### `_from_dict()` (line 130)
**Args**: cls, d


#### `_to_dict()` (line 135)
**Args**: self


#### `_from_dict()` (line 146)
**Args**: cls, d


#### `_to_dict()` (line 151)
**Args**: self


#### `_remove_auth_from_netloc()` (line 164)
**Args**: self, netloc


#### `redacted_url()` (line 179)
_url with user:password part removed unless it is formed with
environment variables as specified in PEP 610, or it is ``git``
in the case of a git URL._

**Args**: self


#### `validate()` (line 191)
**Args**: self


#### `from_dict()` (line 195)
**Args**: cls, d


#### `to_dict()` (line 208)
**Args**: self


#### `from_json()` (line 217)
**Args**: cls, s


#### `to_json()` (line 220)
**Args**: self


#### `is_local_editable()` (line 223)
**Args**: self


### venv_new\Lib\site-packages\pip\_internal\models\format_control.py

#### `__init__()` (line 13)
**Args**: self, no_binary, only_binary


#### `__eq__()` (line 26)
**Args**: self, other


#### `__repr__()` (line 35)
**Args**: self


#### `handle_mutual_excludes()` (line 39)
**Args**: value, target, other


#### `get_allowed_formats()` (line 61)
**Args**: self, canonical_name


#### `disallow_binaries()` (line 73)
**Args**: self


### venv_new\Lib\site-packages\pip\_internal\models\index.py

#### `__init__()` (line 9)
**Args**: self, url, file_storage_domain


#### `_url_for_path()` (line 21)
**Args**: self, path


### venv_new\Lib\site-packages\pip\_internal\models\installation_report.py

#### `__init__()` (line 10)
**Args**: self, install_requirements


#### `_install_req_to_dict()` (line 14)
**Args**: cls, ireq


#### `to_dict()` (line 42)
**Args**: self


### venv_new\Lib\site-packages\pip\_internal\models\link.py

#### `__post_init__()` (line 68)
**Args**: self


#### `find_hash_url_fragment()` (line 73)
_Search a string for a checksum algorithm name and encoded output value._

**Args**: cls, url


#### `as_dict()` (line 81)
**Args**: self


#### `as_hashes()` (line 84)
_Return a Hashes instance which checks only for the current hash._

**Args**: self


#### `is_hash_allowed()` (line 88)
_Return True if the current hash is allowed by `hashes`._

**Args**: self, hashes


#### `__post_init__()` (line 103)
**Args**: self


#### `supported_hashes()` (line 108)
**Args**: hashes


#### `_clean_url_path_part()` (line 119)
_Clean a "part" of a URL path (i.e. after splitting on "@" characters)._

**Args**: part


#### `_clean_file_url_path()` (line 127)
_Clean the first part of a URL path that corresponds to a local
filesystem path (i.e. the first part after splitting on "@" characters)._

**Args**: part


#### `_clean_url_path()` (line 144)
_Clean the path portion of a URL._

**Args**: path, is_local_path


#### `_ensure_quoted_url()` (line 166)
_Make sure a link is fully quoted.
For example, if ' ' occurs in the URL, it will be replaced with "%20",
and without double-quoting other characters._

**Args**: url


#### `_absolute_link_url()` (line 181)
_A faster implementation of urllib.parse.urljoin with a shortcut
for absolute http/https URLs._

**Args**: base_url, url


#### `__init__()` (line 209)
_:param url: url of the resource pointed to (href of the link)
:param comes_from: instance of IndexContent where the link was found,
    or string.
:param requires_python: String containing the `Requires-Python`
    metadata field, specified in PEP 345. This may be specified by
    a data-requires-python attribute in the HTML link tag, as
    described in PEP 503.
:param yanked_reason: the reason the file has been yanked, if the
    file has been yanked, or None if the file hasn't been yanked.
    This is the value of the "data-yanked" attribute, if present, in
    a simple repository HTML link. If the file has been yanked but
    no reason was provided, this should be the empty string. See
    PEP 592 for more information and the specification.
:param metadata_file_data: the metadata attached to the file, or None if
    no such metadata is provided. This argument, if not None, indicates
    that a separate metadata file exists, and also optionally supplies
    hashes for that file.
:param cache_link_parsing: A flag that is used elsewhere to determine
    whether resources retrieved from this link should be cached. PyPI
    URLs should generally have this set to False, for example.
:param hashes: A mapping of hash names to digests to allow us to
    determine the validity of a download._

**Args**: self, url, comes_from, requires_python, yanked_reason, metadata_file_data, cache_link_parsing, hashes


#### `from_json()` (line 275)
_Convert an pypi json document from a simple repository page into a Link._

**Args**: cls, file_data, page_url


#### `from_element()` (line 326)
_Convert an anchor element's attributes in a simple repository page to a Link._

**Args**: cls, anchor_attribs, page_url, base_url


#### `__str__()` (line 377)
**Args**: self


#### `__repr__()` (line 387)
**Args**: self


#### `__hash__()` (line 390)
**Args**: self


#### `__eq__()` (line 393)
**Args**: self, other


#### `__lt__()` (line 398)
**Args**: self, other


#### `url()` (line 404)
**Args**: self


#### `filename()` (line 408)
**Args**: self


#### `file_path()` (line 422)
**Args**: self


#### `scheme()` (line 426)
**Args**: self


#### `netloc()` (line 430)
_This can contain auth information._

**Args**: self


#### `path()` (line 437)
**Args**: self


#### `splitext()` (line 440)
**Args**: self


#### `ext()` (line 444)
**Args**: self


#### `url_without_fragment()` (line 448)
**Args**: self


#### `_egg_fragment()` (line 459)
**Args**: self


#### `subdirectory_fragment()` (line 480)
**Args**: self


#### `metadata_link()` (line 486)
_Return a link to the associated core metadata file (if any)._

**Args**: self


#### `as_hashes()` (line 495)
**Args**: self


#### `hash()` (line 499)
**Args**: self


#### `hash_name()` (line 503)
**Args**: self


#### `show_url()` (line 507)
**Args**: self


#### `is_file()` (line 511)
**Args**: self


#### `is_existing_dir()` (line 514)
**Args**: self


#### `is_wheel()` (line 518)
**Args**: self


#### `is_vcs()` (line 522)
**Args**: self


#### `is_yanked()` (line 528)
**Args**: self


#### `has_hash()` (line 532)
**Args**: self


#### `is_hash_allowed()` (line 535)
_Return True if the link has a hash and it is allowed by `hashes`._

**Args**: self, hashes


#### `_clean_link()` (line 576)
**Args**: link


#### `links_equivalent()` (line 603)
**Args**: link1, link2


### venv_new\Lib\site-packages\pip\_internal\models\search_scope.py

#### `create()` (line 31)
_Create a SearchScope object after normalizing the `find_links`._

**Args**: cls, find_links, index_urls, no_index


#### `get_formatted_locations()` (line 72)
**Args**: self


#### `get_index_urls_locations()` (line 107)
_Returns the locations found via self.index_urls

Checks the url_name on the main (first in the list) index and
use this url_name to produce all locations_

**Args**: self, project_name


#### `mkurl_pypi_url()` (line 114)
**Args**: url


### venv_new\Lib\site-packages\pip\_internal\models\selection_prefs.py

#### `__init__()` (line 26)
_Create a SelectionPreferences object.

:param allow_yanked: Whether files marked as yanked (in the sense
    of PEP 592) are permitted to be candidates for install.
:param format_control: A FormatControl object or None. Used to control
    the selection of source packages / binary packages when consulting
    the index and links.
:param prefer_binary: Whether to prefer an old, but valid, binary
    dist over a new source dist.
:param ignore_requires_python: Whether to ignore incompatible
    "Requires-Python" values in links. Defaults to False._

**Args**: self, allow_yanked, allow_all_prereleases, format_control, prefer_binary, ignore_requires_python


### venv_new\Lib\site-packages\pip\_internal\models\target_python.py

#### `__init__()` (line 27)
_:param platforms: A list of strings or None. If None, searches for
    packages that are supported by the current system. Otherwise, will
    find packages that can be built on the platforms passed in. These
    packages will only be downloaded for distribution: they will
    not be built locally.
:param py_version_info: An optional tuple of ints representing the
    Python version information to use (e.g. `sys.version_info[:3]`).
    This can have length 1, 2, or 3 when provided.
:param abis: A list of strings or None. This is passed to
    compatibility_tags.py's get_supported() function as is.
:param implementation: A string or None. This is passed to
    compatibility_tags.py's get_supported() function as is._

**Args**: self, platforms, py_version_info, abis, implementation


#### `format_given()` (line 68)
_Format the given, non-None attributes for display._

**Args**: self


#### `get_sorted_tags()` (line 88)
_Return the supported PEP 425 tags to check wheel candidates against.

The tags are returned in order of preference (most preferred first)._

**Args**: self


#### `get_unsorted_tags()` (line 113)
_Exactly the same as get_sorted_tags, but returns a set.

This is important for performance._

**Args**: self


### venv_new\Lib\site-packages\pip\_internal\models\wheel.py

#### `__init__()` (line 28)
_:raises InvalidWheelFilename: when the filename is invalid for a wheel_

**Args**: self, filename


#### `get_formatted_file_tags()` (line 70)
_Return the wheel's tags as a sorted list of strings._

**Args**: self


#### `support_index_min()` (line 74)
_Return the lowest index that one of the wheel's file_tag combinations
achieves in the given list of supported tags.

For example, if there are 8 supported tags and one of the file tags
is first in the list, then return 0.

:param tags: the PEP 425 tags to check the wheel against, in order
    with most preferred first.

:raises ValueError: If none of the wheel's file tags match one of
    the supported tags._

**Args**: self, tags


#### `find_most_preferred_tag()` (line 92)
_Return the priority of the most preferred tag that one of the wheel's file
tag combinations achieves in the given list of supported tags using the given
tag_to_priority mapping, where lower priorities are more-preferred.

This is used in place of support_index_min in some cases in order to avoid
an expensive linear scan of a large list of tags.

:param tags: the PEP 425 tags to check the wheel against.
:param tag_to_priority: a mapping from tag to priority of that tag, where
    lower is more preferred.

:raises ValueError: If none of the wheel's file tags match one of
    the supported tags._

**Args**: self, tags, tag_to_priority


#### `supported()` (line 113)
_Return whether the wheel is compatible with one of the given tags.

:param tags: the PEP 425 tags to check the wheel against._

**Args**: self, tags


### venv_new\Lib\site-packages\pip\_internal\network\auth.py

#### `get_auth_info()` (line 51)
**Args**: self, url, username


#### `save_auth_info()` (line 56)
**Args**: self, url, username, password


#### `get_auth_info()` (line 64)
**Args**: self, url, username


#### `save_auth_info()` (line 67)
**Args**: self, url, username, password


#### `__init__()` (line 76)
**Args**: self


#### `get_auth_info()` (line 81)
**Args**: self, url, username


#### `save_auth_info()` (line 99)
**Args**: self, url, username, password


#### `__init__()` (line 114)
**Args**: self, cmd


#### `get_auth_info()` (line 117)
**Args**: self, url, username


#### `save_auth_info()` (line 126)
**Args**: self, url, username, password


#### `_get_password()` (line 129)
_Mirror the implementation of keyring.get_password using cli_

**Args**: self, service_name, username


#### `_set_password()` (line 147)
_Mirror the implementation of keyring.set_password using cli_

**Args**: self, service_name, username, password


#### `get_keyring_provider()` (line 163)
**Args**: provider


#### `PATH_as_shutil_which_determines_it()` (line 188)

#### `__init__()` (line 225)
**Args**: self, prompting, index_urls, keyring_provider


#### `keyring_provider()` (line 243)
**Args**: self


#### `keyring_provider()` (line 247)
**Args**: self, provider


#### `use_keyring()` (line 255)
**Args**: self


#### `_get_keyring_auth()` (line 261)
_Return the tuple auth for a given url from keyring._

**Args**: self, url, username


#### `_get_index_url()` (line 287)
_Return the original index URL matching the requested URL.

Cached or dynamically generated credentials may work against
the original index URL rather than just the netloc.

The provided url should have had its username and password
removed already. If the original index url had credentials then
they will be included in the return value.

Returns None if no matching index was found, or if --no-index
was specified by the user._

**Args**: self, url


#### `_get_new_credentials()` (line 335)
_Find and return credentials for the specified URL._

**Args**: self, original_url


#### `_get_url_and_credentials()` (line 392)
_Return the credentials to use for the provided URL.

If allowed, netrc and keyring may be used to obtain the
correct credentials.

Returns (url_without_credentials, username, password). Note
that even if the original URL contains credentials, this
function may return a different username and password._

**Args**: self, original_url


#### `__call__()` (line 440)
**Args**: self, req


#### `_prompt_for_password()` (line 457)
**Args**: self, netloc


#### `_should_save_password_to_keyring()` (line 471)
**Args**: self


#### `handle_401()` (line 480)
**Args**: self, resp


#### `warn_on_401()` (line 543)
_Response callback to warn about incorrect credentials._

**Args**: self, resp


#### `save_credentials()` (line 551)
_Response callback to save credentials on success._

**Args**: self, resp


### venv_new\Lib\site-packages\pip\_internal\network\cache.py

#### `is_from_cache()` (line 17)
**Args**: response


#### `suppressed_cache_errors()` (line 22)
_If we can't access the cache then we can just skip caching and process
requests as if caching wasn't enabled._


#### `__init__()` (line 50)
**Args**: self, directory


#### `_get_cache_path()` (line 55)
**Args**: self, name


#### `get()` (line 63)
**Args**: self, key


#### `_write()` (line 73)
**Args**: self, path, data


#### `set()` (line 94)
**Args**: self, key, value, expires


#### `delete()` (line 100)
**Args**: self, key


#### `get_body()` (line 107)
**Args**: self, key


#### `set_body()` (line 116)
**Args**: self, key, body


### venv_new\Lib\site-packages\pip\_internal\network\download.py

#### `_get_http_response_size()` (line 24)
**Args**: resp


#### `_prepare_download()` (line 31)
**Args**: resp, link, progress_bar


#### `sanitize_content_filename()` (line 73)
_Sanitize the "filename" value from a Content-Disposition header._

**Args**: filename


#### `parse_content_disposition()` (line 80)
_Parse the "filename" value from a Content-Disposition header, and
return the default filename if the result is empty._

**Args**: content_disposition, default_filename


#### `_get_http_response_filename()` (line 95)
_Get an ideal filename from the given HTTP response, falling back to
the link filename if not provided._

**Args**: resp, link


#### `_http_get_download()` (line 116)
**Args**: session, link


#### `__init__()` (line 124)
**Args**: self, session, progress_bar


#### `__call__()` (line 132)
_Download the file given by link into location._

**Args**: self, link, location


#### `__init__()` (line 155)
**Args**: self, session, progress_bar


#### `__call__()` (line 163)
_Download the files given by links into location._

**Args**: self, links, location


### venv_new\Lib\site-packages\pip\_internal\network\lazy_wheel.py

#### `dist_from_wheel_url()` (line 23)
_Return a distribution object from the given wheel URL.

This uses HTTP range requests to only fetch the portion of the wheel
containing metadata, just enough for the object to be constructed.
If such requests are not supported, HTTPRangeRequestUnsupported
is raised._

**Args**: name, url, session


#### `__init__()` (line 49)
**Args**: self, url, session, chunk_size


#### `mode()` (line 66)
_Opening mode, which is always rb._

**Args**: self


#### `name()` (line 71)
_Path to the underlying file._

**Args**: self


#### `seekable()` (line 75)
_Return whether random access is supported, which is True._

**Args**: self


#### `close()` (line 79)
_Close the file._

**Args**: self


#### `closed()` (line 84)
_Whether the file is closed._

**Args**: self


#### `read()` (line 88)
_Read up to size bytes from the object and return them.

As a convenience, if size is unspecified or -1,
all bytes until EOF are returned.  Fewer than
size bytes may be returned if EOF is reached._

**Args**: self, size


#### `readable()` (line 102)
_Return whether the file is readable, which is True._

**Args**: self


#### `seek()` (line 106)
_Change stream position and return the new absolute position.

Seek to offset relative position indicated by whence:
* 0: Start of stream (the default).  pos should be >= 0;
* 1: Current position - pos may be negative;
* 2: End of stream - pos usually negative._

**Args**: self, offset, whence


#### `tell()` (line 116)
_Return the current position._

**Args**: self


#### `truncate()` (line 120)
_Resize the stream to the given size in bytes.

If size is unspecified resize to the current position.
The current stream position isn't changed.

Return the new file size._

**Args**: self, size


#### `writable()` (line 130)
_Return False._

**Args**: self


#### `__enter__()` (line 134)
**Args**: self


#### `__exit__()` (line 138)
**Args**: self


#### `_stay()` (line 142)
_Return a context manager keeping the position.

At the end of the block, seek back to original position._

**Args**: self


#### `_check_zip()` (line 153)
_Check and download until the file is a valid ZIP._

**Args**: self


#### `_stream_response()` (line 168)
_Return HTTP response to a range request from start to end._

**Args**: self, start, end, base_headers


#### `_merge()` (line 178)
_Return a generator of intervals to be fetched.

Args:
    start (int): Start of needed interval
    end (int): End of needed interval
    left (int): Index of first overlapping downloaded data
    right (int): Index after last overlapping downloaded data_

**Args**: self, start, end, left, right


#### `_download()` (line 200)
_Download bytes from start to end inclusively._

**Args**: self, start, end


### venv_new\Lib\site-packages\pip\_internal\network\session.py

#### `looks_like_ci()` (line 100)
_Return whether it looks like pip is running under CI._


#### `user_agent()` (line 111)
_Return a string representing the user agent._


#### `send()` (line 213)
**Args**: self, request, stream, timeout, verify, cert, proxies


#### `close()` (line 252)
**Args**: self


#### `__init__()` (line 264)
**Args**: self


#### `init_poolmanager()` (line 273)
**Args**: self, connections, maxsize, block


#### `cert_verify()` (line 299)
**Args**: self, conn, url, verify, cert


#### `cert_verify()` (line 310)
**Args**: self, conn, url, verify, cert


#### `__init__()` (line 323)
_:param trusted_hosts: Domains not to emit warnings for when not using
    HTTPS._

**Args**: self


#### `update_index_urls()` (line 404)
_:param new_index_urls: New index urls to update the authentication
    handler with._

**Args**: self, new_index_urls


#### `add_trusted_host()` (line 411)
_:param host: It is okay to provide a host that has previously been
    added.
:param source: An optional source string, for logging where the host
    string came from._

**Args**: self, host, source, suppress_logging


#### `iter_secure_origins()` (line 444)
**Args**: self


#### `is_secure_origin()` (line 449)
**Args**: self, location


#### `request()` (line 516)
**Args**: self, method, url


### venv_new\Lib\site-packages\pip\_internal\network\utils.py

#### `raise_for_status()` (line 31)
**Args**: resp


#### `response_chunks()` (line 59)
_Given a requests Response, provide the data chunks._

**Args**: response, chunk_size


### venv_new\Lib\site-packages\pip\_internal\network\xmlrpc.py

#### `__init__()` (line 26)
**Args**: self, index_url, session, use_datetime


#### `request()` (line 34)
**Args**: self, host, handler, request_body, verbose


### venv_new\Lib\site-packages\pip\_internal\operations\check.py

#### `create_package_set_from_installed()` (line 50)
_Converts a list of distributions into a PackageSet._


#### `check_package_set()` (line 67)
_Check if a package set is consistent

If should_ignore is passed, it should be a callable that takes a
package name and returns a boolean._

**Args**: package_set, should_ignore


#### `check_install_conflicts()` (line 112)
_For checking if the dependency graph would be consistent after     installing given requirements
    _

**Args**: to_install


#### `check_unsupported()` (line 132)
**Args**: packages, supported_tags


#### `_simulate_installation_of()` (line 148)
_Computes the version of packages after installing to_install._

**Args**: to_install, package_set


#### `_create_whitelist()` (line 167)
**Args**: would_be_installed, package_set


### venv_new\Lib\site-packages\pip\_internal\operations\freeze.py

#### `freeze()` (line 27)
**Args**: requirement, local_only, user_only, paths, isolated, exclude_editable, skip


#### `_format_as_name_version()` (line 148)
**Args**: dist


#### `_get_editable_info()` (line 158)
_Compute and return values (req, comments) for use in
FrozenRequirement.from_dist()._

**Args**: dist


#### `canonical_name()` (line 232)
**Args**: self


#### `from_dist()` (line 236)
**Args**: cls, dist


#### `__str__()` (line 252)
**Args**: self


### venv_new\Lib\site-packages\pip\_internal\operations\install\editable_legacy.py

#### `install_editable()` (line 15)
_Install a package in editable mode. Most arguments are pass-through
to setuptools._


### venv_new\Lib\site-packages\pip\_internal\operations\install\wheel.py

#### `save()` (line 70)
**Args**: self


#### `rehash()` (line 80)
_Return (encoded_digest, length) for path using hashlib.sha256()_

**Args**: path, blocksize


#### `csv_io_kwargs()` (line 87)
_Return keyword arguments to properly open a CSV file
in the given mode._

**Args**: mode


#### `fix_script()` (line 94)
_Replace #!python with #!/path/to/python
Return True if file was changed._

**Args**: path


#### `wheel_root_is_purelib()` (line 114)
**Args**: metadata


#### `get_entrypoints()` (line 118)
**Args**: dist


#### `message_about_scripts_not_on_PATH()` (line 129)
_Determine if any scripts are not on PATH and format a warning.
Returns a warning message if one or more scripts are not on PATH,
otherwise None._

**Args**: scripts


#### `_normalized_outrows()` (line 201)
_Normalize the given rows of a RECORD file.

Items in each row are converted into str. Rows are then sorted to make
the value more predictable for tests.

Each row is a 3-tuple (path, hash, size) and corresponds to a record of
a RECORD file (see PEP 376 and PEP 427 for details).  For the rows
passed to this function, the size can be an integer as an int or string,
or the empty string._

**Args**: outrows


#### `_record_to_fs_path()` (line 227)
**Args**: record_path, lib_dir


#### `_fs_to_record_path()` (line 231)
**Args**: path, lib_dir


#### `get_csv_rows_for_installed()` (line 241)
_:param installed: A map from archive RECORD path to installation RECORD
    path._

**Args**: old_csv_rows, installed, changed, generated, lib_dir


#### `get_console_script_specs()` (line 273)
_Given the mapping from entrypoint name to callable, return the relevant
console script specs._

**Args**: console


#### `__init__()` (line 349)
**Args**: self, src_record_path, dest_path, zip_file


#### `_getinfo()` (line 357)
**Args**: self


#### `save()` (line 360)
**Args**: self


#### `__init__()` (line 387)
**Args**: self, file


#### `save()` (line 393)
**Args**: self


#### `__init__()` (line 399)
**Args**: self, entry_point


#### `_raise_for_invalid_entrypoint()` (line 408)
**Args**: specification


#### `make()` (line 415)
**Args**: self, specification, options


#### `_install_wheel()` (line 422)
_Install a wheel.

:param name: Name of the project to install
:param wheel_zip: open ZipFile for wheel being installed
:param scheme: Distutils scheme dictating the install directories
:param req_description: String used in place of the requirement, for
    logging
:param pycompile: Whether to byte-compile installed Python files
:param warn_script_location: Whether to check that scripts are installed
    into a directory on PATH
:raises UnsupportedWheel:
    * when the directory holds an unpacked wheel with incompatible
      Wheel-Version
    * when the .dist-info dir does not match the wheel_

**Args**: name, wheel_zip, wheel_path, scheme, pycompile, warn_script_location, direct_url, requested


#### `record_installed()` (line 462)
_Map archive RECORD paths to installation RECORD paths._

**Args**: srcfile, destfile, modified


#### `is_dir_path()` (line 471)
**Args**: path


#### `assert_no_path_traversal()` (line 474)
**Args**: dest_dir_path, target_path


#### `root_scheme_file_maker()` (line 484)
**Args**: zip_file, dest


#### `make_root_scheme_file()` (line 487)
**Args**: record_path


#### `data_scheme_file_maker()` (line 495)
**Args**: zip_file, scheme


#### `make_data_scheme_file()` (line 500)
**Args**: record_path


#### `is_data_scheme_path()` (line 529)
**Args**: path


#### `is_script_scheme_path()` (line 539)
**Args**: path


#### `is_entrypoint_wrapper()` (line 558)
**Args**: file


#### `pyc_source_file_paths()` (line 593)

#### `pyc_output_path()` (line 606)
_Return the path the pyc file would have been written to._

**Args**: path


#### `_generate_file()` (line 662)
**Args**: path


#### `req_error_context()` (line 712)
**Args**: req_description


#### `install_wheel()` (line 720)
**Args**: name, wheel_path, scheme, req_description, pycompile, warn_script_location, direct_url, requested


### venv_new\Lib\site-packages\pip\_internal\operations\prepare.py

#### `_get_prepared_distribution()` (line 60)
_Prepare a distribution for installation._

**Args**: req, build_tracker, finder, build_isolation, check_build_deps


#### `unpack_vcs_link()` (line 78)
**Args**: link, location, verbosity


#### `__post_init__()` (line 89)
**Args**: self


#### `get_http_url()` (line 94)
**Args**: link, download, download_dir, hashes


#### `get_file_url()` (line 118)
_Get file and optionally check its hash._

**Args**: link, download_dir, hashes


#### `unpack_url()` (line 142)
_Unpack link into location, downloading if required.

:param hashes: A Hashes object, one of whose embedded hashes must match,
    or HashMismatch will be raised. If the Hashes is empty, no matches are
    required, and unhashable types of requirements (like VCS ones, which
    would ordinarily raise HashUnsupported) are allowed._

**Args**: link, location, download, verbosity, download_dir, hashes


#### `_check_download_dir()` (line 185)
_Check download_dir for previously downloaded file with correct hash
If a correct file is found return its path else None_

**Args**: link, download_dir, hashes, warn_on_hash_mismatch


#### `__init__()` (line 218)
**Args**: self, build_dir, download_dir, src_dir, build_isolation, check_build_deps, build_tracker, session, progress_bar, finder, require_hashes, use_user_site, lazy_wheel, verbosity, legacy_resolver


#### `_log_preparing_link()` (line 276)
_Provide context for the requirement being prepared._

**Args**: self, req


#### `_ensure_link_req_src_dir()` (line 303)
_Ensure source_dir of a linked InstallRequirement._

**Args**: self, req, parallel_builds


#### `_get_linked_req_hashes()` (line 326)
**Args**: self, req


#### `_fetch_metadata_only()` (line 358)
**Args**: self, req


#### `_fetch_metadata_using_link_data_attr()` (line 377)
_Fetch metadata from the data-dist-info-metadata attribute, if possible._

**Args**: self, req


#### `_fetch_metadata_using_lazy_wheel()` (line 418)
_Fetch metadata using lazy wheel, if possible._

**Args**: self, link


#### `_complete_partial_requirements()` (line 447)
_Download any requirements which were only fetched by metadata._

**Args**: self, partially_downloaded_reqs, parallel_builds


#### `prepare_linked_requirement()` (line 491)
_Prepare a requirement to be obtained from req.link._

**Args**: self, req, parallel_builds


#### `prepare_linked_requirements_more()` (line 529)
_Prepare linked requirements more, if needed._

**Args**: self, reqs, parallel_builds


#### `_prepare_linked_requirement()` (line 559)
**Args**: self, req, parallel_builds


#### `save_linked_requirement()` (line 651)
**Args**: self, req


#### `prepare_editable_requirement()` (line 677)
_Prepare an editable requirement._

**Args**: self, req


#### `prepare_installed_requirement()` (line 710)
_Prepare an already-installed requirement._

**Args**: self, req, skip_reason


### venv_new\Lib\site-packages\pip\_internal\pyproject.py

#### `_is_list_of_str()` (line 22)
**Args**: obj


#### `make_pyproject_path()` (line 26)
**Args**: unpacked_source_directory


#### `load_pyproject_toml()` (line 35)
_Load the pyproject.toml file.

Parameters:
    use_pep517 - Has the user requested PEP 517 processing? None
                 means the user hasn't explicitly specified.
    pyproject_toml - Location of the project's pyproject.toml file
    setup_py - Location of the project's setup.py file
    req_name - The name of the requirement we're processing (for
               error reporting)

Returns:
    None if we should use the legacy code path, otherwise a tuple
    (
        requirements from pyproject.toml,
        name of PEP 517 backend,
        requirements we should check are installed after setting
            up the build environment
        directory paths to import the backend from (backend-path),
            relative to the project root.
    )_

**Args**: use_pep517, pyproject_toml, setup_py, req_name


### venv_new\Lib\site-packages\pip\_internal\req\__init__.py

#### `_validate_requirements()` (line 27)
**Args**: requirements


#### `install_given_reqs()` (line 35)
_Install everything in the given list.

(to be called after having downloaded and unpacked the packages)_

**Args**: requirements, global_options, root, home, prefix, warn_script_location, use_user_site, pycompile


### venv_new\Lib\site-packages\pip\_internal\req\constructors.py

#### `_strip_extras()` (line 44)
**Args**: path


#### `convert_extras()` (line 56)
**Args**: extras


#### `_set_requirement_extras()` (line 62)
_Returns a new requirement based on the given one, with the supplied extras. If the
given requirement already has extras those are replaced (or dropped if no new extras
are given)._

**Args**: req, new_extras


#### `parse_editable()` (line 87)
_Parses an editable requirement into:
    - a requirement name
    - an URL
    - extras
    - editable options
Accepted requirements:
    svn+http://blahblah@rev#egg=Foobar[baz]&subdirectory=version_subdir
    .[some_extra]_

**Args**: editable_req


#### `check_first_requirement_in_file()` (line 142)
_Check if file is parsable as a requirements file.

This is heavily based on ``pkg_resources.parse_requirements``, but
simplified to just check the first meaningful line.

:raises InvalidRequirement: If the first meaningful line cannot be parsed
    as an requirement._

**Args**: filename


#### `deduce_helpful_msg()` (line 170)
_Returns helpful msg in case requirements file does not exist,
or cannot be parsed.

:params req: Requirements file path_

**Args**: req


#### `parse_req_from_editable()` (line 203)
**Args**: editable_req


#### `install_req_from_editable()` (line 222)
**Args**: editable_req, comes_from


#### `_looks_like_path()` (line 254)
_Checks whether the string "looks like" a path on the filesystem.

This does not check whether the target actually exists, only judge from the
appearance.

Returns true if any of the following conditions is true:
* a path separator is found (either os.path.sep or os.path.altsep);
* a dot is found (which represents the current directory)._

**Args**: name


#### `_get_url_from_path()` (line 273)
_First, it checks whether a provided path is an installable directory. If it
is, returns the path.

If false, check if the path is an archive file (such as a .whl).
The function checks if the path is a file. If false, if the path has
an @, it will treat it as a PEP 440 URL requirement and return the path._

**Args**: path, name


#### `parse_req_from_line()` (line 307)
**Args**: name, line_source


#### `with_source()` (line 355)
**Args**: text


#### `_parse_req_string()` (line 360)
**Args**: req_as_string


#### `install_req_from_line()` (line 386)
_Creates an InstallRequirement from a name, which might be a
requirement, directory containing 'setup.py', filename, or URL.

:param line_source: An optional string describing where the line is from,
    for logging purposes in case of an error._

**Args**: name, comes_from


#### `install_req_from_req_string()` (line 423)
**Args**: req_string, comes_from, isolated, use_pep517, user_supplied


#### `install_req_from_parsed_requirement()` (line 461)
**Args**: parsed_req, isolated, use_pep517, user_supplied, config_settings


#### `install_req_from_link_and_ireq()` (line 501)
**Args**: link, ireq


#### `install_req_drop_extras()` (line 519)
_Creates a new InstallationRequirement using the given template but without
any extras. Sets the original requirement as the new one's parent
(comes_from)._

**Args**: ireq


#### `install_req_extend_extras()` (line 545)
_Returns a copy of an installation requirement with some additional extras.
Makes a shallow copy of the ireq object._

**Args**: ireq, extras


### venv_new\Lib\site-packages\pip\_internal\req\req_file.py

#### `is_editable()` (line 136)
**Args**: self


#### `requirement()` (line 140)
**Args**: self


#### `parse_requirements()` (line 149)
_Parse a requirements file and yield ParsedRequirement instances.

:param filename:    Path or url of requirements file.
:param session:     PipSession instance.
:param finder:      Instance of pip.index.PackageFinder.
:param options:     cli options.
:param constraint:  If true, parsing a constraint file rather than
    requirements file._

**Args**: filename, session, finder, options, constraint


#### `preprocess()` (line 176)
_Split, filter, and join lines, and return a line iterator

:param content: the content of the requirements file_

**Args**: content


#### `handle_requirement_line()` (line 188)
**Args**: line, options


#### `handle_option_line()` (line 222)
**Args**: opts, filename, lineno, finder, options, session


#### `handle_line()` (line 292)
_Handle a single parsed requirements line; This can result in
creating/yielding requirements, or updating the finder.

:param line:        The parsed line to be processed.
:param options:     CLI options.
:param finder:      The finder - updated by non-requirement lines.
:param session:     The session - updated by non-requirement lines.

Returns a ParsedRequirement object if the line is a requirement line,
otherwise returns None.

For lines that contain requirements, the only options that have an effect
are from SUPPORTED_OPTIONS_REQ, and they are scoped to the
requirement. Other options from SUPPORTED_OPTIONS may be present, but are
ignored.

For lines that do not contain requirements, the only options that have an
effect are from SUPPORTED_OPTIONS. Options from SUPPORTED_OPTIONS_REQ may
be present, but are ignored. These lines may contain multiple options
(although our docs imply only one is supported), and all our parsed and
affect the finder._

**Args**: line, options, finder, session


#### `__init__()` (line 337)
**Args**: self, session, line_parser


#### `parse()` (line 345)
_Parse a given file, yielding parsed lines._

**Args**: self, filename, constraint


#### `_parse_and_recurse()` (line 353)
**Args**: self, filename, constraint, parsed_files_stack


#### `_parse_file()` (line 405)
**Args**: self, filename, constraint


#### `get_line_parser()` (line 429)
**Args**: finder


#### `parse_line()` (line 430)
**Args**: line


#### `break_args_options()` (line 453)
_Break up the line into an args and options string.  We only want to shlex
(and then optparse) the options, not the args.  args can contain markers
which are corrupted by shlex._

**Args**: line


#### `__init__()` (line 471)
**Args**: self, msg


#### `build_parser()` (line 475)
_Return a parser for parsing requirement lines_


#### `parser_exit()` (line 488)
**Args**: self, msg


#### `join_lines()` (line 498)
_Joins a line ending in '' with the previous line (except when following
comments).  The joined line takes on the index of the first line._

**Args**: lines_enum


#### `ignore_comments()` (line 529)
_Strips comments and filter empty lines._

**Args**: lines_enum


#### `expand_env_variables()` (line 540)
_Replace all environment variables that can be retrieved via `os.getenv`.

The only allowed format for environment variables defined in the
requirement file is `${MY_VARIABLE_1}` to ensure two things:

1. Strings that contain a `$` aren't accidentally (partially) expanded.
2. Ensure consistency across platforms for requirement files.

These points are the result of a discussion on the `github pull
request #3514 <https://github.com/pypa/pip/pull/3514>`_.

Valid characters in variable names follow the `POSIX standard
<http://pubs.opengroup.org/onlinepubs/9699919799/>`_ and are limited
to uppercase letter, digits and the `_` (underscore)._

**Args**: lines_enum


#### `get_file_content()` (line 567)
_Gets the content of a file; it may be a filename, file: URL, or
http: URL.  Returns (location, content).  Content is unicode.
Respects # -*- coding: declarations on the retrieved files.

:param url:         File path or url.
:param session:     PipSession instance._

**Args**: url, session


#### `_decode_req_file()` (line 597)
**Args**: data, url


### venv_new\Lib\site-packages\pip\_internal\req\req_install.py

#### `__init__()` (line 72)
**Args**: self, req, comes_from, editable, link, markers, use_pep517, isolated


#### `__str__()` (line 200)
**Args**: self


#### `__repr__()` (line 224)
**Args**: self


#### `format_debug()` (line 230)
_An un-tested helper for getting state, for debugging._

**Args**: self


#### `name()` (line 243)
**Args**: self


#### `supports_pyproject_editable()` (line 249)
**Args**: self


#### `specifier()` (line 261)
**Args**: self


#### `is_direct()` (line 266)
_Whether this requirement was specified as a direct URL._

**Args**: self


#### `is_pinned()` (line 271)
_Return whether I am pinned to an exact version.

For example, some-package==1.2 is pinned; some-package>1.2 is not._

**Args**: self


#### `match_markers()` (line 280)
**Args**: self, extras_requested


#### `has_hash_options()` (line 293)
_Return whether any known-good hashes are specified as options.

These activate --require-hashes mode; hashes specified as part of a
URL do not._

**Args**: self


#### `hashes()` (line 302)
_Return a hash-comparer that considers my option- and URL-based
hashes to be known-good.

Hashes in URLs--ones embedded in the requirements file, not ones
downloaded from an index server--are almost peers with ones from
flags. They satisfy --require-hashes (whether it was implicitly or
explicitly activated) but do not activate it. md5 and sha224 are not
allowed in flags, which should nudge people toward good algos. We
always OR all hashes together, even ones from URLs.

:param trust_internet: Whether to trust URL-based (#md5=...) hashes
    downloaded from the internet, as by populate_link()_

**Args**: self, trust_internet


#### `from_path()` (line 329)
_Format a nice indicator to show where this "comes from" _

**Args**: self


#### `ensure_build_location()` (line 344)
**Args**: self, build_dir, autodelete, parallel_builds


#### `_set_requirement()` (line 387)
_Set requirement after generating metadata._

**Args**: self


#### `warn_on_mismatching_name()` (line 409)
**Args**: self


#### `check_if_exists()` (line 427)
_Find an installed distribution that satisfies or conflicts
with this requirement, and set self.satisfied_by or
self.should_reinstall appropriately._

**Args**: self, use_user_site


#### `is_wheel()` (line 466)
**Args**: self


#### `is_wheel_from_cache()` (line 472)
**Args**: self


#### `unpacked_source_directory()` (line 479)
**Args**: self


#### `setup_py_path()` (line 486)
**Args**: self


#### `setup_cfg_path()` (line 493)
**Args**: self


#### `pyproject_toml_path()` (line 500)
**Args**: self


#### `load_pyproject_toml()` (line 504)
_Load the pyproject.toml file.

After calling this routine, all of the attributes related to PEP 517
processing for this requirement have been set. In particular, the
use_pep517 attribute can be used to determine whether we should
follow the PEP 517 or legacy (setup.py) code path._

**Args**: self


#### `isolated_editable_sanity_check()` (line 532)
_Check that an editable requirement if valid for use with PEP 517/518.

This verifies that an editable that has a pyproject.toml either supports PEP 660
or as a setup.py or a setup.cfg_

**Args**: self


#### `prepare_metadata()` (line 553)
_Ensure that project metadata is available.

Under PEP 517 and PEP 660, call the backend hook to prepare the metadata.
Under legacy processing, call setup.py egg-info._

**Args**: self


#### `metadata()` (line 598)
**Args**: self


#### `get_dist()` (line 604)
**Args**: self


#### `assert_source_matches_version()` (line 618)
**Args**: self


#### `ensure_has_source_dir()` (line 636)
_Ensure that a source_dir is set.

This will create a temporary build dir if the name of the requirement
isn't known yet.

:param parent_dir: The ideal pip parent_dir for the source_dir.
    Generally src_dir for editables and build_dir for sdists.
:return: self.source_dir_

**Args**: self, parent_dir, autodelete, parallel_builds


#### `needs_unpacked_archive()` (line 658)
**Args**: self, archive_source


#### `ensure_pristine_source_checkout()` (line 662)
_Ensure the source directory has not yet been built in._

**Args**: self


#### `update_editable()` (line 680)
**Args**: self


#### `uninstall()` (line 700)
_Uninstall the distribution currently satisfying this requirement.

Prompts before removing or modifying files unless
``auto_confirm`` is True.

Refuses to delete or modify files outside of ``sys.prefix`` -
thus uninstallation within a virtual environment can only
modify that virtual environment, even if the virtualenv is
linked to global site-packages._

**Args**: self, auto_confirm, verbose


#### `_get_archive_name()` (line 726)
**Args**: self, path, parentdir, rootdir


#### `_clean_zip_name()` (line 727)
**Args**: name, prefix


#### `archive()` (line 740)
_Saves archive to provided build_dir.

Used for saving downloaded VCS requirements as part of `pip download`._

**Args**: self, build_dir


#### `install()` (line 807)
**Args**: self, global_options, root, home, prefix, warn_script_location, use_user_site, pycompile


#### `check_invalid_constraint_type()` (line 880)
**Args**: req


#### `_has_option()` (line 908)
**Args**: options, reqs, option


#### `check_legacy_setup_py_options()` (line 917)
**Args**: options, reqs


### venv_new\Lib\site-packages\pip\_internal\req\req_set.py

#### `__init__()` (line 13)
_Create a RequirementSet._

**Args**: self, check_supported_wheels


#### `__str__()` (line 21)
**Args**: self


#### `__repr__()` (line 28)
**Args**: self


#### `add_unnamed_requirement()` (line 41)
**Args**: self, install_req


#### `add_named_requirement()` (line 45)
**Args**: self, install_req


#### `has_requirement()` (line 51)
**Args**: self, name


#### `get_requirement()` (line 59)
**Args**: self, name


#### `all_requirements()` (line 68)
**Args**: self


#### `requirements_to_install()` (line 72)
_Return the list of requirements that need to be installed.

TODO remove this property together with the legacy resolver, since the new
     resolver only returns requirements that need to be installed._

**Args**: self


### venv_new\Lib\site-packages\pip\_internal\req\req_uninstall.py

#### `_script_names()` (line 21)
_Create the fully qualified name of the files created by
{console,gui}_scripts for the given ``dist``.
Returns the list of file names_

**Args**: bin_dir, script_name, is_gui


#### `_unique()` (line 40)
**Args**: fn


#### `unique()` (line 44)

#### `uninstallation_paths()` (line 55)
_Yield all the uninstallation paths for dist based on RECORD-without-.py[co]

Yield paths to all the files in RECORD. For each .py file in RECORD, add
the .pyc and .pyo in the same directory.

UninstallPathSet.add() takes care of the __pycache__ .py[co].

If RECORD is not found, raises an error,
with possible information from the INSTALLER file.

https://packaging.python.org/specifications/recording-installed-packages/_

**Args**: dist


#### `compact()` (line 88)
_Compact a path set to contain the minimal number of paths
necessary to contain all paths in the set. If /a/path/ and
/a/path/to/a/file.txt are both in the set, leave only the
shorter path._

**Args**: paths


#### `compress_for_rename()` (line 107)
_Returns a set containing the paths that need to be renamed.

This set may include directories when the original sequence of paths
included every file on disk._

**Args**: paths


#### `norm_join()` (line 118)

#### `compress_for_output_listing()` (line 141)
_Returns a tuple of 2 sets of which paths to display to user

The first set contains paths that would be deleted. Files of a package
are not added and the top-level directory of the package has a '*' added
at the end - to signify that all it's contents are removed.

The second set contains files that would have been skipped in the above
folders._

**Args**: paths


#### `__init__()` (line 194)
**Args**: self


#### `_get_directory_stash()` (line 202)
_Stashes a directory.

Directories are stashed adjacent to their original location if
possible, or else moved/copied into the user's temp dir._

**Args**: self, path


#### `_get_file_stash()` (line 216)
_Stashes a file.

If no root has been provided, one will be created for the directory
in the user's temp directory._

**Args**: self, path


#### `stash()` (line 243)
_Stashes the directory or file and returns its new location.
Handle symlinks as files to avoid modifying the symlink targets._

**Args**: self, path


#### `commit()` (line 264)
_Commits the uninstall by removing stashed files._

**Args**: self


#### `rollback()` (line 271)
_Undoes the uninstall by moving stashed files back._

**Args**: self


#### `can_rollback()` (line 291)
**Args**: self


#### `__init__()` (line 299)
**Args**: self, dist


#### `_permitted()` (line 310)
_Return True if the given path is one we are permitted to
remove/modify, False otherwise._

**Args**: self, path


#### `add()` (line 321)
**Args**: self, path


#### `add_pth()` (line 340)
**Args**: self, pth_file, entry


#### `remove()` (line 349)
_Remove paths in ``self._paths`` with confirmation (unless
``auto_confirm`` is True)._

**Args**: self, auto_confirm, verbose


#### `_allowed_to_proceed()` (line 378)
_Display which files would be deleted and prompt for confirmation_

**Args**: self, verbose


#### `_display()` (line 381)
**Args**: msg, paths


#### `rollback()` (line 406)
_Rollback the changes previously made by remove()._

**Args**: self


#### `commit()` (line 419)
_Remove temporary save dir: rollback will no longer be possible._

**Args**: self


#### `from_dist()` (line 424)
**Args**: cls, dist


#### `iter_scripts_to_remove()` (line 562)
**Args**: dist, bin_dir


#### `__init__()` (line 579)
**Args**: self, pth_file


#### `add()` (line 584)
**Args**: self, entry


#### `remove()` (line 599)
**Args**: self


#### `rollback()` (line 626)
**Args**: self


### venv_new\Lib\site-packages\pip\_internal\resolution\base.py

#### `resolve()` (line 12)
**Args**: self, root_reqs, check_supported_wheels


#### `get_installation_order()` (line 17)
**Args**: self, req_set


### venv_new\Lib\site-packages\pip\_internal\resolution\legacy\resolver.py

#### `_check_dist_requires_python()` (line 55)
_Check whether the given Python version is compatible with a distribution's
"Requires-Python" value.

:param version_info: A 3-tuple of ints representing the Python
    major-minor-micro version to check.
:param ignore_requires_python: Whether to ignore the "Requires-Python"
    value if the given Python version isn't compatible.

:raises UnsupportedPythonVersion: When the given Python version isn't
    compatible._

**Args**: dist, version_info, ignore_requires_python


#### `__init__()` (line 116)
**Args**: self, preparer, finder, wheel_cache, make_install_req, use_user_site, ignore_dependencies, ignore_installed, ignore_requires_python, force_reinstall, upgrade_strategy, py_version_info


#### `resolve()` (line 154)
_Resolve what operations need to be done

As a side-effect of this method, the packages (and their dependencies)
are downloaded, unpacked and prepared for installation. This
preparation is done by ``pip.operations.prepare``.

Once PyPI has static dependency metadata available, it would be
possible to move the preparation to become a step separated from
dependency resolution._

**Args**: self, root_reqs, check_supported_wheels


#### `_add_requirement_to_set()` (line 191)
_Add install_req as a requirement to install.

:param parent_req_name: The name of the requirement that needed this
    added. The name is used because when multiple unnamed requirements
    resolve to the same name, we could otherwise end up with dependency
    links that point outside the Requirements set. parent_req must
    already be added. Note that None implies that this is a user
    supplied requirement, vs an inferred one.
:param extras_requested: an iterable of extras used to evaluate the
    environment markers.
:return: Additional requirements to scan. That is either [] if
    the requirement is not applicable, or [install_req] if the
    requirement is applicable and has just been added._

**Args**: self, requirement_set, install_req, parent_req_name, extras_requested


#### `_is_upgrade_allowed()` (line 306)
**Args**: self, req


#### `_set_req_to_reinstall()` (line 315)
_Set a requirement to be installed._

**Args**: self, req


#### `_check_skip_installed()` (line 326)
_Check if req_to_install should be skipped.

This will check if the req is installed, and whether we should upgrade
or reinstall it, taking into account all the relevant user options.

After calling this req_to_install will only have satisfied_by set to
None if the req_to_install is to be upgraded/reinstalled etc. Any
other value will be a dist recording the current thing installed that
satisfies the requirement.

Note that for vcs urls and the like we can't assess skipping in this
routine - we simply identify that we need to pull the thing down,
then later on it is pulled down and introspected to assess upgrade/
reinstalls etc.

:return: A text reason for why it was skipped, or None._

**Args**: self, req_to_install


#### `_find_requirement_link()` (line 380)
**Args**: self, req


#### `_populate_link()` (line 402)
_Ensure that if a link can be found for this, that it is found.

Note that req.link may still be None - if the requirement is already
installed and not needed to be upgraded based on the return value of
_is_upgrade_allowed().

If preparer.require_hashes is True, don't use the wheel cache, because
cached wheels, always built locally, have different hashes than the
files downloaded from the index server and thus throw false hash
mismatches. Furthermore, cached wheels at present have undeterministic
contents due to file modification times._

**Args**: self, req


#### `_get_dist_for()` (line 441)
_Takes a InstallRequirement and returns a single AbstractDist         representing a prepared variant of the same.
        _

**Args**: self, req


#### `_resolve_one()` (line 487)
_Prepare a single requirements file.

:return: A list of additional InstallRequirements to also install._

**Args**: self, requirement_set, req_to_install


#### `add_req()` (line 516)
**Args**: subreq, extras_requested


#### `get_installation_order()` (line 570)
_Create the installation order.

The installation order is topological - requirements are installed
before the requiring thing. We break cycles at an arbitrary point,
and make no other guarantees._

**Args**: self, req_set


#### `schedule()` (line 585)
**Args**: req


### venv_new\Lib\site-packages\pip\_internal\resolution\resolvelib\base.py

#### `format_name()` (line 15)
**Args**: project, extras


#### `empty()` (line 29)
**Args**: cls


#### `from_ireq()` (line 33)
**Args**: cls, ireq


#### `__bool__()` (line 37)
**Args**: self


#### `__and__()` (line 40)
**Args**: self, other


#### `is_satisfied_by()` (line 50)
**Args**: self, candidate


#### `project_name()` (line 62)
_The "project name" of a requirement.

This is different from ``name`` if this requirement contains extras,
in which case ``name`` would contain the ``[...]`` part, while this
refers to the name of the project._

**Args**: self


#### `name()` (line 72)
_The name identifying this requirement in the resolver.

This is different from ``project_name`` if this requirement contains
extras, where ``project_name`` would not contain the ``[...]`` part._

**Args**: self


#### `is_satisfied_by()` (line 80)
**Args**: self, candidate


#### `get_candidate_lookup()` (line 83)
**Args**: self


#### `format_for_error()` (line 86)
**Args**: self


#### `_match_link()` (line 90)
**Args**: link, candidate


#### `project_name()` (line 98)
_The "project name" of the candidate.

This is different from ``name`` if this candidate contains extras,
in which case ``name`` would contain the ``[...]`` part, while this
refers to the name of the project._

**Args**: self


#### `name()` (line 108)
_The name identifying this candidate in the resolver.

This is different from ``project_name`` if this candidate contains
extras, where ``project_name`` would not contain the ``[...]`` part._

**Args**: self


#### `version()` (line 117)
**Args**: self


#### `is_installed()` (line 121)
**Args**: self


#### `is_editable()` (line 125)
**Args**: self


#### `source_link()` (line 129)
**Args**: self


#### `iter_dependencies()` (line 132)
**Args**: self, with_requires


#### `get_install_requirement()` (line 135)
**Args**: self


#### `format_for_error()` (line 138)
**Args**: self


### venv_new\Lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py

#### `as_base_candidate()` (line 44)
_The runtime version of BaseCandidate._

**Args**: candidate


#### `make_install_req_from_link()` (line 56)
**Args**: link, template


#### `make_install_req_from_editable()` (line 81)
**Args**: link, template


#### `_make_install_req_from_dist()` (line 101)
**Args**: dist, template


#### `__init__()` (line 144)
**Args**: self, link, source_link, ireq, factory, name, version


#### `__str__()` (line 162)
**Args**: self


#### `__repr__()` (line 165)
**Args**: self


#### `__hash__()` (line 168)
**Args**: self


#### `__eq__()` (line 175)
**Args**: self, other


#### `source_link()` (line 181)
**Args**: self


#### `project_name()` (line 185)
_The normalised name of the project the candidate refers to_

**Args**: self


#### `name()` (line 192)
**Args**: self


#### `version()` (line 196)
**Args**: self


#### `format_for_error()` (line 201)
**Args**: self


#### `_prepare_distribution()` (line 207)
**Args**: self


#### `_check_metadata_consistency()` (line 210)
_Check for consistency of project name and version of dist._

**Args**: self, dist


#### `_prepare()` (line 234)
**Args**: self


#### `iter_dependencies()` (line 251)
**Args**: self, with_requires


#### `get_install_requirement()` (line 257)
**Args**: self


#### `__init__()` (line 264)
**Args**: self, link, template, factory, name, version


#### `_prepare_distribution()` (line 313)
**Args**: self


#### `__init__()` (line 321)
**Args**: self, link, template, factory, name, version


#### `_prepare_distribution()` (line 338)
**Args**: self


#### `__init__()` (line 346)
**Args**: self, dist, template, factory


#### `__str__()` (line 364)
**Args**: self


#### `__repr__()` (line 367)
**Args**: self


#### `__eq__()` (line 370)
**Args**: self, other


#### `__hash__()` (line 375)
**Args**: self


#### `project_name()` (line 379)
**Args**: self


#### `name()` (line 383)
**Args**: self


#### `version()` (line 387)
**Args**: self


#### `is_editable()` (line 393)
**Args**: self


#### `format_for_error()` (line 396)
**Args**: self


#### `iter_dependencies()` (line 399)
**Args**: self, with_requires


#### `get_install_requirement()` (line 409)
**Args**: self


#### `__init__()` (line 438)
_:param comes_from: the InstallRequirement that led to this candidate if it
    differs from the base's InstallRequirement. This will often be the
    case in the sense that this candidate's requirement has the extras
    while the base's does not. Unlike the InstallRequirement backed
    candidates, this requirement is used solely for reporting purposes,
    it does not do any leg work._

**Args**: self, base, extras


#### `__str__()` (line 457)
**Args**: self


#### `__repr__()` (line 461)
**Args**: self


#### `__hash__()` (line 464)
**Args**: self


#### `__eq__()` (line 467)
**Args**: self, other


#### `project_name()` (line 473)
**Args**: self


#### `name()` (line 477)
_The normalised name of the project the candidate refers to_

**Args**: self


#### `version()` (line 482)
**Args**: self


#### `format_for_error()` (line 485)
**Args**: self


#### `is_installed()` (line 491)
**Args**: self


#### `is_editable()` (line 495)
**Args**: self


#### `source_link()` (line 499)
**Args**: self


#### `iter_dependencies()` (line 502)
**Args**: self, with_requires


#### `get_install_requirement()` (line 530)
**Args**: self


#### `__init__()` (line 541)
**Args**: self, py_version_info


#### `__str__()` (line 552)
**Args**: self


#### `project_name()` (line 556)
**Args**: self


#### `name()` (line 560)
**Args**: self


#### `version()` (line 564)
**Args**: self


#### `format_for_error()` (line 567)
**Args**: self


#### `iter_dependencies()` (line 570)
**Args**: self, with_requires


#### `get_install_requirement()` (line 573)
**Args**: self


### venv_new\Lib\site-packages\pip\_internal\resolution\resolvelib\factory.py

#### `__init__()` (line 97)
**Args**: self, finder, preparer, make_install_req, wheel_cache, use_user_site, force_reinstall, ignore_installed, ignore_requires_python, py_version_info


#### `force_reinstall()` (line 137)
**Args**: self


#### `_fail_if_link_is_unsupported_wheel()` (line 140)
**Args**: self, link


#### `_make_extras_candidate()` (line 149)
**Args**: self, base, extras


#### `_make_candidate_from_dist()` (line 164)
**Args**: self, dist, extras, template


#### `_make_candidate_from_link()` (line 179)
**Args**: self, link, extras, template, name, version


#### `_make_base_candidate_from_link()` (line 194)
**Args**: self, link, template, name, version


#### `_iter_found_candidates()` (line 251)
**Args**: self, ireqs, specifier, hashes, prefers_installed, incompatible_ids


#### `_get_installed_candidate()` (line 277)
_Get the candidate for the currently-installed version._


#### `iter_index_candidate_infos()` (line 306)

#### `is_pinned()` (line 319)
**Args**: specifier


#### `_iter_explicit_candidates_from_base()` (line 353)
_Produce explicit candidates from the base given an extra-ed package.

:param base_requirements: Requirements known to the resolver. The
    requirements are guaranteed to not have extras.
:param extras: The extras to inject into the explicit requirements'
    candidates._

**Args**: self, base_requirements, extras


#### `_iter_candidates_from_constraints()` (line 375)
_Produce explicit candidates from constraints.

This creates "fake" InstallRequirement objects that are basically clones
of what "should" be the template, but with original_link set to link._

**Args**: self, identifier, constraint, template


#### `find_candidates()` (line 397)
**Args**: self, identifier, requirements, incompatibilities, constraint, prefers_installed, is_satisfied_by


#### `_make_requirements_from_install_req()` (line 473)
_Returns requirement objects associated with the given InstallRequirement. In
most cases this will be a single object but the following special cases exist:
    - the InstallRequirement has markers that do not apply -> result is empty
    - the InstallRequirement has both a constraint (or link) and extras
        -> result is split in two requirement objects: one with the constraint
        (or link) and one with the extra. This allows centralized constraint
        handling for the base, resulting in fewer candidate rejections._

**Args**: self, ireq, requested_extras


#### `collect_root_requirements()` (line 526)
**Args**: self, root_ireqs


#### `make_requirement_from_candidate()` (line 568)
**Args**: self, candidate


#### `make_requirements_from_spec()` (line 573)
_Returns requirement objects associated with the given specifier. In most cases
this will be a single object but the following special cases exist:
    - the specifier has markers that do not apply -> result is empty
    - the specifier has both a constraint and extras -> result is split
        in two requirement objects: one with the constraint and one with the
        extra. This allows centralized constraint handling for the base,
        resulting in fewer candidate rejections._

**Args**: self, specifier, comes_from, requested_extras


#### `make_requires_python_requirement()` (line 591)
**Args**: self, specifier


#### `get_wheel_cache_entry()` (line 602)
_Look up the link in the wheel cache.

If ``preparer.require_hashes`` is True, don't use the wheel cache,
because cached wheels, always built locally, have different hashes
than the files downloaded from the index server and thus throw false
hash mismatches. Furthermore, cached wheels at present have
nondeterministic contents due to file modification times._

**Args**: self, link, name


#### `get_dist_to_uninstall()` (line 621)
**Args**: self, candidate


#### `_report_requires_python_error()` (line 649)
**Args**: self, causes


#### `_report_single_requirement_conflict()` (line 671)
**Args**: self, req, parent


#### `get_installation_error()` (line 723)
**Args**: self, e, constraints


#### `text_join()` (line 759)
**Args**: parts


#### `describe_trigger()` (line 765)
**Args**: parent


### venv_new\Lib\site-packages\pip\_internal\resolution\resolvelib\found_candidates.py

#### `_iter_built()` (line 42)
_Iterator for ``FoundCandidates``.

This iterator is used when the package is not already installed. Candidates
from index come later in their normal ordering._

**Args**: infos


#### `_iter_built_with_prepended()` (line 73)
_Iterator for ``FoundCandidates``.

This iterator is used when the resolver prefers the already-installed
candidate and NOT to upgrade. The installed candidate is therefore
always yielded first, and candidates from index come later in their
normal ordering, except skipped when the version is already installed._

**Args**: installed, infos


#### `_iter_built_with_inserted()` (line 95)
_Iterator for ``FoundCandidates``.

This iterator is used when the resolver prefers to upgrade an
already-installed package. Candidates from index are returned in their
normal ordering, except replaced when the version is already installed.

The implementation iterates through and yields other candidates, inserting
the installed candidate exactly once before we start yielding older or
equivalent candidates, or after all other candidates if they are all newer._

**Args**: installed, infos


#### `__init__()` (line 136)
**Args**: self, get_infos, installed, prefers_installed, incompatible_ids


#### `__getitem__()` (line 148)
**Args**: self, index


#### `__iter__()` (line 154)
**Args**: self


#### `__len__()` (line 164)
**Args**: self


#### `__bool__()` (line 171)
**Args**: self


### venv_new\Lib\site-packages\pip\_internal\resolution\resolvelib\provider.py

#### `_get_with_identifier()` (line 54)
_Get item from a package name lookup mapping with a resolver identifier.

This extra logic is needed when the target mapping is keyed by package
name, which cannot be directly looked up with an identifier (which may
contain requested extras). Additional logic is added to also look up a value
by "cleaning up" the extras from the identifier._

**Args**: mapping, identifier, default


#### `__init__()` (line 90)
**Args**: self, factory, constraints, ignore_dependencies, upgrade_strategy, user_requested


#### `identify()` (line 105)
**Args**: self, requirement_or_candidate


#### `get_preference()` (line 108)
_Produce a sort key for given requirement based on preference.

The lower the return value is, the more preferred this group of
arguments is.

Currently pip considers the following in order:

* Prefer if any of the known requirements is "direct", e.g. points to an
  explicit URL.
* If equal, prefer if any requirement is "pinned", i.e. contains
  operator ``===`` or ``==``.
* If equal, calculate an approximate "depth" and resolve requirements
  closer to the user-specified requirements first. If the depth cannot
  by determined (eg: due to no matching parents), it is considered
  infinite.
* Order user-specified requirements by the order they are specified.
* If equal, prefers "non-free" requirements, i.e. contains at least one
  operator, such as ``>=`` or ``<``.
* If equal, order alphabetically for consistency (helps debuggability)._

**Args**: self, identifier, resolutions, candidates, information, backtrack_causes


#### `find_matches()` (line 199)
**Args**: self, identifier, requirements, incompatibilities


#### `_eligible_for_upgrade()` (line 205)
_Are upgrades allowed for this project?

This checks the upgrade strategy, and whether the project was one
that the user specified in the command line, in order to decide
whether we should upgrade if there's a newer version available.

(Note that we don't need access to the `--upgrade` flag, because
an upgrade strategy of "to-satisfy-only" means that `--upgrade`
was not specified)._

**Args**: identifier


#### `is_satisfied_by()` (line 242)
**Args**: self, requirement, candidate


#### `get_dependencies()` (line 245)
**Args**: self, candidate


#### `is_backtrack_cause()` (line 250)
**Args**: identifier, backtrack_causes


### venv_new\Lib\site-packages\pip\_internal\resolution\resolvelib\reporter.py

#### `__init__()` (line 13)
**Args**: self


#### `rejecting_candidate()` (line 35)
**Args**: self, criterion, candidate


#### `starting()` (line 61)
**Args**: self


#### `starting_round()` (line 64)
**Args**: self, index


#### `ending_round()` (line 67)
**Args**: self, index, state


#### `ending()` (line 71)
**Args**: self, state


#### `adding_requirement()` (line 74)
**Args**: self, requirement, parent


#### `rejecting_candidate()` (line 77)
**Args**: self, criterion, candidate


#### `pinning()` (line 80)
**Args**: self, candidate


### venv_new\Lib\site-packages\pip\_internal\resolution\resolvelib\requirements.py

#### `__init__()` (line 13)
**Args**: self, candidate


#### `__str__()` (line 16)
**Args**: self


#### `__repr__()` (line 19)
**Args**: self


#### `__hash__()` (line 22)
**Args**: self


#### `__eq__()` (line 25)
**Args**: self, other


#### `project_name()` (line 31)
**Args**: self


#### `name()` (line 36)
**Args**: self


#### `format_for_error()` (line 40)
**Args**: self


#### `get_candidate_lookup()` (line 43)
**Args**: self


#### `is_satisfied_by()` (line 46)
**Args**: self, candidate


#### `__init__()` (line 51)
**Args**: self, ireq


#### `_equal()` (line 59)
**Args**: self


#### `__str__()` (line 66)
**Args**: self


#### `__repr__()` (line 69)
**Args**: self


#### `__eq__()` (line 72)
**Args**: self, other


#### `__hash__()` (line 77)
**Args**: self


#### `project_name()` (line 85)
**Args**: self


#### `name()` (line 90)
**Args**: self


#### `format_for_error()` (line 93)
**Args**: self


#### `get_candidate_lookup()` (line 106)
**Args**: self


#### `is_satisfied_by()` (line 109)
**Args**: self, candidate


#### `__init__()` (line 128)
**Args**: self, ireq


#### `_equal()` (line 136)
**Args**: self


#### `__eq__()` (line 143)
**Args**: self, other


#### `__hash__()` (line 148)
**Args**: self


#### `__init__()` (line 159)
**Args**: self, specifier, match


#### `__str__()` (line 165)
**Args**: self


#### `__repr__()` (line 168)
**Args**: self


#### `__hash__()` (line 171)
**Args**: self


#### `__eq__()` (line 178)
**Args**: self, other


#### `project_name()` (line 187)
**Args**: self


#### `name()` (line 191)
**Args**: self


#### `format_for_error()` (line 194)
**Args**: self


#### `get_candidate_lookup()` (line 197)
**Args**: self


#### `is_satisfied_by()` (line 202)
**Args**: self, candidate


#### `__init__()` (line 213)
**Args**: self, name


#### `__str__()` (line 216)
**Args**: self


#### `__repr__()` (line 219)
**Args**: self


#### `__eq__()` (line 222)
**Args**: self, other


#### `__hash__()` (line 227)
**Args**: self


#### `project_name()` (line 231)
**Args**: self


#### `name()` (line 235)
**Args**: self


#### `format_for_error()` (line 238)
**Args**: self


#### `get_candidate_lookup()` (line 241)
**Args**: self


#### `is_satisfied_by()` (line 244)
**Args**: self, candidate


### venv_new\Lib\site-packages\pip\_internal\resolution\resolvelib\resolver.py

#### `__init__()` (line 41)
**Args**: self, preparer, finder, wheel_cache, make_install_req, use_user_site, ignore_dependencies, ignore_installed, ignore_requires_python, force_reinstall, upgrade_strategy, py_version_info


#### `resolve()` (line 73)
**Args**: self, root_reqs, check_supported_wheels


#### `get_installation_order()` (line 185)
_Get order for installation of requirements in RequirementSet.

The returned list contains a requirement before another that depends on
it. This helps ensure that the environment is kept consistent as they
get installed one-by-one.

The current implementation creates a topological ordering of the
dependency graph, giving more weight to packages with less
or no dependencies, while breaking any cycles in the graph at
arbitrary points. We make no guarantees about where the cycle
would be broken, other than it *would* be broken._

**Args**: self, req_set


#### `get_topological_weights()` (line 217)
_Assign weights to each node based on how "deep" they are.

This implementation may change at any point in the future without prior
notice.

We first simplify the dependency graph by pruning any leaves and giving them
the highest weight: a package without any dependencies should be installed
first. This is done again and again in the same way, giving ever less weight
to the newly found leaves. The loop stops when no leaves are left: all
remaining packages have at least one dependency left in the graph.

Then we continue with the remaining graph, by taking the length for the
longest path to any node from root, ignoring any paths that contain a single
node twice (i.e. cycles). This is done through a depth-first search through
the graph, while keeping track of the path to the node.

Cycles in the graph result would result in node being revisited while also
being on its own path. In this case, take no action. This helps ensure we
don't get stuck in a cycle.

When assigning weight, the longer path (i.e. larger length) is preferred.

We are only interested in the weights of packages that are in the
requirement_keys._

**Args**: graph, requirement_keys


#### `visit()` (line 248)
**Args**: node


#### `_req_set_item_sorter()` (line 306)
_Key function used to sort install requirements for installation.

Based on the "weight" mapping calculated in ``get_installation_order()``.
The canonical package name is returned as the second member as a tie-
breaker to ensure the result is predictable, which is useful in tests._

**Args**: item, weights


### venv_new\Lib\site-packages\pip\_internal\self_outdated_check.py

#### `_get_statefile_name()` (line 40)
**Args**: key


#### `_convert_date()` (line 46)
_Convert an ISO format string to a date.

Handles the format 2020-01-22T14:24:01Z (trailing Z)
which is not supported by older versions of fromisoformat._

**Args**: isodate


#### `__init__()` (line 56)
**Args**: self, cache_dir


#### `key()` (line 74)
**Args**: self


#### `get()` (line 77)
_Check if we have a not-outdated version loaded already._

**Args**: self, current_time


#### `set()` (line 96)
**Args**: self, pypi_version, current_time


#### `__rich__()` (line 136)
**Args**: self


#### `was_installed_by_pip()` (line 156)
_Checks whether pkg was installed by pip

This is used not to display the upgrade message when pip is in fact
installed by system package manager, such as dnf on Fedora._

**Args**: pkg


#### `_get_current_remote_pip_version()` (line 166)
**Args**: session, options


#### `_self_version_check_logic()` (line 194)

#### `pip_self_version_check()` (line 228)
_Check for an update for pip.

Limit the frequency of checks to once per week. State is stored either in
the active virtualenv or in the user's USER_CACHE_DIR keyed off the prefix
of the pip script path._

**Args**: session, options


### venv_new\Lib\site-packages\pip\_internal\utils\_jaraco_text.py

#### `_nonblank()` (line 36)
**Args**: str


#### `yield_lines()` (line 41)
_Yield valid lines of a string or iterable.

>>> list(yield_lines(''))
[]
>>> list(yield_lines(['foo', 'bar']))
['foo', 'bar']
>>> list(yield_lines('foo\nbar'))
['foo', 'bar']
>>> list(yield_lines('\nfoo\n#bar\nbaz #comment'))
['foo', 'baz #comment']
>>> list(yield_lines(['foo\nbar', 'baz', 'bing\n\n\n']))
['foo', 'bar', 'baz', 'bing']_

**Args**: iterable


#### `_()` (line 60)
**Args**: text


#### `drop_comment()` (line 64)
_Drop comments.

>>> drop_comment('foo # bar')
'foo'

A hash without a space may be in a URL.

>>> drop_comment('http://example.com/foo#bar')
'http://example.com/foo#bar'_

**Args**: line


#### `join_continuation()` (line 79)
_Join lines continued by a trailing backslash.

>>> list(join_continuation(['foo \\', 'bar', 'baz']))
['foobar', 'baz']
>>> list(join_continuation(['foo \\', 'bar', 'baz']))
['foobar', 'baz']
>>> list(join_continuation(['foo \\', 'bar \\', 'baz']))
['foobarbaz']

Not sure why, but...
The character preceding the backslash is also elided.

>>> list(join_continuation(['goo\\', 'dly']))
['godly']

A terrible idea, but...
If no line is available to continue, suppress the lines.

>>> list(join_continuation(['foo', 'bar\\', 'baz\\']))
['foo']_

**Args**: lines


### venv_new\Lib\site-packages\pip\_internal\utils\_log.py

#### `verbose()` (line 22)
**Args**: self, msg


#### `getLogger()` (line 26)
_logging.getLogger, but ensures our VerboseLogger class is returned_

**Args**: name


#### `init_logging()` (line 31)
_Register our VerboseLogger and VERBOSE log level.

Should be called before any calls to getLogger(),
i.e. in pip._internal.__init___


### venv_new\Lib\site-packages\pip\_internal\utils\appdirs.py

#### `user_cache_dir()` (line 16)
**Args**: appname


#### `_macos_user_config_dir()` (line 20)
**Args**: appname, roaming


#### `user_config_dir()` (line 34)
**Args**: appname, roaming


#### `site_config_dirs()` (line 43)
**Args**: appname


### venv_new\Lib\site-packages\pip\_internal\utils\compat.py

#### `has_tls()` (line 16)

#### `get_path_uid()` (line 29)
_Return path's uid.

Does not follow symlinks:
    https://github.com/pypa/pip/pull/935#discussion_r5307003

Placed this function in compat due to differences on AIX and
Jython, that should eventually go away.

:raises OSError: When path is a symlink or can't be read._

**Args**: path


#### `open_text_resource()` (line 62)
**Args**: package, resource, encoding, errors


### venv_new\Lib\site-packages\pip\_internal\utils\compatibility_tags.py

#### `version_info_to_nodot()` (line 22)
**Args**: version_info


#### `_mac_platforms()` (line 27)
**Args**: arch


#### `_ios_platforms()` (line 47)
**Args**: arch


#### `_custom_manylinux_platforms()` (line 67)
**Args**: arch


#### `_get_custom_platforms()` (line 88)
**Args**: arch


#### `_expand_allowed_platforms()` (line 101)
**Args**: platforms


#### `_get_python_version()` (line 118)
**Args**: version


#### `_get_custom_interpreter()` (line 125)
**Args**: implementation, version


#### `get_supported()` (line 135)
_Return a list of supported tags for each version specified in
`versions`.

:param version: a string version, of the form "33" or "32",
    or None. The version will be assumed to support our ABI.
:param platform: specify a list of platforms you want valid
    tags for, or None. If None, use the local system platform.
:param impl: specify the exact implementation you want valid
    tags for, or None. If None, use the local interpreter impl.
:param abis: specify a list of abis you want valid
    tags for, or None. If None, use the local interpreter abi._

**Args**: version, platforms, impl, abis


### venv_new\Lib\site-packages\pip\_internal\utils\datetime.py

#### `today_is_later_than()` (line 7)
**Args**: year, month, day


### venv_new\Lib\site-packages\pip\_internal\utils\deprecation.py

#### `_showwarning()` (line 24)
**Args**: message, category, filename, lineno, file, line


#### `install_warning_logger()` (line 44)

#### `deprecated()` (line 55)
_Helper to deprecate existing functionality.

reason:
    Textual reason shown to the user about why this functionality has
    been deprecated. Should be a complete sentence.
replacement:
    Textual suggestion shown to the user about what alternative
    functionality they can use.
gone_in:
    The version of pip does this functionality should get removed in.
    Raises an error if pip's current version is greater than or equal to
    this.
feature_flag:
    Command-line flag of the form --use-feature={feature_flag} for testing
    upcoming functionality.
issue:
    Issue number on the tracker that would serve as a useful place for
    users to find related discussion and provide feedback._


### venv_new\Lib\site-packages\pip\_internal\utils\direct_url_helpers.py

#### `direct_url_as_pep440_direct_reference()` (line 9)
_Convert a DirectUrl to a pip requirement string._

**Args**: direct_url, name


#### `direct_url_for_editable()` (line 32)
**Args**: source_dir


#### `direct_url_from_link()` (line 39)
**Args**: link, source_dir, link_is_in_wheel_cache


### venv_new\Lib\site-packages\pip\_internal\utils\egg_link.py

#### `_egg_link_names()` (line 18)
_Convert a Name metadata value to a .egg-link name, by applying
the same substitution as pkg_resources's safe_name function.
Note: we cannot use canonicalize_name because it has a different logic.

We also look for the raw name (without normalization) as setuptools 69 changed
the way it names .egg-link files (https://github.com/pypa/setuptools/issues/4167)._

**Args**: raw_name


#### `egg_link_path_from_sys_path()` (line 33)
_Look for a .egg-link file for project name, by walking sys.path._

**Args**: raw_name


#### `egg_link_path_from_location()` (line 46)
_Return the path for the .egg-link file if it exists, otherwise, None.

There's 3 scenarios:
1) not in a virtualenv
   try to find in site.USER_SITE, then site_packages
2) in a no-global virtualenv
   try to find in site_packages
3) in a yes-global virtualenv
   try to find in site_packages, then site.USER_SITE
   (don't look in global location)

For #1 and #3, there could be odd cases, where there's an egg-link in 2
locations.

This method will just return the first one found._

**Args**: raw_name


### venv_new\Lib\site-packages\pip\_internal\utils\entrypoints.py

#### `_wrapper()` (line 23)
_Central wrapper for all old entrypoints.

Historically pip has had several entrypoints defined. Because of issues
arising from PATH, sys.path, multiple Pythons, their interactions, and most
of them having a pip installed, users suffer every time an entrypoint gets
moved.

To alleviate this pain, and provide a mechanism for warning users and
directing them to an appropriate place for help, we now define all of
our old entrypoints as wrappers for the current one._

**Args**: args


#### `get_best_invocation_for_this_pip()` (line 46)
_Try to figure out the best way to invoke pip in the current environment._


#### `get_best_invocation_for_this_python()` (line 73)
_Try to figure out the best way to invoke the current Python._


### venv_new\Lib\site-packages\pip\_internal\utils\filesystem.py

#### `check_path_owner()` (line 15)
**Args**: path


#### `adjacent_tmp_file()` (line 43)
_Return a file-like object pointing to a tmp file next to path.

The file is created securely and is ensured to be written to disk
after the context reaches its end.

kwargs will be passed to tempfile.NamedTemporaryFile to control
the way the temporary file will be opened._

**Args**: path


#### `test_writable_dir()` (line 72)
_Check if a directory is writable.

Uses os.access() on POSIX, tries creating files on Windows._

**Args**: path


#### `_test_writable_dir_win()` (line 90)
**Args**: path


#### `find_files()` (line 118)
_Returns a list of absolute paths of files beneath path, recursively,
with filenames which match the UNIX-style shell glob pattern._

**Args**: path, pattern


#### `file_size()` (line 128)
**Args**: path


#### `format_file_size()` (line 135)
**Args**: path


#### `directory_size()` (line 139)
**Args**: path


#### `format_directory_size()` (line 148)
**Args**: path


### venv_new\Lib\site-packages\pip\_internal\utils\filetypes.py

#### `is_archive_file()` (line 22)
_Return True if `name` is a considered as an archive file._

**Args**: name


### venv_new\Lib\site-packages\pip\_internal\utils\glibc.py

#### `glibc_version_string()` (line 6)
_Returns glibc version string, or None if not using glibc._


#### `glibc_version_string_confstr()` (line 11)
_Primary implementation of glibc_version_string using os.confstr._


#### `glibc_version_string_ctypes()` (line 31)
_Fallback implementation of glibc_version_string using ctypes._


#### `libc_ver()` (line 91)
_Try to determine the glibc version

Returns a tuple of strings (lib, version) which default to empty strings
in case the lookup fails._


### venv_new\Lib\site-packages\pip\_internal\utils\hashes.py

#### `__init__()` (line 27)
_:param hashes: A dict of algorithm names pointing to lists of allowed
    hex digests_

**Args**: self, hashes


#### `__and__()` (line 39)
**Args**: self, other


#### `digest_count()` (line 59)
**Args**: self


#### `is_hash_allowed()` (line 62)
_Return whether the given hex digest is allowed._

**Args**: self, hash_name, hex_digest


#### `check_against_chunks()` (line 66)
_Check good hashes against ones built from iterable of chunks of
data.

Raise HashMismatch if none match._

**Args**: self, chunks


#### `_raise()` (line 89)
**Args**: self, gots


#### `check_against_file()` (line 92)
_Check good hashes against a file-like object

Raise HashMismatch if none match._

**Args**: self, file


#### `check_against_path()` (line 100)
**Args**: self, path


#### `has_one_of()` (line 104)
_Return whether any of the given hashes are allowed._

**Args**: self, hashes


#### `__bool__()` (line 111)
_Return whether I know any known-good hashes._

**Args**: self


#### `__eq__()` (line 115)
**Args**: self, other


#### `__hash__()` (line 120)
**Args**: self


#### `__init__()` (line 140)
_Don't offer the ``hashes`` kwarg._

**Args**: self


#### `_raise()` (line 146)
**Args**: self, gots


### venv_new\Lib\site-packages\pip\_internal\utils\logging.py

#### `_is_broken_pipe_error()` (line 41)
**Args**: exc_class, exc


#### `indent_log()` (line 55)
_A context manager which will cause the log output to be indented for any
log messages emitted inside it._

**Args**: num


#### `get_indentation()` (line 69)

#### `__init__()` (line 76)
_A logging.Formatter that obeys the indent_log() context manager.

:param add_timestamp: A bool indicating output lines should be prefixed
    with their record's timestamp._

**Args**: self


#### `get_message_start()` (line 91)
_Return the start of the formatted log message (not counting the
prefix to add to each line)._

**Args**: self, formatted, levelno


#### `format()` (line 107)
_Calls the standard formatter, but will indent all of the log message
lines by our current indentation level._

**Args**: self, record


#### `__rich_console__()` (line 129)
**Args**: self, console, options


#### `on_broken_pipe()` (line 141)
**Args**: self


#### `__init__()` (line 150)
**Args**: self, stream, no_color


#### `emit()` (line 160)
**Args**: self, record


#### `handleError()` (line 188)
_Called when logging is unable to log some output._

**Args**: self, record


#### `_open()` (line 208)
**Args**: self


#### `__init__()` (line 214)
**Args**: self, level


#### `filter()` (line 217)
**Args**: self, record


#### `filter()` (line 226)
**Args**: self, record


#### `setup_logging()` (line 232)
_Configures and sets up all of the logging

Returns the requested logging level, as its integer value._

**Args**: verbosity, no_color, user_log_file


### venv_new\Lib\site-packages\pip\_internal\utils\misc.py

#### `get_pip_version()` (line 76)

#### `normalize_version_info()` (line 83)
_Convert a tuple of ints representing a Python version to one of length
three.

:param py_version_info: a tuple of ints representing a Python version,
    or None to specify no version. The tuple can have any length.

:return: a tuple of length three if `py_version_info` is non-None.
    Otherwise, return `py_version_info` unchanged (i.e. None)._

**Args**: py_version_info


#### `ensure_dir()` (line 102)
_os.path.makedirs without EEXIST._

**Args**: path


#### `get_prog()` (line 112)

#### `rmtree()` (line 126)
**Args**: dir, ignore_errors, onexc


#### `_onerror_ignore()` (line 141)

#### `_onerror_reraise()` (line 145)

#### `rmtree_errorhandler()` (line 149)
_`rmtree` error handler to 'force' a file remove (i.e. like `rm -f`).

* If a file is readonly then it's write flag is set and operation is
  retried.

* `onerror` is the original callback from `rmtree(... onerror=onerror)`
  that is chained at the end if the "rm -f" still fails._

**Args**: func, path, exc_info


#### `display_path()` (line 190)
_Gives the display value for a given path, making it relative to cwd
if possible._

**Args**: path


#### `backup_dir()` (line 199)
_Figure out the name of a directory to back up the given dir to
(adding .bak, .bak2, etc)_

**Args**: dir, ext


#### `ask_path_exists()` (line 210)
**Args**: message, options


#### `_check_no_input()` (line 217)
_Raise an error if no input is allowed._

**Args**: message


#### `ask()` (line 225)
_Ask the message interactively, with the given possible responses_

**Args**: message, options


#### `ask_input()` (line 240)
_Ask for input interactively._

**Args**: message


#### `ask_password()` (line 246)
_Ask for a password interactively._

**Args**: message


#### `strtobool()` (line 252)
_Convert a string representation of truth to true (1) or false (0).

True values are 'y', 'yes', 't', 'true', 'on', and '1'; false values
are 'n', 'no', 'f', 'false', 'off', and '0'.  Raises ValueError if
'val' is anything else._

**Args**: val


#### `format_size()` (line 268)
**Args**: bytes


#### `tabulate()` (line 279)
_Return a list of formatted rows and a list of column sizes.

For example::

>>> tabulate([['foobar', 2000], [0xdeadbeef]])
(['foobar     2000', '3735928559'], [10, 4])_

**Args**: rows


#### `is_installable_dir()` (line 293)
_Is path is a directory containing pyproject.toml or setup.py?

If pyproject.toml exists, this is a PEP 517 project. Otherwise we look for
a legacy setuptools layout by identifying setup.py. We don't check for the
setup.cfg because using it without setup.py is only available for PEP 517
projects, which are already covered by the pyproject.toml check._

**Args**: path


#### `read_chunks()` (line 310)
_Yield pieces of data from a file-like object until EOF._

**Args**: file, size


#### `normalize_path()` (line 321)
_Convert a path to its canonical, case-normalized, absolute version._

**Args**: path, resolve_symlinks


#### `splitext()` (line 334)
_Like os.path.splitext, but take off .tar too_

**Args**: path


#### `renames()` (line 343)
_Like os.renames(), but handles renaming across devices._

**Args**: old, new


#### `is_local()` (line 360)
_Return True if path is within sys.prefix, if we're running in a virtualenv.

If we're not in a virtualenv, all paths are considered "local."

Caution: this function assumes the head of path has been normalized
with normalize_path._

**Args**: path


#### `write_output()` (line 374)
**Args**: msg


#### `from_stream()` (line 382)
**Args**: cls, orig_stream


#### `encoding()` (line 390)
**Args**: self


#### `enum()` (line 395)

#### `build_netloc()` (line 402)
_Build a netloc from a host-port pair_

**Args**: host, port


#### `build_url_from_netloc()` (line 414)
_Build a full URL from a netloc._

**Args**: netloc, scheme


#### `parse_netloc()` (line 424)
_Return the host-port pair from a netloc._

**Args**: netloc


#### `split_auth_from_netloc()` (line 433)
_Parse out and remove the auth information from a netloc.

Returns: (netloc, (username, password))._

**Args**: netloc


#### `redact_netloc()` (line 462)
_Replace the sensitive data in a netloc with "****", if it exists.

For example:
    - "user:pass@example.com" returns "user:****@example.com"
    - "accesstoken@example.com" returns "****@example.com"_

**Args**: netloc


#### `_transform_url()` (line 482)
_Transform and replace netloc in a url.

transform_netloc is a function taking the netloc and returning a
tuple. The first element of this tuple is the new netloc. The
entire tuple is returned.

Returns a tuple containing the transformed url as item 0 and the
original tuple returned by transform_netloc as item 1._

**Args**: url, transform_netloc


#### `_get_netloc()` (line 502)
**Args**: netloc


#### `_redact_netloc()` (line 506)
**Args**: netloc


#### `split_auth_netloc_from_url()` (line 510)
_Parse a url into separate netloc, auth, and url with no auth.

Returns: (url_without_auth, netloc, (username, password))_

**Args**: url


#### `remove_auth_from_url()` (line 522)
_Return a copy of url with 'username:password@' removed._

**Args**: url


#### `redact_auth_from_url()` (line 529)
_Replace the password in a given url with ****._

**Args**: url


#### `redact_auth_from_requirement()` (line 534)
_Replace the password in a given requirement url with ****._

**Args**: req


#### `__repr__()` (line 546)
**Args**: self


#### `__str__()` (line 549)
**Args**: self


#### `__eq__()` (line 553)
**Args**: self, other


#### `hide_value()` (line 562)
**Args**: value


#### `hide_url()` (line 566)
**Args**: url


#### `protect_pip_from_modification_on_windows()` (line 571)
_Protection of pip.exe from modification on Windows

On Windows, any operation modifying pip should be run as:
    python -m pip ..._

**Args**: modifying_pip


#### `check_externally_managed()` (line 597)
_Check whether the current environment is externally managed.

If the ``EXTERNALLY-MANAGED`` config file is found, the current environment
is considered externally managed, and an ExternallyManagedEnvironment is
raised._


#### `is_console_interactive()` (line 612)
_Is this console interactive?_


#### `hash_file()` (line 617)
_Return (hash, length) for path using hashlib.sha256()_

**Args**: path, blocksize


#### `pairwise()` (line 629)
_Return paired elements.

For example:
    s -> (s0, s1), (s2, s3), (s4, s5), ..._

**Args**: iterable


#### `partition()` (line 640)
_Use a predicate to partition entries into false entries and true entries,
like

    partition(is_odd, range(10)) --> 0 2 4 6 8   and  1 3 5 7 9_

**Args**: pred, iterable


#### `__init__()` (line 654)
**Args**: self, config_holder, source_dir, build_backend, backend_path, runner, python_executable


#### `build_wheel()` (line 668)
**Args**: self, wheel_directory, config_settings, metadata_directory


#### `build_sdist()` (line 679)
**Args**: self, sdist_directory, config_settings


#### `build_editable()` (line 687)
**Args**: self, wheel_directory, config_settings, metadata_directory


#### `get_requires_for_build_wheel()` (line 698)
**Args**: self, config_settings


#### `get_requires_for_build_sdist()` (line 704)
**Args**: self, config_settings


#### `get_requires_for_build_editable()` (line 710)
**Args**: self, config_settings


#### `prepare_metadata_for_build_wheel()` (line 716)
**Args**: self, metadata_directory, config_settings, _allow_fallback


#### `prepare_metadata_for_build_editable()` (line 729)
**Args**: self, metadata_directory, config_settings, _allow_fallback


#### `warn_if_run_as_root()` (line 743)
_Output a warning for sudo users on Unix.

In a virtual environment, sudo pip still writes to virtualenv.
On Windows, users may run pip as Administrator without issues.
This warning only applies to Unix root users outside of virtualenv._


### venv_new\Lib\site-packages\pip\_internal\utils\packaging.py

#### `check_requires_python()` (line 15)
_Check if the given Python version matches a "Requires-Python" specifier.

:param version_info: A 3-tuple of ints representing a Python
    major-minor-micro version to check (e.g. `sys.version_info[:3]`).

:return: `True` if the given Python version satisfies the requirement.
    Otherwise, return `False`.

:raises InvalidSpecifier: If `requires_python` has an invalid format._

**Args**: requires_python, version_info


#### `get_requirement()` (line 39)
_Construct a packaging.Requirement object with caching_

**Args**: req_string


#### `safe_extra()` (line 49)
_Convert an arbitrary string to a standard 'extra' name

Any runs of non-alphanumeric characters are replaced with a single '_',
and the result is always lowercased.

This function is duplicated from ``pkg_resources``. Note that this is not
the same to either ``canonicalize_name`` or ``_egg_link_name``._

**Args**: extra


### venv_new\Lib\site-packages\pip\_internal\utils\retry.py

#### `retry()` (line 11)
_Decorator to automatically retry a function on error.

If the function raises, the function is recalled with the same arguments
until it returns or the time limit is reached. When the time limit is
surpassed, the last exception raised is reraised.

:param wait: The time to wait after an error before retrying, in seconds.
:param stop_after_delay: The time limit after which retries will cease,
    in seconds._

**Args**: wait, stop_after_delay


#### `wrapper()` (line 25)
**Args**: func


#### `retry_wrapped()` (line 28)

### venv_new\Lib\site-packages\pip\_internal\utils\setuptools_build.py

#### `make_setuptools_shim_args()` (line 49)
_Get setuptools command arguments with shim wrapped setup file invocation.

:param setup_py_path: The path to setup.py to be wrapped.
:param global_options: Additional global options.
:param no_user_config: If True, disables personal user configuration.
:param unbuffered_output: If True, adds the unbuffered switch to the
 argument list._

**Args**: setup_py_path, global_options, no_user_config, unbuffered_output


#### `make_setuptools_bdist_wheel_args()` (line 75)
**Args**: setup_py_path, global_options, build_options, destination_dir


#### `make_setuptools_clean_args()` (line 93)
**Args**: setup_py_path, global_options


#### `make_setuptools_develop_args()` (line 104)
**Args**: setup_py_path


#### `make_setuptools_egg_info_args()` (line 134)
**Args**: setup_py_path, egg_info_dir, no_user_config


### venv_new\Lib\site-packages\pip\_internal\utils\subprocess.py

#### `make_command()` (line 17)
_Create a CommandArgs object._


#### `format_command_args()` (line 34)
_Format command arguments for display._

**Args**: args


#### `reveal_command_args()` (line 49)
_Return the arguments in their raw, unredacted form._

**Args**: args


#### `call_subprocess()` (line 56)
_Args:
  show_stdout: if true, use INFO to log the subprocess's stderr and
    stdout streams.  Otherwise, use DEBUG.  Defaults to False.
  extra_ok_returncodes: an iterable of integer return codes that are
    acceptable, in addition to 0. Defaults to None, which means [].
  unset_environ: an iterable of environment variable names to unset
    prior to calling subprocess.Popen().
  log_failed_cmd: if false, failed commands are not logged, only raised.
  stdout_only: if true, return only stdout, else return both. When true,
    logging of both stdout and stderr occurs when the subprocess has
    terminated, else logging occurs as subprocess output is produced._

**Args**: cmd, show_stdout, cwd, on_returncode, extra_ok_returncodes, extra_environ, unset_environ, spinner, log_failed_cmd, stdout_only


#### `runner_with_spinner_message()` (line 224)
_Provide a subprocess_runner that shows a spinner message.

Intended for use with for BuildBackendHookCaller. Thus, the runner has
an API that matches what's expected by BuildBackendHookCaller.subprocess_runner._

**Args**: message


#### `runner()` (line 231)
**Args**: cmd, cwd, extra_environ


### venv_new\Lib\site-packages\pip\_internal\utils\temp_dir.py

#### `global_tempdir_manager()` (line 40)

#### `__init__()` (line 53)
**Args**: self


#### `set_delete()` (line 56)
_Indicate whether a TempDirectory of the given kind should be
auto-deleted._

**Args**: self, kind, value


#### `get_delete()` (line 62)
_Get configured auto-delete flag for a given TempDirectory type,
default True._

**Args**: self, kind


#### `tempdir_registry()` (line 73)
_Provides a scoped global tempdir registry that can be used to dictate
whether directories should be deleted._


#### `__init__()` (line 114)
**Args**: self, path, delete, kind, globally_managed, ignore_cleanup_errors


#### `path()` (line 150)
**Args**: self


#### `__repr__()` (line 154)
**Args**: self


#### `__enter__()` (line 157)
**Args**: self


#### `__exit__()` (line 160)
**Args**: self, exc, value, tb


#### `_create()` (line 171)
_Create a temporary directory and store its path in self.path_

**Args**: self, kind


#### `cleanup()` (line 181)
_Remove the temporary directory created and reset state_

**Args**: self


#### `onerror()` (line 189)
_Log a warning for a `rmtree` error and continue_

**Args**: func, path, exc_val


#### `__init__()` (line 248)
**Args**: self, original, delete


#### `_generate_names()` (line 253)
_Generates a series of temporary names.

The algorithm replaces the leading characters in the name
with ones that are valid filesystem characters, but are not
valid package names (for both Python and pip definitions of
package)._

**Args**: cls, name


#### `_create()` (line 278)
**Args**: self, kind


### venv_new\Lib\site-packages\pip\_internal\utils\unpacking.py

#### `current_umask()` (line 44)
_Get the current umask which involves having to set it temporarily._


#### `split_leading_dir()` (line 51)
**Args**: path


#### `has_leading_dir()` (line 63)
_Returns true if all the paths have the same leading path name
(i.e., everything is in one subdirectory in an archive)_

**Args**: paths


#### `is_within_directory()` (line 78)
_Return true if the absolute path of target is within the directory_

**Args**: directory, target


#### `_get_default_mode_plus_executable()` (line 89)

#### `set_extracted_file_to_default_mode_plus_executable()` (line 93)
_Make file present at path have execute for user/group/world
(chmod +x) is no-op on windows per python docs_

**Args**: path


#### `zip_item_is_executable()` (line 101)
**Args**: info


#### `unzip_file()` (line 108)
_Unzip the file (with path `filename`) to the destination `location`.  All
files are written based on system defaults and umask (i.e. permissions are
not preserved), except that regular file members with any execute
permissions (user, group, or world) have "chmod +x" applied after being
written. Note that for windows, any execute changes using os.chmod are
no-ops per the python docs._

**Args**: filename, location, flatten


#### `untar_file()` (line 154)
_Untar the file (with path `filename`) to the destination `location`.
All files are written based on system defaults and umask (i.e. permissions
are not preserved), except that regular file members with any execute
permissions (user, group, or world) have "chmod +x" applied on top of the
default.  Note that for windows, any execute changes using os.chmod are
no-ops per the python docs._

**Args**: filename, location


#### `pip_filter()` (line 205)
**Args**: member, path


#### `_untar_without_filter()` (line 251)
_Fallback for Python without tarfile.data_filter_

**Args**: filename, location, tar, leading


#### `unpack_file()` (line 309)
**Args**: filename, location, content_type


### venv_new\Lib\site-packages\pip\_internal\utils\urls.py

#### `path_to_url()` (line 9)
_Convert a path to a file: URL.  The path will be made absolute and have
quoted path parts._

**Args**: path


#### `url_to_path()` (line 19)
_Convert a file: URL to a path._

**Args**: url


### venv_new\Lib\site-packages\pip\_internal\utils\virtualenv.py

#### `_running_under_venv()` (line 14)
_Checks if sys.base_prefix and sys.prefix match.

This handles PEP 405 compliant virtual environments._


#### `_running_under_legacy_virtualenv()` (line 22)
_Checks if sys.real_prefix is set.

This handles virtual environments created with pypa's virtualenv._


#### `running_under_virtualenv()` (line 31)
_True if we're running inside a virtual environment, False otherwise._


#### `_get_pyvenv_cfg_lines()` (line 36)
_Reads {sys.prefix}/pyvenv.cfg and returns its contents as list of lines

Returns None, if it could not read/access the file._


#### `_no_global_under_venv()` (line 51)
_Check `{sys.prefix}/pyvenv.cfg` for system site-packages inclusion

PEP 405 specifies that when system site-packages are not supposed to be
visible from a virtual environment, `pyvenv.cfg` must contain the following
line:

    include-system-site-packages = false

Additionally, log a warning if accessing the file fails._


#### `_no_global_under_legacy_virtualenv()` (line 80)
_Check if "no-global-site-packages.txt" exists beside site.py

This mirrors logic in pypa/virtualenv for determining whether system
site-packages are visible in the virtual environment._


#### `virtualenv_no_global()` (line 94)
_Returns a boolean, whether running in venv with no system site-packages._


### venv_new\Lib\site-packages\pip\_internal\utils\wheel.py

#### `parse_wheel()` (line 20)
_Extract information from the provided wheel, ensuring it meets basic
standards.

Returns the name of the .dist-info directory and the parsed WHEEL metadata._

**Args**: wheel_zip, name


#### `wheel_dist_info_dir()` (line 38)
_Returns the name of the contained .dist-info directory.

Raises AssertionError or UnsupportedWheel if not found, >1 found, or
it doesn't match the provided name._

**Args**: source, name


#### `read_wheel_metadata_file()` (line 69)
**Args**: source, path


#### `wheel_metadata()` (line 78)
_Return the WHEEL metadata of an extracted wheel, if possible.
Otherwise, raise UnsupportedWheel._

**Args**: source, dist_info_dir


#### `wheel_version()` (line 97)
_Given WHEEL metadata, return the parsed Wheel-Version.
Otherwise, raise UnsupportedWheel._

**Args**: wheel_data


#### `check_compatibility()` (line 113)
_Raises errors or warns if called with an incompatible Wheel-Version.

pip should refuse to install a Wheel-Version that's a major series
ahead of what it's compatible with (e.g 2.0 > 1.1); and warn when
installing a version only minor version ahead (e.g 1.2 > 1.1).

version: a 2-tuple representing a Wheel-Version (Major, Minor)
name: name of wheel or package to raise exception about

:raises UnsupportedWheel: when an incompatible Wheel-Version is given_

**Args**: version, name


### venv_new\Lib\site-packages\pip\_internal\vcs\bazaar.py

#### `get_base_rev_args()` (line 33)
**Args**: rev


#### `fetch_new()` (line 36)
**Args**: self, dest, url, rev_options, verbosity


#### `switch()` (line 57)
**Args**: self, dest, url, rev_options


#### `update()` (line 60)
**Args**: self, dest, url, rev_options


#### `get_url_rev_and_auth()` (line 74)
**Args**: cls, url


#### `get_remote_url()` (line 82)
**Args**: cls, location


#### `get_revision()` (line 97)
**Args**: cls, location


#### `is_commit_id_equal()` (line 107)
_Always assume the versions don't match_

**Args**: cls, dest, name


### venv_new\Lib\site-packages\pip\_internal\vcs\git.py

#### `looks_like_hash()` (line 56)
**Args**: sha


#### `get_base_rev_args()` (line 77)
**Args**: rev


#### `is_immutable_rev_checkout()` (line 80)
**Args**: self, url, dest


#### `get_git_version()` (line 94)
**Args**: self


#### `get_current_branch()` (line 108)
_Return the current branch, or None if HEAD isn't at a branch
(e.g. detached HEAD)._

**Args**: cls, location


#### `get_revision_sha()` (line 133)
_Return (sha_or_none, is_branch), where sha_or_none is a commit hash
if the revision names a remote branch or tag, otherwise None.

Args:
  dest: the repository directory.
  rev: the revision name._

**Args**: cls, dest, rev


#### `_should_fetch()` (line 179)
_Return true if rev is a ref or is a commit that we don't have locally.

Branches and tags are not considered in this method because they are
assumed to be always available locally (which is a normal outcome of
``git clone`` and ``git fetch --tags``)._

**Args**: cls, dest, rev


#### `resolve_revision()` (line 202)
_Resolve a revision to a new RevOptions object with the SHA1 of the
branch, tag, or ref if found.

Args:
  rev_options: a RevOptions object._

**Args**: cls, dest, url, rev_options


#### `is_commit_id_equal()` (line 248)
_Return whether the current commit hash equals the given name.

Args:
  dest: the repository directory.
  name: a string name._

**Args**: cls, dest, name


#### `fetch_new()` (line 262)
**Args**: self, dest, url, rev_options, verbosity


#### `switch()` (line 325)
**Args**: self, dest, url, rev_options


#### `update()` (line 335)
**Args**: self, dest, url, rev_options


#### `get_remote_url()` (line 350)
_Return URL of the first remote encountered.

Raises RemoteNotFoundError if the repository does not have a remote
url configured._

**Args**: cls, location


#### `_git_remote_to_pip_url()` (line 380)
_Convert a remote url from what git uses to what pip accepts.

There are 3 legal forms **url** may take:

    1. A fully qualified url: ssh://git@example.com/foo/bar.git
    2. A local project.git folder: /path/to/bare/repository.git
    3. SCP shorthand for form 1: git@example.com:foo/bar.git

Form 1 is output as-is. Form 2 must be converted to URI and form 3 must
be converted to form 1.

See the corresponding test test_git_remote_url_to_pip() for examples of
sample inputs/outputs._

**Args**: url


#### `has_commit()` (line 411)
_Check if rev is a commit that is available in the local repository._

**Args**: cls, location, rev


#### `get_revision()` (line 427)
**Args**: cls, location, rev


#### `get_subdirectory()` (line 439)
_Return the path to Python project root, relative to the repo root.
Return None if the project root is in the repo root._

**Args**: cls, location


#### `get_url_rev_and_auth()` (line 457)
_Prefixes stub URLs like 'user@hostname:user/repo.git' with 'ssh://'.
That's required because although they use SSH they sometimes don't
work with a ssh:// scheme (e.g. GitHub). But we need a scheme for
parsing. Hence we remove it again afterwards and return it as a stub._

**Args**: cls, url


#### `update_submodules()` (line 488)
**Args**: cls, location


#### `get_repository_root()` (line 497)
**Args**: cls, location


#### `should_add_vcs_url_prefix()` (line 522)
_In either https or ssh form, requirements must be prefixed with git+._

**Args**: repo_url


### venv_new\Lib\site-packages\pip\_internal\vcs\mercurial.py

#### `get_base_rev_args()` (line 33)
**Args**: rev


#### `fetch_new()` (line 36)
**Args**: self, dest, url, rev_options, verbosity


#### `switch()` (line 60)
**Args**: self, dest, url, rev_options


#### `update()` (line 74)
**Args**: self, dest, url, rev_options


#### `get_remote_url()` (line 80)
**Args**: cls, location


#### `get_revision()` (line 92)
_Return the repository-local changeset revision number, as an integer._

**Args**: cls, location


#### `get_requirement_revision()` (line 105)
_Return the changeset identification hash, as a 40-character
hexadecimal string_

**Args**: cls, location


#### `is_commit_id_equal()` (line 119)
_Always assume the versions don't match_

**Args**: cls, dest, name


#### `get_subdirectory()` (line 124)
_Return the path to Python project root, relative to the repo root.
Return None if the project root is in the repo root._

**Args**: cls, location


#### `get_repository_root()` (line 138)
**Args**: cls, location


### venv_new\Lib\site-packages\pip\_internal\vcs\subversion.py

#### `should_add_vcs_url_prefix()` (line 37)
**Args**: cls, remote_url


#### `get_base_rev_args()` (line 41)
**Args**: rev


#### `get_revision()` (line 45)
_Return the maximum revision for all files under a given location_

**Args**: cls, location


#### `get_netloc_and_auth()` (line 74)
_This override allows the auth information to be passed to svn via the
--username and --password options instead of via the URL._

**Args**: cls, netloc, scheme


#### `get_url_rev_and_auth()` (line 89)
**Args**: cls, url


#### `make_rev_args()` (line 97)
**Args**: username, password


#### `get_remote_url()` (line 109)
**Args**: cls, location


#### `_get_svn_url_rev()` (line 133)
**Args**: cls, location


#### `is_commit_id_equal()` (line 183)
_Always assume the versions don't match_

**Args**: cls, dest, name


#### `__init__()` (line 187)
**Args**: self, use_interactive


#### `call_vcs_version()` (line 201)
_Query the version of the currently installed Subversion client.

:return: A tuple containing the parts of the version information or
    ``()`` if the version returned from ``svn`` could not be parsed.
:raises: BadCommand: If ``svn`` is not installed._

**Args**: self


#### `get_vcs_version()` (line 229)
_Return the version of the currently installed Subversion client.

If the version of the Subversion client has already been queried,
a cached value will be used.

:return: A tuple containing the parts of the version information or
    ``()`` if the version returned from ``svn`` could not be parsed.
:raises: BadCommand: If ``svn`` is not installed._

**Args**: self


#### `get_remote_call_options()` (line 249)
_Return options to be used on calls to Subversion that contact the server.

These options are applicable for the following ``svn`` subcommands used
in this class.

    - checkout
    - switch
    - update

:return: A list of command line arguments to pass to ``svn``._

**Args**: self


#### `fetch_new()` (line 280)
**Args**: self, dest, url, rev_options, verbosity


#### `switch()` (line 304)
**Args**: self, dest, url, rev_options


#### `update()` (line 314)
**Args**: self, dest, url, rev_options


### venv_new\Lib\site-packages\pip\_internal\vcs\versioncontrol.py

#### `is_url()` (line 50)
_Return true if the name looks like a URL._

**Args**: name


#### `make_vcs_requirement_url()` (line 60)
_Return the URL for a VCS requirement.

Args:
  repo_url: the remote VCS url, with any needed VCS prefix (e.g. "git+").
  project_name: the (unescaped) project name._

**Args**: repo_url, rev, project_name, subdir


#### `find_path_to_project_root_from_repo_root()` (line 78)
_Find the the Python project's root by searching up the filesystem from
`location`. Return the path to project root relative to `repo_root`.
Return None if the project root is `repo_root`, or cannot be found._

**Args**: location, repo_root


#### `__init__()` (line 112)
**Args**: self, url


#### `__repr__()` (line 134)
**Args**: self


#### `arg_rev()` (line 138)
**Args**: self


#### `to_args()` (line 144)
_Return the VCS-specific command arguments._

**Args**: self


#### `to_display()` (line 156)
**Args**: self


#### `make_new()` (line 162)
_Make a copy of the current instance, but with a new rev.

Args:
  rev: the name of the revision for the new object._

**Args**: self, rev


#### `__init__()` (line 176)
**Args**: self


#### `__iter__()` (line 182)
**Args**: self


#### `backends()` (line 186)
**Args**: self


#### `dirnames()` (line 190)
**Args**: self


#### `all_schemes()` (line 194)
**Args**: self


#### `register()` (line 200)
**Args**: self, cls


#### `unregister()` (line 208)
**Args**: self, name


#### `get_backend_for_dir()` (line 212)
_Return a VersionControl object if a repository of that type is found
at the given directory._

**Args**: self, location


#### `get_backend_for_scheme()` (line 235)
_Return a VersionControl object or None._

**Args**: self, scheme


#### `get_backend()` (line 244)
_Return a VersionControl object or None._

**Args**: self, name


#### `should_add_vcs_url_prefix()` (line 266)
_Return whether the vcs prefix (e.g. "git+") should be added to a
repository's remote url when used in a requirement._

**Args**: cls, remote_url


#### `get_subdirectory()` (line 274)
_Return the path to Python project root, relative to the repo root.
Return None if the project root is in the repo root._

**Args**: cls, location


#### `get_requirement_revision()` (line 282)
_Return the revision string that should be used in a requirement._

**Args**: cls, repo_dir


#### `get_src_requirement()` (line 289)
_Return the requirement string to use to redownload the files
currently at the given repository directory.

Args:
  project_name: the (unescaped) project name.

The return value has a form similar to the following:

    {repository_url}@{revision}#egg={project_name}_

**Args**: cls, repo_dir, project_name


#### `get_base_rev_args()` (line 313)
_Return the base revision arguments for a vcs command.

Args:
  rev: the name of a revision to install.  Cannot be None._

**Args**: rev


#### `is_immutable_rev_checkout()` (line 322)
_Return true if the commit hash checked out at dest matches
the revision in url.

Always return False, if the VCS does not support immutable commit
hashes.

This method does not check if there are local uncommitted changes
in dest after checkout, as pip currently has no use case for that._

**Args**: self, url, dest


#### `make_rev_options()` (line 336)
_Return a RevOptions object.

Args:
  rev: the name of a revision to install.
  extra_args: a list of extra options._

**Args**: cls, rev, extra_args


#### `_is_local_repository()` (line 349)
_posix absolute paths start with os.path.sep,
win32 ones start with drive (like c:\folder)_

**Args**: cls, repo


#### `get_netloc_and_auth()` (line 358)
_Parse the repository URL's netloc, and return the new netloc to use
along with auth information.

Args:
  netloc: the original repository URL netloc.
  scheme: the repository URL's scheme without the vcs prefix.

This is mainly for the Subversion class to override, so that auth
information can be provided via the --username and --password options
instead of through the URL.  For other subclasses like Git without
such an option, auth information must stay in the URL.

Returns: (netloc, (username, password))._

**Args**: cls, netloc, scheme


#### `get_url_rev_and_auth()` (line 379)
_Parse the repository URL to use, and return the URL, revision,
and auth info to use.

Returns: (url, rev, (username, password))._

**Args**: cls, url


#### `make_rev_args()` (line 409)
_Return the RevOptions "extra arguments" to use in obtain()._

**Args**: username, password


#### `get_url_rev_options()` (line 417)
_Return the URL and RevOptions object to use in obtain(),
as a tuple (url, rev_options)._

**Args**: self, url


#### `normalize_url()` (line 433)
_Normalize a URL for comparison by unquoting it and removing any
trailing slash._

**Args**: url


#### `compare_urls()` (line 441)
_Compare two repo URLs for identity, ignoring incidental differences._

**Args**: cls, url1, url2


#### `fetch_new()` (line 447)
_Fetch a revision from a repository, in the case that this is the
first fetch from the repository.

Args:
  dest: the directory to fetch the repository to.
  rev_options: a RevOptions object.
  verbosity: verbosity level._

**Args**: self, dest, url, rev_options, verbosity


#### `switch()` (line 461)
_Switch the repo at ``dest`` to point to ``URL``.

Args:
  rev_options: a RevOptions object._

**Args**: self, dest, url, rev_options


#### `update()` (line 470)
_Update an already-existing repo to the given ``rev_options``.

Args:
  rev_options: a RevOptions object._

**Args**: self, dest, url, rev_options


#### `is_commit_id_equal()` (line 480)
_Return whether the id of the current commit equals the given name.

Args:
  dest: the repository directory.
  name: a string name._

**Args**: cls, dest, name


#### `obtain()` (line 490)
_Install or update in editable mode the package represented by this
VersionControl object.

:param dest: the repository directory in which to install or update.
:param url: the repository URL starting with a vcs prefix.
:param verbosity: verbosity level._

**Args**: self, dest, url, verbosity


#### `unpack()` (line 579)
_Clean up current location and download the url repository
(and vcs infos) into location

:param url: the repository URL starting with a vcs prefix.
:param verbosity: verbosity level._

**Args**: self, location, url, verbosity


#### `get_remote_url()` (line 592)
_Return the url used at location

Raises RemoteNotFoundError if the repository does not have a remote
url configured._

**Args**: cls, location


#### `get_revision()` (line 602)
_Return the current commit id of the files at the given location._

**Args**: cls, location


#### `run_command()` (line 609)
_Run a VCS subcommand
This is simply a wrapper around call_subprocess that adds the VCS
command name, and checks that the VCS is available_

**Args**: cls, cmd, show_stdout, cwd, on_returncode, extra_ok_returncodes, command_desc, extra_environ, spinner, log_failed_cmd, stdout_only


#### `is_repository_directory()` (line 667)
_Return whether a directory path is a repository directory._

**Args**: cls, path


#### `get_repository_root()` (line 675)
_Return the "root" (top-level) directory controlled by the vcs,
or `None` if the directory is not in any.

It is meant to be overridden to implement smarter detection
mechanisms for specific vcs.

This can do more than is_repository_directory() alone. For
example, the Git override checks that Git is actually available._

**Args**: cls, location


### venv_new\Lib\site-packages\pip\_internal\wheel_builder.py

#### `_contains_egg_info()` (line 37)
_Determine whether the string looks like an egg_info.

:param s: The string to parse. E.g. foo-2.1_

**Args**: s


#### `_should_build()` (line 45)
_Return whether an InstallRequirement should be built into a wheel._

**Args**: req, need_wheel


#### `should_build_for_wheel_command()` (line 78)
**Args**: req


#### `should_build_for_install_command()` (line 84)
**Args**: req


#### `_should_cache()` (line 90)
_Return whether a built InstallRequirement can be stored in the persistent
wheel cache, assuming the wheel cache is available, and _should_build()
has determined a wheel needs to be built._

**Args**: req


#### `_get_cache_dir()` (line 122)
_Return the persistent or temporary cache directory where the built
wheel need to be stored._

**Args**: req, wheel_cache


#### `_verify_one()` (line 138)
**Args**: req, wheel_path


#### `_build_one()` (line 167)
_Build one wheel.

:return: The filename of the built wheel, or None if the build failed._

**Args**: req, output_dir, verify, build_options, global_options, editable


#### `_build_one_inside_env()` (line 205)
**Args**: req, output_dir, build_options, global_options, editable


#### `_clean_one_legacy()` (line 276)
**Args**: req, global_options


#### `build()` (line 293)
_Build wheels.

:return: The list of InstallRequirement that succeeded to build and
    the list of InstallRequirement that failed to build._

**Args**: requirements, wheel_cache, verify, build_options, global_options


### venv_new\Lib\site-packages\pip\_vendor\__init__.py

#### `vendored()` (line 29)
**Args**: modulename


### venv_new\Lib\site-packages\pip\_vendor\cachecontrol\_cmd.py

#### `setup_logging()` (line 22)

#### `get_session()` (line 28)

#### `get_args()` (line 40)

#### `main()` (line 46)

### venv_new\Lib\site-packages\pip\_vendor\cachecontrol\adapter.py

#### `__init__()` (line 29)
**Args**: self, cache, cache_etags, controller_class, serializer, heuristic, cacheable_methods


#### `send()` (line 50)
_Send a request. Use the request information to see if it
exists in the cache and cache the response if we need to and can._

**Args**: self, request, stream, timeout, verify, cert, proxies, cacheable_methods


#### `build_response()` (line 80)
_Build a response by making a request or using the cache.

This will end up calling send and returning a potentially
cached response_

**Args**: self, request, response, from_cache, cacheable_methods


#### `_update_chunk_length()` (line 137)
**Args**: self


#### `close()` (line 159)
**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\cachecontrol\cache.py

#### `get()` (line 20)
**Args**: self, key


#### `set()` (line 23)
**Args**: self, key, value, expires


#### `delete()` (line 28)
**Args**: self, key


#### `close()` (line 31)
**Args**: self


#### `__init__()` (line 36)
**Args**: self, init_dict


#### `get()` (line 40)
**Args**: self, key


#### `set()` (line 43)
**Args**: self, key, value, expires


#### `delete()` (line 49)
**Args**: self, key


#### `set_body()` (line 68)
**Args**: self, key, body


#### `get_body()` (line 71)
_Return the body as file-like object._

**Args**: self, key


### venv_new\Lib\site-packages\pip\_vendor\cachecontrol\caches\file_cache.py

#### `_secure_open_write()` (line 21)
**Args**: filename, fmode


#### `__init__()` (line 65)
**Args**: self, directory, forever, filemode, dirmode, lock_class


#### `encode()` (line 95)
**Args**: x


#### `_fn()` (line 98)
**Args**: self, name


#### `get()` (line 105)
**Args**: self, key


#### `set()` (line 114)
**Args**: self, key, value, expires


#### `_write()` (line 120)
_Safely write the data to the given path._

**Args**: self, path, data


#### `_delete()` (line 135)
**Args**: self, key, suffix


#### `delete()` (line 150)
**Args**: self, key


#### `get_body()` (line 160)
**Args**: self, key


#### `set_body()` (line 167)
**Args**: self, key, body


#### `delete()` (line 171)
**Args**: self, key


#### `url_to_file_path()` (line 176)
_Return the file cache path based on the URL.

This does not ensure the file exists!_

**Args**: url, filecache


### venv_new\Lib\site-packages\pip\_vendor\cachecontrol\caches\redis_cache.py

#### `__init__()` (line 17)
**Args**: self, conn


#### `get()` (line 20)
**Args**: self, key


#### `set()` (line 23)
**Args**: self, key, value, expires


#### `delete()` (line 37)
**Args**: self, key


#### `clear()` (line 40)
_Helper for clearing all the keys in a database. Use with
caution!_

**Args**: self


#### `close()` (line 46)
_Redis uses connection pooling, no need to close the connection._

**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\cachecontrol\controller.py

#### `parse_uri()` (line 38)
_Parses a URI using the regex given in Appendix B of RFC 3986.

(scheme, authority, path, query, fragment) = parse_uri(uri)_

**Args**: uri


#### `__init__()` (line 52)
**Args**: self, cache, cache_etags, serializer, status_codes


#### `_urlnorm()` (line 65)
_Normalize the URL to create a safe key for the cache_

**Args**: cls, uri


#### `cache_url()` (line 85)
**Args**: cls, uri


#### `parse_cache_control()` (line 88)
**Args**: self, headers


#### `_load_from_cache()` (line 142)
_Load a cached response, or return None if it's not available._

**Args**: self, request


#### `cached_request()` (line 168)
_Return a cached response if it exists in the cache, otherwise
return False._

**Args**: self, request


#### `conditional_headers()` (line 278)
**Args**: self, request


#### `_cache_set()` (line 293)
_Store the data in the cache._

**Args**: self, cache_url, request, response, body, expires_time


#### `cache_response()` (line 323)
_Algorithm for caching requests.

This assumes a requests Response object._

**Args**: self, request, response, body, status_codes


#### `update_cached_response()` (line 460)
_On a 304 we will get a new set of headers that we want to
update our cached value with, assuming we have one.

This should only ever be called when we've sent an ETag and
gotten a 304 as the response._

**Args**: self, request, response


### venv_new\Lib\site-packages\pip\_vendor\cachecontrol\filewrapper.py

#### `__init__()` (line 33)
**Args**: self, fp, callback


#### `__getattr__()` (line 40)
**Args**: self, name


#### `__is_fp_closed()` (line 52)
**Args**: self


#### `_close()` (line 70)
**Args**: self


#### `read()` (line 97)
**Args**: self, amt


#### `_safe_read()` (line 108)
**Args**: self, amt


### venv_new\Lib\site-packages\pip\_vendor\cachecontrol\heuristics.py

#### `expire_after()` (line 18)
**Args**: delta, date


#### `datetime_to_header()` (line 23)
**Args**: dt


#### `warning()` (line 28)
_Return a valid 1xx warning header value describing the cache
adjustments.

The response is provided too allow warnings like 113
http://tools.ietf.org/html/rfc7234#section-5.5.4 where we need
to explicitly say response is over 24 hours old._

**Args**: self, response


#### `update_headers()` (line 39)
_Update the response headers with any new headers.

NOTE: This SHOULD always include some Warning header to
      signify that the response was cached by the client, not
      by way of the provided headers._

**Args**: self, response


#### `apply()` (line 48)
**Args**: self, response


#### `update_headers()` (line 66)
**Args**: self, response


#### `__init__()` (line 85)
**Args**: self


#### `update_headers()` (line 88)
**Args**: self, response


#### `warning()` (line 92)
**Args**: self, response


#### `update_headers()` (line 124)
**Args**: self, resp


#### `warning()` (line 156)
**Args**: self, resp


### venv_new\Lib\site-packages\pip\_vendor\cachecontrol\serialize.py

#### `dumps()` (line 20)
**Args**: self, request, response, body


#### `serialize()` (line 62)
**Args**: self, data


#### `loads()` (line 65)
**Args**: self, request, data, body_file


#### `prepare_response()` (line 83)
_Verify our vary headers match and construct a real urllib3
HTTPResponse object._

**Args**: self, request, cached, body_file


#### `_loads_v4()` (line 135)
**Args**: self, request, data, body_file


### venv_new\Lib\site-packages\pip\_vendor\cachecontrol\wrapper.py

#### `CacheControl()` (line 20)
**Args**: sess, cache, cache_etags, serializer, heuristic, controller_class, adapter_class, cacheable_methods


### venv_new\Lib\site-packages\pip\_vendor\certifi\core.py

#### `exit_cacert_ctx()` (line 10)

#### `where()` (line 21)

#### `contents()` (line 46)

#### `where()` (line 56)

#### `contents()` (line 82)

#### `read_text()` (line 97)
**Args**: package, resource, encoding, errors


#### `where()` (line 108)

#### `contents()` (line 113)

### venv_new\Lib\site-packages\pip\_vendor\distlib\__init__.py

#### `handle()` (line 22)
**Args**: self, record


#### `emit()` (line 25)
**Args**: self, record


#### `createLock()` (line 28)
**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\distlib\compat.py

#### `quote()` (line 30)
**Args**: s


#### `_dnsname_match()` (line 96)
_Matching according to RFC 6125, section 6.4.3

http://tools.ietf.org/html/rfc6125#section-6.4.3_

**Args**: dn, hostname, max_wildcards


#### `match_hostname()` (line 145)
_Verify that *cert* (in decoded format as returned by
SSLSocket.getpeercert()) matches the *hostname*.  RFC 2818 and RFC 6125
rules are followed, but IP addresses are not accepted for *hostname*.

CertificateError is raised on failure. On success, the function
returns nothing._

**Args**: cert, hostname


#### `__init__()` (line 197)
**Args**: self


#### `which()` (line 205)
_Given a command, mode, and a PATH string, return the path which
conforms to the given mode on the PATH, or None if there is no such
file.

`mode` defaults to os.F_OK | os.X_OK. `path` defaults to the result
of os.environ.get("PATH"), or can be overridden with a custom search
path._

**Args**: cmd, mode, path


#### `_access_check()` (line 219)
**Args**: fn, mode


#### `__init__()` (line 279)
**Args**: self, base


#### `__enter__()` (line 282)
**Args**: self


#### `__exit__()` (line 285)
**Args**: self


#### `__enter__()` (line 291)
**Args**: self


#### `__exit__()` (line 294)
**Args**: self


#### `open()` (line 298)
**Args**: self


#### `python_implementation()` (line 307)
_Return a string identifying the Python implementation._


#### `callable()` (line 325)
**Args**: obj


#### `fsencode()` (line 345)
**Args**: filename


#### `fsdecode()` (line 354)
**Args**: filename


#### `_get_normal_name()` (line 371)
_Imitates get_normal_name in tokenizer.c._

**Args**: orig_enc


#### `detect_encoding()` (line 382)
_The detect_encoding() function is used to detect the encoding that should
be used to decode a Python source file.  It requires one argument, readline,
in the same way as the tokenize() generator.

It will call readline a maximum of twice, and return the encoding used
(as a string) and a list of any lines (left as bytes) it has read in.

It detects the encoding from the presence of a utf-8 bom or an encoding
cookie as specified in pep-0263.  If both a bom and a cookie are present,
but disagree, a SyntaxError will be raised.  If the encoding cookie is an
invalid charset, raise a SyntaxError.  Note that if a utf-8 bom is found,
'utf-8-sig' is returned.

If no encoding is specified, then the default of 'utf-8' will be returned._

**Args**: readline


#### `read_or_stop()` (line 407)

#### `find_cookie()` (line 413)
**Args**: line


#### `_recursive_repr()` (line 494)
_Decorator to make a repr function return fillvalue for a recursive
call_

**Args**: fillvalue


#### `decorating_function()` (line 500)
**Args**: user_function


#### `wrapper()` (line 503)
**Args**: self


#### `__init__()` (line 537)
_Initialize a ChainMap by setting *maps* to the given mappings.
If no mappings are provided, a single empty dictionary is used._

**Args**: self


#### `__missing__()` (line 544)
**Args**: self, key


#### `__getitem__()` (line 547)
**Args**: self, key


#### `get()` (line 557)
**Args**: self, key, default


#### `__len__()` (line 560)
**Args**: self


#### `__iter__()` (line 564)
**Args**: self


#### `__contains__()` (line 567)
**Args**: self, key


#### `__bool__()` (line 570)
**Args**: self


#### `__repr__()` (line 574)
**Args**: self


#### `fromkeys()` (line 579)
_Create a ChainMap with a single dict created from the iterable._

**Args**: cls, iterable


#### `copy()` (line 583)
_New ChainMap or subclass with a new copy of maps[0] and refs to maps[1:]_

**Args**: self


#### `new_child()` (line 589)
_New ChainMap with a new dict followed by all previous maps._

**Args**: self


#### `parents()` (line 594)
_New ChainMap from maps[1:]._

**Args**: self


#### `__setitem__()` (line 598)
**Args**: self, key, value


#### `__delitem__()` (line 601)
**Args**: self, key


#### `popitem()` (line 608)
_Remove and return an item pair from maps[0]. Raise KeyError is maps[0] is empty._

**Args**: self


#### `pop()` (line 615)
_Remove *key* from maps[0] and return its value. Raise KeyError if *key* not in maps[0]._

**Args**: self, key


#### `clear()` (line 623)
_Clear maps[0], leaving maps[1:] intact._

**Args**: self


#### `cache_from_source()` (line 632)
**Args**: path, debug_override


#### `__init__()` (line 672)
_Initialize an ordered dictionary.  Signature is the same as for
regular dictionaries, but keyword arguments are not recommended
because their insertion order is arbitrary._

**Args**: self


#### `__setitem__()` (line 689)
_od.__setitem__(i, y) <==> od[i]=y_

**Args**: self, key, value, dict_setitem


#### `__delitem__()` (line 699)
_od.__delitem__(y) <==> del od[y]_

**Args**: self, key, dict_delitem


#### `__iter__()` (line 708)
_od.__iter__() <==> iter(od)_

**Args**: self


#### `__reversed__()` (line 716)
_od.__reversed__() <==> reversed(od)_

**Args**: self


#### `clear()` (line 724)
_od.clear() -> None.  Remove all items from od._

**Args**: self


#### `popitem()` (line 736)
_od.popitem() -> (k, v), return and remove a (key, value) pair.
Pairs are returned in LIFO order if last is true or FIFO order if false._

**Args**: self, last


#### `keys()` (line 761)
_od.keys() -> list of keys in od_

**Args**: self


#### `values()` (line 765)
_od.values() -> list of values in od_

**Args**: self


#### `items()` (line 769)
_od.items() -> list of (key, value) pairs in od_

**Args**: self


#### `iterkeys()` (line 773)
_od.iterkeys() -> an iterator over the keys in od_

**Args**: self


#### `itervalues()` (line 777)
_od.itervalues -> an iterator over the values in od_

**Args**: self


#### `iteritems()` (line 782)
_od.iteritems -> an iterator over the (key, value) items in od_

**Args**: self


#### `update()` (line 787)
_od.update(E, **F) -> None.  Update od from dict/iterable E and F.

If E is a dict instance, does:           for k in E: od[k] = E[k]
If E has a .keys() method, does:         for k in E.keys(): od[k] = E[k]
Or if E is an iterable of items, does:   for k, v in E: od[k] = v
In either case, this is followed by:     for k, v in F.items(): od[k] = v_


#### `pop()` (line 822)
_od.pop(k[,d]) -> v, remove specified key and return the corresponding value.
If key is not found, d is returned if given, otherwise KeyError is raised._

**Args**: self, key, default


#### `setdefault()` (line 835)
_od.setdefault(k[,d]) -> od.get(k,d), also set od[k]=d if k not in od_

**Args**: self, key, default


#### `__repr__()` (line 842)
_od.__repr__() <==> repr(od)_

**Args**: self, _repr_running


#### `__reduce__()` (line 857)
_Return state information for pickling_

**Args**: self


#### `copy()` (line 867)
_od.copy() -> a shallow copy of od_

**Args**: self


#### `fromkeys()` (line 872)
_OD.fromkeys(S[, v]) -> New ordered dictionary with keys from S
and values equal to v (which defaults to None)._

**Args**: cls, iterable, value


#### `__eq__()` (line 882)
_od.__eq__(y) <==> od==y.  Comparison to another OD is order-sensitive
while comparison to a regular mapping is order-insensitive._

**Args**: self, other


#### `__ne__()` (line 892)
**Args**: self, other


#### `viewkeys()` (line 897)
_od.viewkeys() -> a set-like object providing a view on od's keys_

**Args**: self


#### `viewvalues()` (line 901)
_od.viewvalues() -> an object providing a view on od's values_

**Args**: self


#### `viewitems()` (line 905)
_od.viewitems() -> a set-like object providing a view on od's items_

**Args**: self


#### `valid_ident()` (line 915)
**Args**: s


#### `__getitem__()` (line 933)
**Args**: self, key


#### `get()` (line 945)
**Args**: self, key, default


#### `pop()` (line 957)
**Args**: self, key, default


#### `__getitem__()` (line 970)
**Args**: self, key


#### `pop()` (line 982)
**Args**: self, idx


#### `__getitem__()` (line 994)
**Args**: self, key


#### `__init__()` (line 1024)
**Args**: self, config


#### `resolve()` (line 1028)
_Resolve strings to objects using standard import and attribute
syntax._

**Args**: self, s


#### `ext_convert()` (line 1051)
_Default converter for the ext:// protocol._

**Args**: self, value


#### `cfg_convert()` (line 1055)
_Default converter for the cfg:// protocol._

**Args**: self, value


#### `convert()` (line 1090)
_Convert values to an appropriate type. dicts, lists and tuples are
replaced by their converting alternatives. Strings are checked to
see if they have a conversion format and are converted if they do._

**Args**: self, value


#### `configure_custom()` (line 1119)
_Configure an object with a user-supplied factory._

**Args**: self, config


#### `as_tuple()` (line 1133)
_Utility function which converts lists to tuples._

**Args**: self, value


### venv_new\Lib\site-packages\pip\_vendor\distlib\database.py

#### `__init__()` (line 46)
_Initialise an instance. There is normally one for each DistributionPath._

**Args**: self


#### `clear()` (line 54)
_Clear the cache, setting it to its initial state._

**Args**: self


#### `add()` (line 62)
_Add a distribution to the cache.
:param dist: The distribution to add._

**Args**: self, dist


#### `__init__()` (line 77)
_Create an instance from a path, optionally including legacy (distutils/
setuptools/distribute) distributions.
:param path: The path to use, as a list of directories. If not specified,
             sys.path is used.
:param include_egg: If True, this instance will look for and return legacy
                    distributions as well as those based on PEP 376._

**Args**: self, path, include_egg


#### `_get_cache_enabled()` (line 97)
**Args**: self


#### `_set_cache_enabled()` (line 100)
**Args**: self, value


#### `clear_cache()` (line 105)
_Clears the internal cache._

**Args**: self


#### `_yield_distributions()` (line 112)
_Yield .dist-info and/or .egg(-info) distributions._

**Args**: self


#### `_generate_cache()` (line 158)
_Scan the path for distributions and populate the cache with
those that are found._

**Args**: self


#### `distinfo_dirname()` (line 178)
_The *name* and *version* parameters are converted into their
filename-escaped form, i.e. any ``'-'`` characters are replaced
with ``'_'`` other than the one in ``'dist-info'`` and the one
separating the name from the version number.

:parameter name: is converted to a standard distribution name by replacing
                 any runs of non- alphanumeric characters with a single
                 ``'-'``.
:type name: string
:parameter version: is converted to a standard version string. Spaces
                    become dots, and all other non-alphanumeric characters
                    (except dots) become dashes, with runs of multiple
                    dashes condensed to a single dash.
:type version: string
:returns: directory name
:rtype: string_

**Args**: cls, name, version


#### `get_distributions()` (line 199)
_Provides an iterator that looks for distributions and returns
:class:`InstalledDistribution` or
:class:`EggInfoDistribution` instances for each one of them.

:rtype: iterator of :class:`InstalledDistribution` and
        :class:`EggInfoDistribution` instances_

**Args**: self


#### `get_distribution()` (line 221)
_Looks for a named distribution on the path.

This function only returns the first result found, as no more than one
value is expected. If nothing is found, ``None`` is returned.

:rtype: :class:`InstalledDistribution`, :class:`EggInfoDistribution`
        or ``None``_

**Args**: self, name


#### `provides_distribution()` (line 247)
_Iterates over all distributions to find which distributions provide *name*.
If a *version* is provided, it will be used to filter the results.

This function only returns the first result found, since no more than
one values are expected. If the directory is not found, returns ``None``.

:parameter version: a version specifier that indicates the version
                    required, conforming to the format in ``PEP-345``

:type name: string
:type version: string_

**Args**: self, name, version


#### `get_file_path()` (line 287)
_Return the path to a resource file._

**Args**: self, name, relative_path


#### `get_exported_entries()` (line 296)
_Return all of the exported entries in a particular category.

:param category: The category to search for entries.
:param name: If specified, only entries with that name are returned._

**Args**: self, category, name


#### `__init__()` (line 333)
_Initialise an instance.
:param metadata: The instance of :class:`Metadata` describing this
distribution._

**Args**: self, metadata


#### `source_url()` (line 351)
_The source archive download URL for this distribution._

**Args**: self


#### `name_and_version()` (line 360)
_A utility property which displays the name and version in parentheses._

**Args**: self


#### `provides()` (line 367)
_A set of distribution names and versions provided by this distribution.
:return: A set of "name (version)" strings._

**Args**: self


#### `_get_requirements()` (line 378)
**Args**: self, req_attr


#### `run_requires()` (line 385)
**Args**: self


#### `meta_requires()` (line 389)
**Args**: self


#### `build_requires()` (line 393)
**Args**: self


#### `test_requires()` (line 397)
**Args**: self


#### `dev_requires()` (line 401)
**Args**: self


#### `matches_requirement()` (line 404)
_Say if this instance matches (fulfills) a requirement.
:param req: The requirement to match.
:rtype req: str
:return: True if it matches, else False._

**Args**: self, req


#### `__repr__()` (line 437)
_Return a textual representation of this instance,_

**Args**: self


#### `__eq__()` (line 447)
_See if this distribution is the same as another.
:param other: The distribution to compare with. To be equal to one
              another. distributions must have the same type, name,
              version and source_url.
:return: True if it is the same, else False._

**Args**: self, other


#### `__hash__()` (line 461)
_Compute hash in a way which matches the equality test._

**Args**: self


#### `__init__()` (line 476)
_Initialise an instance.
:param metadata: An instance of :class:`Metadata` which describes the
                 distribution. This will normally have been initialised
                 from a metadata file in the ``path``.
:param path:     The path of the ``.dist-info`` or ``.egg-info``
                 directory for the distribution.
:param env:      This is normally the :class:`DistributionPath`
                 instance where this distribution was found._

**Args**: self, metadata, path, env


#### `get_hash()` (line 491)
_Get the hash of some data, using a particular hash algorithm, if
specified.

:param data: The data to be hashed.
:type data: bytes
:param hasher: The name of a hash implementation, supported by hashlib,
               or ``None``. Examples of valid values are ``'sha1'``,
               ``'sha224'``, ``'sha384'``, '``sha256'``, ``'md5'`` and
               ``'sha512'``. If no hasher is specified, the ``hasher``
               attribute of the :class:`InstalledDistribution` instance
               is used. If the hasher is determined to be ``None``, MD5
               is used as the hashing algorithm.
:returns: The hash of the data. If a hasher was explicitly specified,
          the returned hash will be prefixed with the specified hasher
          followed by '='.
:rtype: str_

**Args**: self, data, hasher


#### `__init__()` (line 533)
**Args**: self, path, metadata, env


#### `__repr__()` (line 566)
**Args**: self


#### `__str__()` (line 569)
**Args**: self


#### `_get_records()` (line 572)
_Get the list of installed files for the distribution
:return: A list of tuples of path, hash and size. Note that hash and
         size might be ``None`` for some entries. The path is exactly
         as stored in the file (which is as in PEP 376)._

**Args**: self


#### `exports()` (line 596)
_Return the information exported by this distribution.
:return: A dictionary of exports, mapping an export category to a dict
         of :class:`ExportEntry` instances describing the individual
         export entries, and keyed by name._

**Args**: self


#### `read_exports()` (line 609)
_Read exports data from a file in .ini format.

:return: A dictionary of exports, mapping an export category to a list
         of :class:`ExportEntry` instances describing the individual
         export entries._

**Args**: self


#### `write_exports()` (line 624)
_Write a dictionary of exports to a file in .ini format.
:param exports: A dictionary of exports, mapping an export category to
                a list of :class:`ExportEntry` instances describing the
                individual export entries._

**Args**: self, exports


#### `get_resource_path()` (line 635)
_NOTE: This API may change in the future.

Return the absolute path to a resource file with the given relative
path.

:param relative_path: The path, relative to .dist-info, of the resource
                      of interest.
:return: The absolute path where the resource is to be found._

**Args**: self, relative_path


#### `list_installed_files()` (line 655)
_Iterates over the ``RECORD`` entries and returns a tuple
``(path, hash, size)`` for each line.

:returns: iterator of (path, hash, size)_

**Args**: self


#### `write_installed_files()` (line 665)
_Writes the ``RECORD`` file, using the ``paths`` iterable passed in. Any
existing ``RECORD`` file is silently overwritten.

prefix is used to determine when to write absolute paths._

**Args**: self, paths, prefix, dry_run


#### `check_installed_files()` (line 699)
_Checks that the hashes and sizes of the files in ``RECORD`` are
matched by the files themselves. Returns a (possibly empty) list of
mismatches. Each entry in the mismatch list will be a tuple consisting
of the path, 'exists', 'size' or 'hash' according to what didn't match
(existence is checked first, then size, then hash), the expected
value and the actual value._

**Args**: self


#### `shared_locations()` (line 735)
_A dictionary of shared locations whose keys are in the set 'prefix',
'purelib', 'platlib', 'scripts', 'headers', 'data' and 'namespace'.
The corresponding value is the absolute path of that category for
this distribution, and takes into account any paths selected by the
user at installation time (e.g. via command-line arguments). In the
case of the 'namespace' key, this would be a list of absolute paths
for the roots of namespace packages in this distribution.

The first time this property is accessed, the relevant information is
read from the SHARED file in the .dist-info directory._

**Args**: self


#### `write_shared_locations()` (line 761)
_Write shared location information to the SHARED file in .dist-info.
:param paths: A dictionary as described in the documentation for
:meth:`shared_locations`.
:param dry_run: If True, the action is logged but no file is actually
                written.
:return: The path of the file written to._

**Args**: self, paths, dry_run


#### `get_distinfo_resource()` (line 786)
**Args**: self, path


#### `get_distinfo_file()` (line 795)
_Returns a path located under the ``.dist-info`` directory. Returns a
string representing the path.

:parameter path: a ``'/'``-separated path relative to the
                 ``.dist-info`` directory or an absolute path;
                 If *path* is an absolute path and doesn't start
                 with the ``.dist-info`` directory path,
                 a :class:`DistlibException` is raised
:type path: str
:rtype: str_

**Args**: self, path


#### `list_distinfo_files()` (line 823)
_Iterates over the ``RECORD`` entries and returns paths for each line if
the path is pointing to a file located in the ``.dist-info`` directory
or one of its subdirectories.

:returns: iterator of paths_

**Args**: self


#### `__eq__()` (line 839)
**Args**: self, other


#### `__init__()` (line 855)
**Args**: self, path, env


#### `set_name_and_version()` (line 857)
**Args**: s, n, v


#### `_get_metadata()` (line 877)
**Args**: self, path


#### `parse_requires_data()` (line 880)
_Create a list of dependencies from a requires.txt file.

*data*: the contents of a setuptools-produced requires.txt file._

**Args**: data


#### `parse_requires_path()` (line 909)
_Create a list of dependencies from a requires.txt file.

*req_path*: the path to a setuptools-produced requires.txt file._

**Args**: req_path


#### `__repr__()` (line 968)
**Args**: self


#### `__str__()` (line 971)
**Args**: self


#### `check_installed_files()` (line 974)
_Checks that the hashes and sizes of the files in ``RECORD`` are
matched by the files themselves. Returns a (possibly empty) list of
mismatches. Each entry in the mismatch list will be a tuple consisting
of the path, 'exists', 'size' or 'hash' according to what didn't match
(existence is checked first, then size, then hash), the expected
value and the actual value._

**Args**: self


#### `list_installed_files()` (line 993)
_Iterates over the ``installed-files.txt`` entries and returns a tuple
``(path, hash, size)`` for each line.

:returns: a list of (path, hash, size)_

**Args**: self


#### `_md5()` (line 1001)
**Args**: path


#### `_size()` (line 1009)
**Args**: path


#### `list_distinfo_files()` (line 1031)
_Iterates over the ``installed-files.txt`` entries and returns paths for
each line if the path is pointing to a file located in the
``.egg-info`` directory or one of its subdirectories.

:parameter absolute: If *absolute* is ``True``, each returned path is
                  transformed into a local absolute path. Otherwise the
                  raw value from ``installed-files.txt`` is returned.
:type absolute: boolean
:returns: iterator of paths_

**Args**: self, absolute


#### `__eq__()` (line 1060)
**Args**: self, other


#### `__init__()` (line 1087)
**Args**: self


#### `add_distribution()` (line 1092)
_Add the *distribution* to the graph.

:type distribution: :class:`distutils2.database.InstalledDistribution`
                    or :class:`distutils2.database.EggInfoDistribution`_

**Args**: self, distribution


#### `add_edge()` (line 1102)
_Add an edge from distribution *x* to distribution *y* with the given
*label*.

:type x: :class:`distutils2.database.InstalledDistribution` or
         :class:`distutils2.database.EggInfoDistribution`
:type y: :class:`distutils2.database.InstalledDistribution` or
         :class:`distutils2.database.EggInfoDistribution`
:type label: ``str`` or ``None``_

**Args**: self, x, y, label


#### `add_missing()` (line 1117)
_Add a missing *requirement* for the given *distribution*.

:type distribution: :class:`distutils2.database.InstalledDistribution`
                    or :class:`distutils2.database.EggInfoDistribution`
:type requirement: ``str``_

**Args**: self, distribution, requirement


#### `_repr_dist()` (line 1128)
**Args**: self, dist


#### `repr_node()` (line 1131)
_Prints only a subgraph_

**Args**: self, dist, level


#### `to_dot()` (line 1144)
_Writes a DOT output for the graph to the provided file *f*.

If *skip_disconnected* is set to ``True``, then all distributions
that are not dependent on any other distribution are skipped.

:type f: has to support ``file``-like operations
:type skip_disconnected: ``bool``_

**Args**: self, f, skip_disconnected


#### `topological_sort()` (line 1175)
_Perform a topological sort of the graph.
:return: A tuple, the first element of which is a topologically sorted
         list of distributions, and the second element of which is a
         list of distributions that cannot be sorted because they have
         circular dependencies and so form a cycle._

**Args**: self


#### `__repr__()` (line 1205)
_Representation of the graph_

**Args**: self


#### `make_graph()` (line 1213)
_Makes a dependency graph from the given distributions.

:parameter dists: a list of distributions
:type dists: list of :class:`distutils2.database.InstalledDistribution` and
             :class:`distutils2.database.EggInfoDistribution` instances
:rtype: a :class:`DependencyGraph` instance_

**Args**: dists, scheme


#### `get_dependent_dists()` (line 1265)
_Recursively generate a list of distributions from *dists* that are
dependent on *dist*.

:param dists: a list of distributions
:param dist: a distribution, member of *dists* for which we are interested_

**Args**: dists, dist


#### `get_required_dists()` (line 1291)
_Recursively generate a list of distributions from *dists* that are
required by *dist*.

:param dists: a list of distributions
:param dist: a distribution, member of *dists* for which we are interested
             in finding the dependencies._

**Args**: dists, dist


#### `make_dist()` (line 1320)
_A convenience method for making a dist given just a name and version._

**Args**: name, version


### venv_new\Lib\site-packages\pip\_vendor\distlib\index.py

#### `__init__()` (line 37)
_Initialise an instance.

:param url: The URL of the index. If not specified, the URL for PyPI is
            used._

**Args**: self, url


#### `_get_pypirc_command()` (line 66)
_Get the distutils command for interacting with PyPI configurations.
:return: the command._

**Args**: self


#### `read_configuration()` (line 74)
_Read the PyPI access configuration as supported by distutils. This populates
``username``, ``password``, ``realm`` and ``url`` attributes from the
configuration._

**Args**: self


#### `save_configuration()` (line 87)
_Save the PyPI access configuration. You must have set ``username`` and
``password`` attributes before calling this method._

**Args**: self


#### `check_credentials()` (line 96)
_Check that ``username`` and ``password`` have been set, and raise an
exception if not._

**Args**: self


#### `register()` (line 108)
_Register a distribution on PyPI, using the provided metadata.

:param metadata: A :class:`Metadata` instance defining at least a name
                 and version number for the distribution to be
                 registered.
:return: The HTTP response received from PyPI upon submission of the
        request._

**Args**: self, metadata


#### `_reader()` (line 128)
_Thread runner for reading lines of from a subprocess into a buffer.

:param name: The logical name of the stream (used for logging only).
:param stream: The stream to read from. This will typically a pipe
               connected to the output stream of a subprocess.
:param outbuf: The list to append the read lines to._

**Args**: self, name, stream, outbuf


#### `get_sign_command()` (line 146)
_Return a suitable command for signing a file.

:param filename: The pathname to the file to be signed.
:param signer: The identifier of the signer of the file.
:param sign_password: The passphrase for the signer's
                      private key used for signing.
:param keystore: The path to a directory which contains the keys
                 used in verification. If not specified, the
                 instance's ``gpg_home`` attribute is used instead.
:return: The signing command as a list suitable to be
         passed to :class:`subprocess.Popen`._

**Args**: self, filename, signer, sign_password, keystore


#### `run_command()` (line 174)
_Run a command in a child process , passing it any input data specified.

:param cmd: The command to run.
:param input_data: If specified, this must be a byte string containing
                   data to be sent to the child process.
:return: A tuple consisting of the subprocess' exit code, a list of
         lines read from the subprocess' ``stdout``, and a list of
         lines read from the subprocess' ``stderr``._

**Args**: self, cmd, input_data


#### `sign_file()` (line 209)
_Sign a file.

:param filename: The pathname to the file to be signed.
:param signer: The identifier of the signer of the file.
:param sign_password: The passphrase for the signer's
                      private key used for signing.
:param keystore: The path to a directory which contains the keys
                 used in signing. If not specified, the instance's
                 ``gpg_home`` attribute is used instead.
:return: The absolute pathname of the file where the signature is
         stored._

**Args**: self, filename, signer, sign_password, keystore


#### `upload_file()` (line 232)
_Upload a release file to the index.

:param metadata: A :class:`Metadata` instance defining at least a name
                 and version number for the file to be uploaded.
:param filename: The pathname of the file to be uploaded.
:param signer: The identifier of the signer of the file.
:param sign_password: The passphrase for the signer's
                      private key used for signing.
:param filetype: The type of the file being uploaded. This is the
                distutils command which produced that file, e.g.
                ``sdist`` or ``bdist_wheel``.
:param pyversion: The version of Python which the release relates
                  to. For code compatible with any Python, this would
                  be ``source``, otherwise it would be e.g. ``3.2``.
:param keystore: The path to a directory which contains the keys
                 used in signing. If not specified, the instance's
                 ``gpg_home`` attribute is used instead.
:return: The HTTP response received from PyPI upon submission of the
        request._

**Args**: self, metadata, filename, signer, sign_password, filetype, pyversion, keystore


#### `upload_documentation()` (line 289)
_Upload documentation to the index.

:param metadata: A :class:`Metadata` instance defining at least a name
                 and version number for the documentation to be
                 uploaded.
:param doc_dir: The pathname of the directory which contains the
                documentation. This should be the directory that
                contains the ``index.html`` for the documentation.
:return: The HTTP response received from PyPI upon submission of the
        request._

**Args**: self, metadata, doc_dir


#### `get_verify_command()` (line 317)
_Return a suitable command for verifying a file.

:param signature_filename: The pathname to the file containing the
                           signature.
:param data_filename: The pathname to the file containing the
                      signed data.
:param keystore: The path to a directory which contains the keys
                 used in verification. If not specified, the
                 instance's ``gpg_home`` attribute is used instead.
:return: The verifying command as a list suitable to be
         passed to :class:`subprocess.Popen`._

**Args**: self, signature_filename, data_filename, keystore


#### `verify_signature()` (line 341)
_Verify a signature for a file.

:param signature_filename: The pathname to the file containing the
                           signature.
:param data_filename: The pathname to the file containing the
                      signed data.
:param keystore: The path to a directory which contains the keys
                 used in verification. If not specified, the
                 instance's ``gpg_home`` attribute is used instead.
:return: True if the signature was verified, else False._

**Args**: self, signature_filename, data_filename, keystore


#### `download_file()` (line 365)
_This is a convenience method for downloading a file from an URL.
Normally, this will be a file from the index, though currently
no check is made for this (i.e. a file can be downloaded from
anywhere).

The method is just like the :func:`urlretrieve` function in the
standard library, except that it allows digest computation to be
done during download and checking that the downloaded data
matched any expected value.

:param url: The URL of the file to be downloaded (assumed to be
            available via an HTTP GET request).
:param destfile: The pathname where the downloaded file is to be
                 saved.
:param digest: If specified, this must be a (hasher, value)
               tuple, where hasher is the algorithm used (e.g.
               ``'md5'``) and ``value`` is the expected value.
:param reporthook: The same as for :func:`urlretrieve` in the
                   standard library._

**Args**: self, url, destfile, digest, reporthook


#### `send_request()` (line 442)
_Send a standard library :class:`Request` to PyPI and return its
response.

:param req: The request to send.
:return: The HTTP response from PyPI (a standard library HTTPResponse)._

**Args**: self, req


#### `encode_request()` (line 458)
_Encode fields and files for posting to an HTTP server.

:param fields: The fields to send as a list of (fieldname, value)
               tuples.
:param files: The files to send as a list of (fieldname, filename,
              file_bytes) tuple._

**Args**: self, fields, files


#### `search()` (line 501)
**Args**: self, terms, operator


### venv_new\Lib\site-packages\pip\_vendor\distlib\locators.py

#### `get_all_distribution_names()` (line 39)
_Return all distribution names known by an index.
:param url: The URL of the index.
:return: A list of all known distribution names._

**Args**: url


#### `http_error_302()` (line 64)
**Args**: self, req, fp, code, msg, headers


#### `__init__()` (line 102)
_Initialise an instance.
:param scheme: Because locators look for most recent versions, they
               need to know the version scheme to use. This specifies
               the current PEP-recommended scheme - use ``'legacy'``
               if you need to support existing distributions on PyPI._

**Args**: self, scheme


#### `get_errors()` (line 121)
_Return any errors which have occurred._

**Args**: self


#### `clear_errors()` (line 135)
_Clear any errors which may have been logged._

**Args**: self


#### `clear_cache()` (line 142)
**Args**: self


#### `_get_scheme()` (line 145)
**Args**: self


#### `_set_scheme()` (line 148)
**Args**: self, value


#### `_get_project()` (line 153)
_For a given project, get a dictionary mapping available versions to Distribution
instances.

This should be implemented in subclasses.

If called from a locate() request, self.matcher will be set to a
matcher for the requirement to satisfy, otherwise it will be None._

**Args**: self, name


#### `get_distribution_names()` (line 165)
_Return all the distribution names known to this locator._

**Args**: self


#### `get_project()` (line 171)
_For a given project, get a dictionary mapping available versions to Distribution
instances.

This calls _get_project to do all the work, and just implements a caching layer on top._

**Args**: self, name


#### `score_url()` (line 188)
_Give an url a score which can be used to choose preferred URLs
for a given project release._

**Args**: self, url


#### `prefer_url()` (line 202)
_Choose one of two URLs where both are candidates for distribution
archives for the same version of a distribution (for example,
.tar.gz vs. zip).

The current implementation favours https:// URLs over http://, archives
from PyPI over those from other locations, wheel compatibility (if a
wheel) and then the archive name._

**Args**: self, url1, url2


#### `split_filename()` (line 224)
_Attempt to split a filename in project name, version and Python version._

**Args**: self, filename, project_name


#### `convert_url_to_download_info()` (line 230)
_See if a URL is a candidate for a download URL for a project (the URL
has typically been scraped from an HTML page).

If it is, a dictionary is returned with keys "name", "version",
"filename" and "url"; otherwise, None is returned._

**Args**: self, url, project_name


#### `same_project()` (line 239)
**Args**: name1, name2


#### `_get_digest()` (line 300)
_Get a digest from a dictionary by looking at a "digests" dictionary
or keys of the form 'algo_digest'.

Returns a 2-tuple (algo, digest) if found, else None. Currently
looks only for SHA256, then MD5._

**Args**: self, info


#### `_update_version_data()` (line 323)
_Update a result dictionary (the final result from _get_project) with a
dictionary for a specific version, which typically holds information
gleaned from a filename or URL for an archive for the distribution._

**Args**: self, result, info


#### `locate()` (line 346)
_Find the most recent distribution which matches the given
requirement.

:param requirement: A requirement of the form 'foo (1.0)' or perhaps
                    'foo (>= 1.0, < 2.0, != 1.3)'
:param prereleases: If ``True``, allow pre-release versions
                    to be located. Otherwise, pre-release versions
                    are not returned.
:return: A :class:`Distribution` instance, or ``None`` if no such
         distribution could be located._

**Args**: self, requirement, prereleases


#### `__init__()` (line 409)
_Initialise an instance.

:param url: The URL to use for XML-RPC.
:param kwargs: Passed to the superclass constructor._

**Args**: self, url


#### `get_distribution_names()` (line 420)
_Return all the distribution names known to this locator._

**Args**: self


#### `_get_project()` (line 426)
**Args**: self, name


#### `__init__()` (line 459)
**Args**: self, url


#### `get_distribution_names()` (line 463)
_Return all the distribution names known to this locator._

**Args**: self


#### `_get_project()` (line 469)
**Args**: self, name


#### `__init__()` (line 542)
_Initialise an instance with the Unicode page contents and the URL they
came from._

**Args**: self, data, url


#### `links()` (line 556)
_Return the URLs of all the links on a page together with information
about their "rel" attribute, for determining which ones to treat as
downloads and which ones to queue for further scraping._

**Args**: self


#### `clean()` (line 563)
_Tidy up an URL._

**Args**: url


#### `__init__()` (line 597)
_Initialise an instance.
:param url: The root URL to use for scraping.
:param timeout: The timeout, in seconds, to be applied to requests.
                This defaults to ``None`` (no timeout specified).
:param num_workers: The number of worker threads you want to do I/O,
                    This defaults to 10.
:param kwargs: Passed to the superclass._

**Args**: self, url, timeout, num_workers


#### `_prepare_threads()` (line 624)
_Threads are created only when get_project is called, and terminate
before it returns. They are there primarily to parallelise I/O (i.e.
fetching web pages)._

**Args**: self


#### `_wait_threads()` (line 637)
_Tell all the threads to terminate (by sending a sentinel value) and
wait for them to do so._

**Args**: self


#### `_get_project()` (line 650)
**Args**: self, name


#### `_is_platform_dependent()` (line 671)
_Does an URL refer to a platform-specific download?_

**Args**: self, url


#### `_process_download()` (line 677)
_See if an URL is a suitable download for a project.

If it is, register information in the result dictionary (for
_get_project) about the specific version it's for.

Note that the return value isn't actually used other than as a boolean
value._

**Args**: self, url


#### `_should_queue()` (line 697)
_Determine whether a link URL from a referring page and with a
particular "rel" attribute should be queued for scraping._

**Args**: self, link, referrer, rel


#### `_fetch()` (line 724)
_Get a URL to fetch from the work queue, get the HTML page, examine its
links for download candidates and candidates for further scraping.

This is a handy method to run in a thread._

**Args**: self


#### `get_page()` (line 756)
_Get the HTML for an URL, possibly from an in-memory cache.

XXX TODO Note: this cache is never actually cleared. It's assumed that
the data won't get stale over the lifetime of a locator instance (not
necessarily true for the default_locator)._

**Args**: self, url


#### `get_distribution_names()` (line 817)
_Return all the distribution names known to this locator._

**Args**: self


#### `__init__()` (line 835)
_Initialise an instance.
:param path: The root of the directory tree to search.
:param kwargs: Passed to the superclass constructor,
               except for:
               * recursive - if True (the default), subdirectories are
                 recursed into. If False, only the top-level directory
                 is searched,_

**Args**: self, path


#### `should_include()` (line 852)
_Should a filename be considered as a candidate for a distribution
archive? As well as the filename, the directory which contains it
is provided, though not used by the current implementation._

**Args**: self, filename, parent


#### `_get_project()` (line 860)
**Args**: self, name


#### `get_distribution_names()` (line 874)
_Return all the distribution names known to this locator._

**Args**: self


#### `get_distribution_names()` (line 900)
_Return all the distribution names known to this locator._

**Args**: self


#### `_get_project()` (line 906)
**Args**: self, name


#### `__init__()` (line 938)
_Initialise an instance.

:param distpath: A :class:`DistributionPath` instance to search._

**Args**: self, distpath


#### `_get_project()` (line 948)
**Args**: self, name


#### `__init__()` (line 970)
_Initialise an instance.

:param locators: The list of locators to search.
:param kwargs: Passed to the superclass constructor,
               except for:
               * merge - if False (the default), the first successful
                 search from any of the locators is returned. If True,
                 the results from all locators are merged (this can be
                 slow)._

**Args**: self


#### `clear_cache()` (line 986)
**Args**: self


#### `_set_scheme()` (line 991)
**Args**: self, value


#### `_get_project()` (line 998)
**Args**: self, name


#### `get_distribution_names()` (line 1042)
_Return all the distribution names known to this locator._

**Args**: self


#### `__init__()` (line 1070)
_Initialise an instance, using the specified locator
to locate distributions._

**Args**: self, locator


#### `add_distribution()` (line 1078)
_Add a distribution to the finder. This will update internal information
about who provides what.
:param dist: The distribution to add._

**Args**: self, dist


#### `remove_distribution()` (line 1093)
_Remove a distribution from the finder. This will update internal
information about who provides what.
:param dist: The distribution to remove._

**Args**: self, dist


#### `get_matcher()` (line 1111)
_Get a version matcher for a requirement.
:param reqt: The requirement
:type reqt: str
:return: A version matcher (an instance of
         :class:`distlib.version.Matcher`)._

**Args**: self, reqt


#### `find_providers()` (line 1127)
_Find the distributions which can fulfill a requirement.

:param reqt: The requirement.
 :type reqt: str
:return: A set of distribution which can fulfill the requirement._

**Args**: self, reqt


#### `try_to_replace()` (line 1151)
_Attempt to replace one provider with another. This is typically used
when resolving dependencies from multiple sources, e.g. A requires
(B >= 1.0) while C requires (B >= 1.1).

For successful replacement, ``provider`` must meet all the requirements
which ``other`` fulfills.

:param provider: The provider we are trying to replace with.
:param other: The provider we're trying to replace.
:param problems: If False is returned, this will contain what
                 problems prevented replacement. This is currently
                 a tuple of the literal string 'cantreplace',
                 ``provider``, ``other``  and the set of requirements
                 that ``provider`` couldn't fulfill.
:return: True if we can replace ``other`` with ``provider``, else
         False._

**Args**: self, provider, other, problems


#### `find()` (line 1190)
_Find a distribution and all distributions it depends on.

:param requirement: The requirement specifying the distribution to
                    find, or a Distribution instance.
:param meta_extras: A list of meta extras such as :test:, :build: and
                    so on.
:param prereleases: If ``True``, allow pre-release versions to be
                    returned - otherwise, don't return prereleases
                    unless they're all that's available.

Return a set of :class:`Distribution` instances and a set of
problems.

The distributions returned should be such that they have the
:attr:`required` attribute set to ``True`` if they were
from the ``requirement`` passed to ``find()``, and they have the
:attr:`build_time_dependency` attribute set to ``True`` unless they
are post-installation dependencies of the ``requirement``.

The problems should be a tuple consisting of the string
``'unsatisfied'`` and the requirement which couldn't be satisfied
by any distribution known to the locator._

**Args**: self, requirement, meta_extras, prereleases


### venv_new\Lib\site-packages\pip\_vendor\distlib\manifest.py

#### `__init__()` (line 44)
_Initialise an instance.

:param base: The base directory to explore under._

**Args**: self, base


#### `findall()` (line 59)
_Find all files under the base and set ``allfiles`` to the absolute
pathnames of files found._

**Args**: self


#### `add()` (line 86)
_Add a file to the manifest.

:param item: The pathname to add. This can be relative to the base._

**Args**: self, item


#### `add_many()` (line 96)
_Add a list of files to the manifest.

:param items: The pathnames to add. These can be relative to the base._

**Args**: self, items


#### `sorted()` (line 105)
_Return sorted files in directory order_

**Args**: self, wantdirs


#### `add_dir()` (line 110)
**Args**: dirs, d


#### `clear()` (line 127)
_Clear all collected files._

**Args**: self


#### `process_directive()` (line 132)
_Process a directive which either adds some files from ``allfiles`` to
``files``, or removes some files from ``files``.

:param directive: The directive to process. This should be in a format
             compatible with distutils ``MANIFEST.in`` files:

             http://docs.python.org/distutils/sourcedist.html#commands_

**Args**: self, directive


#### `_parse_directive()` (line 200)
_Validate a directive.
:param directive: The directive to validate.
:return: A tuple of action, patterns, thedir, dir_patterns_

**Args**: self, directive


#### `_include_pattern()` (line 247)
_Select strings (presumably filenames) from 'self.files' that
match 'pattern', a Unix-style wildcard (glob) pattern.

Patterns are not quite the same as implemented by the 'fnmatch'
module: '*' and '?'  match non-special characters, where "special"
is platform-dependent: slash on Unix; colon, slash, and backslash on
DOS/Windows; and colon on Mac OS.

If 'anchor' is true (the default), then the pattern match is more
stringent: "*.py" will match "foo.py" but not "foo/bar.py".  If
'anchor' is false, both of these will match.

If 'prefix' is supplied, then only filenames starting with 'prefix'
(itself a pattern) and ending with 'pattern', with anything in between
them, will match.  'anchor' is ignored in this case.

If 'is_regex' is true, 'anchor' and 'prefix' are ignored, and
'pattern' is assumed to be either a string containing a regex or a
regex object -- no translation is done, the regex is just compiled
and used as-is.

Selected strings will be added to self.files.

Return True if files are found._

**Args**: self, pattern, anchor, prefix, is_regex


#### `_exclude_pattern()` (line 288)
_Remove strings (presumably filenames) from 'files' that match
'pattern'.

Other parameters are the same as for 'include_pattern()', above.
The list 'self.files' is modified in place. Return True if files are
found.

This API is public to allow e.g. exclusion of SCM subdirs, e.g. when
packaging source distributions_

**Args**: self, pattern, anchor, prefix, is_regex


#### `_translate_pattern()` (line 308)
_Translate a shell-like wildcard pattern to a compiled regular
expression.

Return the compiled regex.  If 'is_regex' true,
then 'pattern' is directly compiled to a regex (if it's a string)
or just returned as-is (assumes it's a regex object)._

**Args**: self, pattern, anchor, prefix, is_regex


#### `_glob_to_re()` (line 363)
_Translate a shell-like glob pattern to a regular expression.

Return a string containing the regex.  Differs from
'fnmatch.translate()' in that '*' does not match "special characters"
(which are platform-specific)._

**Args**: self, pattern


### venv_new\Lib\site-packages\pip\_vendor\distlib\markers.py

#### `_is_version_marker()` (line 30)
**Args**: s


#### `_is_literal()` (line 34)
**Args**: o


#### `_get_versions()` (line 40)
**Args**: s


#### `evaluate()` (line 64)
_Evaluate a marker expression returned by the :func:`parse_requirement`
function in the specified context._

**Args**: self, expr, context


#### `default_context()` (line 102)

#### `format_full_version()` (line 104)
**Args**: info


#### `interpret()` (line 144)
_Interpret a marker and return a result depending on environment.

:param marker: The marker to interpret.
:type marker: str
:param execution_context: The context used for name lookup.
:type execution_context: mapping_

**Args**: marker, execution_context


### venv_new\Lib\site-packages\pip\_vendor\distlib\metadata.py

#### `_version2fieldlist()` (line 103)
**Args**: version


#### `_best_version()` (line 121)
_Detect the best version depending on the fields used._

**Args**: fields


#### `_has_marker()` (line 124)
**Args**: keys, markers


#### `_get_name_and_version()` (line 215)
_Return the distribution name with version.

If for_filename is true, return a filename-escaped form._

**Args**: name, version, for_filename


#### `__init__()` (line 241)
**Args**: self, path, fileobj, mapping, scheme


#### `set_metadata_version()` (line 256)
**Args**: self


#### `_write_field()` (line 259)
**Args**: self, fileobj, name, value


#### `__getitem__()` (line 262)
**Args**: self, name


#### `__setitem__()` (line 265)
**Args**: self, name, value


#### `__delitem__()` (line 268)
**Args**: self, name


#### `__contains__()` (line 275)
**Args**: self, name


#### `_convert_name()` (line 278)
**Args**: self, name


#### `_default_value()` (line 284)
**Args**: self, name


#### `_remove_line_prefix()` (line 289)
**Args**: self, value


#### `__getattr__()` (line 295)
**Args**: self, name


#### `get_fullname()` (line 304)
_Return the distribution name with version.

If filesafe is true, return a filename-escaped form._

**Args**: self, filesafe


#### `is_field()` (line 312)
_return True if name is a valid metadata key_

**Args**: self, name


#### `is_multi_field()` (line 317)
**Args**: self, name


#### `read()` (line 321)
_Read the metadata values from a file path._

**Args**: self, filepath


#### `read_file()` (line 329)
_Read the metadata values from a file object._

**Args**: self, fileob


#### `write()` (line 357)
_Write the metadata fields to filepath._

**Args**: self, filepath, skip_unknown


#### `write_file()` (line 365)
_Write the PKG-INFO format data to a file object._

**Args**: self, fileobject, skip_unknown


#### `update()` (line 390)
_Set metadata values from the given iterable `other` and kwargs.

Behavior is like `dict.update`: If `other` has a ``keys`` method,
they are looped over and ``self[key]`` is assigned ``other[key]``.
Else, ``other`` is an iterable of ``(key, value)`` iterables.

Keys that don't match a metadata field or that have an empty value are
dropped._

**Args**: self, other


#### `_set()` (line 401)
**Args**: key, value


#### `set()` (line 419)
_Control then set a metadata field._

**Args**: self, name, value


#### `get()` (line 457)
_Get a metadata field._

**Args**: self, name, default


#### `check()` (line 486)
_Check if the metadata is compliant. If strict is True then raise if
no Name or Version are provided_

**Args**: self, strict


#### `are_valid_constraints()` (line 512)
**Args**: value


#### `todict()` (line 528)
_Return fields as a dict.

Field names will be converted to use the underscore-lowercase style
instead of hyphen-mixed case (i.e. home_page instead of Home-page).
This is as per https://www.python.org/dev/peps/pep-0566/#id17._

**Args**: self, skip_missing


#### `add_requirements()` (line 551)
**Args**: self, requirements


#### `keys()` (line 562)
**Args**: self


#### `__iter__()` (line 565)
**Args**: self


#### `values()` (line 569)
**Args**: self


#### `items()` (line 572)
**Args**: self


#### `__repr__()` (line 575)
**Args**: self


#### `__init__()` (line 629)
**Args**: self, path, fileobj, mapping, scheme


#### `__getattribute__()` (line 695)
**Args**: self, key


#### `_validate_value()` (line 737)
**Args**: self, key, value, scheme


#### `__setattr__()` (line 746)
**Args**: self, key, value


#### `name_and_version()` (line 785)
**Args**: self


#### `provides()` (line 789)
**Args**: self


#### `provides()` (line 800)
**Args**: self, value


#### `get_requirements()` (line 806)
_Base method to get dependencies, given a set of extras
to satisfy and an optional environment context.
:param reqts: A list of sometimes-wanted dependencies,
              perhaps dependent on extras and environment.
:param extras: A list of optional components being requested.
:param env: An optional environment for marker evaluation._

**Args**: self, reqts, extras, env


#### `dictionary()` (line 848)
**Args**: self


#### `dependencies()` (line 854)
**Args**: self


#### `dependencies()` (line 861)
**Args**: self, value


#### `_validate_mapping()` (line 867)
**Args**: self, mapping, scheme


#### `validate()` (line 881)
**Args**: self


#### `todict()` (line 889)
**Args**: self


#### `_from_legacy()` (line 896)
**Args**: self


#### `_to_legacy()` (line 936)
**Args**: self


#### `process_entries()` (line 938)
**Args**: entries


#### `write()` (line 987)
**Args**: self, path, fileobj, legacy, skip_unknown


#### `add_requirements()` (line 1011)
**Args**: self, requirements


#### `__repr__()` (line 1028)
**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\distlib\resources.py

#### `__init__()` (line 28)
**Args**: self, base


#### `is_stale()` (line 34)
_Is the cache stale for the given resource?

:param resource: The :class:`Resource` being cached.
:param path: The path of the resource in the cache.
:return: True if the cache is stale._

**Args**: self, resource, path


#### `get()` (line 45)
_Get a resource into the cache,

:param resource: A :class:`Resource` instance.
:return: The pathname of the resource in the cache._

**Args**: self, resource


#### `__init__()` (line 72)
**Args**: self, finder, name


#### `as_stream()` (line 85)
_Get the resource as a stream.

This is not a property to make it obvious that it returns a new stream
each time._

**Args**: self


#### `file_path()` (line 95)
**Args**: self


#### `bytes()` (line 102)
**Args**: self


#### `size()` (line 106)
**Args**: self


#### `resources()` (line 114)
**Args**: self


#### `__init__()` (line 128)
**Args**: self, module


#### `_adjust_path()` (line 133)
**Args**: self, path


#### `_make_path()` (line 136)
**Args**: self, resource_name


#### `_find()` (line 148)
**Args**: self, path


#### `get_cache_info()` (line 151)
**Args**: self, resource


#### `find()` (line 154)
**Args**: self, resource_name


#### `get_stream()` (line 166)
**Args**: self, resource


#### `get_bytes()` (line 169)
**Args**: self, resource


#### `get_size()` (line 173)
**Args**: self, resource


#### `get_resources()` (line 176)
**Args**: self, resource


#### `allowed()` (line 177)
**Args**: f


#### `is_container()` (line 182)
**Args**: self, resource


#### `iterator()` (line 187)
**Args**: self, resource_name


#### `__init__()` (line 212)
**Args**: self, module


#### `_adjust_path()` (line 223)
**Args**: self, path


#### `_find()` (line 226)
**Args**: self, path


#### `get_cache_info()` (line 244)
**Args**: self, resource


#### `get_bytes()` (line 249)
**Args**: self, resource


#### `get_stream()` (line 252)
**Args**: self, resource


#### `get_size()` (line 255)
**Args**: self, resource


#### `get_resources()` (line 259)
**Args**: self, resource


#### `_is_directory()` (line 274)
**Args**: self, path


#### `register_finder()` (line 306)
**Args**: loader, finder_maker


#### `finder()` (line 313)
_Return a resource finder for a package.
:param package: The name of the package.
:return: A :class:`ResourceFinder` instance for the package._

**Args**: package


#### `finder_for_path()` (line 341)
_Return a resource finder for a path, which should represent a container.

:param path: The path.
:return: A :class:`ResourceFinder` instance for the path._

**Args**: path


### venv_new\Lib\site-packages\pip\_vendor\distlib\scripts.py

#### `enquote_executable()` (line 71)
**Args**: executable


#### `__init__()` (line 100)
**Args**: self, source_dir, target_dir, add_launchers, dry_run, fileop


#### `_get_alternate_executable()` (line 114)
**Args**: self, executable, options


#### `_is_shell()` (line 123)
_Determine if the specified executable is a script
(contains a #! line)_

**Args**: self, executable


#### `_fix_jython_executable()` (line 135)
**Args**: self, executable


#### `_build_shebang()` (line 147)
_Build a shebang line. In the simple case (on Windows, or a shebang line
which is not too long or contains spaces) use a simple formulation for
the shebang. Otherwise, use /bin/sh as the executable, with a contrived
shebang which allows the script to run either under Python or sh, using
suitable quoting. Thanks to Harald Nordgren for his input.

See also: http://www.in-ulm.de/~mascheck/various/shebang/#length
          https://hg.mozilla.org/mozilla-central/file/tip/mach_

**Args**: self, executable, post_interp


#### `_get_shebang()` (line 183)
**Args**: self, encoding, post_interp, options


#### `_get_script_text()` (line 249)
**Args**: self, entry


#### `get_manifest()` (line 255)
**Args**: self, exename


#### `_write_script()` (line 259)
**Args**: self, names, shebang, script_bytes, filenames, ext


#### `get_script_filenames()` (line 316)
**Args**: self, name


#### `_make_script()` (line 326)
**Args**: self, entry, filenames, options


#### `_copy_script()` (line 342)
**Args**: self, script, filenames


#### `dry_run()` (line 393)
**Args**: self


#### `dry_run()` (line 397)
**Args**: self, value


#### `_get_launcher()` (line 404)
**Args**: self, kind


#### `make()` (line 419)
_Make a script.

:param specification: The specification, which is either a valid export
                      entry specification (to make a script from a
                      callable) or a filename (to make a script by
                      copying from a source location).
:param options: A dictionary of options controlling script generation.
:return: A list of all absolute pathnames written to._

**Args**: self, specification, options


#### `make_multiple()` (line 438)
_Take a list of specifications and make scripts from them,
:param specifications: A list of specifications.
:return: A list of all absolute pathnames written to,_

**Args**: self, specifications, options


### venv_new\Lib\site-packages\pip\_vendor\distlib\util.py

#### `parse_marker()` (line 54)
_Parse a marker string and return a dictionary containing a marker expression.

The dictionary will contain keys "op", "lhs" and "rhs" for non-terminals in
the expression grammar, or strings. A string contained in quotes is to be
interpreted as a literal string, and a string not contained in quotes is a
variable (such as os_name)._

**Args**: marker_string


#### `marker_var()` (line 64)
**Args**: remaining


#### `marker_expr()` (line 100)
**Args**: remaining


#### `marker_and()` (line 119)
**Args**: remaining


#### `marker()` (line 130)
**Args**: remaining


#### `parse_requirement()` (line 144)
_Parse a requirement passed in as a string. Return a Container
whose attributes contain the various parts of the requirement._

**Args**: req


#### `get_versions()` (line 196)
_Return a list of operator, version tuples if any are
specified, else None._

**Args**: ver_remaining


#### `get_resources_dests()` (line 268)
_Find destinations for resources files_

**Args**: resources_root, rules


#### `get_rel_path()` (line 271)
**Args**: root, path


#### `in_venv()` (line 294)

#### `get_executable()` (line 304)

#### `proceed()` (line 322)
**Args**: prompt, allowed_chars, error_prompt, default


#### `extract_by_key()` (line 338)
**Args**: d, keys


#### `read_exports()` (line 348)
**Args**: stream


#### `read_stream()` (line 368)
**Args**: cp, stream


#### `write_exports()` (line 395)
**Args**: exports, stream


#### `tempdir()` (line 415)

#### `chdir()` (line 424)
**Args**: d


#### `socket_timeout()` (line 434)
**Args**: seconds


#### `__init__()` (line 445)
**Args**: self, func


#### `__get__()` (line 450)
**Args**: self, obj, cls


#### `convert_path()` (line 459)
_Return 'pathname' as a name that will work on the native filesystem.

The path is split on '/' and put back together again using the current
directory separator.  Needed because filenames in the setup script are
always supplied in Unix style, and have to be converted to the local
convention before we can actually use them in the filesystem.  Raises
ValueError on non-Unix-ish systems if 'pathname' either starts or
ends with a slash._

**Args**: pathname


#### `__init__()` (line 488)
**Args**: self, dry_run


#### `_init_record()` (line 493)
**Args**: self


#### `record_as_written()` (line 498)
**Args**: self, path


#### `newer()` (line 502)
_Tell if the target is newer than the source.

Returns true if 'source' exists and is more recently modified than
'target', or if 'source' exists and 'target' doesn't.

Returns false if both exist and 'target' is the same age or younger
than 'source'. Raise PackagingFileError if 'source' does not exist.

Note that this test is not very accurate: files created in the same
second will have the same "age"._

**Args**: self, source, target


#### `copy_file()` (line 521)
_Copy a file respecting dry-run and force flags.
        _

**Args**: self, infile, outfile, check


#### `copy_stream()` (line 538)
**Args**: self, instream, outfile, encoding


#### `write_binary_file()` (line 553)
**Args**: self, path, data


#### `write_text_file()` (line 562)
**Args**: self, path, data, encoding


#### `set_mode()` (line 565)
**Args**: self, bits, mask, files


#### `ensure_dir()` (line 579)
**Args**: self, path


#### `byte_compile()` (line 591)
**Args**: self, path, optimize, force, prefix, hashed_invalidation


#### `ensure_removed()` (line 610)
**Args**: self, path


#### `is_writable()` (line 631)
**Args**: self, path


#### `commit()` (line 643)
_Commit recorded changes, turn off recording, return
changes._

**Args**: self


#### `rollback()` (line 653)
**Args**: self


#### `resolve()` (line 672)
**Args**: module_name, dotted_path


#### `__init__()` (line 689)
**Args**: self, name, prefix, suffix, flags


#### `value()` (line 696)
**Args**: self


#### `__repr__()` (line 699)
**Args**: self


#### `__eq__()` (line 702)
**Args**: self, other


#### `get_export_entry()` (line 720)
**Args**: specification


#### `get_cache_base()` (line 751)
_Return the default base location for distlib caches. If the directory does
not exist, it is created. Use the suffix provided for the base directory,
and default to '.distlib' if it isn't provided.

On Windows, if LOCALAPPDATA is defined in the environment, then it is
assumed to be a directory, and will be the parent directory of the result.
On POSIX, and on Windows if LOCALAPPDATA is not defined, the user's home
directory - using os.expanduser('~') - will be the parent directory of
the result.

The result is just the directory '.distlib' in the parent directory as
determined above, or with the name specified with ``suffix``._

**Args**: suffix


#### `path_to_cache_dir()` (line 792)
_Convert an absolute path to a directory name for use in a cache.

The algorithm used is:

#. On Windows, any ``':'`` in the drive is replaced with ``'---'``.
#. Any occurrence of ``os.sep`` is replaced with ``'--'``.
#. ``'.cache'`` is appended._

**Args**: path, use_abspath


#### `ensure_slash()` (line 809)
**Args**: s


#### `parse_credentials()` (line 815)
**Args**: netloc


#### `get_process_umask()` (line 830)

#### `is_string_sequence()` (line 836)
**Args**: seq


#### `split_filename()` (line 852)
_Extract name, version, python version from a filename (no extension)

Return name, version, pyver or None_

**Args**: filename, project_name


#### `parse_name_and_version()` (line 882)
_A utility method used to get name and version from a string.

From e.g. a Provides-Dist value.

:param p: A value in a form 'foo (1.0)'
:return: The name and version as a tuple._

**Args**: p


#### `get_extras()` (line 898)
**Args**: requested, available


#### `_get_external_data()` (line 926)
**Args**: url


#### `get_project_data()` (line 950)
**Args**: name


#### `get_package_data()` (line 957)
**Args**: name, version


#### `__init__()` (line 970)
_Initialise an instance.

:param base: The base directory where the cache should be located._

**Args**: self, base


#### `prefix_to_dir()` (line 984)
_Converts a resource prefix to a directory name in the cache._

**Args**: self, prefix, use_abspath


#### `clear()` (line 990)
_Clear the cache._

**Args**: self


#### `__init__()` (line 1012)
**Args**: self


#### `add()` (line 1015)
_Add a subscriber for an event.

:param event: The name of an event.
:param subscriber: The subscriber to be added (and called when the
                   event is published).
:param append: Whether to append or prepend the subscriber to an
               existing subscriber list for the event._

**Args**: self, event, subscriber, append


#### `remove()` (line 1035)
_Remove a subscriber for an event.

:param event: The name of an event.
:param subscriber: The subscriber to be removed._

**Args**: self, event, subscriber


#### `get_subscribers()` (line 1047)
_Return an iterator for the subscribers for an event.
:param event: The event to return subscribers for._

**Args**: self, event


#### `publish()` (line 1054)
_Publish a event and return a list of values returned by its
subscribers.

:param event: The event to publish.
:param args: The positional arguments to pass to the event's
             subscribers.
:param kwargs: The keyword arguments to pass to the event's
               subscribers._

**Args**: self, event


#### `__init__()` (line 1082)
**Args**: self


#### `add_node()` (line 1087)
**Args**: self, node


#### `remove_node()` (line 1090)
**Args**: self, node, edges


#### `add()` (line 1106)
**Args**: self, pred, succ


#### `remove()` (line 1111)
**Args**: self, pred, succ


#### `is_step()` (line 1124)
**Args**: self, step


#### `get_steps()` (line 1127)
**Args**: self, final


#### `strong_connections()` (line 1153)
**Args**: self


#### `strongconnect()` (line 1163)
**Args**: node


#### `dot()` (line 1205)
**Args**: self


#### `unarchive()` (line 1224)
**Args**: archive_filename, dest_dir, format, check


#### `check_path()` (line 1226)
**Args**: path


#### `extraction_filter()` (line 1275)
_Run tarfile.tar_filter, but raise the expected ValueError_

**Args**: member, path


#### `zip_dir()` (line 1292)
_zip a directory tree into a BytesIO object_

**Args**: directory


#### `__init__()` (line 1316)
**Args**: self, minval, maxval


#### `update()` (line 1324)
**Args**: self, curval


#### `increment()` (line 1334)
**Args**: self, incr


#### `start()` (line 1338)
**Args**: self


#### `stop()` (line 1342)
**Args**: self


#### `maximum()` (line 1348)
**Args**: self


#### `percentage()` (line 1352)
**Args**: self


#### `format_duration()` (line 1362)
**Args**: self, duration


#### `ETA()` (line 1372)
**Args**: self


#### `speed()` (line 1391)
**Args**: self


#### `iglob()` (line 1412)
_Extended globbing function that supports ** and {opt1,opt2,opt3}._

**Args**: path_glob


#### `_iglob()` (line 1423)
**Args**: path_glob


#### `connect()` (line 1463)
**Args**: self


#### `__init__()` (line 1493)
**Args**: self, ca_certs, check_domain


#### `_conn_maker()` (line 1498)
_This is called to create a connection instance. Normally you'd
pass a connection class to do_open, but it doesn't actually check for
a class, and just expects a callable. As long as we behave just as a
constructor would have, we should be OK. If it ever changes so that
we *must* pass a class, we'll create an UnsafeHTTPSConnection class
which just sets check_domain to False in the class definition, and
choose which one to pass to do_open._

**Args**: self


#### `https_open()` (line 1514)
**Args**: self, req


#### `http_open()` (line 1535)
**Args**: self, req


#### `__init__()` (line 1545)
**Args**: self, timeout, use_datetime


#### `make_connection()` (line 1549)
**Args**: self, host


#### `__init__()` (line 1561)
**Args**: self, timeout, use_datetime


#### `make_connection()` (line 1565)
**Args**: self, host


#### `__init__()` (line 1578)
**Args**: self, uri


#### `_csv_open()` (line 1601)
**Args**: fn, mode


#### `__enter__()` (line 1619)
**Args**: self


#### `__exit__()` (line 1622)
**Args**: self


#### `__init__()` (line 1628)
**Args**: self


#### `__iter__()` (line 1639)
**Args**: self


#### `next()` (line 1642)
**Args**: self


#### `__init__()` (line 1655)
**Args**: self, fn


#### `writerow()` (line 1659)
**Args**: self, row


#### `__init__()` (line 1680)
**Args**: self, config, base


#### `configure_custom()` (line 1684)
**Args**: self, config


#### `convert()` (line 1686)
**Args**: o


#### `__getitem__()` (line 1716)
**Args**: self, key


#### `inc_convert()` (line 1722)
_Default converter for the inc:// protocol._

**Args**: self, value


#### `__init__()` (line 1736)
**Args**: self, verbose, progress


#### `reader()` (line 1740)
_Read lines from a subprocess' output stream and either pass to a progress
callable (if specified) or write progress information to sys.stderr._

**Args**: self, stream, context


#### `run_command()` (line 1761)
**Args**: self, cmd


#### `normalize_name()` (line 1777)
_Normalize a python package name a la PEP 503_

**Args**: name


#### `__init__()` (line 1799)
**Args**: self, fn, url


#### `read()` (line 1805)
**Args**: self


#### `update()` (line 1858)
**Args**: self, username, password


#### `_load_pypirc()` (line 1871)
_Read the PyPI access configuration as supported by distutils._

**Args**: index


#### `_store_pypirc()` (line 1878)
**Args**: index


#### `get_host_platform()` (line 1888)
_Return a string that identifies the current platform.  This is used mainly to
distinguish platform-specific build directories and platform-specific built
distributions.  Typically includes the OS name and version and the
architecture (as supplied by 'os.uname()'), although the exact information
included depends on the OS; eg. on Linux, the kernel version isn't
particularly important.

Examples of returned values:
   linux-i586
   linux-alpha (?)
   solaris-2.6-sun4u

Windows will return one of:
   win-amd64 (64bit Windows on AMD64 (aka x86_64, Intel64, EM64T, etc)
   win32 (all others - specifically, sys.platform is returned)

For other non-POSIX platforms, currently just returns 'sys.platform'._


#### `get_platform()` (line 1978)

### venv_new\Lib\site-packages\pip\_vendor\distlib\version.py

#### `__init__()` (line 31)
**Args**: self, s


#### `parse()` (line 37)
**Args**: self, s


#### `_check_compatible()` (line 40)
**Args**: self, other


#### `__eq__()` (line 44)
**Args**: self, other


#### `__ne__()` (line 48)
**Args**: self, other


#### `__lt__()` (line 51)
**Args**: self, other


#### `__gt__()` (line 55)
**Args**: self, other


#### `__le__()` (line 58)
**Args**: self, other


#### `__ge__()` (line 61)
**Args**: self, other


#### `__hash__()` (line 65)
**Args**: self


#### `__repr__()` (line 68)
**Args**: self


#### `__str__()` (line 71)
**Args**: self


#### `is_prerelease()` (line 75)
**Args**: self


#### `parse_requirement()` (line 97)
**Args**: self, s


#### `__init__()` (line 100)
**Args**: self, s


#### `match()` (line 129)
_Check if the provided version matches the constraints.

:param version: The version to match against this instance.
:type version: String or :class:`Version` instance._

**Args**: self, version


#### `exact_version()` (line 151)
**Args**: self


#### `_check_compatible()` (line 157)
**Args**: self, other


#### `__eq__()` (line 161)
**Args**: self, other


#### `__ne__()` (line 165)
**Args**: self, other


#### `__hash__()` (line 169)
**Args**: self


#### `__repr__()` (line 172)
**Args**: self


#### `__str__()` (line 175)
**Args**: self


#### `_pep_440_key()` (line 184)
**Args**: s


#### `parse()` (line 274)
**Args**: self, s


#### `is_prerelease()` (line 288)
**Args**: self


#### `_match_prefix()` (line 292)
**Args**: x, y


#### `_adjust_local()` (line 318)
**Args**: self, version, constraint, prefix


#### `_match_lt()` (line 332)
**Args**: self, version, constraint, prefix


#### `_match_gt()` (line 340)
**Args**: self, version, constraint, prefix


#### `_match_le()` (line 348)
**Args**: self, version, constraint, prefix


#### `_match_ge()` (line 352)
**Args**: self, version, constraint, prefix


#### `_match_eq()` (line 356)
**Args**: self, version, constraint, prefix


#### `_match_arbitrary()` (line 364)
**Args**: self, version, constraint, prefix


#### `_match_ne()` (line 367)
**Args**: self, version, constraint, prefix


#### `_match_compatible()` (line 375)
**Args**: self, version, constraint, prefix


#### `_suggest_semantic_version()` (line 415)
_Try to suggest a semantic form for a version for which
_suggest_normalized_version couldn't come up with anything._

**Args**: s


#### `_suggest_normalized_version()` (line 461)
_Suggest a normalized version close to the given version string.

If you have a version string that isn't rational (i.e. NormalizedVersion
doesn't like it) then you might be able to get an equivalent (or close)
rational version from this function.

This does a number of simple normalizations to the given string, based
on observation of versions currently in use on PyPI. Given a dump of
those version during PyCon 2009, 4287 of them:
- 2312 (53.93%) match NormalizedVersion without change
  with the automatic suggestion
- 3474 (81.04%) match when using this suggestion method

@param s {str} An irrational version string.
@returns A rational version string, or None, if couldn't determine one._

**Args**: s


#### `_legacy_key()` (line 588)
**Args**: s


#### `get_parts()` (line 589)
**Args**: s


#### `parse()` (line 615)
**Args**: self, s


#### `is_prerelease()` (line 619)
**Args**: self


#### `_match_compatible()` (line 636)
**Args**: self, version, constraint, prefix


#### `is_semver()` (line 659)
**Args**: s


#### `_semantic_key()` (line 663)
**Args**: s


#### `make_tuple()` (line 664)
**Args**: s, absent


#### `parse()` (line 685)
**Args**: self, s


#### `is_prerelease()` (line 689)
**Args**: self


#### `__init__()` (line 698)
**Args**: self, key, matcher, suggester


#### `is_valid_version()` (line 703)
**Args**: self, s


#### `is_valid_matcher()` (line 711)
**Args**: self, s


#### `is_valid_constraint_list()` (line 719)
_Used for processing some metadata fields_

**Args**: self, s


#### `suggest()` (line 728)
**Args**: self, s


#### `get_scheme()` (line 747)
**Args**: name


### venv_new\Lib\site-packages\pip\_vendor\distlib\wheel.py

#### `_derive_abi()` (line 58)

#### `_get_suffixes()` (line 114)

#### `_load_dynamic()` (line 121)
**Args**: name, path


#### `__init__()` (line 135)
**Args**: self


#### `add()` (line 139)
**Args**: self, pathname, extensions


#### `remove()` (line 143)
**Args**: self, pathname


#### `find_module()` (line 149)
**Args**: self, fullname, path


#### `load_module()` (line 156)
**Args**: self, fullname


#### `__init__()` (line 181)
_Initialise an instance using a (valid) filename._

**Args**: self, filename, sign, verify


#### `filename()` (line 223)
_Build and return a filename from the various components._

**Args**: self


#### `exists()` (line 239)
**Args**: self


#### `tags()` (line 244)
**Args**: self


#### `metadata()` (line 251)
**Args**: self


#### `get_wheel_metadata()` (line 282)
**Args**: self, zf


#### `info()` (line 292)
**Args**: self


#### `process_shebang()` (line 298)
**Args**: self, data


#### `get_hash()` (line 328)
**Args**: self, data, hash_kind


#### `write_record()` (line 339)
**Args**: self, records, record_path, archive_record_path


#### `write_records()` (line 346)
**Args**: self, info, libdir, archive_paths


#### `build_zip()` (line 362)
**Args**: self, pathname, archive_paths


#### `build()` (line 368)
_Build a wheel from files in specified paths, and use any specified tags
when determining the name of the wheel._

**Args**: self, paths, tags, wheel_version


#### `sorter()` (line 468)
**Args**: t


#### `skip_entry()` (line 485)
_Determine whether an archive entry should be skipped when verifying
or installing._

**Args**: self, arcname


#### `install()` (line 501)
_Install a wheel to the specified paths. If kwarg ``warner`` is
specified, it should be a callable, which will be called with two
tuples indicating the wheel version of this software and the wheel
version in the file, if there is a discrepancy in the versions.
This can be used to issue any warnings to raise any exceptions.
If kwarg ``lib_only`` is True, only the purelib/platlib files are
installed, and the headers, scripts, data and dist-info metadata are
not written. If kwarg ``bytecode_hashed_invalidation`` is True, written
bytecode will try to use file-hash based invalidation (PEP-552) on
supported interpreter versions (CPython 3.7+).

The return value is a :class:`InstalledDistribution` instance unless
``options.lib_only`` is True, in which case the return value is ``None``._

**Args**: self, paths, maker


#### `_get_dylib_cache()` (line 734)
**Args**: self


#### `_get_extensions()` (line 742)
**Args**: self


#### `is_compatible()` (line 776)
_Determine if a wheel is compatible with the running system._

**Args**: self


#### `is_mountable()` (line 782)
_Determine if a wheel is asserted as mountable by its metadata._

**Args**: self


#### `mount()` (line 788)
**Args**: self, append


#### `unmount()` (line 809)
**Args**: self


#### `verify()` (line 821)
**Args**: self


#### `update()` (line 877)
_Update the contents of a wheel in a generic way. The modifier should
be a callable which expects a dictionary argument: its keys are
archive-entry paths, and its values are absolute filesystem paths
where the contents the corresponding archive entries can be found. The
modifier is free to change the contents of the files pointed to, add
new entries and remove entries, before returning. This method will
extract the entire contents of the wheel to a temporary location, call
the modifier, and then use the passed (and possibly updated)
dictionary to write a new wheel. If ``dest_dir`` is specified, the new
wheel is written there -- otherwise, the original wheel is overwritten.

The modifier should return True if it updated the wheel, else False.
This method returns the same value the modifier returns._

**Args**: self, modifier, dest_dir


#### `get_version()` (line 894)
**Args**: path_map, info_dir


#### `update_version()` (line 904)
**Args**: version, path


#### `_get_glibc_version()` (line 975)

#### `compatible_tags()` (line 986)
_Return (pyver, abi, arch) tuples compatible with this Python._


#### `__init__()` (line 991)
**Args**: self, major, minor


#### `__str__()` (line 996)
**Args**: self


#### `is_compatible()` (line 1090)
**Args**: wheel, tags


### venv_new\Lib\site-packages\pip\_vendor\distro\distro.py

#### `linux_distribution()` (line 160)
_.. deprecated:: 1.6.0

    :func:`distro.linux_distribution()` is deprecated. It should only be
    used as a compatibility shim with Python's
    :py:func:`platform.linux_distribution()`. Please use :func:`distro.id`,
    :func:`distro.version` and :func:`distro.name` instead.

Return information about the current OS distribution as a tuple
``(id_name, version, codename)`` with items as follows:

* ``id_name``:  If *full_distribution_name* is false, the result of
  :func:`distro.id`. Otherwise, the result of :func:`distro.name`.

* ``version``:  The result of :func:`distro.version`.

* ``codename``:  The extra item (usually in parentheses) after the
  os-release version number, or the result of :func:`distro.codename`.

The interface of this function is compatible with the original
:py:func:`platform.linux_distribution` function, supporting a subset of
its parameters.

The data it returns may not exactly be the same, because it uses more data
sources than the original function, and that may lead to different data if
the OS distribution is not consistent across multiple data sources it
provides (there are indeed such distributions ...).

Another reason for differences is the fact that the :func:`distro.id`
method normalizes the distro ID string to a reliable machine-readable value
for a number of popular OS distributions._

**Args**: full_distribution_name


#### `id()` (line 203)
_Return the distro ID of the current distribution, as a
machine-readable string.

For a number of OS distributions, the returned distro ID value is
*reliable*, in the sense that it is documented and that it does not change
across releases of the distribution.

This package maintains the following reliable distro ID values:

==============  =========================================
Distro ID       Distribution
==============  =========================================
"ubuntu"        Ubuntu
"debian"        Debian
"rhel"          RedHat Enterprise Linux
"centos"        CentOS
"fedora"        Fedora
"sles"          SUSE Linux Enterprise Server
"opensuse"      openSUSE
"amzn"          Amazon Linux
"arch"          Arch Linux
"buildroot"     Buildroot
"cloudlinux"    CloudLinux OS
"exherbo"       Exherbo Linux
"gentoo"        GenToo Linux
"ibm_powerkvm"  IBM PowerKVM
"kvmibm"        KVM for IBM z Systems
"linuxmint"     Linux Mint
"mageia"        Mageia
"mandriva"      Mandriva Linux
"parallels"     Parallels
"pidora"        Pidora
"raspbian"      Raspbian
"oracle"        Oracle Linux (and Oracle Enterprise Linux)
"scientific"    Scientific Linux
"slackware"     Slackware
"xenserver"     XenServer
"openbsd"       OpenBSD
"netbsd"        NetBSD
"freebsd"       FreeBSD
"midnightbsd"   MidnightBSD
"rocky"         Rocky Linux
"aix"           AIX
"guix"          Guix System
"altlinux"      ALT Linux
==============  =========================================

If you have a need to get distros for reliable IDs added into this set,
or if you find that the :func:`distro.id` function returns a different
distro ID for one of the listed distros, please create an issue in the
`distro issue tracker`_.

**Lookup hierarchy and transformations:**

First, the ID is obtained from the following sources, in the specified
order. The first available and non-empty value is used:

* the value of the "ID" attribute of the os-release file,

* the value of the "Distributor ID" attribute returned by the lsb_release
  command,

* the first part of the file name of the distro release file,

The so determined ID value then passes the following transformations,
before it is returned by this method:

* it is translated to lower case,

* blanks (which should not be there anyway) are translated to underscores,

* a normalization of the ID is performed, based upon
  `normalization tables`_. The purpose of this normalization is to ensure
  that the ID is as reliable as possible, even across incompatible changes
  in the OS distributions. A common reason for an incompatible change is
  the addition of an os-release file, or the addition of the lsb_release
  command, with ID values that differ from what was previously determined
  from the distro release file name._


#### `name()` (line 287)
_Return the name of the current OS distribution, as a human-readable
string.

If *pretty* is false, the name is returned without version or codename.
(e.g. "CentOS Linux")

If *pretty* is true, the version and codename are appended.
(e.g. "CentOS Linux 7.1.1503 (Core)")

**Lookup hierarchy:**

The name is obtained from the following sources, in the specified order.
The first available and non-empty value is used:

* If *pretty* is false:

  - the value of the "NAME" attribute of the os-release file,

  - the value of the "Distributor ID" attribute returned by the lsb_release
    command,

  - the value of the "<name>" field of the distro release file.

* If *pretty* is true:

  - the value of the "PRETTY_NAME" attribute of the os-release file,

  - the value of the "Description" attribute returned by the lsb_release
    command,

  - the value of the "<name>" field of the distro release file, appended
    with the value of the pretty version ("<version_id>" and "<codename>"
    fields) of the distro release file, if available._

**Args**: pretty


#### `version()` (line 326)
_Return the version of the current OS distribution, as a human-readable
string.

If *pretty* is false, the version is returned without codename (e.g.
"7.0").

If *pretty* is true, the codename in parenthesis is appended, if the
codename is non-empty (e.g. "7.0 (Maipo)").

Some distributions provide version numbers with different precisions in
the different sources of distribution information. Examining the different
sources in a fixed priority order does not always yield the most precise
version (e.g. for Debian 8.2, or CentOS 7.1).

Some other distributions may not provide this kind of information. In these
cases, an empty string would be returned. This behavior can be observed
with rolling releases distributions (e.g. Arch Linux).

The *best* parameter can be used to control the approach for the returned
version:

If *best* is false, the first non-empty version number in priority order of
the examined sources is returned.

If *best* is true, the most precise version number out of all examined
sources is returned.

**Lookup hierarchy:**

In all cases, the version number is obtained from the following sources.
If *best* is false, this order represents the priority order:

* the value of the "VERSION_ID" attribute of the os-release file,
* the value of the "Release" attribute returned by the lsb_release
  command,
* the version number parsed from the "<version_id>" field of the first line
  of the distro release file,
* the version number parsed from the "PRETTY_NAME" attribute of the
  os-release file, if it follows the format of the distro release files.
* the version number parsed from the "Description" attribute returned by
  the lsb_release command, if it follows the format of the distro release
  files._

**Args**: pretty, best


#### `version_parts()` (line 374)
_Return the version of the current OS distribution as a tuple
``(major, minor, build_number)`` with items as follows:

* ``major``:  The result of :func:`distro.major_version`.

* ``minor``:  The result of :func:`distro.minor_version`.

* ``build_number``:  The result of :func:`distro.build_number`.

For a description of the *best* parameter, see the :func:`distro.version`
method._

**Args**: best


#### `major_version()` (line 391)
_Return the major version of the current OS distribution, as a string,
if provided.
Otherwise, the empty string is returned. The major version is the first
part of the dot-separated version string.

For a description of the *best* parameter, see the :func:`distro.version`
method._

**Args**: best


#### `minor_version()` (line 404)
_Return the minor version of the current OS distribution, as a string,
if provided.
Otherwise, the empty string is returned. The minor version is the second
part of the dot-separated version string.

For a description of the *best* parameter, see the :func:`distro.version`
method._

**Args**: best


#### `build_number()` (line 417)
_Return the build number of the current OS distribution, as a string,
if provided.
Otherwise, the empty string is returned. The build number is the third part
of the dot-separated version string.

For a description of the *best* parameter, see the :func:`distro.version`
method._

**Args**: best


#### `like()` (line 430)
_Return a space-separated list of distro IDs of distributions that are
closely related to the current OS distribution in regards to packaging
and programming interfaces, for example distributions the current
distribution is a derivative from.

**Lookup hierarchy:**

This information item is only provided by the os-release file.
For details, see the description of the "ID_LIKE" attribute in the
`os-release man page
<http://www.freedesktop.org/software/systemd/man/os-release.html>`_._


#### `codename()` (line 447)
_Return the codename for the release of the current OS distribution,
as a string.

If the distribution does not have a codename, an empty string is returned.

Note that the returned codename is not always really a codename. For
example, openSUSE returns "x86_64". This function does not handle such
cases in any special way and just returns the string it finds, if any.

**Lookup hierarchy:**

* the codename within the "VERSION" attribute of the os-release file, if
  provided,

* the value of the "Codename" attribute returned by the lsb_release
  command,

* the value of the "<codename>" field of the distro release file._


#### `info()` (line 471)
_Return certain machine-readable information items about the current OS
distribution in a dictionary, as shown in the following example:

.. sourcecode:: python

    {
        'id': 'rhel',
        'version': '7.0',
        'version_parts': {
            'major': '7',
            'minor': '0',
            'build_number': ''
        },
        'like': 'fedora',
        'codename': 'Maipo'
    }

The dictionary structure and keys are always the same, regardless of which
information items are available in the underlying data sources. The values
for the various keys are as follows:

* ``id``:  The result of :func:`distro.id`.

* ``version``:  The result of :func:`distro.version`.

* ``version_parts -> major``:  The result of :func:`distro.major_version`.

* ``version_parts -> minor``:  The result of :func:`distro.minor_version`.

* ``version_parts -> build_number``:  The result of
  :func:`distro.build_number`.

* ``like``:  The result of :func:`distro.like`.

* ``codename``:  The result of :func:`distro.codename`.

For a description of the *pretty* and *best* parameters, see the
:func:`distro.version` method._

**Args**: pretty, best


#### `os_release_info()` (line 515)
_Return a dictionary containing key-value pairs for the information items
from the os-release file data source of the current OS distribution.

See `os-release file`_ for details about these information items._


#### `lsb_release_info()` (line 525)
_Return a dictionary containing key-value pairs for the information items
from the lsb_release command data source of the current OS distribution.

See `lsb_release command output`_ for details about these information
items._


#### `distro_release_info()` (line 536)
_Return a dictionary containing key-value pairs for the information items
from the distro release file data source of the current OS distribution.

See `distro release file`_ for details about these information items._


#### `uname_info()` (line 546)
_Return a dictionary containing key-value pairs for the information items
from the distro release file data source of the current OS distribution._


#### `os_release_attr()` (line 554)
_Return a single named information item from the os-release file data source
of the current OS distribution.

Parameters:

* ``attribute`` (string): Key of the information item.

Returns:

* (string): Value of the information item, if the item exists.
  The empty string, if the item does not exist.

See `os-release file`_ for details about these information items._

**Args**: attribute


#### `lsb_release_attr()` (line 573)
_Return a single named information item from the lsb_release command output
data source of the current OS distribution.

Parameters:

* ``attribute`` (string): Key of the information item.

Returns:

* (string): Value of the information item, if the item exists.
  The empty string, if the item does not exist.

See `lsb_release command output`_ for details about these information
items._

**Args**: attribute


#### `distro_release_attr()` (line 593)
_Return a single named information item from the distro release file
data source of the current OS distribution.

Parameters:

* ``attribute`` (string): Key of the information item.

Returns:

* (string): Value of the information item, if the item exists.
  The empty string, if the item does not exist.

See `distro release file`_ for details about these information items._

**Args**: attribute


#### `uname_attr()` (line 612)
_Return a single named information item from the distro release file
data source of the current OS distribution.

Parameters:

* ``attribute`` (string): Key of the information item.

Returns:

* (string): Value of the information item, if the item exists.
            The empty string, if the item does not exist._

**Args**: attribute


#### `__init__()` (line 639)
**Args**: self, f


#### `__get__()` (line 643)
**Args**: self, obj, owner


#### `__init__()` (line 667)
_The initialization method of this class gathers information from the
available data sources, and stores that in private instance attributes.
Subsequent access to the information items uses these private instance
attributes, so that the data sources are read only once.

Parameters:

* ``include_lsb`` (bool): Controls whether the
  `lsb_release command output`_ is included as a data source.

  If the lsb_release command is not available in the program execution
  path, the data source for the lsb_release command will be empty.

* ``os_release_file`` (string): The path name of the
  `os-release file`_ that is to be used as a data source.

  An empty string (the default) will cause the default path name to
  be used (see `os-release file`_ for details).

  If the specified or defaulted os-release file does not exist, the
  data source for the os-release file will be empty.

* ``distro_release_file`` (string): The path name of the
  `distro release file`_ that is to be used as a data source.

  An empty string (the default) will cause a default search algorithm
  to be used (see `distro release file`_ for details).

  If the specified distro release file does not exist, or if no default
  distro release file can be found, the data source for the distro
  release file will be empty.

* ``include_uname`` (bool): Controls whether uname command output is
  included as a data source. If the uname command is not available in
  the program execution path the data source for the uname command will
  be empty.

* ``root_dir`` (string): The absolute path to the root directory to use
  to find distro-related information files. Note that ``include_*``
  parameters must not be enabled in combination with ``root_dir``.

* ``include_oslevel`` (bool): Controls whether (AIX) oslevel command
  output is included as a data source. If the oslevel command is not
  available in the program execution path the data source will be
  empty.

Public instance attributes:

* ``os_release_file`` (string): The path name of the
  `os-release file`_ that is actually used as a data source. The
  empty string if no distro release file is used as a data source.

* ``distro_release_file`` (string): The path name of the
  `distro release file`_ that is actually used as a data source. The
  empty string if no distro release file is used as a data source.

* ``include_lsb`` (bool): The result of the ``include_lsb`` parameter.
  This controls whether the lsb information will be loaded.

* ``include_uname`` (bool): The result of the ``include_uname``
  parameter. This controls whether the uname information will
  be loaded.

* ``include_oslevel`` (bool): The result of the ``include_oslevel``
  parameter. This controls whether (AIX) oslevel information will be
  loaded.

* ``root_dir`` (string): The result of the ``root_dir`` parameter.
  The absolute path to the root directory to use to find distro-related
  information files.

Raises:

* :py:exc:`ValueError`: Initialization parameters combination is not
   supported.

* :py:exc:`OSError`: Some I/O issue with an os-release file or distro
  release file.

* :py:exc:`UnicodeError`: A data source has unexpected characters or
  uses an unexpected encoding._

**Args**: self, include_lsb, os_release_file, distro_release_file, include_uname, root_dir, include_oslevel


#### `__repr__()` (line 800)
_Return repr of all info_

**Args**: self


#### `linux_distribution()` (line 817)
_Return information about the OS distribution that is compatible
with Python's :func:`platform.linux_distribution`, supporting a subset
of its parameters.

For details, see :func:`distro.linux_distribution`._

**Args**: self, full_distribution_name


#### `id()` (line 833)
_Return the distro ID of the OS distribution, as a string.

For details, see :func:`distro.id`._

**Args**: self


#### `normalize()` (line 839)
**Args**: distro_id, table


#### `name()` (line 861)
_Return the name of the OS distribution, as a string.

For details, see :func:`distro.name`._

**Args**: self, pretty


#### `version()` (line 884)
_Return the version of the OS distribution, as a string.

For details, see :func:`distro.version`._

**Args**: self, pretty, best


#### `version_parts()` (line 926)
_Return the version of the OS distribution, as a tuple of version
numbers.

For details, see :func:`distro.version_parts`._

**Args**: self, best


#### `major_version()` (line 942)
_Return the major version number of the current distribution.

For details, see :func:`distro.major_version`._

**Args**: self, best


#### `minor_version()` (line 950)
_Return the minor version number of the current distribution.

For details, see :func:`distro.minor_version`._

**Args**: self, best


#### `build_number()` (line 958)
_Return the build number of the current distribution.

For details, see :func:`distro.build_number`._

**Args**: self, best


#### `like()` (line 966)
_Return the IDs of distributions that are like the OS distribution.

For details, see :func:`distro.like`._

**Args**: self


#### `codename()` (line 974)
_Return the codename of the OS distribution.

For details, see :func:`distro.codename`._

**Args**: self


#### `info()` (line 991)
_Return certain machine-readable information about the OS
distribution.

For details, see :func:`distro.info`._

**Args**: self, pretty, best


#### `os_release_info()` (line 1010)
_Return a dictionary containing key-value pairs for the information
items from the os-release file data source of the OS distribution.

For details, see :func:`distro.os_release_info`._

**Args**: self


#### `lsb_release_info()` (line 1019)
_Return a dictionary containing key-value pairs for the information
items from the lsb_release command data source of the OS
distribution.

For details, see :func:`distro.lsb_release_info`._

**Args**: self


#### `distro_release_info()` (line 1029)
_Return a dictionary containing key-value pairs for the information
items from the distro release file data source of the OS
distribution.

For details, see :func:`distro.distro_release_info`._

**Args**: self


#### `uname_info()` (line 1039)
_Return a dictionary containing key-value pairs for the information
items from the uname command data source of the OS distribution.

For details, see :func:`distro.uname_info`._

**Args**: self


#### `oslevel_info()` (line 1048)
_Return AIX' oslevel command output._

**Args**: self


#### `os_release_attr()` (line 1054)
_Return a single named information item from the os-release file data
source of the OS distribution.

For details, see :func:`distro.os_release_attr`._

**Args**: self, attribute


#### `lsb_release_attr()` (line 1063)
_Return a single named information item from the lsb_release command
output data source of the OS distribution.

For details, see :func:`distro.lsb_release_attr`._

**Args**: self, attribute


#### `distro_release_attr()` (line 1072)
_Return a single named information item from the distro release file
data source of the OS distribution.

For details, see :func:`distro.distro_release_attr`._

**Args**: self, attribute


#### `uname_attr()` (line 1081)
_Return a single named information item from the uname command
output data source of the OS distribution.

For details, see :func:`distro.uname_attr`._

**Args**: self, attribute


#### `_os_release_info()` (line 1091)
_Get the information items from the specified os-release file.

Returns:
    A dictionary containing all information items._

**Args**: self


#### `_parse_os_release_content()` (line 1104)
_Parse the lines of an os-release file.

Parameters:

* lines: Iterable through the lines in the os-release file.
         Each line must be a unicode string or a UTF-8 encoded byte
         string.

Returns:
    A dictionary containing all information items._

**Args**: lines


#### `_lsb_release_info()` (line 1154)
_Get the information items from the lsb_release command output.

Returns:
    A dictionary containing all information items._

**Args**: self


#### `_parse_lsb_release_content()` (line 1173)
_Parse the output of the lsb_release command.

Parameters:

* lines: Iterable through the lines of the lsb_release output.
         Each line must be a unicode string or a UTF-8 encoded byte
         string.

Returns:
    A dictionary containing all information items._

**Args**: lines


#### `_uname_info()` (line 1197)
**Args**: self


#### `_oslevel_info()` (line 1209)
**Args**: self


#### `_debian_version()` (line 1219)
**Args**: self


#### `_parse_uname_content()` (line 1229)
**Args**: lines


#### `_to_str()` (line 1248)
**Args**: bytestring


#### `_distro_release_info()` (line 1253)
_Get the information items from the specified distro release file.

Returns:
    A dictionary containing all information items._

**Args**: self


#### `_parse_distro_release_file()` (line 1311)
_Parse a distro release file.

Parameters:

* filepath: Path name of the distro release file.

Returns:
    A dictionary containing all information items._

**Args**: self, filepath


#### `_parse_distro_release_content()` (line 1334)
_Parse a line from a distro release file.

Parameters:
* line: Line from the distro release file. Must be a unicode string
        or a UTF-8 encoded byte string.

Returns:
    A dictionary containing all information items._

**Args**: line


#### `main()` (line 1362)

### venv_new\Lib\site-packages\pip\_vendor\idna\codec.py

#### `encode()` (line 11)
**Args**: self, data, errors


#### `decode()` (line 20)
**Args**: self, data, errors


#### `_buffer_encode()` (line 31)
**Args**: self, data, errors, final


#### `_buffer_decode()` (line 65)
**Args**: self, data, errors, final


#### `search_function()` (line 108)
**Args**: name


### venv_new\Lib\site-packages\pip\_vendor\idna\compat.py

#### `ToASCII()` (line 6)
**Args**: label


#### `ToUnicode()` (line 10)
**Args**: label


#### `nameprep()` (line 14)
**Args**: s


### venv_new\Lib\site-packages\pip\_vendor\idna\core.py

#### `_combining_class()` (line 38)
**Args**: cp


#### `_is_script()` (line 46)
**Args**: cp, script


#### `_punycode()` (line 50)
**Args**: s


#### `_unot()` (line 54)
**Args**: s


#### `valid_label_length()` (line 58)
**Args**: label


#### `valid_string_length()` (line 64)
**Args**: label, trailing_dot


#### `check_bidi()` (line 70)
**Args**: label, check_ltr


#### `check_initial_combiner()` (line 140)
**Args**: label


#### `check_hyphen_ok()` (line 146)
**Args**: label


#### `check_nfc()` (line 154)
**Args**: label


#### `valid_contextj()` (line 159)
**Args**: label, pos


#### `valid_contexto()` (line 203)
**Args**: label, pos, exception


#### `check_label()` (line 245)
**Args**: label


#### `alabel()` (line 284)
**Args**: label


#### `ulabel()` (line 303)
**Args**: label


#### `uts46_remap()` (line 332)
_Re-map the characters in the string according to UTS46 processing._

**Args**: domain, std3_rules, transitional


#### `encode()` (line 366)
**Args**: s, strict, uts46, std3_rules, transitional


#### `decode()` (line 405)
**Args**: s, strict, uts46, std3_rules


### venv_new\Lib\site-packages\pip\_vendor\idna\intranges.py

#### `intranges_from_list()` (line 12)
_Represent a list of integers as a sequence of ranges:
((start_0, end_0), (start_1, end_1), ...), such that the original
integers are exactly those x such that start_i <= x < end_i for some i.

Ranges are encoded as single integers (start << 32 | end), not as tuples._

**Args**: list_


#### `_encode_range()` (line 34)
**Args**: start, end


#### `_decode_range()` (line 38)
**Args**: r


#### `intranges_contain()` (line 42)
_Determine if `int_` falls into one of the ranges in `ranges`._

**Args**: int_, ranges


### venv_new\Lib\site-packages\pip\_vendor\idna\uts46data.py

#### `_seg_0()` (line 12)

#### `_seg_1()` (line 117)

#### `_seg_2()` (line 222)

#### `_seg_3()` (line 327)

#### `_seg_4()` (line 432)

#### `_seg_5()` (line 537)

#### `_seg_6()` (line 642)

#### `_seg_7()` (line 747)

#### `_seg_8()` (line 852)

#### `_seg_9()` (line 957)

#### `_seg_10()` (line 1062)

#### `_seg_11()` (line 1167)

#### `_seg_12()` (line 1272)

#### `_seg_13()` (line 1377)

#### `_seg_14()` (line 1482)

#### `_seg_15()` (line 1587)

#### `_seg_16()` (line 1692)

#### `_seg_17()` (line 1797)

#### `_seg_18()` (line 1902)

#### `_seg_19()` (line 2007)

#### `_seg_20()` (line 2112)

#### `_seg_21()` (line 2217)

#### `_seg_22()` (line 2322)

#### `_seg_23()` (line 2427)

#### `_seg_24()` (line 2532)

#### `_seg_25()` (line 2637)

#### `_seg_26()` (line 2742)

#### `_seg_27()` (line 2847)

#### `_seg_28()` (line 2952)

#### `_seg_29()` (line 3057)

#### `_seg_30()` (line 3162)

#### `_seg_31()` (line 3267)

#### `_seg_32()` (line 3372)

#### `_seg_33()` (line 3477)

#### `_seg_34()` (line 3582)

#### `_seg_35()` (line 3687)

#### `_seg_36()` (line 3792)

#### `_seg_37()` (line 3897)

#### `_seg_38()` (line 4002)

#### `_seg_39()` (line 4107)

#### `_seg_40()` (line 4212)

#### `_seg_41()` (line 4317)

#### `_seg_42()` (line 4422)

#### `_seg_43()` (line 4527)

#### `_seg_44()` (line 4632)

#### `_seg_45()` (line 4737)

#### `_seg_46()` (line 4842)

#### `_seg_47()` (line 4947)

#### `_seg_48()` (line 5052)

#### `_seg_49()` (line 5157)

#### `_seg_50()` (line 5262)

#### `_seg_51()` (line 5367)

#### `_seg_52()` (line 5472)

#### `_seg_53()` (line 5577)

#### `_seg_54()` (line 5682)

#### `_seg_55()` (line 5787)

#### `_seg_56()` (line 5892)

#### `_seg_57()` (line 5997)

#### `_seg_58()` (line 6102)

#### `_seg_59()` (line 6207)

#### `_seg_60()` (line 6312)

#### `_seg_61()` (line 6417)

#### `_seg_62()` (line 6522)

#### `_seg_63()` (line 6627)

#### `_seg_64()` (line 6732)

#### `_seg_65()` (line 6837)

#### `_seg_66()` (line 6942)

#### `_seg_67()` (line 7047)

#### `_seg_68()` (line 7152)

#### `_seg_69()` (line 7257)

#### `_seg_70()` (line 7362)

#### `_seg_71()` (line 7467)

#### `_seg_72()` (line 7572)

#### `_seg_73()` (line 7677)

#### `_seg_74()` (line 7782)

#### `_seg_75()` (line 7887)

#### `_seg_76()` (line 7992)

#### `_seg_77()` (line 8097)

#### `_seg_78()` (line 8202)

#### `_seg_79()` (line 8307)

#### `_seg_80()` (line 8412)

#### `_seg_81()` (line 8517)

### venv_new\Lib\site-packages\pip\_vendor\msgpack\__init__.py

#### `pack()` (line 20)
_Pack object `o` and write it to `stream`

See :class:`Packer` for options._

**Args**: o, stream


#### `packb()` (line 30)
_Pack object `o` and return packed bytes

See :class:`Packer` for options._

**Args**: o


#### `unpack()` (line 39)
_Unpack an object from `stream`.

Raises `ExtraData` when `stream` contains extra bytes.
See :class:`Unpacker` for options._

**Args**: stream


### venv_new\Lib\site-packages\pip\_vendor\msgpack\exceptions.py

#### `__init__()` (line 37)
**Args**: self, unpacked, extra


#### `__str__()` (line 41)
**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\msgpack\ext.py

#### `__new__()` (line 9)
**Args**: cls, code, data


#### `__init__()` (line 31)
_Initialize a Timestamp object.

:param int seconds:
    Number of seconds since the UNIX epoch (00:00:00 UTC Jan 1 1970, minus leap seconds).
    May be negative.

:param int nanoseconds:
    Number of nanoseconds to add to `seconds` to get fractional time.
    Maximum is 999_999_999.  Default is 0.

Note: Negative times (before the UNIX epoch) are represented as neg. seconds + pos. ns._

**Args**: self, seconds, nanoseconds


#### `__repr__()` (line 53)
_String representation of Timestamp._

**Args**: self


#### `__eq__()` (line 57)
_Check for equality with another Timestamp object_

**Args**: self, other


#### `__ne__()` (line 63)
_not-equals method (see :func:`__eq__()`)_

**Args**: self, other


#### `__hash__()` (line 67)
**Args**: self


#### `from_bytes()` (line 71)
_Unpack bytes into a `Timestamp` object.

Used for pure-Python msgpack unpacking.

:param b: Payload from msgpack ext message with code -1
:type b: bytes

:returns: Timestamp object unpacked from msgpack ext payload
:rtype: Timestamp_

**Args**: b


#### `to_bytes()` (line 97)
_Pack this Timestamp object into bytes.

Used for pure-Python msgpack packing.

:returns data: Payload for EXT message with code -1 (timestamp type)
:rtype: bytes_

**Args**: self


#### `from_unix()` (line 119)
_Create a Timestamp from posix timestamp in seconds.

:param unix_float: Posix timestamp in seconds.
:type unix_float: int or float_

**Args**: unix_sec


#### `to_unix()` (line 129)
_Get the timestamp as a floating-point value.

:returns: posix timestamp
:rtype: float_

**Args**: self


#### `from_unix_nano()` (line 138)
_Create a Timestamp from posix timestamp in nanoseconds.

:param int unix_ns: Posix timestamp in nanoseconds.
:rtype: Timestamp_

**Args**: unix_ns


#### `to_unix_nano()` (line 146)
_Get the timestamp as a unixtime in nanoseconds.

:returns: posix timestamp in nanoseconds
:rtype: int_

**Args**: self


#### `to_datetime()` (line 154)
_Get the timestamp as a UTC datetime.

:rtype: `datetime.datetime`_

**Args**: self


#### `from_datetime()` (line 165)
_Create a Timestamp from datetime with tzinfo.

:rtype: Timestamp_

**Args**: dt


### venv_new\Lib\site-packages\pip\_vendor\msgpack\fallback.py

#### `__init__()` (line 14)
**Args**: self, s


#### `write()` (line 21)
**Args**: self, s


#### `getvalue()` (line 28)
**Args**: self


#### `newlist_hint()` (line 36)
**Args**: size


#### `_check_type_strict()` (line 58)
**Args**: obj, t, type, tuple


#### `_get_data_from_buffer()` (line 65)
**Args**: obj


#### `unpackb()` (line 72)
_Unpack an object from `packed`.

Raises ``ExtraData`` when *packed* contains extra bytes.
Raises ``ValueError`` when *packed* is incomplete.
Raises ``FormatError`` when *packed* is not valid msgpack.
Raises ``StackError`` when *packed* contains too nested.
Other exceptions can be raised during unpacking.

See :class:`Unpacker` for options._

**Args**: packed


#### `__init__()` (line 226)
**Args**: self, file_like


#### `feed()` (line 318)
**Args**: self, next_bytes


#### `_consume()` (line 334)
_Gets rid of the used parts of the buffer._

**Args**: self


#### `_got_extradata()` (line 339)
**Args**: self


#### `_get_extradata()` (line 342)
**Args**: self


#### `read_bytes()` (line 345)
**Args**: self, n


#### `_read()` (line 350)
**Args**: self, n, raise_outofdata


#### `_reserve()` (line 358)
**Args**: self, n, raise_outofdata


#### `_read_header()` (line 392)
**Args**: self


#### `_unpack()` (line 488)
**Args**: self, execute


#### `__iter__()` (line 562)
**Args**: self


#### `__next__()` (line 565)
**Args**: self


#### `skip()` (line 578)
**Args**: self


#### `unpack()` (line 582)
**Args**: self


#### `read_array_header()` (line 590)
**Args**: self


#### `read_map_header()` (line 595)
**Args**: self


#### `tell()` (line 600)
**Args**: self


#### `__init__()` (line 653)
**Args**: self


#### `_pack()` (line 676)
**Args**: self, obj, nest_limit, check, check_type_strict


#### `pack()` (line 800)
**Args**: self, obj


#### `pack_map_pairs()` (line 811)
**Args**: self, pairs


#### `pack_array_header()` (line 818)
**Args**: self, n


#### `pack_map_header()` (line 827)
**Args**: self, n


#### `pack_ext_type()` (line 836)
**Args**: self, typecode, data


#### `_pack_array_header()` (line 865)
**Args**: self, n


#### `_pack_map_header()` (line 874)
**Args**: self, n


#### `_pack_map_pairs()` (line 883)
**Args**: self, n, pairs, nest_limit


#### `_pack_raw_header()` (line 889)
**Args**: self, n


#### `_pack_bin_header()` (line 901)
**Args**: self, n


#### `bytes()` (line 913)
_Return internal buffer contents as bytes object_

**Args**: self


#### `reset()` (line 917)
_Reset internal buffer.

This method is useful only when autoreset=False._

**Args**: self


#### `getbuffer()` (line 924)
_Return view of internal buffer._

**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\packaging\_elffile.py

#### `__init__()` (line 46)
**Args**: self, f


#### `_read()` (line 92)
**Args**: self, fmt


#### `interpreter()` (line 96)
_The path recorded in the ``PT_INTERP`` section header._

**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\packaging\_manylinux.py

#### `_parse_elf()` (line 22)
**Args**: path


#### `_is_linux_armhf()` (line 30)
**Args**: executable


#### `_is_linux_i686()` (line 45)
**Args**: executable


#### `_have_compatible_abi()` (line 55)
**Args**: executable, archs


#### `_glibc_version_string_confstr()` (line 85)
_Primary implementation of glibc_version_string using os.confstr._


#### `_glibc_version_string_ctypes()` (line 104)
_Fallback implementation of glibc_version_string using ctypes._


#### `_glibc_version_string()` (line 148)
_Returns glibc version string, or None if not using glibc._


#### `_parse_glibc_version()` (line 153)
_Parse glibc version.

We use a regexp instead of str.split because we want to discard any
random junk that might come after the minor version -- this might happen
in patched/forked versions of glibc (e.g. Linaro's version of glibc
uses version strings like "2.20-2014.11"). See gh-3588._

**Args**: version_str


#### `_get_glibc_version()` (line 174)

#### `_is_compatible()` (line 182)
**Args**: arch, version


#### `platform_tags()` (line 218)
_Generate manylinux tags compatible to the current platform.

:param archs: Sequence of compatible architectures.
    The first one shall be the closest to the actual architecture and be the part of
    platform tag after the ``linux_`` prefix, e.g. ``x86_64``.
    The ``linux_`` prefix is assumed as a prerequisite for the current platform to
    be manylinux-compatible.

:returns: An iterator of compatible manylinux tags._

**Args**: archs


### venv_new\Lib\site-packages\pip\_vendor\packaging\_musllinux.py

#### `_parse_musl_version()` (line 23)
**Args**: output


#### `_get_musl_version()` (line 34)
_Detect currently-running musl runtime version.

This is done by checking the specified executable's dynamic linking
information, and invoking the loader to parse its output for a version
string. If the loader is musl, the output would be something like::

    musl libc (x86_64)
    Version 1.2.2
    Dynamic Program Loader_

**Args**: executable


#### `platform_tags()` (line 56)
_Generate musllinux tags compatible to the current platform.

:param archs: Sequence of compatible architectures.
    The first one shall be the closest to the actual architecture and be the part of
    platform tag after the ``linux_`` prefix, e.g. ``x86_64``.
    The ``linux_`` prefix is assumed as a prerequisite for the current platform to
    be musllinux-compatible.

:returns: An iterator of compatible musllinux tags._

**Args**: archs


### venv_new\Lib\site-packages\pip\_vendor\packaging\_parser.py

#### `__init__()` (line 16)
**Args**: self, value


#### `__str__()` (line 19)
**Args**: self


#### `__repr__()` (line 22)
**Args**: self


#### `serialize()` (line 25)
**Args**: self


#### `serialize()` (line 30)
**Args**: self


#### `serialize()` (line 35)
**Args**: self


#### `serialize()` (line 40)
**Args**: self


#### `parse_requirement()` (line 61)
**Args**: source


#### `_parse_requirement()` (line 65)
_requirement = WS? IDENTIFIER WS? extras WS? requirement_details_

**Args**: tokenizer


#### `_parse_requirement_details()` (line 86)
_requirement_details = AT URL (WS requirement_marker?)?
                    | specifier WS? (requirement_marker)?_

**Args**: tokenizer


#### `_parse_requirement_marker()` (line 137)
_requirement_marker = SEMICOLON marker WS?_

**Args**: tokenizer


#### `_parse_extras()` (line 157)
_extras = (LEFT_BRACKET wsp* extras_list? wsp* RIGHT_BRACKET)?_

**Args**: tokenizer


#### `_parse_extras_list()` (line 176)
_extras_list = identifier (wsp* ',' wsp* identifier)*_

**Args**: tokenizer


#### `_parse_specifier()` (line 203)
_specifier = LEFT_PARENTHESIS WS? version_many WS? RIGHT_PARENTHESIS
          | WS? version_many WS?_

**Args**: tokenizer


#### `_parse_version_many()` (line 220)
_version_many = (SPECIFIER (WS? COMMA WS? SPECIFIER)*)?_

**Args**: tokenizer


#### `parse_marker()` (line 252)
**Args**: source


#### `_parse_full_marker()` (line 256)
**Args**: tokenizer


#### `_parse_marker()` (line 262)
_marker = marker_atom (BOOLOP marker_atom)+_

**Args**: tokenizer


#### `_parse_marker_atom()` (line 274)
_marker_atom = WS? LEFT_PARENTHESIS WS? marker WS? RIGHT_PARENTHESIS WS?
            | WS? marker_item WS?_

**Args**: tokenizer


#### `_parse_marker_item()` (line 296)
_marker_item = WS? marker_var WS? marker_op WS? marker_var WS?_

**Args**: tokenizer


#### `_parse_marker_var()` (line 310)
_marker_var = VARIABLE | QUOTED_STRING_

**Args**: tokenizer


#### `process_env_var()` (line 324)
**Args**: env_var


#### `process_python_str()` (line 331)
**Args**: python_str


#### `_parse_marker_op()` (line 336)
_marker_op = IN | NOT IN | OP_

**Args**: tokenizer


### venv_new\Lib\site-packages\pip\_vendor\packaging\_structures.py

#### `__repr__()` (line 7)
**Args**: self


#### `__hash__()` (line 10)
**Args**: self


#### `__lt__()` (line 13)
**Args**: self, other


#### `__le__()` (line 16)
**Args**: self, other


#### `__eq__()` (line 19)
**Args**: self, other


#### `__gt__()` (line 22)
**Args**: self, other


#### `__ge__()` (line 25)
**Args**: self, other


#### `__neg__()` (line 28)
**Args**: self


#### `__repr__()` (line 36)
**Args**: self


#### `__hash__()` (line 39)
**Args**: self


#### `__lt__()` (line 42)
**Args**: self, other


#### `__le__()` (line 45)
**Args**: self, other


#### `__eq__()` (line 48)
**Args**: self, other


#### `__gt__()` (line 51)
**Args**: self, other


#### `__ge__()` (line 54)
**Args**: self, other


#### `__neg__()` (line 57)
**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\packaging\_tokenizer.py

#### `__init__()` (line 21)
**Args**: self, message


#### `__str__()` (line 34)
**Args**: self


#### `__init__()` (line 97)
**Args**: self, source


#### `consume()` (line 110)
_Move beyond provided token name, if at current position._

**Args**: self, name


#### `check()` (line 115)
_Check whether the next token has the provided name.

By default, if the check succeeds, the token *must* be read before
another check. If `peek` is set to `True`, the token is not loaded and
would need to be checked again._

**Args**: self, name


#### `expect()` (line 136)
_Expect a certain token name next, failing with a syntax error otherwise.

The token is *not* read._

**Args**: self, name


#### `read()` (line 145)
_Consume the next token and return it._

**Args**: self


#### `raise_syntax_error()` (line 155)
_Raise ParserSyntaxError at the given position._

**Args**: self, message


#### `enclosing_tokens()` (line 174)
**Args**: self, open_token, close_token


### venv_new\Lib\site-packages\pip\_vendor\packaging\licenses\__init__.py

#### `canonicalize_license_expression()` (line 60)
**Args**: raw_license_expression


### venv_new\Lib\site-packages\pip\_vendor\packaging\markers.py

#### `_normalize_extra_values()` (line 121)
_Normalize extra values._

**Args**: results


#### `_format_marker()` (line 137)
**Args**: marker, first


#### `_eval_op()` (line 177)
**Args**: lhs, op, rhs


#### `_normalize()` (line 192)

#### `_evaluate_markers()` (line 204)
**Args**: markers, environment


#### `format_full_version()` (line 234)
**Args**: info


#### `default_environment()` (line 242)

#### `__init__()` (line 261)
**Args**: self, marker


#### `__str__()` (line 286)
**Args**: self


#### `__repr__()` (line 289)
**Args**: self


#### `__hash__()` (line 292)
**Args**: self


#### `__eq__()` (line 295)
**Args**: self, other


#### `evaluate()` (line 301)
_Evaluate a marker.

Return the boolean from evaluating the given marker against the
environment. environment is an optional argument to override all or
part of the determined environment.

The environment is determined from the current Python process._

**Args**: self, environment


#### `_repair_python_full_version()` (line 324)
_Work around platform.python_version() returning something that is not PEP 440
compliant for non-tagged Python builds._

**Args**: env


### venv_new\Lib\site-packages\pip\_vendor\packaging\metadata.py

#### `__init__()` (line 41)
**Args**: self, message, exceptions


#### `__repr__()` (line 45)
**Args**: self


#### `__init__()` (line 55)
**Args**: self, field, message


#### `_parse_keywords()` (line 175)
_Split a string of comma-separated keywords into a list of keywords._

**Args**: data


#### `_parse_project_urls()` (line 180)
_Parse a list of label/URL string pairings separated by a comma._

**Args**: data


#### `_get_payload()` (line 220)
_Get the body of the message._

**Args**: msg, source


#### `parse_email()` (line 286)
_Parse a distribution's metadata stored as email headers (e.g. from ``METADATA``).

This function returns a two-item tuple of dicts. The first dict is of
recognized fields from the core metadata specification. Fields that can be
parsed and translated into Python's built-in types are converted
appropriately. All other fields are left as-is. Fields that are allowed to
appear multiple times are stored as lists.

The second dict contains all other fields from the metadata. This includes
any unrecognized fields. It also includes any fields which are expected to
be parsed into a built-in type but were not formatted appropriately. Finally,
any fields that are expected to appear only once but are repeated are
included in this dict._

**Args**: data


#### `__init__()` (line 486)
**Args**: self


#### `__set_name__()` (line 493)
**Args**: self, _owner, name


#### `__get__()` (line 497)
**Args**: self, instance, _owner


#### `_invalid_metadata()` (line 524)
**Args**: self, msg, cause


#### `_process_metadata_version()` (line 533)
**Args**: self, value


#### `_process_name()` (line 539)
**Args**: self, value


#### `_process_version()` (line 552)
**Args**: self, value


#### `_process_summary()` (line 562)
_Check the field contains no newlines._

**Args**: self, value


#### `_process_description_content_type()` (line 568)
**Args**: self, value


#### `_process_dynamic()` (line 600)
**Args**: self, value


#### `_process_provides_extra()` (line 612)
**Args**: self, value


#### `_process_requires_python()` (line 627)
**Args**: self, value


#### `_process_requires_dist()` (line 635)
**Args**: self, value


#### `_process_license_expression()` (line 650)
**Args**: self, value


#### `_process_license_files()` (line 660)
**Args**: self, value


#### `from_raw()` (line 700)
_Create an instance from :class:`RawMetadata`.

If *validate* is true, all metadata will be validated. All exceptions
related to validation will be gathered and raised as an :class:`ExceptionGroup`._

**Args**: cls, data


#### `from_email()` (line 757)
_Parse metadata from email headers.

If *validate* is true, the metadata will be validated. All exceptions
related to validation will be gathered and raised as an :class:`ExceptionGroup`._

**Args**: cls, data


### venv_new\Lib\site-packages\pip\_vendor\packaging\requirements.py

#### `__init__()` (line 34)
**Args**: self, requirement_string


#### `_iter_parts()` (line 49)
**Args**: self, name


#### `__str__()` (line 67)
**Args**: self


#### `__repr__()` (line 70)
**Args**: self


#### `__hash__()` (line 73)
**Args**: self


#### `__eq__()` (line 81)
**Args**: self, other


### venv_new\Lib\site-packages\pip\_vendor\packaging\specifiers.py

#### `_coerce_version()` (line 26)
**Args**: version


#### `__str__()` (line 46)
_Returns the str representation of this Specifier-like object. This
should be representative of the Specifier itself._

**Args**: self


#### `__hash__()` (line 53)
_Returns a hash value for this Specifier-like object._

**Args**: self


#### `__eq__()` (line 59)
_Returns a boolean representing whether or not the two Specifier-like
objects are equal.

:param other: The other object to check against._

**Args**: self, other


#### `prereleases()` (line 69)
_Whether or not pre-releases as a whole are allowed.

This can be set to either ``True`` or ``False`` to explicitly enable or disable
prereleases or it can be set to ``None`` (the default) to use default semantics._

**Args**: self


#### `prereleases()` (line 77)
_Setter for :attr:`prereleases`.

:param value: The value to set._

**Args**: self, value


#### `contains()` (line 84)
_Determines if the given item is contained within this specifier._

**Args**: self, item, prereleases


#### `filter()` (line 90)
_Takes an iterable of items and filters them so that only items which
are contained within this specifier are allowed in it._

**Args**: self, iterable, prereleases


#### `__init__()` (line 222)
_Initialize a Specifier instance.

:param spec:
    The string representation of a specifier which will be parsed and
    normalized before use.
:param prereleases:
    This tells the specifier if it should accept prerelease versions if
    applicable or not. The default of ``None`` will autodetect it from the
    given specifiers.
:raises InvalidSpecifier:
    If the given specifier is invalid (i.e. bad syntax)._

**Args**: self, spec, prereleases


#### `prereleases()` (line 249)
**Args**: self


#### `prereleases()` (line 273)
**Args**: self, value


#### `operator()` (line 277)
_The operator of this specifier.

>>> Specifier("==1.2.3").operator
'=='_

**Args**: self


#### `version()` (line 286)
_The version of this specifier.

>>> Specifier("==1.2.3").version
'1.2.3'_

**Args**: self


#### `__repr__()` (line 294)
_A representation of the Specifier that shows all internal state.

>>> Specifier('>=1.0.0')
<Specifier('>=1.0.0')>
>>> Specifier('>=1.0.0', prereleases=False)
<Specifier('>=1.0.0', prereleases=False)>
>>> Specifier('>=1.0.0', prereleases=True)
<Specifier('>=1.0.0', prereleases=True)>_

**Args**: self


#### `__str__()` (line 312)
_A string representation of the Specifier that can be round-tripped.

>>> str(Specifier('>=1.0.0'))
'>=1.0.0'
>>> str(Specifier('>=1.0.0', prereleases=False))
'>=1.0.0'_

**Args**: self


#### `_canonical_spec()` (line 323)
**Args**: self


#### `__hash__()` (line 330)
**Args**: self


#### `__eq__()` (line 333)
_Whether or not the two Specifier-like objects are equal.

:param other: The other object to check against.

The value of :attr:`prereleases` is ignored.

>>> Specifier("==1.2.3") == Specifier("== 1.2.3.0")
True
>>> (Specifier("==1.2.3", prereleases=False) ==
...  Specifier("==1.2.3", prereleases=True))
True
>>> Specifier("==1.2.3") == "==1.2.3"
True
>>> Specifier("==1.2.3") == Specifier("==1.2.4")
False
>>> Specifier("==1.2.3") == Specifier("~=1.2.3")
False_

**Args**: self, other


#### `_get_operator()` (line 362)
**Args**: self, op


#### `_compare_compatible()` (line 368)
**Args**: self, prospective, spec


#### `_compare_equal()` (line 388)
**Args**: self, prospective, spec


#### `_compare_not_equal()` (line 428)
**Args**: self, prospective, spec


#### `_compare_less_than_equal()` (line 431)
**Args**: self, prospective, spec


#### `_compare_greater_than_equal()` (line 437)
**Args**: self, prospective, spec


#### `_compare_less_than()` (line 443)
**Args**: self, prospective, spec_str


#### `_compare_greater_than()` (line 467)
**Args**: self, prospective, spec_str


#### `_compare_arbitrary()` (line 497)
**Args**: self, prospective, spec


#### `__contains__()` (line 500)
_Return whether or not the item is contained in this specifier.

:param item: The item to check for.

This is used for the ``in`` operator and behaves the same as
:meth:`contains` with no ``prereleases`` argument passed.

>>> "1.2.3" in Specifier(">=1.2.3")
True
>>> Version("1.2.3") in Specifier(">=1.2.3")
True
>>> "1.0.0" in Specifier(">=1.2.3")
False
>>> "1.3.0a1" in Specifier(">=1.2.3")
False
>>> "1.3.0a1" in Specifier(">=1.2.3", prereleases=True)
True_

**Args**: self, item


#### `contains()` (line 521)
_Return whether or not the item is contained in this specifier.

:param item:
    The item to check for, which can be a version string or a
    :class:`Version` instance.
:param prereleases:
    Whether or not to match prereleases with this Specifier. If set to
    ``None`` (the default), it uses :attr:`prereleases` to determine
    whether or not prereleases are allowed.

>>> Specifier(">=1.2.3").contains("1.2.3")
True
>>> Specifier(">=1.2.3").contains(Version("1.2.3"))
True
>>> Specifier(">=1.2.3").contains("1.0.0")
False
>>> Specifier(">=1.2.3").contains("1.3.0a1")
False
>>> Specifier(">=1.2.3", prereleases=True).contains("1.3.0a1")
True
>>> Specifier(">=1.2.3").contains("1.3.0a1", prereleases=True)
True_

**Args**: self, item, prereleases


#### `filter()` (line 565)
_Filter items in the given iterable, that match the specifier.

:param iterable:
    An iterable that can contain version strings and :class:`Version` instances.
    The items in the iterable will be filtered according to the specifier.
:param prereleases:
    Whether or not to allow prereleases in the returned iterator. If set to
    ``None`` (the default), it will be intelligently decide whether to allow
    prereleases or not (based on the :attr:`prereleases` attribute, and
    whether the only versions matching are prereleases).

This method is smarter than just ``filter(Specifier().contains, [...])``
because it implements the rule from :pep:`440` that a prerelease item
SHOULD be accepted if no other versions match the given specifier.

>>> list(Specifier(">=1.2.3").filter(["1.2", "1.3", "1.5a1"]))
['1.3']
>>> list(Specifier(">=1.2.3").filter(["1.2", "1.2.3", "1.3", Version("1.4")]))
['1.2.3', '1.3', <Version('1.4')>]
>>> list(Specifier(">=1.2.3").filter(["1.2", "1.5a1"]))
['1.5a1']
>>> list(Specifier(">=1.2.3").filter(["1.3", "1.5a1"], prereleases=True))
['1.3', '1.5a1']
>>> list(Specifier(">=1.2.3", prereleases=True).filter(["1.3", "1.5a1"]))
['1.3', '1.5a1']_

**Args**: self, iterable, prereleases


#### `_version_split()` (line 630)
_Split version into components.

The split components are intended for version comparison. The logic does
not attempt to retain the original version string, so joining the
components back with :func:`_version_join` may not produce the original
version string._

**Args**: version


#### `_version_join()` (line 652)
_Join split version components into a version string.

This function assumes the input came from :func:`_version_split`, where the
first component must be the epoch (either empty or numeric), and all other
components numeric._

**Args**: components


#### `_is_not_suffix()` (line 663)
**Args**: segment


#### `_pad_version()` (line 669)
**Args**: left, right


#### `__init__()` (line 697)
_Initialize a SpecifierSet instance.

:param specifiers:
    The string representation of a specifier or a comma-separated list of
    specifiers which will be parsed and normalized before use.
    May also be an iterable of ``Specifier`` instances, which will be used
    as is.
:param prereleases:
    This tells the SpecifierSet if it should accept prerelease versions if
    applicable or not. The default of ``None`` will autodetect it from the
    given specifiers.

:raises InvalidSpecifier:
    If the given ``specifiers`` are not parseable than this exception will be
    raised._

**Args**: self, specifiers, prereleases


#### `prereleases()` (line 736)
**Args**: self


#### `prereleases()` (line 753)
**Args**: self, value


#### `__repr__()` (line 756)
_A representation of the specifier set that shows all internal state.

Note that the ordering of the individual specifiers within the set may not
match the input string.

>>> SpecifierSet('>=1.0.0,!=2.0.0')
<SpecifierSet('!=2.0.0,>=1.0.0')>
>>> SpecifierSet('>=1.0.0,!=2.0.0', prereleases=False)
<SpecifierSet('!=2.0.0,>=1.0.0', prereleases=False)>
>>> SpecifierSet('>=1.0.0,!=2.0.0', prereleases=True)
<SpecifierSet('!=2.0.0,>=1.0.0', prereleases=True)>_

**Args**: self


#### `__str__()` (line 777)
_A string representation of the specifier set that can be round-tripped.

Note that the ordering of the individual specifiers within the set may not
match the input string.

>>> str(SpecifierSet(">=1.0.0,!=1.0.1"))
'!=1.0.1,>=1.0.0'
>>> str(SpecifierSet(">=1.0.0,!=1.0.1", prereleases=False))
'!=1.0.1,>=1.0.0'_

**Args**: self


#### `__hash__()` (line 790)
**Args**: self


#### `__and__()` (line 793)
_Return a SpecifierSet which is a combination of the two sets.

:param other: The other object to combine with.

>>> SpecifierSet(">=1.0.0,!=1.0.1") & '<=2.0.0,!=2.0.1'
<SpecifierSet('!=1.0.1,!=2.0.1,<=2.0.0,>=1.0.0')>
>>> SpecifierSet(">=1.0.0,!=1.0.1") & SpecifierSet('<=2.0.0,!=2.0.1')
<SpecifierSet('!=1.0.1,!=2.0.1,<=2.0.0,>=1.0.0')>_

**Args**: self, other


#### `__eq__()` (line 825)
_Whether or not the two SpecifierSet-like objects are equal.

:param other: The other object to check against.

The value of :attr:`prereleases` is ignored.

>>> SpecifierSet(">=1.0.0,!=1.0.1") == SpecifierSet(">=1.0.0,!=1.0.1")
True
>>> (SpecifierSet(">=1.0.0,!=1.0.1", prereleases=False) ==
...  SpecifierSet(">=1.0.0,!=1.0.1", prereleases=True))
True
>>> SpecifierSet(">=1.0.0,!=1.0.1") == ">=1.0.0,!=1.0.1"
True
>>> SpecifierSet(">=1.0.0,!=1.0.1") == SpecifierSet(">=1.0.0")
False
>>> SpecifierSet(">=1.0.0,!=1.0.1") == SpecifierSet(">=1.0.0,!=1.0.2")
False_

**Args**: self, other


#### `__len__()` (line 851)
_Returns the number of specifiers in this specifier set._

**Args**: self


#### `__iter__()` (line 855)
_Returns an iterator over all the underlying :class:`Specifier` instances
in this specifier set.

>>> sorted(SpecifierSet(">=1.0.0,!=1.0.1"), key=str)
[<Specifier('!=1.0.1')>, <Specifier('>=1.0.0')>]_

**Args**: self


#### `__contains__()` (line 865)
_Return whether or not the item is contained in this specifier.

:param item: The item to check for.

This is used for the ``in`` operator and behaves the same as
:meth:`contains` with no ``prereleases`` argument passed.

>>> "1.2.3" in SpecifierSet(">=1.0.0,!=1.0.1")
True
>>> Version("1.2.3") in SpecifierSet(">=1.0.0,!=1.0.1")
True
>>> "1.0.1" in SpecifierSet(">=1.0.0,!=1.0.1")
False
>>> "1.3.0a1" in SpecifierSet(">=1.0.0,!=1.0.1")
False
>>> "1.3.0a1" in SpecifierSet(">=1.0.0,!=1.0.1", prereleases=True)
True_

**Args**: self, item


#### `contains()` (line 886)
_Return whether or not the item is contained in this SpecifierSet.

:param item:
    The item to check for, which can be a version string or a
    :class:`Version` instance.
:param prereleases:
    Whether or not to match prereleases with this SpecifierSet. If set to
    ``None`` (the default), it uses :attr:`prereleases` to determine
    whether or not prereleases are allowed.

>>> SpecifierSet(">=1.0.0,!=1.0.1").contains("1.2.3")
True
>>> SpecifierSet(">=1.0.0,!=1.0.1").contains(Version("1.2.3"))
True
>>> SpecifierSet(">=1.0.0,!=1.0.1").contains("1.0.1")
False
>>> SpecifierSet(">=1.0.0,!=1.0.1").contains("1.3.0a1")
False
>>> SpecifierSet(">=1.0.0,!=1.0.1", prereleases=True).contains("1.3.0a1")
True
>>> SpecifierSet(">=1.0.0,!=1.0.1").contains("1.3.0a1", prereleases=True)
True_

**Args**: self, item, prereleases, installed


#### `filter()` (line 943)
_Filter items in the given iterable, that match the specifiers in this set.

:param iterable:
    An iterable that can contain version strings and :class:`Version` instances.
    The items in the iterable will be filtered according to the specifier.
:param prereleases:
    Whether or not to allow prereleases in the returned iterator. If set to
    ``None`` (the default), it will be intelligently decide whether to allow
    prereleases or not (based on the :attr:`prereleases` attribute, and
    whether the only versions matching are prereleases).

This method is smarter than just ``filter(SpecifierSet(...).contains, [...])``
because it implements the rule from :pep:`440` that a prerelease item
SHOULD be accepted if no other versions match the given specifier.

>>> list(SpecifierSet(">=1.2.3").filter(["1.2", "1.3", "1.5a1"]))
['1.3']
>>> list(SpecifierSet(">=1.2.3").filter(["1.2", "1.3", Version("1.4")]))
['1.3', <Version('1.4')>]
>>> list(SpecifierSet(">=1.2.3").filter(["1.2", "1.5a1"]))
[]
>>> list(SpecifierSet(">=1.2.3").filter(["1.3", "1.5a1"], prereleases=True))
['1.3', '1.5a1']
>>> list(SpecifierSet(">=1.2.3", prereleases=True).filter(["1.3", "1.5a1"]))
['1.3', '1.5a1']

An "empty" SpecifierSet will filter items based on the presence of prerelease
versions in the set.

>>> list(SpecifierSet("").filter(["1.3", "1.5a1"]))
['1.3']
>>> list(SpecifierSet("").filter(["1.5a1"]))
['1.5a1']
>>> list(SpecifierSet("", prereleases=True).filter(["1.3", "1.5a1"]))
['1.3', '1.5a1']
>>> list(SpecifierSet("").filter(["1.3", "1.5a1"], prereleases=True))
['1.3', '1.5a1']_

**Args**: self, iterable, prereleases


### venv_new\Lib\site-packages\pip\_vendor\packaging\tags.py

#### `__init__()` (line 52)
**Args**: self, interpreter, abi, platform


#### `interpreter()` (line 64)
**Args**: self


#### `abi()` (line 68)
**Args**: self


#### `platform()` (line 72)
**Args**: self


#### `__eq__()` (line 75)
**Args**: self, other


#### `__hash__()` (line 86)
**Args**: self


#### `__str__()` (line 89)
**Args**: self


#### `__repr__()` (line 92)
**Args**: self


#### `parse_tag()` (line 96)
_Parses the provided tag (e.g. `py3-none-any`) into a frozenset of Tag instances.

Returning a set is required due to the possibility that the tag is a
compressed tag set._

**Args**: tag


#### `_get_config_var()` (line 112)
**Args**: name, warn


#### `_normalize_string()` (line 121)
**Args**: string


#### `_is_threaded_cpython()` (line 125)
_Determine if the ABI corresponds to a threaded (`--disable-gil`) build.

The threaded builds are indicated by a "t" in the abiflags._

**Args**: abis


#### `_abi3_applies()` (line 141)
_Determine if the Python version supports abi3.

PEP 384 was first implemented in Python 3.2. The threaded (`--disable-gil`)
builds do not support abi3._

**Args**: python_version, threading


#### `_cpython_abis()` (line 151)
**Args**: py_version, warn


#### `cpython_tags()` (line 184)
_Yields the tags for a CPython interpreter.

The tags consist of:
- cp<python_version>-<abi>-<platform>
- cp<python_version>-abi3-<platform>
- cp<python_version>-none-<platform>
- cp<less than python_version>-abi3-<platform>  # Older Python versions down to 3.2.

If python_version only specifies a major version then user-provided ABIs and
the 'none' ABItag will be used.

If 'abi3' or 'none' are specified in 'abis' then they will be yielded at
their normal position and not at the beginning._

**Args**: python_version, abis, platforms


#### `_generic_abi()` (line 243)
_Return the ABI tag based on EXT_SUFFIX._


#### `generic_tags()` (line 284)
_Yields the tags for a generic interpreter.

The tags consist of:
- <interpreter>-<abi>-<platform>

The "none" ABI will be added if it was not explicitly provided._

**Args**: interpreter, abis, platforms


#### `_py_interpreter_range()` (line 315)
_Yields Python versions in descending order.

After the latest version, the major-only version will be yielded, and then
all previous versions of that major version._

**Args**: py_version


#### `compatible_tags()` (line 330)
_Yields the sequence of tags that are compatible with a specific version of Python.

The tags consist of:
- py*-none-<platform>
- <interpreter>-none-any  # ... if `interpreter` is provided.
- py*-none-any_

**Args**: python_version, interpreter, platforms


#### `_mac_arch()` (line 355)
**Args**: arch, is_32bit


#### `_mac_binary_formats()` (line 365)
**Args**: version, cpu_arch


#### `mac_platforms()` (line 397)
_Yields the platform tags for a macOS system.

The `version` parameter is a two-item tuple specifying the macOS version to
generate platform tags for. The `arch` parameter is the CPU architecture to
generate platform tags for. Both parameters default to the appropriate value
for the current system._

**Args**: version, arch


#### `ios_platforms()` (line 476)
_Yields the platform tags for an iOS system.

:param version: A two-item tuple specifying the iOS version to generate
    platform tags for. Defaults to the current iOS version.
:param multiarch: The CPU architecture+ABI to generate platform tags for -
    (the value used by `sys.implementation._multiarch` e.g.,
    `arm64_iphoneos` or `x84_64_iphonesimulator`). Defaults to the current
    multiarch value._

**Args**: version, multiarch


#### `_linux_platforms()` (line 533)
**Args**: is_32bit


#### `_generic_platforms()` (line 552)

#### `platform_tags()` (line 556)
_Provides the platform tags for this installation._


#### `interpreter_name()` (line 570)
_Returns the name of the running interpreter.

Some implementations have a reserved, two-letter abbreviation which will
be returned when appropriate._


#### `interpreter_version()` (line 581)
_Returns the version of the running interpreter._


#### `_version_nodot()` (line 593)
**Args**: version


#### `sys_tags()` (line 597)
_Returns the sequence of tag triples for the running interpreter.

The order of the sequence corresponds to priority order for the
interpreter, from most to least important._


### venv_new\Lib\site-packages\pip\_vendor\packaging\utils.py

#### `canonicalize_name()` (line 46)
**Args**: name


#### `is_normalized_name()` (line 54)
**Args**: name


#### `canonicalize_version()` (line 59)
_Return a canonical form of a version as a string.

>>> canonicalize_version('1.0.1')
'1.0.1'

Per PEP 625, versions may have multiple canonical forms, differing
only by trailing zeros.

>>> canonicalize_version('1.0.0')
'1'
>>> canonicalize_version('1.0.0', strip_trailing_zero=False)
'1.0.0'

Invalid versions are returned unaltered.

>>> canonicalize_version('foo bar baz')
'foo bar baz'_

**Args**: version


#### `_()` (line 85)
**Args**: version


#### `parse_wheel_filename()` (line 94)
**Args**: filename


#### `parse_sdist_filename()` (line 137)
**Args**: filename


### venv_new\Lib\site-packages\pip\_vendor\packaging\version.py

#### `parse()` (line 47)
_Parse the given version string.

>>> parse('1.0.dev1')
<Version('1.0.dev1')>

:param version: The version string to parse.
:raises InvalidVersion: When the version string is not a valid version._

**Args**: version


#### `__hash__()` (line 72)
**Args**: self


#### `__lt__()` (line 78)
**Args**: self, other


#### `__le__()` (line 84)
**Args**: self, other


#### `__eq__()` (line 90)
**Args**: self, other


#### `__ge__()` (line 96)
**Args**: self, other


#### `__gt__()` (line 102)
**Args**: self, other


#### `__ne__()` (line 108)
**Args**: self, other


#### `__init__()` (line 188)
_Initialize a Version object.

:param version:
    The string representation of a version which will be parsed and normalized
    before use.
:raises InvalidVersion:
    If the ``version`` does not conform to PEP 440 in any way then this
    exception will be raised._

**Args**: self, version


#### `__repr__()` (line 226)
_A representation of the Version that shows all internal state.

>>> Version('1.0.0')
<Version('1.0.0')>_

**Args**: self


#### `__str__()` (line 234)
_A string representation of the version that can be round-tripped.

>>> str(Version("1.0a5"))
'1.0a5'_

**Args**: self


#### `epoch()` (line 268)
_The epoch of the version.

>>> Version("2.0.0").epoch
0
>>> Version("1!2.0.0").epoch
1_

**Args**: self


#### `release()` (line 279)
_The components of the "release" segment of the version.

>>> Version("1.2.3").release
(1, 2, 3)
>>> Version("2.0.0").release
(2, 0, 0)
>>> Version("1!2.0.0.post0").release
(2, 0, 0)

Includes trailing zeroes but not the epoch or any pre-release / development /
post-release suffixes._

**Args**: self


#### `pre()` (line 295)
_The pre-release segment of the version.

>>> print(Version("1.2.3").pre)
None
>>> Version("1.2.3a1").pre
('a', 1)
>>> Version("1.2.3b1").pre
('b', 1)
>>> Version("1.2.3rc1").pre
('rc', 1)_

**Args**: self


#### `post()` (line 310)
_The post-release number of the version.

>>> print(Version("1.2.3").post)
None
>>> Version("1.2.3.post1").post
1_

**Args**: self


#### `dev()` (line 321)
_The development number of the version.

>>> print(Version("1.2.3").dev)
None
>>> Version("1.2.3.dev1").dev
1_

**Args**: self


#### `local()` (line 332)
_The local version segment of the version.

>>> print(Version("1.2.3").local)
None
>>> Version("1.2.3+abc").local
'abc'_

**Args**: self


#### `public()` (line 346)
_The public portion of the version.

>>> Version("1.2.3").public
'1.2.3'
>>> Version("1.2.3+abc").public
'1.2.3'
>>> Version("1!1.2.3dev1+abc").public
'1!1.2.3.dev1'_

**Args**: self


#### `base_version()` (line 359)
_The "base version" of the version.

>>> Version("1.2.3").base_version
'1.2.3'
>>> Version("1.2.3+abc").base_version
'1.2.3'
>>> Version("1!1.2.3dev1+abc").base_version
'1!1.2.3'

The "base version" is the public version of the project without any pre or post
release markers._

**Args**: self


#### `is_prerelease()` (line 384)
_Whether this version is a pre-release.

>>> Version("1.2.3").is_prerelease
False
>>> Version("1.2.3a1").is_prerelease
True
>>> Version("1.2.3b1").is_prerelease
True
>>> Version("1.2.3rc1").is_prerelease
True
>>> Version("1.2.3dev1").is_prerelease
True_

**Args**: self


#### `is_postrelease()` (line 401)
_Whether this version is a post-release.

>>> Version("1.2.3").is_postrelease
False
>>> Version("1.2.3.post1").is_postrelease
True_

**Args**: self


#### `is_devrelease()` (line 412)
_Whether this version is a development release.

>>> Version("1.2.3").is_devrelease
False
>>> Version("1.2.3.dev1").is_devrelease
True_

**Args**: self


#### `major()` (line 423)
_The first item of :attr:`release` or ``0`` if unavailable.

>>> Version("1.2.3").major
1_

**Args**: self


#### `minor()` (line 432)
_The second item of :attr:`release` or ``0`` if unavailable.

>>> Version("1.2.3").minor
2
>>> Version("1").minor
0_

**Args**: self


#### `micro()` (line 443)
_The third item of :attr:`release` or ``0`` if unavailable.

>>> Version("1.2.3").micro
3
>>> Version("1").micro
0_

**Args**: self


#### `release()` (line 456)
_Release segment without any trailing zeros.

>>> _TrimmedRelease('1.0.0').release
(1,)
>>> _TrimmedRelease('0.0').release
(0,)_

**Args**: self


#### `_parse_letter_version()` (line 471)
**Args**: letter, number


#### `_parse_local_version()` (line 511)
_Takes a string like abc.1.twelve and turns it into ("abc", 1, "twelve")._

**Args**: local


#### `_cmpkey()` (line 523)
**Args**: epoch, release, pre, post, dev, local


### venv_new\Lib\site-packages\pip\_vendor\pkg_resources\__init__.py

#### `load_module()` (line 136)

#### `_declare_state()` (line 159)
**Args**: vartype, varname, initial_value


#### `__getstate__()` (line 164)

#### `__setstate__()` (line 172)
**Args**: state


#### `_sget_dict()` (line 179)
**Args**: val


#### `_sset_dict()` (line 183)
**Args**: key, ob, state


#### `_sget_object()` (line 188)
**Args**: val


#### `_sset_object()` (line 192)
**Args**: key, ob, state


#### `get_supported_platform()` (line 199)
_Return this platform's maximum compatible version.

distutils.util.get_platform() normally reports the minimum version
of macOS that would be required to *use* extensions produced by
distutils.  But what we want when checking compatibility is to know the
version of macOS that we are *running*.  To allow usage of packages that
explicitly require a newer version of macOS, we must also know the
current version of the OS.

If this condition occurs for any other platform with a version in its
platform strings, this function should be extended accordingly._


#### `__repr__()` (line 312)
**Args**: self


#### `dist()` (line 327)
**Args**: self


#### `req()` (line 331)
**Args**: self


#### `report()` (line 334)
**Args**: self


#### `with_context()` (line 337)
_If required_by is non-empty, return a version of self that is a
ContextualVersionConflict._

**Args**: self, required_by


#### `required_by()` (line 357)
**Args**: self


#### `req()` (line 370)
**Args**: self


#### `requirers()` (line 374)
**Args**: self


#### `requirers_str()` (line 378)
**Args**: self


#### `report()` (line 383)
**Args**: self


#### `__str__()` (line 386)
**Args**: self


#### `register_loader_type()` (line 404)
_Register `provider_factory` to make providers for `loader_type`

`loader_type` is the type or class of a PEP 302 ``module.__loader__``,
and `provider_factory` is a function that, passed a *module* object,
returns an ``IResourceProvider`` for that module._

**Args**: loader_type, provider_factory


#### `get_provider()` (line 417)
**Args**: moduleOrReq


#### `get_provider()` (line 419)
**Args**: moduleOrReq


#### `get_provider()` (line 420)
_Return an IResourceProvider for the named module or requirement_

**Args**: moduleOrReq


#### `_macos_vers()` (line 434)

#### `_macos_arch()` (line 447)
**Args**: machine


#### `get_build_platform()` (line 451)
_Return this platform's string for platform-specific distributions

XXX Currently this is the same as ``distutils.util.get_platform()``, but it
needs some hacks for Linux and macOS._


#### `compatible_platforms()` (line 482)
_Can code for the `provided` platform run on the `required` platform?

Returns true if either platform is ``None``, or the platforms are equal.

XXX Needs compatibility checks for Linux and other unixy OSes._

**Args**: provided, required


#### `get_distribution()` (line 532)
**Args**: dist


#### `get_distribution()` (line 534)
**Args**: dist


#### `get_distribution()` (line 535)
_Return a current distribution object for a Requirement or string_

**Args**: dist


#### `load_entry_point()` (line 547)
_Return `name` entry point of `group` for `dist` or raise ImportError_

**Args**: dist, group, name


#### `get_entry_map()` (line 553)
**Args**: dist, group


#### `get_entry_map()` (line 557)
**Args**: dist, group


#### `get_entry_map()` (line 558)
_Return the entry point map for `group`, or the full entry map_

**Args**: dist, group


#### `get_entry_info()` (line 563)
_Return the EntryPoint object for `group`+`name`, or ``None``_

**Args**: dist, group, name


#### `has_metadata()` (line 569)
_Does the package's distribution contain the named metadata?_

**Args**: self, name


#### `get_metadata()` (line 572)
_The named metadata resource as a string_

**Args**: self, name


#### `get_metadata_lines()` (line 575)
_Yield named metadata resource as list of non-blank non-comment lines

Leading and trailing whitespace is stripped from each line, and lines
with ``#`` as the first non-blank character are omitted._

**Args**: self, name


#### `metadata_isdir()` (line 581)
_Is the named metadata a directory?  (like ``os.path.isdir()``)_

**Args**: self, name


#### `metadata_listdir()` (line 584)
_List of metadata names in the directory (like ``os.listdir()``)_

**Args**: self, name


#### `run_script()` (line 587)
_Execute the named script in the supplied namespace dictionary_

**Args**: self, script_name, namespace


#### `get_resource_filename()` (line 594)
_Return a true filesystem path for `resource_name`

`manager` must be a ``ResourceManager``_

**Args**: self, manager, resource_name


#### `get_resource_stream()` (line 601)
_Return a readable file-like object for `resource_name`

`manager` must be a ``ResourceManager``_

**Args**: self, manager, resource_name


#### `get_resource_string()` (line 608)
_Return the contents of `resource_name` as :obj:`bytes`

`manager` must be a ``ResourceManager``_

**Args**: self, manager, resource_name


#### `has_resource()` (line 615)
_Does the package contain the named resource?_

**Args**: self, resource_name


#### `resource_isdir()` (line 618)
_Is the named resource a directory?  (like ``os.path.isdir()``)_

**Args**: self, resource_name


#### `resource_listdir()` (line 621)
_List of resource names in the directory (like ``os.listdir()``)_

**Args**: self, resource_name


#### `__init__()` (line 628)
_Create working set from list of path entries (default=sys.path)_

**Args**: self, entries


#### `_build_master()` (line 643)
_Prepare the master working set._

**Args**: cls


#### `_build_from_requirements()` (line 663)
_Build a working set from a requirement spec. Rewrites sys.path._

**Args**: cls, req_spec


#### `add_entry()` (line 684)
_Add a path item to ``.entries``, finding any distributions on it

``find_distributions(entry, True)`` is used to find distributions
corresponding to the path entry, and they are added.  `entry` is
always appended to ``.entries``, even if it is already present.
(This is because ``sys.path`` can contain the same value more than
once, and the ``.entries`` of the ``sys.path`` WorkingSet should always
equal ``sys.path``.)_

**Args**: self, entry


#### `__contains__()` (line 699)
_True if `dist` is the active distribution for its project_

**Args**: self, dist


#### `find()` (line 703)
_Find a distribution matching requirement `req`

If there is an active distribution for the requested project, this
returns it as long as it meets the version requirement specified by
`req`.  But, if there is an active distribution for the project and it
does *not* meet the `req` requirement, ``VersionConflict`` is raised.
If there is no active distribution for the requested project, ``None``
is returned._

**Args**: self, req


#### `iter_entry_points()` (line 727)
_Yield entry point objects from `group` matching `name`

If `name` is None, yields all entry points in `group` from all
distributions in the working set, otherwise only ones matching
both `group` and `name` are yielded (in distribution order)._

**Args**: self, group, name


#### `run_script()` (line 741)
_Locate distribution for `requires` and run `script_name` script_

**Args**: self, requires, script_name


#### `__iter__()` (line 749)
_Yield distributions for non-duplicate projects in the working set

The yield order is the order in which the items' path entries were
added to the working set._

**Args**: self


#### `add()` (line 766)
_Add `dist` to working set, associated with `entry`

If `entry` is unspecified, it defaults to the ``.location`` of `dist`.
On exit from this routine, `entry` is added to the end of the working
set's ``.entries`` (if it wasn't already present).

`dist` is only added to the working set if it's for a project that
doesn't already have a distribution in the set, unless `replace=True`.
If it's added, any callbacks registered with the ``subscribe()`` method
will be called._

**Args**: self, dist, entry, insert, replace


#### `resolve()` (line 805)
**Args**: self, requirements, env, installer, replace_conflicting, extras


#### `resolve()` (line 814)
**Args**: self, requirements, env


#### `resolve()` (line 824)
**Args**: self, requirements, env, installer, replace_conflicting, extras


#### `resolve()` (line 832)
_List all distributions needed to (recursively) meet `requirements`

`requirements` must be a sequence of ``Requirement`` objects.  `env`,
if supplied, should be an ``Environment`` instance.  If
not supplied, it defaults to all distributions available within any
entry or distribution in the working set.  `installer`, if supplied,
will be invoked with each requirement that cannot be met by an
already-installed distribution; it should return a ``Distribution`` or
``None``.

Unless `replace_conflicting=True`, raises a VersionConflict exception
if
any requirements are found on the path that have the correct name but
the wrong version.  Otherwise, if an `installer` is supplied it will be
invoked to obtain the correct version of the requirement and activate
it.

`extras` is a list of the extras to be used with these requirements.
This is important because extra requirements may look like `my_req;
extra = "my_extra"`, which would otherwise be interpreted as a purely
optional requirement.  Instead, we want to be able to assert that these
requirements are truly required._

**Args**: self, requirements, env, installer, replace_conflicting, extras


#### `_resolve_dist()` (line 906)
**Args**: self, req, best, replace_conflicting, env, installer, required_by, to_activate


#### `find_plugins()` (line 938)
**Args**: self, plugin_env, full_env, installer, fallback


#### `find_plugins()` (line 946)
**Args**: self, plugin_env, full_env


#### `find_plugins()` (line 955)
**Args**: self, plugin_env, full_env, installer, fallback


#### `find_plugins()` (line 962)
_Find all activatable distributions in `plugin_env`

Example usage::

    distributions, errors = working_set.find_plugins(
        Environment(plugin_dirlist)
    )
    # add plugins+libs to sys.path
    map(working_set.add, distributions)
    # display errors
    print('Could not load', errors)

The `plugin_env` should be an ``Environment`` instance that contains
only distributions that are in the project's "plugin directory" or
directories. The `full_env`, if supplied, should be an ``Environment``
contains all currently-available distributions.  If `full_env` is not
supplied, one is created automatically from the ``WorkingSet`` this
method is called on, which will typically mean that every directory on
``sys.path`` will be scanned for distributions.

`installer` is a standard installer callback as used by the
``resolve()`` method. The `fallback` flag indicates whether we should
attempt to resolve older versions of a plugin if the newest version
cannot be resolved.

This method returns a 2-tuple: (`distributions`, `error_info`), where
`distributions` is a list of the distributions found in `plugin_env`
that were loadable, along with any other distributions that are needed
to resolve their dependencies.  `error_info` is a dictionary mapping
unloadable plugin distributions to an exception instance describing the
error that occurred. Usually this will be a ``DistributionNotFound`` or
``VersionConflict`` instance._

**Args**: self, plugin_env, full_env, installer, fallback


#### `require()` (line 1052)
_Ensure that distributions matching `requirements` are activated

`requirements` must be a string or a (possibly-nested) sequence
thereof, specifying the distributions and versions required.  The
return value is a sequence of the distributions that needed to be
activated to fulfill the requirements; all relevant distributions are
included, even if they were already activated in this working set._

**Args**: self


#### `subscribe()` (line 1068)
_Invoke `callback` for all distributions

If `existing=True` (default),
call on all existing ones, as well._

**Args**: self, callback, existing


#### `_added_new()` (line 1084)
**Args**: self, dist


#### `__getstate__()` (line 1088)
**Args**: self


#### `__setstate__()` (line 1097)
**Args**: self, e_k_b_n_c


#### `markers_pass()` (line 1111)
_Evaluate markers for req against each extra that
demanded it.

Return False if the req has a marker and fails
evaluation. Otherwise, return True._

**Args**: self, req, extras


#### `__init__()` (line 1129)
_Snapshot distributions available on a search path

Any distributions found on `search_path` are added to the environment.
`search_path` should be a sequence of ``sys.path`` items.  If not
supplied, ``sys.path`` is used.

`platform` is an optional string specifying the name of the platform
that platform-specific distributions must be compatible with.  If
unspecified, it defaults to the current platform.  `python` is an
optional string naming the desired version of Python (e.g. ``'3.6'``);
it defaults to the current version.

You may explicitly set `platform` (and/or `python`) to ``None`` if you
wish to map *all* distributions, not just those compatible with the
running platform or Python version._

**Args**: self, search_path, platform, python


#### `can_add()` (line 1156)
_Is distribution `dist` acceptable for this environment?

The distribution must match the platform and python version
requirements specified when this environment was created, or False
is returned._

**Args**: self, dist


#### `remove()` (line 1170)
_Remove `dist` from the environment_

**Args**: self, dist


#### `scan()` (line 1174)
_Scan `search_path` for distributions usable in this environment

Any distributions found are added to the environment.
`search_path` should be a sequence of ``sys.path`` items.  If not
supplied, ``sys.path`` is used.  Only distributions conforming to
the platform/python version defined at initialization are added._

**Args**: self, search_path


#### `__getitem__()` (line 1189)
_Return a newest-to-oldest list of distributions for `project_name`

Uses case-insensitive `project_name` comparison, assuming all the
project's distributions use their project's name converted to all
lowercase as their key._

**Args**: self, project_name


#### `add()` (line 1200)
_Add `dist` if we ``can_add()`` it and it has not already been added_

**Args**: self, dist


#### `best_match()` (line 1209)
**Args**: self, req, working_set, installer, replace_conflicting


#### `best_match()` (line 1217)
**Args**: self, req, working_set, installer, replace_conflicting


#### `best_match()` (line 1224)
_Find distribution best matching `req` and usable on `working_set`

This calls the ``find(req)`` method of the `working_set` to see if a
suitable distribution is already active.  (This may raise
``VersionConflict`` if an unsuitable version of the project is already
active in the specified `working_set`.)  If a suitable distribution
isn't active, this method returns the newest distribution in the
environment that meets the ``Requirement`` in `req`.  If no suitable
distribution is found, and `installer` is supplied, then the result of
calling the environment's ``obtain(req, installer)`` method will be
returned._

**Args**: self, req, working_set, installer, replace_conflicting


#### `obtain()` (line 1258)
**Args**: self, requirement, installer


#### `obtain()` (line 1264)
**Args**: self, requirement, installer


#### `obtain()` (line 1270)
**Args**: self, requirement, installer


#### `obtain()` (line 1275)
_Obtain a distribution matching `requirement` (e.g. via download)

Obtain a distro that matches requirement (e.g. via download).  In the
base ``Environment`` class, this routine just returns
``installer(requirement)``, unless `installer` is None, in which case
None is returned instead.  This method is a hook that allows subclasses
to attempt other ways of obtaining a distribution before falling back
to the `installer` argument._

**Args**: self, requirement, installer


#### `__iter__()` (line 1293)
_Yield the unique project names of the available distributions_

**Args**: self


#### `__iadd__()` (line 1299)
_In-place addition of a distribution or environment_

**Args**: self, other


#### `__add__()` (line 1311)
_Add an environment or distribution to an environment_

**Args**: self, other


#### `__init__()` (line 1348)
**Args**: self


#### `resource_exists()` (line 1351)
_Does the named resource exist?_

**Args**: self, package_or_requirement, resource_name


#### `resource_isdir()` (line 1355)
_Is the named resource an existing directory?_

**Args**: self, package_or_requirement, resource_name


#### `resource_filename()` (line 1359)
_Return a true filesystem path for specified resource_

**Args**: self, package_or_requirement, resource_name


#### `resource_stream()` (line 1367)
_Return a readable file-like object for specified resource_

**Args**: self, package_or_requirement, resource_name


#### `resource_string()` (line 1373)
_Return specified resource as :obj:`bytes`_

**Args**: self, package_or_requirement, resource_name


#### `resource_listdir()` (line 1381)
_List the contents of the named resource directory_

**Args**: self, package_or_requirement, resource_name


#### `extraction_error()` (line 1385)
_Give an error message for problems extracting file(s)_

**Args**: self


#### `get_cache_path()` (line 1415)
_Return absolute location in cache for `archive_name` and `names`

The parent directory of the resulting path will be created if it does
not already exist.  `archive_name` should be the base filename of the
enclosing egg (which may not be the name of the enclosing zipfile!),
including its ".egg" extension.  `names`, if provided, should be a
sequence of path name parts "under" the egg's extraction location.

This method should only be called by resource providers that need to
obtain an extraction location, and only for names they intend to
extract, as it tracks the generated names for possible cleanup later._

**Args**: self, archive_name, names


#### `_warn_unsafe_extraction_path()` (line 1441)
_If the default extraction path is overridden and set to an insecure
location, such as /tmp, it opens up an opportunity for an attacker to
replace an extracted file with an unauthorized payload. Warn the user
if a known insecure location is used.

See Distribute #375 for more details._

**Args**: path


#### `postprocess()` (line 1467)
_Perform any platform-specific postprocessing of `tempname`

This is where Mac header rewrites should be done; other platforms don't
have anything special they should do.

Resource providers should call this method ONLY after successfully
extracting a compressed resource.  They must NOT call it on resources
that are already in the filesystem.

`tempname` is the current (temporary) name of the file, and `filename`
is the name it will be renamed to by the caller after this routine
returns._

**Args**: self, tempname, filename


#### `set_extraction_path()` (line 1487)
_Set the base path where resources will be extracted to, if needed.

If you do not call this routine before any extractions take place, the
path defaults to the return value of ``get_default_cache()``.  (Which
is based on the ``PYTHON_EGG_CACHE`` environment variable, with various
platform-specific fallbacks.  See that routine's documentation for more
details.)

Resources are extracted to subdirectories of this path based upon
information given by the ``IResourceProvider``.  You may set this to a
temporary directory, but then you must call ``cleanup_resources()`` to
delete the extracted files when done.  There is no guarantee that
``cleanup_resources()`` will be able to remove all extracted files.

(Note: you may not change the extraction path for a given resource
manager once resources have been extracted, unless you first call
``cleanup_resources()``.)_

**Args**: self, path


#### `cleanup_resources()` (line 1511)
_Delete all extracted resource files and directories, returning a list
of the file and directory names that could not be successfully removed.
This function does not have any concurrency protection, so it should
generally only be called when the extraction path is a temporary
directory exclusive to a single process.  This method is not
automatically called; you must call it explicitly or register it as an
``atexit`` function if you wish to ensure cleanup of a temporary
directory used for extractions._

**Args**: self, force


#### `get_default_cache()` (line 1526)
_Return the ``PYTHON_EGG_CACHE`` environment variable
or a platform-relevant user cache dir for an app
named "Python-Eggs"._


#### `safe_name()` (line 1535)
_Convert an arbitrary string to a standard distribution name

Any runs of non-alphanumeric/. characters are replaced with a single '-'._

**Args**: name


#### `safe_version()` (line 1543)
_Convert an arbitrary string to a standard version string_

**Args**: version


#### `_forgiving_version()` (line 1555)
_Fallback when ``safe_version`` is not safe enough
>>> parse_version(_forgiving_version('0.23ubuntu1'))
<Version('0.23.dev0+sanitized.ubuntu1')>
>>> parse_version(_forgiving_version('0.23-'))
<Version('0.23.dev0+sanitized')>
>>> parse_version(_forgiving_version('0.-_'))
<Version('0.dev0+sanitized')>
>>> parse_version(_forgiving_version('42.+?1'))
<Version('42.dev0+sanitized.1')>
>>> parse_version(_forgiving_version('hello world'))
<Version('0.dev0+sanitized.hello.world')>_

**Args**: version


#### `_safe_segment()` (line 1580)
_Convert an arbitrary string into a safe segment_

**Args**: segment


#### `safe_extra()` (line 1587)
_Convert an arbitrary string to a standard 'extra' name

Any runs of non-alphanumeric characters are replaced with a single '_',
and the result is always lowercased._

**Args**: extra


#### `to_filename()` (line 1596)
_Convert a project or version name to its filename-escaped form

Any '-' characters are currently replaced with '_'._

**Args**: name


#### `invalid_marker()` (line 1604)
_Validate text as a PEP 508 environment marker; return an exception
if invalid or False otherwise._

**Args**: text


#### `evaluate_marker()` (line 1618)
_Evaluate a PEP 508 environment marker.
Return a boolean indicating the marker result in this environment.
Raise SyntaxError if marker is invalid.

This implementation uses the 'pyparsing' module._

**Args**: text, extra


#### `__init__()` (line 1640)
**Args**: self, module


#### `get_resource_filename()` (line 1644)
**Args**: self, manager, resource_name


#### `get_resource_stream()` (line 1647)
**Args**: self, manager, resource_name


#### `get_resource_string()` (line 1650)
**Args**: self, manager, resource_name


#### `has_resource()` (line 1655)
**Args**: self, resource_name


#### `_get_metadata_path()` (line 1658)
**Args**: self, name


#### `has_metadata()` (line 1661)
**Args**: self, name


#### `get_metadata()` (line 1668)
**Args**: self, name


#### `get_metadata_lines()` (line 1681)
**Args**: self, name


#### `resource_isdir()` (line 1684)
**Args**: self, resource_name


#### `metadata_isdir()` (line 1687)
**Args**: self, name


#### `resource_listdir()` (line 1690)
**Args**: self, resource_name


#### `metadata_listdir()` (line 1693)
**Args**: self, name


#### `run_script()` (line 1698)
**Args**: self, script_name, namespace


#### `_has()` (line 1727)
**Args**: self, path


#### `_isdir()` (line 1732)
**Args**: self, path


#### `_listdir()` (line 1737)
**Args**: self, path


#### `_fn()` (line 1742)
**Args**: self, base, resource_name


#### `_validate_resource_path()` (line 1753)
_Validate the resource paths according to the docs.
https://setuptools.pypa.io/en/latest/pkg_resources.html#basic-resource-access

>>> warned = getfixture('recwarn')
>>> warnings.simplefilter('always')
>>> vrp = NullProvider._validate_resource_path
>>> vrp('foo/bar.txt')
>>> bool(warned)
False
>>> vrp('../foo/bar.txt')
>>> bool(warned)
True
>>> warned.clear()
>>> vrp('/foo/bar.txt')
>>> bool(warned)
True
>>> vrp('foo/../../bar.txt')
>>> bool(warned)
True
>>> warned.clear()
>>> vrp('foo/f../bar.txt')
>>> bool(warned)
False

Windows path separators are straight-up disallowed.
>>> vrp(r'\foo/bar.txt')
Traceback (most recent call last):
...
ValueError: Use of .. or absolute path in a resource path is not allowed.

>>> vrp(r'C:\foo/bar.txt')
Traceback (most recent call last):
...
ValueError: Use of .. or absolute path in a resource path is not allowed.

Blank values are allowed

>>> vrp('')
>>> bool(warned)
False

Non-string values are not.

>>> vrp(None)
Traceback (most recent call last):
...
AttributeError: ..._

**Args**: path


#### `_get()` (line 1827)
**Args**: self, path


#### `_parents()` (line 1839)
_yield all parents of path including path_

**Args**: path


#### `__init__()` (line 1853)
**Args**: self, module


#### `_setup_prefix()` (line 1857)
**Args**: self


#### `_set_egg()` (line 1864)
**Args**: self, path


#### `_has()` (line 1873)
**Args**: self, path


#### `_isdir()` (line 1876)
**Args**: self, path


#### `_listdir()` (line 1879)
**Args**: self, path


#### `get_resource_stream()` (line 1882)
**Args**: self, manager, resource_name


#### `_get()` (line 1885)
**Args**: self, path


#### `_register()` (line 1890)
**Args**: cls


#### `_get()` (line 1911)
**Args**: self, path


#### `_listdir()` (line 1914)
**Args**: self, path


#### `__init__()` (line 1917)
**Args**: self


#### `build()` (line 1931)
_Build a dictionary similar to the zipimport directory
caches, except instead of tuples, store ZipInfo objects.

Use a platform-specific path separator (os.sep) for the path keys
for compatibility with pypy on Windows._

**Args**: cls, path


#### `load()` (line 1961)
_Load a manifest at path or return a suitable manifest already loaded._

**Args**: self, path


#### `__init__()` (line 1983)
**Args**: self, module


#### `_zipinfo_name()` (line 1987)
**Args**: self, fspath


#### `_parts()` (line 1997)
**Args**: self, zip_path


#### `zipinfo()` (line 2006)
**Args**: self


#### `get_resource_filename()` (line 2009)
**Args**: self, manager, resource_name


#### `_get_date_and_size()` (line 2023)
**Args**: zip_stat


#### `_extract_resource()` (line 2032)
**Args**: self, manager, zip_path


#### `_is_current()` (line 2086)
_Return True if the file_path is current for this zip_path_

**Args**: self, file_path, zip_path


#### `_get_eager_resources()` (line 2102)
**Args**: self


#### `_index()` (line 2111)
**Args**: self


#### `_has()` (line 2128)
**Args**: self, fspath


#### `_isdir()` (line 2132)
**Args**: self, fspath


#### `_listdir()` (line 2135)
**Args**: self, fspath


#### `_eager_to_zip()` (line 2138)
**Args**: self, resource_name


#### `_resource_to_zip()` (line 2141)
**Args**: self, resource_name


#### `__init__()` (line 2160)
**Args**: self, path


#### `_get_metadata_path()` (line 2163)
**Args**: self, name


#### `has_metadata()` (line 2166)
**Args**: self, name


#### `get_metadata()` (line 2169)
**Args**: self, name


#### `_warn_on_replacement()` (line 2178)
**Args**: self, metadata


#### `get_metadata_lines()` (line 2185)
**Args**: self, name


#### `__init__()` (line 2209)
**Args**: self, path, egg_info


#### `__init__()` (line 2217)
_Create a metadata provider from a zipimporter_

**Args**: self, importer


#### `register_finder()` (line 2234)
_Register `distribution_finder` to find distributions in sys.path items

`importer_type` is the type or class of a PEP 302 "Importer" (sys.path item
handler), and `distribution_finder` is a callable that, passed a path
item and the importer instance, yields ``Distribution`` instances found on
that path item.  See ``pkg_resources.find_on_path`` for an example._

**Args**: importer_type, distribution_finder


#### `find_distributions()` (line 2244)
_Yield distributions accessible via `path_item`_

**Args**: path_item, only


#### `find_eggs_in_zip()` (line 2251)
_Find eggs in zip files; possibly multiple nested eggs._

**Args**: importer, path_item, only


#### `find_nothing()` (line 2282)
**Args**: importer, path_item, only


#### `find_on_path()` (line 2291)
_Yield distributions accessible on a sys.path directory_

**Args**: importer, path_item, only


#### `dist_factory()` (line 2311)
_Return a dist_factory for the given entry._

**Args**: path_item, entry, only


#### `__bool__()` (line 2339)
**Args**: self


#### `__call__()` (line 2342)
**Args**: self, fullpath


#### `safe_listdir()` (line 2346)
_Attempt to list contents of path, but suppress some exceptions._

**Args**: path


#### `distributions_from_metadata()` (line 2362)
**Args**: path


#### `non_empty_lines()` (line 2380)
_Yield non-empty lines from file at path_

**Args**: path


#### `resolve_egg_link()` (line 2390)
_Given a path to an .egg-link, resolve distributions
present in the referenced path._

**Args**: path


#### `register_namespace_handler()` (line 2416)
_Register `namespace_handler` to declare namespace packages

`importer_type` is the type or class of a PEP 302 "Importer" (sys.path item
handler), and `namespace_handler` is a callable like this::

    def namespace_handler(importer, path_entry, moduleName, module):
        # return a path_entry to use for child packages

Namespace handlers are only called if the importer object has already
agreed that it can handle the relevant path item, and they should only
return a subpath if the module __path__ does not already contain an
equivalent subpath.  For an example namespace handler, see
``pkg_resources.file_ns_handler``._

**Args**: importer_type, namespace_handler


#### `_handle_ns()` (line 2436)
_Ensure that named package includes a subpath of path_item (if needed)_

**Args**: packageName, path_item


#### `_rebuild_mod_path()` (line 2473)
_Rebuild module.__path__ ensuring that all entries are ordered
corresponding to their sys.path order_

**Args**: orig_path, package_name, module


#### `safe_sys_path_index()` (line 2480)
_Workaround for #520 and #513._

**Args**: entry


#### `position_in_sys_path()` (line 2489)
_Return the ordinal of the path based on its position in sys.path_

**Args**: path


#### `declare_namespace()` (line 2507)
_Declare that package 'packageName' is a namespace package_

**Args**: packageName


#### `fixup_namespace_packages()` (line 2550)
_Ensure that previously-declared namespace packages include path_item_

**Args**: path_item, parent


#### `file_ns_handler()` (line 2562)
_Compute an ns-package subpath for a filesystem or zipfile importer_

**Args**: importer, path_item, packageName, module


#### `null_ns_handler()` (line 2587)
**Args**: importer, path_item, packageName, module


#### `normalize_path()` (line 2600)
**Args**: filename


#### `normalize_path()` (line 2602)
**Args**: filename


#### `normalize_path()` (line 2603)
_Normalize a file/dir name for comparison purposes_

**Args**: filename


#### `_cygwin_patch()` (line 2608)
_Contrary to POSIX 2008, on Cygwin, getcwd (3) contains
symlink components. Using
os.path.abspath() works around this limitation. A fix in os.getcwd()
would probably better, in Cygwin even more so, except
that this seems to be by design..._

**Args**: filename


#### `_normalize_cached()` (line 2623)
**Args**: filename


#### `_normalize_cached()` (line 2625)
**Args**: filename


#### `_normalize_cached()` (line 2626)
**Args**: filename


#### `_normalize_cached()` (line 2630)
**Args**: filename


#### `_is_egg_path()` (line 2634)
_Determine if given path appears to be an egg._

**Args**: path


#### `_is_zip_egg()` (line 2641)
**Args**: path


#### `_is_unpacked_egg()` (line 2649)
_Determine if given path appears to be an unpacked egg._

**Args**: path


#### `_set_parent_ns()` (line 2658)
**Args**: packageName


#### `__init__()` (line 2684)
**Args**: self, name, module_name, attrs, extras, dist


#### `__str__()` (line 2700)
**Args**: self


#### `__repr__()` (line 2708)
**Args**: self


#### `load()` (line 2712)
**Args**: self, require, env, installer


#### `load()` (line 2719)
**Args**: self, require


#### `load()` (line 2725)
_Require packages for this EntryPoint, then resolve it._

**Args**: self, require


#### `resolve()` (line 2747)
_Resolve the entry point from its module and attrs._

**Args**: self


#### `require()` (line 2757)
**Args**: self, env, installer


#### `parse()` (line 2785)
_Parse a single entry point from string `src`

Entry point syntax follows the form::

    name = some.module:some.attr [extra1, extra2]

The entry name and module name are required, but the ``:attrs`` and
``[extras]`` parts are optional_

**Args**: cls, src, dist


#### `_parse_extras()` (line 2805)
**Args**: cls, extras_spec


#### `parse_group()` (line 2814)
_Parse an entry point group_

**Args**: cls, group, lines, dist


#### `parse_map()` (line 2832)
_Parse a map of entry point groups_

**Args**: cls, data, dist


#### `_version_from_file()` (line 2856)
_Given an iterable of lines from a Metadata file, return
the value of the Version field, if present, or None otherwise._

**Args**: lines


#### `is_version_line()` (line 2862)
**Args**: line


#### `__init__()` (line 2876)
**Args**: self, location, metadata, project_name, version, py_version, platform, precedence


#### `from_location()` (line 2896)
**Args**: cls, location, basename, metadata


#### `_reload_version()` (line 2923)
**Args**: self


#### `hashcmp()` (line 2927)
**Args**: self


#### `__hash__()` (line 2937)
**Args**: self


#### `__lt__()` (line 2940)
**Args**: self, other


#### `__le__()` (line 2943)
**Args**: self, other


#### `__gt__()` (line 2946)
**Args**: self, other


#### `__ge__()` (line 2949)
**Args**: self, other


#### `__eq__()` (line 2952)
**Args**: self, other


#### `__ne__()` (line 2958)
**Args**: self, other


#### `key()` (line 2966)
**Args**: self


#### `parsed_version()` (line 2974)
**Args**: self


#### `_forgiving_parsed_version()` (line 2988)
**Args**: self


#### `version()` (line 3014)
**Args**: self


#### `_dep_map()` (line 3029)
_A map of extra to its list of (direct) requirements
for this distribution, including the null extra._

**Args**: self


#### `_filter_extras()` (line 3041)
_Given a mapping of extras to dependencies, strip off
environment markers and filter out any dependencies
not matching the markers._

**Args**: dm


#### `_build_dep_map()` (line 3061)
**Args**: self


#### `requires()` (line 3068)
_List of Requirements needed for this distro if `extras` are used_

**Args**: self, extras


#### `_get_metadata_path_for_display()` (line 3082)
_Return the path to the given metadata file, if available._

**Args**: self, name


#### `_get_metadata()` (line 3099)
**Args**: self, name


#### `_get_version()` (line 3103)
**Args**: self


#### `activate()` (line 3107)
_Ensure distribution is importable on `path` (default=sys.path)_

**Args**: self, path, replace


#### `egg_name()` (line 3118)
_Return what this distribution's standard .egg filename should be_

**Args**: self


#### `__repr__()` (line 3130)
**Args**: self


#### `__str__()` (line 3136)
**Args**: self


#### `__getattr__()` (line 3144)
_Delegate all unrecognized public attributes to .metadata provider_

**Args**: self, attr


#### `__dir__()` (line 3150)
**Args**: self


#### `from_filename()` (line 3157)
**Args**: cls, filename, metadata


#### `as_requirement()` (line 3167)
_Return a ``Requirement`` that matches this distribution exactly_

**Args**: self


#### `load_entry_point()` (line 3176)
_Return the `name` entry point of `group` or raise ImportError_

**Args**: self, group, name


#### `get_entry_map()` (line 3184)
**Args**: self, group


#### `get_entry_map()` (line 3186)
**Args**: self, group


#### `get_entry_map()` (line 3187)
_Return the entry point map for `group`, or the full entry map_

**Args**: self, group


#### `get_entry_info()` (line 3197)
_Return the EntryPoint object for `group`+`name`, or ``None``_

**Args**: self, group, name


#### `insert_on()` (line 3202)
_Ensure self.location is on path

If replace=False (default):
    - If location is already in path anywhere, do nothing.
    - Else:
      - If it's an egg and its parent directory is on path,
        insert just ahead of the parent.
      - Else: add to the end of path.
If replace=True:
    - If location is already on path anywhere (not eggs)
      or higher priority than its parent (eggs)
      do nothing.
    - Else:
      - If it's an egg and its parent directory is on path,
        insert just ahead of the parent,
        removing any lower-priority entries.
      - Else: add it to the front of path._

**Args**: self, path, loc, replace


#### `check_version_conflict()` (line 3275)
**Args**: self


#### `has_version()` (line 3301)
**Args**: self


#### `clone()` (line 3312)
_Copy this distribution, substituting in any changed keyword args_

**Args**: self


#### `extras()` (line 3322)
**Args**: self


#### `_reload_version()` (line 3327)
_Packages installed by distutils (e.g. numpy or scipy),
which uses an old safe_version, and so
their version numbers can get mangled when
converted to filenames (e.g., 1.11.0.dev0+2329eae to
1.11.0.dev0_2329eae). These distributions will not be
parsed properly
downstream by Distribution and safe_version, so
take an extra step and try to get the version number from
the metadata file itself instead of the filename._

**Args**: self


#### `_parsed_pkg_info()` (line 3355)
_Parse and cache metadata_

**Args**: self


#### `_dep_map()` (line 3365)
**Args**: self


#### `_compute_dependencies()` (line 3372)
_Recompute this distribution's dependencies._

**Args**: self


#### `reqs_for_extra()` (line 3381)
**Args**: extra


#### `issue_warning()` (line 3405)

#### `parse_requirements()` (line 3418)
_Yield ``Requirement`` objects for each specification in `strs`.

`strs` must be a string, or a (possibly-nested) iterable thereof._

**Args**: strs


#### `__init__()` (line 3432)
_DO NOT CALL THIS UNDOCUMENTED METHOD; use Requirement.parse()!_

**Args**: self, requirement_string


#### `__eq__()` (line 3450)
**Args**: self, other


#### `__ne__()` (line 3453)
**Args**: self, other


#### `__contains__()` (line 3456)
**Args**: self, item


#### `__hash__()` (line 3468)
**Args**: self


#### `__repr__()` (line 3471)
**Args**: self


#### `parse()` (line 3475)
**Args**: s


#### `_always_object()` (line 3480)
_Ensure object appears in the mro even
for old-style classes._

**Args**: classes


#### `_find_adapter()` (line 3490)
_Return an adapter factory for `ob` from `registry`_

**Args**: registry, ob


#### `ensure_directory()` (line 3501)
_Ensure that the parent directory of `path` exists_

**Args**: path


#### `_bypass_ensure_directory()` (line 3507)
_Sandbox-bypassing version of ensure_directory()_

**Args**: path


#### `split_sections()` (line 3520)
_Split a string or iterable thereof into (section, content) pairs

Each ``section`` is a stripped version of the section header ("[section]")
and each ``content`` is a list of stripped lines excluding blank lines and
comment-only lines.  If there are any such lines before the first section
header, they're returned in a first ``section`` of ``None``._

**Args**: s


#### `_mkstemp()` (line 3546)

#### `_read_utf8_with_fallback()` (line 3577)
_See setuptools.unicode_utils._read_utf8_with_fallback_

**Args**: file, fallback_encoding


#### `_call_aside()` (line 3606)
**Args**: f


#### `_initialize()` (line 3612)
_Set up global resource manager (deliberately not state-saved)_

**Args**: g


#### `_initialize_master_working_set()` (line 3624)
_Prepare the master working set and make the ``require()``
API available.

This function has explicit effects on the global state
of pkg_resources. It is intended to be invoked once at
the initialization of this module.

Invocation by other packages is unsupported and done
at their own risk._


### venv_new\Lib\site-packages\pip\_vendor\platformdirs\__init__.py

#### `_set_platform_dir_class()` (line 30)

#### `user_data_dir()` (line 53)
_:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param roaming: See `roaming <platformdirs.api.PlatformDirsABC.roaming>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: data directory tied to the user_

**Args**: appname, appauthor, version, roaming, ensure_exists


#### `site_data_dir()` (line 77)
_:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param multipath: See `roaming <platformdirs.api.PlatformDirsABC.multipath>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: data directory shared by users_

**Args**: appname, appauthor, version, multipath, ensure_exists


#### `user_config_dir()` (line 101)
_:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param roaming: See `roaming <platformdirs.api.PlatformDirsABC.roaming>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: config directory tied to the user_

**Args**: appname, appauthor, version, roaming, ensure_exists


#### `site_config_dir()` (line 125)
_:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param multipath: See `roaming <platformdirs.api.PlatformDirsABC.multipath>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: config directory shared by the users_

**Args**: appname, appauthor, version, multipath, ensure_exists


#### `user_cache_dir()` (line 149)
_:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `roaming <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: cache directory tied to the user_

**Args**: appname, appauthor, version, opinion, ensure_exists


#### `site_cache_dir()` (line 173)
_:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `opinion <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: cache directory tied to the user_

**Args**: appname, appauthor, version, opinion, ensure_exists


#### `user_state_dir()` (line 197)
_:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param roaming: See `roaming <platformdirs.api.PlatformDirsABC.roaming>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: state directory tied to the user_

**Args**: appname, appauthor, version, roaming, ensure_exists


#### `user_log_dir()` (line 221)
_:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `roaming <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: log directory tied to the user_

**Args**: appname, appauthor, version, opinion, ensure_exists


#### `user_documents_dir()` (line 245)
_:returns: documents directory tied to the user_


#### `user_downloads_dir()` (line 250)
_:returns: downloads directory tied to the user_


#### `user_pictures_dir()` (line 255)
_:returns: pictures directory tied to the user_


#### `user_videos_dir()` (line 260)
_:returns: videos directory tied to the user_


#### `user_music_dir()` (line 265)
_:returns: music directory tied to the user_


#### `user_desktop_dir()` (line 270)
_:returns: desktop directory tied to the user_


#### `user_runtime_dir()` (line 275)
_:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `opinion <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: runtime directory tied to the user_

**Args**: appname, appauthor, version, opinion, ensure_exists


#### `site_runtime_dir()` (line 299)
_:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `opinion <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: runtime directory shared by users_

**Args**: appname, appauthor, version, opinion, ensure_exists


#### `user_data_path()` (line 323)
_:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param roaming: See `roaming <platformdirs.api.PlatformDirsABC.roaming>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: data path tied to the user_

**Args**: appname, appauthor, version, roaming, ensure_exists


#### `site_data_path()` (line 347)
_:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param multipath: See `multipath <platformdirs.api.PlatformDirsABC.multipath>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: data path shared by users_

**Args**: appname, appauthor, version, multipath, ensure_exists


#### `user_config_path()` (line 371)
_:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param roaming: See `roaming <platformdirs.api.PlatformDirsABC.roaming>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: config path tied to the user_

**Args**: appname, appauthor, version, roaming, ensure_exists


#### `site_config_path()` (line 395)
_:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param multipath: See `roaming <platformdirs.api.PlatformDirsABC.multipath>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: config path shared by the users_

**Args**: appname, appauthor, version, multipath, ensure_exists


#### `site_cache_path()` (line 419)
_:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `opinion <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: cache directory tied to the user_

**Args**: appname, appauthor, version, opinion, ensure_exists


#### `user_cache_path()` (line 443)
_:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `roaming <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: cache path tied to the user_

**Args**: appname, appauthor, version, opinion, ensure_exists


#### `user_state_path()` (line 467)
_:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param roaming: See `roaming <platformdirs.api.PlatformDirsABC.roaming>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: state path tied to the user_

**Args**: appname, appauthor, version, roaming, ensure_exists


#### `user_log_path()` (line 491)
_:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `roaming <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: log path tied to the user_

**Args**: appname, appauthor, version, opinion, ensure_exists


#### `user_documents_path()` (line 515)
_:returns: documents a path tied to the user_


#### `user_downloads_path()` (line 520)
_:returns: downloads path tied to the user_


#### `user_pictures_path()` (line 525)
_:returns: pictures path tied to the user_


#### `user_videos_path()` (line 530)
_:returns: videos path tied to the user_


#### `user_music_path()` (line 535)
_:returns: music path tied to the user_


#### `user_desktop_path()` (line 540)
_:returns: desktop path tied to the user_


#### `user_runtime_path()` (line 545)
_:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `opinion <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: runtime path tied to the user_

**Args**: appname, appauthor, version, opinion, ensure_exists


#### `site_runtime_path()` (line 569)
_:param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
:param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
:param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
:param opinion: See `opinion <platformdirs.api.PlatformDirsABC.opinion>`.
:param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
:returns: runtime path shared by users_

**Args**: appname, appauthor, version, opinion, ensure_exists


### venv_new\Lib\site-packages\pip\_vendor\platformdirs\__main__.py

#### `main()` (line 26)
_Run the main entry point._


### venv_new\Lib\site-packages\pip\_vendor\platformdirs\android.py

#### `user_data_dir()` (line 24)
_:return: data directory tied to the user, e.g. ``/data/user/<userid>/<packagename>/files/<AppName>``_

**Args**: self


#### `site_data_dir()` (line 29)
_:return: data directory shared by users, same as `user_data_dir`_

**Args**: self


#### `user_config_dir()` (line 34)
_:return: config directory tied to the user, e.g.         ``/data/user/<userid>/<packagename>/shared_prefs/<AppName>``_

**Args**: self


#### `site_config_dir()` (line 42)
_:return: config directory shared by the users, same as `user_config_dir`_

**Args**: self


#### `user_cache_dir()` (line 47)
_:return: cache directory tied to the user, e.g.,``/data/user/<userid>/<packagename>/cache/<AppName>``_

**Args**: self


#### `site_cache_dir()` (line 52)
_:return: cache directory shared by users, same as `user_cache_dir`_

**Args**: self


#### `user_state_dir()` (line 57)
_:return: state directory tied to the user, same as `user_data_dir`_

**Args**: self


#### `user_log_dir()` (line 62)
_:return: log directory tied to the user, same as `user_cache_dir` if not opinionated else ``log`` in it,
  e.g. ``/data/user/<userid>/<packagename>/cache/<AppName>/log``_

**Args**: self


#### `user_documents_dir()` (line 73)
_:return: documents directory tied to the user e.g. ``/storage/emulated/0/Documents``_

**Args**: self


#### `user_downloads_dir()` (line 78)
_:return: downloads directory tied to the user e.g. ``/storage/emulated/0/Downloads``_

**Args**: self


#### `user_pictures_dir()` (line 83)
_:return: pictures directory tied to the user e.g. ``/storage/emulated/0/Pictures``_

**Args**: self


#### `user_videos_dir()` (line 88)
_:return: videos directory tied to the user e.g. ``/storage/emulated/0/DCIM/Camera``_

**Args**: self


#### `user_music_dir()` (line 93)
_:return: music directory tied to the user e.g. ``/storage/emulated/0/Music``_

**Args**: self


#### `user_desktop_dir()` (line 98)
_:return: desktop directory tied to the user e.g. ``/storage/emulated/0/Desktop``_

**Args**: self


#### `user_runtime_dir()` (line 103)
_:return: runtime directory tied to the user, same as `user_cache_dir` if not opinionated else ``tmp`` in it,
  e.g. ``/data/user/<userid>/<packagename>/cache/<AppName>/tmp``_

**Args**: self


#### `site_runtime_dir()` (line 114)
_:return: runtime directory shared by users, same as `user_runtime_dir`_

**Args**: self


#### `_android_folder()` (line 120)
_:return: base folder for the Android OS or None if it cannot be found_


#### `_android_documents_folder()` (line 168)
_:return: documents folder for the Android OS_


#### `_android_downloads_folder()` (line 184)
_:return: downloads folder for the Android OS_


#### `_android_pictures_folder()` (line 200)
_:return: pictures folder for the Android OS_


#### `_android_videos_folder()` (line 216)
_:return: videos folder for the Android OS_


#### `_android_music_folder()` (line 232)
_:return: music folder for the Android OS_


### venv_new\Lib\site-packages\pip\_vendor\platformdirs\api.py

#### `__init__()` (line 17)
_Create a new platform directory.

:param appname: See `appname`.
:param appauthor: See `appauthor`.
:param version: See `version`.
:param roaming: See `roaming`.
:param multipath: See `multipath`.
:param opinion: See `opinion`.
:param ensure_exists: See `ensure_exists`._

**Args**: self, appname, appauthor, version, roaming, multipath, opinion, ensure_exists


#### `_append_app_name_and_version()` (line 80)
**Args**: self


#### `_optionally_create_directory()` (line 90)
**Args**: self, path


#### `_first_item_as_path_if_multipath()` (line 94)
**Args**: self, directory


#### `user_data_dir()` (line 102)
_:return: data directory tied to the user_

**Args**: self


#### `site_data_dir()` (line 107)
_:return: data directory shared by users_

**Args**: self


#### `user_config_dir()` (line 112)
_:return: config directory tied to the user_

**Args**: self


#### `site_config_dir()` (line 117)
_:return: config directory shared by the users_

**Args**: self


#### `user_cache_dir()` (line 122)
_:return: cache directory tied to the user_

**Args**: self


#### `site_cache_dir()` (line 127)
_:return: cache directory shared by users_

**Args**: self


#### `user_state_dir()` (line 132)
_:return: state directory tied to the user_

**Args**: self


#### `user_log_dir()` (line 137)
_:return: log directory tied to the user_

**Args**: self


#### `user_documents_dir()` (line 142)
_:return: documents directory tied to the user_

**Args**: self


#### `user_downloads_dir()` (line 147)
_:return: downloads directory tied to the user_

**Args**: self


#### `user_pictures_dir()` (line 152)
_:return: pictures directory tied to the user_

**Args**: self


#### `user_videos_dir()` (line 157)
_:return: videos directory tied to the user_

**Args**: self


#### `user_music_dir()` (line 162)
_:return: music directory tied to the user_

**Args**: self


#### `user_desktop_dir()` (line 167)
_:return: desktop directory tied to the user_

**Args**: self


#### `user_runtime_dir()` (line 172)
_:return: runtime directory tied to the user_

**Args**: self


#### `site_runtime_dir()` (line 177)
_:return: runtime directory shared by users_

**Args**: self


#### `user_data_path()` (line 181)
_:return: data path tied to the user_

**Args**: self


#### `site_data_path()` (line 186)
_:return: data path shared by users_

**Args**: self


#### `user_config_path()` (line 191)
_:return: config path tied to the user_

**Args**: self


#### `site_config_path()` (line 196)
_:return: config path shared by the users_

**Args**: self


#### `user_cache_path()` (line 201)
_:return: cache path tied to the user_

**Args**: self


#### `site_cache_path()` (line 206)
_:return: cache path shared by users_

**Args**: self


#### `user_state_path()` (line 211)
_:return: state path tied to the user_

**Args**: self


#### `user_log_path()` (line 216)
_:return: log path tied to the user_

**Args**: self


#### `user_documents_path()` (line 221)
_:return: documents a path tied to the user_

**Args**: self


#### `user_downloads_path()` (line 226)
_:return: downloads path tied to the user_

**Args**: self


#### `user_pictures_path()` (line 231)
_:return: pictures path tied to the user_

**Args**: self


#### `user_videos_path()` (line 236)
_:return: videos path tied to the user_

**Args**: self


#### `user_music_path()` (line 241)
_:return: music path tied to the user_

**Args**: self


#### `user_desktop_path()` (line 246)
_:return: desktop path tied to the user_

**Args**: self


#### `user_runtime_path()` (line 251)
_:return: runtime path tied to the user_

**Args**: self


#### `site_runtime_path()` (line 256)
_:return: runtime path shared by users_

**Args**: self


#### `iter_config_dirs()` (line 260)
_:yield: all user and site configuration directories._

**Args**: self


#### `iter_data_dirs()` (line 265)
_:yield: all user and site data directories._

**Args**: self


#### `iter_cache_dirs()` (line 270)
_:yield: all user and site cache directories._

**Args**: self


#### `iter_runtime_dirs()` (line 275)
_:yield: all user and site runtime directories._

**Args**: self


#### `iter_config_paths()` (line 280)
_:yield: all user and site configuration paths._

**Args**: self


#### `iter_data_paths()` (line 285)
_:yield: all user and site data paths._

**Args**: self


#### `iter_cache_paths()` (line 290)
_:yield: all user and site cache paths._

**Args**: self


#### `iter_runtime_paths()` (line 295)
_:yield: all user and site runtime paths._

**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\platformdirs\macos.py

#### `user_data_dir()` (line 28)
_:return: data directory tied to the user, e.g. ``~/Library/Application Support/$appname/$version``_

**Args**: self


#### `site_data_dir()` (line 33)
_:return: data directory shared by users, e.g. ``/Library/Application Support/$appname/$version``.
  If we're using a Python binary managed by `Homebrew <https://brew.sh>`_, the directory
  will be under the Homebrew prefix, e.g. ``/opt/homebrew/share/$appname/$version``.
  If `multipath <platformdirs.api.PlatformDirsABC.multipath>` is enabled, and we're in Homebrew,
  the response is a multi-path string separated by ":", e.g.
  ``/opt/homebrew/share/$appname/$version:/Library/Application Support/$appname/$version``_

**Args**: self


#### `site_data_path()` (line 50)
_:return: data path shared by users. Only return the first item, even if ``multipath`` is set to ``True``_

**Args**: self


#### `user_config_dir()` (line 55)
_:return: config directory tied to the user, same as `user_data_dir`_

**Args**: self


#### `site_config_dir()` (line 60)
_:return: config directory shared by the users, same as `site_data_dir`_

**Args**: self


#### `user_cache_dir()` (line 65)
_:return: cache directory tied to the user, e.g. ``~/Library/Caches/$appname/$version``_

**Args**: self


#### `site_cache_dir()` (line 70)
_:return: cache directory shared by users, e.g. ``/Library/Caches/$appname/$version``.
  If we're using a Python binary managed by `Homebrew <https://brew.sh>`_, the directory
  will be under the Homebrew prefix, e.g. ``/opt/homebrew/var/cache/$appname/$version``.
  If `multipath <platformdirs.api.PlatformDirsABC.multipath>` is enabled, and we're in Homebrew,
  the response is a multi-path string separated by ":", e.g.
  ``/opt/homebrew/var/cache/$appname/$version:/Library/Caches/$appname/$version``_

**Args**: self


#### `site_cache_path()` (line 87)
_:return: cache path shared by users. Only return the first item, even if ``multipath`` is set to ``True``_

**Args**: self


#### `user_state_dir()` (line 92)
_:return: state directory tied to the user, same as `user_data_dir`_

**Args**: self


#### `user_log_dir()` (line 97)
_:return: log directory tied to the user, e.g. ``~/Library/Logs/$appname/$version``_

**Args**: self


#### `user_documents_dir()` (line 102)
_:return: documents directory tied to the user, e.g. ``~/Documents``_

**Args**: self


#### `user_downloads_dir()` (line 107)
_:return: downloads directory tied to the user, e.g. ``~/Downloads``_

**Args**: self


#### `user_pictures_dir()` (line 112)
_:return: pictures directory tied to the user, e.g. ``~/Pictures``_

**Args**: self


#### `user_videos_dir()` (line 117)
_:return: videos directory tied to the user, e.g. ``~/Movies``_

**Args**: self


#### `user_music_dir()` (line 122)
_:return: music directory tied to the user, e.g. ``~/Music``_

**Args**: self


#### `user_desktop_dir()` (line 127)
_:return: desktop directory tied to the user, e.g. ``~/Desktop``_

**Args**: self


#### `user_runtime_dir()` (line 132)
_:return: runtime directory tied to the user, e.g. ``~/Library/Caches/TemporaryItems/$appname/$version``_

**Args**: self


#### `site_runtime_dir()` (line 137)
_:return: runtime directory shared by users, same as `user_runtime_dir`_

**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\platformdirs\unix.py

#### `getuid()` (line 15)

#### `user_data_dir()` (line 37)
_:return: data directory tied to the user, e.g. ``~/.local/share/$appname/$version`` or
 ``$XDG_DATA_HOME/$appname/$version``_

**Args**: self


#### `_site_data_dirs()` (line 48)
**Args**: self


#### `site_data_dir()` (line 55)
_:return: data directories shared by users (if `multipath <platformdirs.api.PlatformDirsABC.multipath>` is
 enabled and ``XDG_DATA_DIRS`` is set and a multi path the response is also a multi path separated by the
 OS path separator), e.g. ``/usr/local/share/$appname/$version`` or ``/usr/share/$appname/$version``_

**Args**: self


#### `user_config_dir()` (line 68)
_:return: config directory tied to the user, e.g. ``~/.config/$appname/$version`` or
 ``$XDG_CONFIG_HOME/$appname/$version``_

**Args**: self


#### `_site_config_dirs()` (line 79)
**Args**: self


#### `site_config_dir()` (line 86)
_:return: config directories shared by users (if `multipath <platformdirs.api.PlatformDirsABC.multipath>`
 is enabled and ``XDG_CONFIG_DIRS`` is set and a multi path the response is also a multi path separated by
 the OS path separator), e.g. ``/etc/xdg/$appname/$version``_

**Args**: self


#### `user_cache_dir()` (line 99)
_:return: cache directory tied to the user, e.g. ``~/.cache/$appname/$version`` or
 ``~/$XDG_CACHE_HOME/$appname/$version``_

**Args**: self


#### `site_cache_dir()` (line 110)
_:return: cache directory shared by users, e.g. ``/var/cache/$appname/$version``_

**Args**: self


#### `user_state_dir()` (line 115)
_:return: state directory tied to the user, e.g. ``~/.local/state/$appname/$version`` or
 ``$XDG_STATE_HOME/$appname/$version``_

**Args**: self


#### `user_log_dir()` (line 126)
_:return: log directory tied to the user, same as `user_state_dir` if not opinionated else ``log`` in it_

**Args**: self


#### `user_documents_dir()` (line 135)
_:return: documents directory tied to the user, e.g. ``~/Documents``_

**Args**: self


#### `user_downloads_dir()` (line 140)
_:return: downloads directory tied to the user, e.g. ``~/Downloads``_

**Args**: self


#### `user_pictures_dir()` (line 145)
_:return: pictures directory tied to the user, e.g. ``~/Pictures``_

**Args**: self


#### `user_videos_dir()` (line 150)
_:return: videos directory tied to the user, e.g. ``~/Videos``_

**Args**: self


#### `user_music_dir()` (line 155)
_:return: music directory tied to the user, e.g. ``~/Music``_

**Args**: self


#### `user_desktop_dir()` (line 160)
_:return: desktop directory tied to the user, e.g. ``~/Desktop``_

**Args**: self


#### `user_runtime_dir()` (line 165)
_:return: runtime directory tied to the user, e.g. ``/run/user/$(id -u)/$appname/$version`` or
 ``$XDG_RUNTIME_DIR/$appname/$version``.

 For FreeBSD/OpenBSD/NetBSD, it would return ``/var/run/user/$(id -u)/$appname/$version`` if
 exists, otherwise ``/tmp/runtime-$(id -u)/$appname/$version``, if``$XDG_RUNTIME_DIR``
 is not set._

**Args**: self


#### `site_runtime_dir()` (line 185)
_:return: runtime directory shared by users, e.g. ``/run/$appname/$version`` or         ``$XDG_RUNTIME_DIR/$appname/$version``.

Note that this behaves almost exactly like `user_runtime_dir` if ``$XDG_RUNTIME_DIR`` is set, but will
fall back to paths associated to the root user instead of a regular logged-in user if it's not set.

If you wish to ensure that a logged-in root user path is returned e.g. ``/run/user/0``, use `user_runtime_dir`
instead.

For FreeBSD/OpenBSD/NetBSD, it would return ``/var/run/$appname/$version`` if ``$XDG_RUNTIME_DIR`` is not set._

**Args**: self


#### `site_data_path()` (line 207)
_:return: data path shared by users. Only return the first item, even if ``multipath`` is set to ``True``_

**Args**: self


#### `site_config_path()` (line 212)
_:return: config path shared by the users, returns the first item, even if ``multipath`` is set to ``True``_

**Args**: self


#### `site_cache_path()` (line 217)
_:return: cache path shared by users. Only return the first item, even if ``multipath`` is set to ``True``_

**Args**: self


#### `iter_config_dirs()` (line 221)
_:yield: all user and site configuration directories._

**Args**: self


#### `iter_data_dirs()` (line 226)
_:yield: all user and site data directories._

**Args**: self


#### `_get_user_media_dir()` (line 232)
**Args**: env_var, fallback_tilde_path


#### `_get_user_dirs_folder()` (line 242)
_Return directory from user-dirs.dirs config file.

See https://freedesktop.org/wiki/Software/xdg-user-dirs/._

**Args**: key


### venv_new\Lib\site-packages\pip\_vendor\platformdirs\windows.py

#### `user_data_dir()` (line 28)
_:return: data directory tied to the user, e.g.
 ``%USERPROFILE%\AppData\Local\$appauthor\$appname`` (not roaming) or
 ``%USERPROFILE%\AppData\Roaming\$appauthor\$appname`` (roaming)_

**Args**: self


#### `_append_parts()` (line 38)
**Args**: self, path


#### `site_data_dir()` (line 54)
_:return: data directory shared by users, e.g. ``C:\ProgramData\$appauthor\$appname``_

**Args**: self


#### `user_config_dir()` (line 60)
_:return: config directory tied to the user, same as `user_data_dir`_

**Args**: self


#### `site_config_dir()` (line 65)
_:return: config directory shared by the users, same as `site_data_dir`_

**Args**: self


#### `user_cache_dir()` (line 70)
_:return: cache directory tied to the user (if opinionated with ``Cache`` folder within ``$appname``) e.g.
 ``%USERPROFILE%\AppData\Local\$appauthor\$appname\Cache\$version``_

**Args**: self


#### `site_cache_dir()` (line 79)
_:return: cache directory shared by users, e.g. ``C:\ProgramData\$appauthor\$appname\Cache\$version``_

**Args**: self


#### `user_state_dir()` (line 85)
_:return: state directory tied to the user, same as `user_data_dir`_

**Args**: self


#### `user_log_dir()` (line 90)
_:return: log directory tied to the user, same as `user_data_dir` if not opinionated else ``Logs`` in it_

**Args**: self


#### `user_documents_dir()` (line 99)
_:return: documents directory tied to the user e.g. ``%USERPROFILE%\Documents``_

**Args**: self


#### `user_downloads_dir()` (line 104)
_:return: downloads directory tied to the user e.g. ``%USERPROFILE%\Downloads``_

**Args**: self


#### `user_pictures_dir()` (line 109)
_:return: pictures directory tied to the user e.g. ``%USERPROFILE%\Pictures``_

**Args**: self


#### `user_videos_dir()` (line 114)
_:return: videos directory tied to the user e.g. ``%USERPROFILE%\Videos``_

**Args**: self


#### `user_music_dir()` (line 119)
_:return: music directory tied to the user e.g. ``%USERPROFILE%\Music``_

**Args**: self


#### `user_desktop_dir()` (line 124)
_:return: desktop directory tied to the user, e.g. ``%USERPROFILE%\Desktop``_

**Args**: self


#### `user_runtime_dir()` (line 129)
_:return: runtime directory tied to the user, e.g.
 ``%USERPROFILE%\AppData\Local\Temp\$appauthor\$appname``_

**Args**: self


#### `site_runtime_dir()` (line 138)
_:return: runtime directory shared by users, same as `user_runtime_dir`_

**Args**: self


#### `get_win_folder_from_env_vars()` (line 143)
_Get folder from environment variables._

**Args**: csidl_name


#### `get_win_folder_if_csidl_name_not_env_var()` (line 164)
_Get a folder for a CSIDL name that does not exist as an environment variable._

**Args**: csidl_name


#### `get_win_folder_from_registry()` (line 183)
_Get folder from the registry.

This is a fallback technique at best. I'm not sure if using the registry for these guarantees us the correct answer
for all CSIDL_* names._

**Args**: csidl_name


#### `get_win_folder_via_ctypes()` (line 213)
_Get folder with ctypes._

**Args**: csidl_name


#### `_pick_get_win_folder()` (line 252)

### venv_new\Lib\site-packages\pip\_vendor\pygments\__init__.py

#### `lex()` (line 35)
_Lex `code` with the `lexer` (must be a `Lexer` instance)
and return an iterable of tokens. Currently, this only calls
`lexer.get_tokens()`._

**Args**: code, lexer


#### `format()` (line 52)
_Format ``tokens`` (an iterable of tokens) with the formatter ``formatter``
(a `Formatter` instance).

If ``outfile`` is given and a valid file object (an object with a
``write`` method), the result will be written to it, otherwise it
is returned as a string._

**Args**: tokens, formatter, outfile


#### `highlight()` (line 77)
_This is the most high-level highlighting function. It combines `lex` and
`format` in one function._

**Args**: code, lexer, formatter, outfile


### venv_new\Lib\site-packages\pip\_vendor\pygments\cmdline.py

#### `_parse_options()` (line 33)
**Args**: o_strs


#### `_parse_filters()` (line 54)
**Args**: f_strs


#### `_print_help()` (line 67)
**Args**: what, name


#### `_print_list()` (line 87)
**Args**: what


#### `_print_list_as_json()` (line 138)
**Args**: requested_items


#### `main_inner()` (line 182)
**Args**: parser, argns


#### `is_only_option()` (line 192)
**Args**: opt


#### `__init__()` (line 518)
**Args**: self, prog, indent_increment, max_help_position, width


#### `main()` (line 528)
_Main command line entry point._

**Args**: args


### venv_new\Lib\site-packages\pip\_vendor\pygments\console.py

#### `reset_color()` (line 40)

#### `colorize()` (line 44)
**Args**: color_key, text


#### `ansiformat()` (line 48)
_Format ``text`` with a color and/or some attributes::

    color       normal color
    *color*     bold color
    _color_     underlined color
    +color+     blinking color_

**Args**: attr, text


### venv_new\Lib\site-packages\pip\_vendor\pygments\filter.py

#### `apply_filters()` (line 12)
_Use this method to apply an iterable of filters to
a stream. If lexer is given it's forwarded to the
filter, otherwise the filter receives `None`._

**Args**: stream, filters, lexer


#### `_apply()` (line 18)
**Args**: filter_, stream


#### `simplefilter()` (line 25)
_Decorator that converts a function into a filter::

    @simplefilter
    def lowercase(self, lexer, stream, options):
        for ttype, value in stream:
            yield ttype, value.lower()_

**Args**: f


#### `__init__()` (line 47)
**Args**: self


#### `filter()` (line 50)
**Args**: self, lexer, stream


#### `__init__()` (line 63)
**Args**: self


#### `filter()` (line 68)
**Args**: self, lexer, stream


### venv_new\Lib\site-packages\pip\_vendor\pygments\filters\__init__.py

#### `find_filter_class()` (line 22)
_Lookup a filter by name. Return None if not found._

**Args**: filtername


#### `get_filter_by_name()` (line 32)
_Return an instantiated filter.

Options are passed to the filter initializer if wanted.
Raise a ClassNotFound if not found._

**Args**: filtername


#### `get_all_filters()` (line 45)
_Return a generator of all filter names._


#### `_replace_special()` (line 52)
**Args**: ttype, value, regex, specialttype, replacefunc


#### `__init__()` (line 78)
**Args**: self


#### `filter()` (line 86)
**Args**: self, lexer, stream


#### `__init__()` (line 673)
**Args**: self


#### `filter()` (line 679)
**Args**: self, lexer, stream


#### `__init__()` (line 701)
**Args**: self


#### `filter()` (line 707)
**Args**: self, lexer, stream


#### `__init__()` (line 739)
**Args**: self


#### `filter()` (line 748)
**Args**: self, lexer, stream


#### `__init__()` (line 772)
**Args**: self


#### `filter()` (line 782)
**Args**: self, lexer, stream


#### `__init__()` (line 819)
**Args**: self


#### `filter()` (line 836)
**Args**: self, lexer, stream


#### `replacefunc()` (line 843)
**Args**: wschar


#### `__init__()` (line 882)
**Args**: self


#### `gobble()` (line 886)
**Args**: self, value, left


#### `filter()` (line 892)
**Args**: self, lexer, stream


#### `__init__()` (line 913)
**Args**: self


#### `filter()` (line 916)
**Args**: self, lexer, stream


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatter.py

#### `_lookup_style()` (line 19)
**Args**: style


#### `__init__()` (line 83)
_As with lexers, this constructor takes arbitrary optional arguments,
and if you override it, you should first process your own options, then
call the base class implementation._

**Args**: self


#### `get_style_defs()` (line 99)
_This method must return statements or declarations suitable to define
the current style for subsequent highlighted text (e.g. CSS classes
in the `HTMLFormatter`).

The optional argument `arg` can be used to modify the generation and
is formatter dependent (it is standardized because it can be given on
the command line).

This method is called by the ``-S`` :doc:`command-line option <cmdline>`,
the `arg` is then given by the ``-a`` option._

**Args**: self, arg


#### `format()` (line 114)
_This method must format the tokens from the `tokensource` iterable and
write the formatted version to the file object `outfile`.

Formatter options can control how exactly the tokens are converted._

**Args**: self, tokensource, outfile


#### `__class_getitem__()` (line 128)
**Args**: cls, name


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\__init__.py

#### `_fn_matches()` (line 28)
_Return whether the supplied file name fn matches pattern filename._

**Args**: fn, glob


#### `_load_formatters()` (line 36)
_Load a formatter (and all others in the module too)._

**Args**: module_name


#### `get_all_formatters()` (line 44)
_Return a generator for all formatter classes._


#### `find_formatter_class()` (line 55)
_Lookup a formatter by alias.

Returns None if not found._

**Args**: alias


#### `get_formatter_by_name()` (line 70)
_Return an instance of a :class:`.Formatter` subclass that has `alias` in its
aliases list. The formatter is given the `options` at its instantiation.

Will raise :exc:`pygments.util.ClassNotFound` if no formatter with that
alias is found._

**Args**: _alias


#### `load_formatter_from_file()` (line 84)
_Return a `Formatter` subclass instance loaded from the provided file, relative
to the current directory.

The file is expected to contain a Formatter class named ``formattername``
(by default, CustomFormatter). Users should be very careful with the input, because
this method is equivalent to running ``eval()`` on the input file. The formatter is
given the `options` at its instantiation.

:exc:`pygments.util.ClassNotFound` is raised if there are any errors loading
the formatter.

.. versionadded:: 2.2_

**Args**: filename, formattername


#### `get_formatter_for_filename()` (line 118)
_Return a :class:`.Formatter` subclass instance that has a filename pattern
matching `fn`. The formatter is given the `options` at its instantiation.

Will raise :exc:`pygments.util.ClassNotFound` if no formatter for that filename
is found._

**Args**: fn


#### `__getattr__()` (line 143)
**Args**: self, name


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\bbcode.py

#### `__init__()` (line 51)
**Args**: self


#### `_make_styles()` (line 59)
**Args**: self


#### `format_unencoded()` (line 78)
**Args**: self, tokensource, outfile


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\groff.py

#### `__init__()` (line 45)
**Args**: self


#### `_make_styles()` (line 58)
**Args**: self


#### `_define_colors()` (line 81)
**Args**: self, outfile


#### `_write_lineno()` (line 91)
**Args**: self, outfile


#### `_wrap_line()` (line 96)
**Args**: self, line


#### `_escape_chars()` (line 119)
**Args**: self, text


#### `format_unencoded()` (line 138)
**Args**: self, tokensource, outfile


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\html.py

#### `escape_html()` (line 38)
_Escape &, <, > as well as single and double quotes for HTML._

**Args**: text, table


#### `webify()` (line 43)
**Args**: color


#### `_get_ttype_class()` (line 50)
**Args**: ttype


#### `__init__()` (line 411)
**Args**: self


#### `_get_css_class()` (line 460)
_Return the css class of this token type prefixed with
the classprefix option._

**Args**: self, ttype


#### `_get_css_classes()` (line 468)
_Return the CSS classes of this token type prefixed with the classprefix option._

**Args**: self, ttype


#### `_get_css_inline_styles()` (line 476)
_Return the inline CSS styles for this token type._

**Args**: self, ttype


#### `_create_stylesheet()` (line 484)
**Args**: self


#### `get_style_defs()` (line 508)
_Return CSS style definitions for the classes produced by the current
highlighting style. ``arg`` can be a string or list of selectors to
insert before the token type classes._

**Args**: self, arg


#### `get_token_style_defs()` (line 522)
**Args**: self, arg


#### `get_background_style_defs()` (line 539)
**Args**: self, arg


#### `get_linenos_style_defs()` (line 562)
**Args**: self


#### `get_css_prefix()` (line 573)
**Args**: self, arg


#### `prefix()` (line 581)
**Args**: cls


#### `_pre_style()` (line 592)
**Args**: self


#### `_linenos_style()` (line 596)
**Args**: self


#### `_linenos_special_style()` (line 602)
**Args**: self


#### `_decodeifneeded()` (line 607)
**Args**: self, value


#### `_wrap_full()` (line 614)
**Args**: self, inner, outfile


#### `_wrap_tablelinenos()` (line 655)
**Args**: self, inner


#### `_wrap_inlinelinenos()` (line 723)
**Args**: self, inner


#### `_wrap_lineanchors()` (line 766)
**Args**: self, inner


#### `_wrap_linespans()` (line 778)
**Args**: self, inner


#### `_wrap_div()` (line 788)
**Args**: self, inner


#### `_wrap_pre()` (line 802)
**Args**: self, inner


#### `_wrap_code()` (line 819)
**Args**: self, inner


#### `_translate_parts()` (line 825)
_HTML-escape a value and split it by newlines._

**Args**: self, value


#### `_format_lines()` (line 829)
_Just format the tokens, without any wrapping tags.
Yield individual lines._

**Args**: self, tokensource


#### `_lookup_ctag()` (line 907)
**Args**: self, token


#### `_highlight_lines()` (line 914)
_Highlighted the lines specified in the `hl_lines` option by
post-processing the token stream coming from `_format_lines`._

**Args**: self, tokensource


#### `wrap()` (line 935)
_Wrap the ``source``, which is a generator yielding
individual lines, in custom generators. See docstring
for `format`. Can be overridden._

**Args**: self, source


#### `format_unencoded()` (line 950)
_The formatting process uses several nested generators; which of
them are used is determined by the user's options.

Each generator should take at least one argument, ``inner``,
and wrap the pieces of text generated by this.

Always yield 2-tuples: (code, text). If "code" is 1, the text
is part of the original tokensource being highlighted, if it's
0, the text is some piece of wrapping. This makes it possible to
use several different wrappers that process the original source
linewise, e.g. line number generators._

**Args**: self, tokensource, outfile


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\img.py

#### `__init__()` (line 65)
**Args**: self, font_name, font_size


#### `_get_nix_font_path()` (line 92)
**Args**: self, name, style


#### `_create_nix()` (line 106)
**Args**: self


#### `_get_mac_font_path()` (line 126)
**Args**: self, font_map, name, style


#### `_create_mac()` (line 129)
**Args**: self


#### `_lookup_win()` (line 157)
**Args**: self, key, basename, styles, fail


#### `_create_win()` (line 171)
**Args**: self


#### `get_char_size()` (line 210)
_Get the character size._

**Args**: self


#### `get_text_size()` (line 216)
_Get the text size (width, height)._

**Args**: self, text


#### `get_font()` (line 226)
_Get the font based on bold and italic flags._

**Args**: self, bold, oblique


#### `get_style()` (line 251)
_Get the specified style of the font if it is a variable font.
If not found, return the normal font._

**Args**: self, style


#### `__init__()` (line 389)
_See the class docstring for explanation of options._

**Args**: self


#### `get_style_defs()` (line 445)
**Args**: self, arg


#### `_get_line_height()` (line 449)
_Get the height of a line._

**Args**: self


#### `_get_line_y()` (line 455)
_Get the Y coordinate of a line number._

**Args**: self, lineno


#### `_get_char_width()` (line 461)
_Get the width of a character._

**Args**: self


#### `_get_char_x()` (line 467)
_Get the X coordinate of a character position._

**Args**: self, linelength


#### `_get_text_pos()` (line 473)
_Get the actual position for a character and line position._

**Args**: self, linelength, lineno


#### `_get_linenumber_pos()` (line 479)
_Get the actual position for the start of a line number._

**Args**: self, lineno


#### `_get_text_color()` (line 485)
_Get the correct color for the token from the style._

**Args**: self, style


#### `_get_text_bg_color()` (line 495)
_Get the correct background color for the token from the style._

**Args**: self, style


#### `_get_style_font()` (line 505)
_Get the correct font for the style._

**Args**: self, style


#### `_get_image_size()` (line 511)
_Get the required image size._

**Args**: self, maxlinelength, maxlineno


#### `_draw_linenumber()` (line 518)
_Remember a line number drawable to paint later._

**Args**: self, posno, lineno


#### `_draw_text()` (line 531)
_Remember a single drawable tuple to paint later._

**Args**: self, pos, text, font, text_fg, text_bg


#### `_create_drawables()` (line 537)
_Create drawables for the token content._

**Args**: self, tokensource


#### `_draw_line_numbers()` (line 577)
_Create drawables for the line numbers._

**Args**: self


#### `_paint_line_number_bg()` (line 588)
_Paint the line number background on the image._

**Args**: self, im


#### `format()` (line 605)
_Format ``tokensource``, an iterable of ``(tokentype, tokenstring)``
tuples and write it into ``outfile``.

This implementation calculates where it should draw each token on the
pixmap, then calculates the required pixmap size and draws the items._

**Args**: self, tokensource, outfile


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\irc.py

#### `ircformat()` (line 76)
**Args**: color, text


#### `__init__()` (line 122)
**Args**: self


#### `_write_lineno()` (line 130)
**Args**: self, outfile


#### `format_unencoded()` (line 135)
**Args**: self, tokensource, outfile


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\latex.py

#### `escape_tex()` (line 22)
**Args**: text, commandprefix


#### `_get_ttype_name()` (line 135)
**Args**: ttype


#### `__init__()` (line 256)
**Args**: self


#### `_create_stylesheet()` (line 279)
**Args**: self


#### `rgbcolor()` (line 284)
**Args**: col


#### `get_style_defs()` (line 321)
_Return the command sequences needed to define the commands
used to format text in the verbatim environment. ``arg`` is ignored._

**Args**: self, arg


#### `format_unencoded()` (line 333)
**Args**: self, tokensource, outfile


#### `__init__()` (line 448)
**Args**: self, left, right, lang


#### `get_tokens_unprocessed()` (line 454)
**Args**: self, text


#### `_find_safe_escape_tokens()` (line 473)
_find escape tokens that are not in strings or comments _

**Args**: self, text


#### `_filter_to()` (line 485)
_Keep only the tokens that match `pred`, merge the others together _

**Args**: self, it, pred


#### `_find_escape_tokens()` (line 502)
_Find escape tokens within text, give token=None otherwise _

**Args**: self, text


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\other.py

#### `format()` (line 27)
**Args**: self, tokensource, outfile


#### `__init__()` (line 62)
**Args**: self


#### `format()` (line 79)
**Args**: self, tokensource, outfile


#### `write()` (line 95)
**Args**: text


#### `flush()` (line 98)

#### `__init__()` (line 138)
**Args**: self


#### `format()` (line 143)
**Args**: self, tokensource, outfile


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\pangomarkup.py

#### `escape_special_chars()` (line 23)
_Escape & and < for Pango Markup._

**Args**: text, table


#### `__init__()` (line 39)
**Args**: self


#### `format_unencoded()` (line 61)
**Args**: self, tokensource, outfile


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\rtf.py

#### `__init__()` (line 105)
_Additional options accepted:

``fontface``
    Name of the font used. Could for example be ``'Courier New'``
    to further specify the default which is ``'\fmodern'``. The RTF
    specification claims that ``\fmodern`` are "Fixed-pitch serif
    and sans serif fonts". Hope every RTF implementation thinks
    the same about modern..._

**Args**: self


#### `_escape()` (line 155)
**Args**: self, text


#### `_escape_text()` (line 160)
**Args**: self, text


#### `hex_to_rtf_color()` (line 185)
**Args**: hex_color


#### `_split_tokens_on_newlines()` (line 195)
_Split tokens containing newline characters into multiple token
each representing a line of the input file. Needed for numbering
lines of e.g. multiline comments._

**Args**: self, tokensource


#### `_create_color_mapping()` (line 213)
_Create a mapping of style hex colors to index/offset in
the RTF color table._

**Args**: self


#### `_lineno_template()` (line 238)
**Args**: self


#### `_hl_open_str()` (line 248)
**Args**: self


#### `_rtf_header()` (line 252)
**Args**: self


#### `format_unencoded()` (line 278)
**Args**: self, tokensource, outfile


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\svg.py

#### `escape_html()` (line 18)
_Escape &, <, > as well as single and double quotes for HTML._

**Args**: text


#### `__init__()` (line 93)
**Args**: self


#### `format_unencoded()` (line 115)
_Format ``tokensource``, an iterable of ``(tokentype, tokenstring)``
tuples and write it into ``outfile``.

For our implementation we put all lines in their own 'line group'._

**Args**: self, tokensource, outfile


#### `_get_style()` (line 170)
**Args**: self, tokentype


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\terminal.py

#### `__init__()` (line 83)
**Args**: self


#### `format()` (line 91)
**Args**: self, tokensource, outfile


#### `_write_lineno()` (line 94)
**Args**: self, outfile


#### `_get_color()` (line 98)
**Args**: self, ttype


#### `format_unencoded()` (line 108)
**Args**: self, tokensource, outfile


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\terminal256.py

#### `__init__()` (line 35)
**Args**: self, fg, bg, bold, underline, italic


#### `escape()` (line 42)
**Args**: self, attrs


#### `color_string()` (line 47)
**Args**: self


#### `true_color_string()` (line 73)
**Args**: self


#### `reset_string()` (line 87)
**Args**: self


#### `__init__()` (line 135)
**Args**: self


#### `_build_color_table()` (line 152)
**Args**: self


#### `_closest_color()` (line 188)
**Args**: self, r, g, b


#### `_color_index()` (line 205)
**Args**: self, color


#### `_setup_styles()` (line 224)
**Args**: self


#### `_write_lineno()` (line 245)
**Args**: self, outfile


#### `format()` (line 249)
**Args**: self, tokensource, outfile


#### `format_unencoded()` (line 252)
**Args**: self, tokensource, outfile


#### `_build_color_table()` (line 311)
**Args**: self


#### `_color_tuple()` (line 314)
**Args**: self, color


#### `_setup_styles()` (line 324)
**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\pygments\lexer.py

#### `__new__()` (line 43)
**Args**: mcs, name, bases, d


#### `__init__()` (line 145)
_This constructor takes arbitrary options as keyword arguments.
Every subclass must first process its own options and then call
the `Lexer` constructor, since it processes the basic
options like `stripnl`.

An example looks like this:

.. sourcecode:: python

   def __init__(self, **options):
       self.compress = options.get('compress', '')
       Lexer.__init__(self, **options)

As these options must all be specifiable as strings (due to the
command line usage), there are various utility functions
available to help with that, see `Utilities`_._

**Args**: self


#### `__repr__()` (line 175)
**Args**: self


#### `add_filter()` (line 181)
_Add a new stream filter to this lexer._

**Args**: self, filter_


#### `analyse_text()` (line 189)
_A static method which is called for lexer guessing.

It should analyse the text and return a float in the range
from ``0.0`` to ``1.0``.  If it returns ``0.0``, the lexer
will not be selected as the most probable one, if it returns
``1.0``, it will be selected immediately.  This is used by
`guess_lexer`.

The `LexerMeta` metaclass automatically wraps this function so
that it works like a static method (no ``self`` or ``cls``
parameter) and the return value is automatically converted to
`float`. If the return value is an object that is boolean `False`
it's the same as if the return values was ``0.0``._

**Args**: text


#### `_preprocess_lexer_input()` (line 206)
_Apply preprocessing such as decoding the input, removing BOM and normalizing newlines._

**Args**: self, text


#### `get_tokens()` (line 255)
_This method is the basic interface of a lexer. It is called by
the `highlight()` function. It must process the text and return an
iterable of ``(tokentype, value)`` pairs from `text`.

Normally, you don't need to override this method. The default
implementation processes the options recognized by all lexers
(`stripnl`, `stripall` and so on), and then yields all tokens
from `get_tokens_unprocessed()`, with the ``index`` dropped.

If `unfiltered` is set to `True`, the filtering mechanism is
bypassed even if filters are defined._

**Args**: self, text, unfiltered


#### `streamer()` (line 271)

#### `get_tokens_unprocessed()` (line 279)
_This method should process the text and return an iterable of
``(index, tokentype, value)`` tuples where ``index`` is the starting
position of the token within the input text.

It must be overridden by subclasses. It is recommended to
implement it as a generator to maximize effectiveness._

**Args**: self, text


#### `__init__()` (line 301)
**Args**: self, _root_lexer, _language_lexer, _needle


#### `get_tokens_unprocessed()` (line 307)
**Args**: self, text


#### `__repr__()` (line 341)
**Args**: self


#### `__new__()` (line 352)
**Args**: cls


#### `__init__()` (line 355)
**Args**: self


#### `__init__()` (line 365)
**Args**: self, start, text


#### `start()` (line 369)
**Args**: self, arg


#### `end()` (line 372)
**Args**: self, arg


#### `group()` (line 375)
**Args**: self, arg


#### `groups()` (line 380)
**Args**: self


#### `groupdict()` (line 383)
**Args**: self


#### `bygroups()` (line 387)
_Callback that yields multiple actions for each group in the match._


#### `callback()` (line 391)
**Args**: lexer, match, ctx


#### `using()` (line 422)
_Callback that processes the match with a different lexer.

The keyword arguments are forwarded to the lexer, except `state` which
is handled separately.

`state` specifies the state that the new lexer will start in, and can
be an enumerable such as ('root', 'inline', 'string') or a simple
string which is assumed to be on top of the root state.

Note: For that to work, `_other` must not be an `ExtendedRegexLexer`._

**Args**: _other


#### `callback()` (line 444)
**Args**: lexer, match, ctx


#### `callback()` (line 459)
**Args**: lexer, match, ctx


#### `__init__()` (line 480)
**Args**: self, state


#### `__init__()` (line 491)
**Args**: self, words, prefix, suffix


#### `get()` (line 496)
**Args**: self


#### `_process_regex()` (line 506)
_Preprocess the regular expression component of a token definition._

**Args**: cls, regex, rflags, state


#### `_process_token()` (line 512)
_Preprocess the token component of a token definition._

**Args**: cls, token


#### `_process_new_state()` (line 518)
_Preprocess the state transition action of a token definition._

**Args**: cls, new_state, unprocessed, processed


#### `_process_state()` (line 553)
_Preprocess a single state definition._

**Args**: cls, unprocessed, processed, state


#### `process_tokendef()` (line 596)
_Preprocess a dictionary of token definitions._

**Args**: cls, name, tokendefs


#### `get_tokendefs()` (line 604)
_Merge tokens from superclasses in MRO order, returning a single tokendef
dictionary.

Any state that is not defined by a subclass will be inherited
automatically.  States that *are* defined by subclasses will, by
default, override that state in the superclass.  If a subclass wishes to
inherit definitions from a superclass, it can use the special value
"inherit", which will cause the superclass' state definition to be
included at that point in the state._

**Args**: cls


#### `__call__()` (line 653)
_Instantiate cls after preprocessing its token definitions._

**Args**: cls


#### `get_tokens_unprocessed()` (line 702)
_Split ``text`` into (tokentype, text) pairs.

``stack`` is the initial stack (default: ``['root']``)_

**Args**: self, text, stack


#### `__init__()` (line 769)
**Args**: self, text, pos, stack, end


#### `__repr__()` (line 775)
**Args**: self


#### `get_tokens_unprocessed()` (line 784)
_Split ``text`` into (tokentype, text) pairs.
If ``context`` is given, use this lexer context instead._

**Args**: self, text, context


#### `do_insertions()` (line 851)
_Helper for lexers which must combine the results of several
sublexers.

``insertions`` is a list of ``(index, itokens)`` pairs.
Each ``itokens`` iterable should be inserted at position
``index`` into the token stream given by the ``tokens``
argument.

The result is a combined token stream.

TODO: clean up the code here._

**Args**: insertions, tokens


#### `_process_regex()` (line 918)
**Args**: cls, regex, rflags, state


#### `match_func()` (line 926)
**Args**: text, pos, endpos


#### `get_tokens_unprocessed()` (line 943)
**Args**: self, text, stack


### venv_new\Lib\site-packages\pip\_vendor\pygments\lexers\__init__.py

#### `_fn_matches()` (line 35)
_Return whether the supplied file name fn matches pattern filename._

**Args**: fn, glob


#### `_load_lexers()` (line 43)
_Load a lexer (and all others in the module too)._

**Args**: module_name


#### `get_all_lexers()` (line 51)
_Return a generator of tuples in the form ``(name, aliases,
filenames, mimetypes)`` of all know lexers.

If *plugins* is true (the default), plugin lexers supplied by entrypoints
are also returned.  Otherwise, only builtin ones are considered._

**Args**: plugins


#### `find_lexer_class()` (line 65)
_Return the `Lexer` subclass that with the *name* attribute as given by
the *name* argument._

**Args**: name


#### `find_lexer_class_by_name()` (line 83)
_Return the `Lexer` subclass that has `alias` in its aliases list, without
instantiating it.

Like `get_lexer_by_name`, but does not instantiate the class.

Will raise :exc:`pygments.util.ClassNotFound` if no lexer with that alias is
found.

.. versionadded:: 2.2_

**Args**: _alias


#### `get_lexer_by_name()` (line 110)
_Return an instance of a `Lexer` subclass that has `alias` in its
aliases list. The lexer is given the `options` at its
instantiation.

Will raise :exc:`pygments.util.ClassNotFound` if no lexer with that alias is
found._

**Args**: _alias


#### `load_lexer_from_file()` (line 135)
_Load a lexer from a file.

This method expects a file located relative to the current working
directory, which contains a Lexer class. By default, it expects the
Lexer to be name CustomLexer; you can specify your own class name
as the second argument to this function.

Users should be very careful with the input, because this method
is equivalent to running eval on the input file.

Raises ClassNotFound if there are any problems importing the Lexer.

.. versionadded:: 2.2_

**Args**: filename, lexername


#### `find_lexer_class_for_filename()` (line 169)
_Get a lexer for a filename.

If multiple lexers match the filename pattern, use ``analyse_text()`` to
figure out which one is more appropriate.

Returns None if not found._

**Args**: _fn, code


#### `get_rating()` (line 194)
**Args**: info


#### `get_lexer_for_filename()` (line 212)
_Get a lexer for a filename.

Return a `Lexer` subclass instance that has a filename pattern
matching `fn`. The lexer is given the `options` at its
instantiation.

Raise :exc:`pygments.util.ClassNotFound` if no lexer for that filename
is found.

If multiple lexers match the filename pattern, use their ``analyse_text()``
methods to figure out which one is more appropriate._

**Args**: _fn, code


#### `get_lexer_for_mimetype()` (line 231)
_Return a `Lexer` subclass instance that has `mime` in its mimetype
list. The lexer is given the `options` at its instantiation.

Will raise :exc:`pygments.util.ClassNotFound` if not lexer for that mimetype
is found._

**Args**: _mime


#### `_iter_lexerclasses()` (line 250)
_Return an iterator over all lexer classes._

**Args**: plugins


#### `guess_lexer_for_filename()` (line 261)
_As :func:`guess_lexer()`, but only lexers which have a pattern in `filenames`
or `alias_filenames` that matches `filename` are taken into consideration.

:exc:`pygments.util.ClassNotFound` is raised if no lexer thinks it can
handle the content._

**Args**: _fn, _text


#### `type_sort()` (line 292)
**Args**: t


#### `guess_lexer()` (line 304)
_Return a `Lexer` subclass instance that's guessed from the text in
`text`. For that, the :meth:`.analyse_text()` method of every known lexer
class is called with the text as argument, and the lexer which returned the
highest value will be instantiated and returned.

:exc:`pygments.util.ClassNotFound` is raised if no lexer thinks it can
handle the content._

**Args**: _text


#### `__getattr__()` (line 346)
**Args**: self, name


### venv_new\Lib\site-packages\pip\_vendor\pygments\lexers\python.py

#### `innerstring_rules()` (line 65)
**Args**: ttype


#### `fstring_rules()` (line 85)
**Args**: ttype


#### `analyse_text()` (line 408)
**Args**: text


#### `innerstring_rules()` (line 433)
**Args**: ttype


#### `analyse_text()` (line 635)
**Args**: text


#### `__init__()` (line 704)
**Args**: self


#### `__init__()` (line 718)
**Args**: self


#### `get_tokens_unprocessed()` (line 1186)
**Args**: self, text


#### `analyse_text()` (line 1194)
**Args**: text


### venv_new\Lib\site-packages\pip\_vendor\pygments\modeline.py

#### `get_filetype_from_line()` (line 22)
**Args**: l


#### `get_filetype_from_buffer()` (line 28)
_Scan the buffer for modelines and return filetype if one is found._

**Args**: buf, max_lines


### venv_new\Lib\site-packages\pip\_vendor\pygments\plugin.py

#### `iter_entry_points()` (line 43)
**Args**: group_name


#### `find_plugin_lexers()` (line 55)

#### `find_plugin_formatters()` (line 60)

#### `find_plugin_styles()` (line 65)

#### `find_plugin_filters()` (line 70)

### venv_new\Lib\site-packages\pip\_vendor\pygments\regexopt.py

#### `make_charset()` (line 22)
**Args**: letters


#### `regex_opt_inner()` (line 26)
_Return a regex that matches any string in the sorted list of strings._

**Args**: strings, open_paren


#### `regex_opt()` (line 82)
_Return a compiled regex that matches any string in the given list.

The strings to match must be literal strings, not regexes.  They will be
regex-escaped.

*prefix* and *suffix* are pre- and appended to the final regex._

**Args**: strings, prefix, suffix


### venv_new\Lib\site-packages\pip\_vendor\pygments\scanner.py

#### `__init__()` (line 35)
_:param text:    The text which should be scanned
:param flags:   default regular expression flags_

**Args**: self, text, flags


#### `eos()` (line 49)
_`True` if the scanner reached the end of text._

**Args**: self


#### `check()` (line 54)
_Apply `pattern` on the current position and return
the match object. (Doesn't touch pos). Use this for
lookahead._

**Args**: self, pattern


#### `test()` (line 66)
_Apply a pattern on the current position and check
if it patches. Doesn't touch pos._

**Args**: self, pattern


#### `scan()` (line 72)
_Scan the text for the given pattern and update pos/match
and related fields. The return value is a boolean that
indicates if the pattern matched. The matched value is
stored on the instance as ``match``, the last value is
stored as ``last``. ``start_pos`` is the position of the
pointer before the pattern was matched, ``pos`` is the
end position._

**Args**: self, pattern


#### `get_char()` (line 95)
_Scan exactly one char._

**Args**: self


#### `__repr__()` (line 99)
**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\pygments\sphinxext.py

#### `run()` (line 71)
**Args**: self


#### `document_lexers_overview()` (line 90)
_Generate a tabular overview of all lexers.

The columns are the lexer name, the extensions handled by this lexer
(or "None"), the aliases and a link to the lexer class._

**Args**: self


#### `format_link()` (line 101)
**Args**: name, url


#### `write_row()` (line 121)
_Format a table row_


#### `write_seperator()` (line 132)
_Write a table separator row_


#### `document_lexers()` (line 150)
**Args**: self


#### `document_formatters()` (line 215)
**Args**: self


#### `document_filters()` (line 233)
**Args**: self


#### `setup()` (line 246)
**Args**: app


### venv_new\Lib\site-packages\pip\_vendor\pygments\style.py

#### `__new__()` (line 60)
**Args**: mcs, name, bases, dct


#### `colorformat()` (line 66)
**Args**: text


#### `style_for_token()` (line 126)
**Args**: cls, token


#### `list_styles()` (line 156)
**Args**: cls


#### `styles_token()` (line 159)
**Args**: cls, ttype


#### `__iter__()` (line 162)
**Args**: cls


#### `__len__()` (line 166)
**Args**: cls


### venv_new\Lib\site-packages\pip\_vendor\pygments\styles\__init__.py

#### `get_style_by_name()` (line 24)
_Return a style class by its short name. The names of the builtin styles
are listed in :data:`pygments.styles.STYLE_MAP`.

Will raise :exc:`pygments.util.ClassNotFound` if no style of that name is
found._

**Args**: name


#### `get_all_styles()` (line 56)
_Return a generator for all styles by name, both builtin and plugin._


### venv_new\Lib\site-packages\pip\_vendor\pygments\token.py

#### `split()` (line 15)
**Args**: self


#### `__init__()` (line 24)
**Args**: self


#### `__contains__()` (line 28)
**Args**: self, val


#### `__getattr__()` (line 34)
**Args**: self, val


#### `__repr__()` (line 43)
**Args**: self


#### `__copy__()` (line 46)
**Args**: self


#### `__deepcopy__()` (line 50)
**Args**: self, memo


#### `is_token_subtype()` (line 85)
_Return True if ``ttype`` is a subtype of ``other``.

exists for backwards compatibility. use ``ttype in other`` now._

**Args**: ttype, other


#### `string_to_tokentype()` (line 94)
_Convert a string into a token type::

    >>> string_to_token('String.Double')
    Token.Literal.String.Double
    >>> string_to_token('Token.Literal.Number')
    Token.Literal.Number
    >>> string_to_token('')
    Token

Tokens that are already tokens are returned unchanged:

    >>> string_to_token(String)
    Token.Literal.String_

**Args**: s


### venv_new\Lib\site-packages\pip\_vendor\pygments\unistring.py

#### `combine()` (line 82)

#### `allexcept()` (line 86)

#### `_handle_runs()` (line 93)
**Args**: char_list


### venv_new\Lib\site-packages\pip\_vendor\pygments\util.py

#### `get_choice_opt()` (line 40)
_If the key `optname` from the dictionary is not in the sequence
`allowed`, raise an error, otherwise return it._

**Args**: options, optname, allowed, default, normcase


#### `get_bool_opt()` (line 53)
_Intuitively, this is `options.get(optname, default)`, but restricted to
Boolean value. The Booleans can be represented as string, in order to accept
Boolean value from the command line arguments. If the key `optname` is
present in the dictionary `options` and is not associated with a Boolean,
raise an `OptionError`. If it is absent, `default` is returned instead.

The valid string values for ``True`` are ``1``, ``yes``, ``true`` and
``on``, the ones for ``False`` are ``0``, ``no``, ``false`` and ``off``
(matched case-insensitively)._

**Args**: options, optname, default


#### `get_int_opt()` (line 82)
_As :func:`get_bool_opt`, but interpret the value as an integer._

**Args**: options, optname, default


#### `get_list_opt()` (line 94)
_If the key `optname` from the dictionary `options` is a string,
split it at whitespace and return it. If it is already a list
or a tuple, it is returned as a list._

**Args**: options, optname, default


#### `docstring_headline()` (line 110)
**Args**: obj


#### `make_analysator()` (line 122)
_Return a static text analyser function that returns float values._

**Args**: f


#### `text_analyse()` (line 124)
**Args**: text


#### `shebang_matches()` (line 139)
_Check if the given regular expression matches the last part of the
shebang if one exists.

    >>> from pygments.util import shebang_matches
    >>> shebang_matches('#!/usr/bin/env python', r'python(2\.\d)?')
    True
    >>> shebang_matches('#!/usr/bin/python2.4', r'python(2\.\d)?')
    True
    >>> shebang_matches('#!/usr/bin/python-ruby', r'python(2\.\d)?')
    False
    >>> shebang_matches('#!/usr/bin/python/ruby', r'python(2\.\d)?')
    False
    >>> shebang_matches('#!/usr/bin/startsomethingwith python',
    ...                 r'python(2\.\d)?')
    True

It also checks for common windows executable file extensions::

    >>> shebang_matches('#!C:\\Python2.4\\Python.exe', r'python(2\.\d)?')
    True

Parameters (``'-f'`` or ``'--foo'`` are ignored so ``'perl'`` does
the same as ``'perl -e'``)

Note that this method automatically searches the whole string (eg:
the regular expression is wrapped in ``'^$'``)_

**Args**: text, regex


#### `doctype_matches()` (line 184)
_Check if the doctype matches a regular expression (if present).

Note that this method only checks the first part of a DOCTYPE.
eg: 'html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"'_

**Args**: text, regex


#### `html_doctype_matches()` (line 197)
_Check if the file looks like it has a html doctype._

**Args**: text


#### `looks_like_xml()` (line 205)
_Check if a doctype exists or if we have some tags._

**Args**: text


#### `surrogatepair()` (line 221)
_Given a unicode character code with length greater than 16 bits,
return the two 16 bit surrogate pair._

**Args**: c


#### `format_lines()` (line 230)
_Formats a sequence of strings for output._

**Args**: var_name, seq, raw, indent_level


#### `duplicates_removed()` (line 249)
_Returns a list with duplicates removed from the iterable `it`.

Order is preserved._

**Args**: it, already_seen


#### `get()` (line 271)
**Args**: self


#### `guess_decode()` (line 275)
_Decode *text* with guessed encoding.

First try UTF-8; this should fail for non-UTF-8 encodings.
Then try the preferred locale encoding.
Fall back to latin-1, which always works._

**Args**: text


#### `guess_decode_from_terminal()` (line 296)
_Decode *text* coming from terminal *term*.

First try the terminal encoding, if given.
Then try UTF-8.  Then try the preferred locale encoding.
Fall back to latin-1, which always works._

**Args**: text, term


#### `terminal_encoding()` (line 313)
_Return our best guess of encoding for the given *term*._

**Args**: term


#### `close()` (line 323)
**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py

#### `__call__()` (line 19)
**Args**: self, cmd, cwd, extra_environ


#### `write_json()` (line 28)
**Args**: obj, path


#### `read_json()` (line 33)
**Args**: path


#### `__init__()` (line 41)
**Args**: self, traceback, message, backend_name, backend_path


#### `__init__()` (line 58)
**Args**: self, hook_name


#### `__init__()` (line 66)
**Args**: self, traceback


#### `default_subprocess_runner()` (line 70)
_The default method of calling the wrapper subprocess.

This uses :func:`subprocess.check_call` under the hood._

**Args**: cmd, cwd, extra_environ


#### `quiet_subprocess_runner()` (line 86)
_Call the subprocess while suppressing output.

This uses :func:`subprocess.check_output` under the hood._

**Args**: cmd, cwd, extra_environ


#### `norm_and_check()` (line 102)
_Normalise and check a backend path.

Ensure that the requested backend path is specified as a relative path,
and resolves to a location under the given source tree.

Return an absolute version of the requested path._

**Args**: source_tree, requested


#### `__init__()` (line 129)
_:param source_dir: The source directory to invoke the build backend for
:param build_backend: The build backend spec
:param backend_path: Additional path entries for the build backend spec
:param runner: The :ref:`subprocess runner <Subprocess Runners>` to use
:param python_executable:
    The Python executable used to invoke the build backend_

**Args**: self, source_dir, build_backend, backend_path, runner, python_executable


#### `subprocess_runner()` (line 159)
_A context manager for temporarily overriding the default
:ref:`subprocess runner <Subprocess Runners>`.

:param runner: The new subprocess runner to use within the context.

.. code-block:: python

    hook_caller = BuildBackendHookCaller(...)
    with hook_caller.subprocess_runner(quiet_subprocess_runner):
        ..._

**Args**: self, runner


#### `_supported_features()` (line 178)
_Return the list of optional features supported by the backend._

**Args**: self


#### `get_requires_for_build_wheel()` (line 182)
_Get additional dependencies required for building a wheel.

:param config_settings: The configuration settings for the build backend
:returns: A list of :pep:`dependency specifiers <508>`.

.. admonition:: Fallback

    If the build backend does not defined a hook with this name, an
    empty list will be returned._

**Args**: self, config_settings


#### `prepare_metadata_for_build_wheel()` (line 200)
_Prepare a ``*.dist-info`` folder with metadata for this project.

:param metadata_directory: The directory to write the metadata to
:param config_settings: The configuration settings for the build backend
:param _allow_fallback:
    Whether to allow the fallback to building a wheel and extracting
    the metadata from it. Should be passed as a keyword argument only.

:returns: Name of the newly created subfolder within
          ``metadata_directory``, containing the metadata.

.. admonition:: Fallback

    If the build backend does not define a hook with this name and
    ``_allow_fallback`` is truthy, the backend will be asked to build a
    wheel via the ``build_wheel`` hook and the dist-info extracted from
    that will be returned._

**Args**: self, metadata_directory, config_settings, _allow_fallback


#### `build_wheel()` (line 233)
_Build a wheel from this project.

:param wheel_directory: The directory to write the wheel to
:param config_settings: The configuration settings for the build backend
:param metadata_directory: The directory to reuse existing metadata from
:returns:
    The name of the newly created wheel within ``wheel_directory``.

.. admonition:: Interaction with fallback

    If the ``build_wheel`` hook was called in the fallback for
    :meth:`prepare_metadata_for_build_wheel`, the build backend would
    not be invoked. Instead, the previously built wheel will be copied
    to ``wheel_directory`` and the name of that file will be returned._

**Args**: self, wheel_directory, config_settings, metadata_directory


#### `get_requires_for_build_editable()` (line 265)
_Get additional dependencies required for building an editable wheel.

:param config_settings: The configuration settings for the build backend
:returns: A list of :pep:`dependency specifiers <508>`.

.. admonition:: Fallback

    If the build backend does not defined a hook with this name, an
    empty list will be returned._

**Args**: self, config_settings


#### `prepare_metadata_for_build_editable()` (line 283)
_Prepare a ``*.dist-info`` folder with metadata for this project.

:param metadata_directory: The directory to write the metadata to
:param config_settings: The configuration settings for the build backend
:param _allow_fallback:
    Whether to allow the fallback to building a wheel and extracting
    the metadata from it. Should be passed as a keyword argument only.
:returns: Name of the newly created subfolder within
          ``metadata_directory``, containing the metadata.

.. admonition:: Fallback

    If the build backend does not define a hook with this name and
    ``_allow_fallback`` is truthy, the backend will be asked to build a
    wheel via the ``build_editable`` hook and the dist-info
    extracted from that will be returned._

**Args**: self, metadata_directory, config_settings, _allow_fallback


#### `build_editable()` (line 315)
_Build an editable wheel from this project.

:param wheel_directory: The directory to write the wheel to
:param config_settings: The configuration settings for the build backend
:param metadata_directory: The directory to reuse existing metadata from
:returns:
    The name of the newly created wheel within ``wheel_directory``.

.. admonition:: Interaction with fallback

    If the ``build_editable`` hook was called in the fallback for
    :meth:`prepare_metadata_for_build_editable`, the build backend
    would not be invoked. Instead, the previously built wheel will be
    copied to ``wheel_directory`` and the name of that file will be
    returned._

**Args**: self, wheel_directory, config_settings, metadata_directory


#### `get_requires_for_build_sdist()` (line 348)
_Get additional dependencies required for building an sdist.

:returns: A list of :pep:`dependency specifiers <508>`._

**Args**: self, config_settings


#### `build_sdist()` (line 360)
_Build an sdist from this project.

:returns:
    The name of the newly created sdist within ``wheel_directory``._

**Args**: self, sdist_directory, config_settings


#### `_call_hook()` (line 378)
**Args**: self, hook_name, kwargs


### venv_new\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\__init__.py

#### `_in_proc_script_path()` (line 13)

#### `_in_proc_script_path()` (line 18)

### venv_new\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py

#### `write_json()` (line 31)
**Args**: obj, path


#### `read_json()` (line 36)
**Args**: path


#### `__init__()` (line 44)
**Args**: self, message, traceback


#### `__init__()` (line 53)
**Args**: self, hook_name


#### `_build_backend()` (line 58)
_Find and load the build backend_


#### `__init__()` (line 89)
**Args**: self, backend_path, backend_module


#### `find_spec()` (line 94)
**Args**: self, fullname, _path, _target


#### `find_distributions()` (line 111)
**Args**: self, context


#### `_supported_features()` (line 119)
_Return the list of options features supported by the backend.

Returns a list of strings.
The only possible value is 'build_editable'._


#### `get_requires_for_build_wheel()` (line 132)
_Invoke the optional get_requires_for_build_wheel hook

Returns [] if the hook is not defined._

**Args**: config_settings


#### `get_requires_for_build_editable()` (line 146)
_Invoke the optional get_requires_for_build_editable hook

Returns [] if the hook is not defined._

**Args**: config_settings


#### `prepare_metadata_for_build_wheel()` (line 160)
_Invoke optional prepare_metadata_for_build_wheel

Implements a fallback by building a wheel if the hook isn't defined,
unless _allow_fallback is False in which case HookMissing is raised._

**Args**: metadata_directory, config_settings, _allow_fallback


#### `prepare_metadata_for_build_editable()` (line 184)
_Invoke optional prepare_metadata_for_build_editable

Implements a fallback by building an editable wheel if the hook isn't
defined, unless _allow_fallback is False in which case HookMissing is
raised._

**Args**: metadata_directory, config_settings, _allow_fallback


#### `_dist_info_files()` (line 215)
_Identify the .dist-info folder inside a wheel ZipFile._

**Args**: whl_zip


#### `_get_wheel_metadata_from_wheel()` (line 227)
_Extract the metadata from a wheel.

Fallback for when the build backend does not
define the 'get_wheel_metadata' hook._

**Args**: whl_basename, metadata_directory, config_settings


#### `_find_already_built_wheel()` (line 245)
_Check for a wheel already built during the get_wheel_metadata hook._

**Args**: metadata_directory


#### `build_wheel()` (line 268)
_Invoke the mandatory build_wheel hook.

If a wheel was already built in the
prepare_metadata_for_build_wheel fallback, this
will copy it rather than rebuilding the wheel._

**Args**: wheel_directory, config_settings, metadata_directory


#### `build_editable()` (line 285)
_Invoke the optional build_editable hook.

If a wheel was already built in the
prepare_metadata_for_build_editable fallback, this
will copy it rather than rebuilding the wheel._

**Args**: wheel_directory, config_settings, metadata_directory


#### `get_requires_for_build_sdist()` (line 306)
_Invoke the optional get_requires_for_build_wheel hook

Returns [] if the hook is not defined._

**Args**: config_settings


#### `__init__()` (line 327)
**Args**: self, traceback


#### `build_sdist()` (line 331)
_Invoke the mandatory build_sdist hook._

**Args**: sdist_directory, config_settings


#### `main()` (line 353)

### venv_new\Lib\site-packages\pip\_vendor\requests\__init__.py

#### `check_compatibility()` (line 51)
**Args**: urllib3_version, chardet_version, charset_normalizer_version


#### `_check_cryptography()` (line 83)
**Args**: cryptography_version


### venv_new\Lib\site-packages\pip\_vendor\requests\_internal_utils.py

#### `to_native_string()` (line 25)
_Given a string object, regardless of type, returns a representation of
that string in the native string type, encoding and decoding where
necessary. This assumes ASCII unless told otherwise._

**Args**: string, encoding


#### `unicode_is_ascii()` (line 38)
_Determine if unicode string only contains ASCII characters.

:param str u_string: unicode string to check. Must be unicode
    and not Python 2 `str`.
:rtype: bool_

**Args**: u_string


### venv_new\Lib\site-packages\pip\_vendor\requests\adapters.py

#### `SOCKSProxyManager()` (line 63)

#### `_urllib3_request_context()` (line 90)
**Args**: request, verify, client_cert, poolmanager


#### `__init__()` (line 140)
**Args**: self


#### `send()` (line 143)
_Sends PreparedRequest object. Returns Response object.

:param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
:param stream: (optional) Whether to stream the request content.
:param timeout: (optional) How long to wait for the server to send
    data before giving up, as a float, or a :ref:`(connect timeout,
    read timeout) <timeouts>` tuple.
:type timeout: float or tuple
:param verify: (optional) Either a boolean, in which case it controls whether we verify
    the server's TLS certificate, or a string, in which case it must be a path
    to a CA bundle to use
:param cert: (optional) Any user-provided SSL certificate to be trusted.
:param proxies: (optional) The proxies dictionary to apply to the request._

**Args**: self, request, stream, timeout, verify, cert, proxies


#### `close()` (line 162)
_Cleans up adapter specific items._

**Args**: self


#### `__init__()` (line 202)
**Args**: self, pool_connections, pool_maxsize, max_retries, pool_block


#### `__getstate__()` (line 224)
**Args**: self


#### `__setstate__()` (line 227)
**Args**: self, state


#### `init_poolmanager()` (line 240)
_Initializes a urllib3 PoolManager.

This method should not be called from user code, and is only
exposed for use when subclassing the
:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

:param connections: The number of urllib3 connection pools to cache.
:param maxsize: The maximum number of connections to save in the pool.
:param block: Block when no free connections are available.
:param pool_kwargs: Extra keyword arguments used to initialize the Pool Manager._

**Args**: self, connections, maxsize, block


#### `proxy_manager_for()` (line 266)
_Return urllib3 ProxyManager for the given proxy.

This method should not be called from user code, and is only
exposed for use when subclassing the
:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

:param proxy: The proxy to return a urllib3 ProxyManager for.
:param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.
:returns: ProxyManager
:rtype: urllib3.ProxyManager_

**Args**: self, proxy


#### `cert_verify()` (line 304)
_Verify a SSL certificate. This method should not be called from user
code, and is only exposed for use when subclassing the
:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

:param conn: The urllib3 connection object associated with the cert.
:param url: The requested URL.
:param verify: Either a boolean, in which case it controls whether we verify
    the server's TLS certificate, or a string, in which case it must be a path
    to a CA bundle to use
:param cert: The SSL certificate to verify._

**Args**: self, conn, url, verify, cert


#### `build_response()` (line 359)
_Builds a :class:`Response <requests.Response>` object from a urllib3
response. This should not be called from user code, and is only exposed
for use when subclassing the
:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`

:param req: The :class:`PreparedRequest <PreparedRequest>` used to generate the response.
:param resp: The urllib3 response object.
:rtype: requests.Response_

**Args**: self, req, resp


#### `build_connection_pool_key_attributes()` (line 396)
_Build the PoolKey attributes used by urllib3 to return a connection.

This looks at the PreparedRequest, the user-specified verify value,
and the value of the cert parameter to determine what PoolKey values
to use to select a connection from a given urllib3 Connection Pool.

The SSL related pool key arguments are not consistently set. As of
this writing, use the following to determine what keys may be in that
dictionary:

* If ``verify`` is ``True``, ``"ssl_context"`` will be set and will be the
  default Requests SSL Context
* If ``verify`` is ``False``, ``"ssl_context"`` will not be set but
  ``"cert_reqs"`` will be set
* If ``verify`` is a string, (i.e., it is a user-specified trust bundle)
  ``"ca_certs"`` will be set if the string is not a directory recognized
  by :py:func:`os.path.isdir`, otherwise ``"ca_certs_dir"`` will be
  set.
* If ``"cert"`` is specified, ``"cert_file"`` will always be set. If
  ``"cert"`` is a tuple with a second item, ``"key_file"`` will also
  be present

To override these settings, one may subclass this class, call this
method and use the above logic to change parameters as desired. For
example, if one wishes to use a custom :py:class:`ssl.SSLContext` one
must both set ``"ssl_context"`` and based on what else they require,
alter the other keys to ensure the desired behaviour.

:param request:
    The PreparedReqest being sent over the connection.
:type request:
    :class:`~requests.models.PreparedRequest`
:param verify:
    Either a boolean, in which case it controls whether
    we verify the server's TLS certificate, or a string, in which case it
    must be a path to a CA bundle to use.
:param cert:
    (optional) Any user-provided SSL certificate for client
    authentication (a.k.a., mTLS). This may be a string (i.e., just
    the path to a file which holds both certificate and key) or a
    tuple of length 2 with the certificate file path and key file
    path.
:returns:
    A tuple of two dictionaries. The first is the "host parameters"
    portion of the Pool Key including scheme, hostname, and port. The
    second is a dictionary of SSLContext related parameters._

**Args**: self, request, verify, cert


#### `get_connection_with_tls_context()` (line 446)
_Returns a urllib3 connection for the given request and TLS settings.
This should not be called from user code, and is only exposed for use
when subclassing the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

:param request:
    The :class:`PreparedRequest <PreparedRequest>` object to be sent
    over the connection.
:param verify:
    Either a boolean, in which case it controls whether we verify the
    server's TLS certificate, or a string, in which case it must be a
    path to a CA bundle to use.
:param proxies:
    (optional) The proxies dictionary to apply to the request.
:param cert:
    (optional) Any user-provided SSL certificate to be used for client
    authentication (a.k.a., mTLS).
:rtype:
    urllib3.ConnectionPool_

**Args**: self, request, verify, proxies, cert


#### `get_connection()` (line 495)
_DEPRECATED: Users should move to `get_connection_with_tls_context`
for all subclasses of HTTPAdapter using Requests>=2.32.2.

Returns a urllib3 connection for the given URL. This should not be
called from user code, and is only exposed for use when subclassing the
:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

:param url: The URL to connect to.
:param proxies: (optional) A Requests-style dictionary of proxies used on this request.
:rtype: urllib3.ConnectionPool_

**Args**: self, url, proxies


#### `close()` (line 536)
_Disposes of any internal state.

Currently, this closes the PoolManager and any active ProxyManager,
which closes any pooled connections._

**Args**: self


#### `request_url()` (line 546)
_Obtain the url to use when making the final request.

If the message is being sent through a HTTP proxy, the full URL has to
be used. Otherwise, we should only use the path portion of the URL.

This should not be called from user code, and is only exposed for use
when subclassing the
:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

:param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
:param proxies: A dictionary of schemes or schemes and hosts to proxy URLs.
:rtype: str_

**Args**: self, request, proxies


#### `add_headers()` (line 578)
_Add any headers needed by the connection. As of v2.0 this does
nothing by default, but is left for overriding by users that subclass
the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

This should not be called from user code, and is only exposed for use
when subclassing the
:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

:param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.
:param kwargs: The keyword arguments from the call to send()._

**Args**: self, request


#### `proxy_headers()` (line 592)
_Returns a dictionary of the headers to add to any request sent
through a proxy. This works with urllib3 magic to ensure that they are
correctly sent to the proxy, rather than in a tunnelled request if
CONNECT is being used.

This should not be called from user code, and is only exposed for use
when subclassing the
:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

:param proxy: The url of the proxy being used for this request.
:rtype: dict_

**Args**: self, proxy


#### `send()` (line 613)
_Sends PreparedRequest object. Returns Response object.

:param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
:param stream: (optional) Whether to stream the request content.
:param timeout: (optional) How long to wait for the server to send
    data before giving up, as a float, or a :ref:`(connect timeout,
    read timeout) <timeouts>` tuple.
:type timeout: float or tuple or urllib3 Timeout object
:param verify: (optional) Either a boolean, in which case it controls whether
    we verify the server's TLS certificate, or a string, in which case it
    must be a path to a CA bundle to use
:param cert: (optional) Any user-provided SSL certificate to be trusted.
:param proxies: (optional) The proxies dictionary to apply to the request.
:rtype: requests.Response_

**Args**: self, request, stream, timeout, verify, cert, proxies


### venv_new\Lib\site-packages\pip\_vendor\requests\api.py

#### `request()` (line 14)
_Constructs and sends a :class:`Request <Request>`.

:param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.
:param url: URL for the new :class:`Request` object.
:param params: (optional) Dictionary, list of tuples or bytes to send
    in the query string for the :class:`Request`.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
    object to send in the body of the :class:`Request`.
:param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
:param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.
:param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.
:param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.
    ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``
    or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string
    defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers
    to add for the file.
:param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.
:param timeout: (optional) How many seconds to wait for the server to send data
    before giving up, as a float, or a :ref:`(connect timeout, read
    timeout) <timeouts>` tuple.
:type timeout: float or tuple
:param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.
:type allow_redirects: bool
:param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.
:param verify: (optional) Either a boolean, in which case it controls whether we verify
        the server's TLS certificate, or a string, in which case it must be a path
        to a CA bundle to use. Defaults to ``True``.
:param stream: (optional) if ``False``, the response content will be immediately downloaded.
:param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.
:return: :class:`Response <Response>` object
:rtype: requests.Response

Usage::

  >>> import requests
  >>> req = requests.request('GET', 'https://httpbin.org/get')
  >>> req
  <Response [200]>_

**Args**: method, url


#### `get()` (line 62)
_Sends a GET request.

:param url: URL for the new :class:`Request` object.
:param params: (optional) Dictionary, list of tuples or bytes to send
    in the query string for the :class:`Request`.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:return: :class:`Response <Response>` object
:rtype: requests.Response_

**Args**: url, params


#### `options()` (line 76)
_Sends an OPTIONS request.

:param url: URL for the new :class:`Request` object.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:return: :class:`Response <Response>` object
:rtype: requests.Response_

**Args**: url


#### `head()` (line 88)
_Sends a HEAD request.

:param url: URL for the new :class:`Request` object.
:param \*\*kwargs: Optional arguments that ``request`` takes. If
    `allow_redirects` is not provided, it will be set to `False` (as
    opposed to the default :meth:`request` behavior).
:return: :class:`Response <Response>` object
:rtype: requests.Response_

**Args**: url


#### `post()` (line 103)
_Sends a POST request.

:param url: URL for the new :class:`Request` object.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
    object to send in the body of the :class:`Request`.
:param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:return: :class:`Response <Response>` object
:rtype: requests.Response_

**Args**: url, data, json


#### `put()` (line 118)
_Sends a PUT request.

:param url: URL for the new :class:`Request` object.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
    object to send in the body of the :class:`Request`.
:param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:return: :class:`Response <Response>` object
:rtype: requests.Response_

**Args**: url, data


#### `patch()` (line 133)
_Sends a PATCH request.

:param url: URL for the new :class:`Request` object.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
    object to send in the body of the :class:`Request`.
:param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:return: :class:`Response <Response>` object
:rtype: requests.Response_

**Args**: url, data


#### `delete()` (line 148)
_Sends a DELETE request.

:param url: URL for the new :class:`Request` object.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:return: :class:`Response <Response>` object
:rtype: requests.Response_

**Args**: url


### venv_new\Lib\site-packages\pip\_vendor\requests\auth.py

#### `_basic_auth_str()` (line 25)
_Returns a Basic Auth string._

**Args**: username, password


#### `__call__()` (line 72)
**Args**: self, r


#### `__init__()` (line 79)
**Args**: self, username, password


#### `__eq__()` (line 83)
**Args**: self, other


#### `__ne__()` (line 91)
**Args**: self, other


#### `__call__()` (line 94)
**Args**: self, r


#### `__call__()` (line 102)
**Args**: self, r


#### `__init__()` (line 110)
**Args**: self, username, password


#### `init_per_thread_state()` (line 116)
**Args**: self


#### `build_digest_header()` (line 126)
_:rtype: str_

**Args**: self, method, url


#### `md5_utf8()` (line 145)
**Args**: x


#### `sha_utf8()` (line 153)
**Args**: x


#### `sha256_utf8()` (line 161)
**Args**: x


#### `sha512_utf8()` (line 169)
**Args**: x


#### `handle_redirect()` (line 236)
_Reset num_401_calls counter on redirects._

**Args**: self, r


#### `handle_401()` (line 241)
_Takes the given response and tries digest-auth, if needed.

:rtype: requests.Response_

**Args**: self, r


#### `__call__()` (line 285)
**Args**: self, r


#### `__eq__()` (line 305)
**Args**: self, other


#### `__ne__()` (line 313)
**Args**: self, other


### venv_new\Lib\site-packages\pip\_vendor\requests\compat.py

#### `_resolve_char_detection()` (line 17)
_Find supported character detection libraries._


### venv_new\Lib\site-packages\pip\_vendor\requests\cookies.py

#### `__init__()` (line 35)
**Args**: self, request


#### `get_type()` (line 40)
**Args**: self


#### `get_host()` (line 43)
**Args**: self


#### `get_origin_req_host()` (line 46)
**Args**: self


#### `get_full_url()` (line 49)
**Args**: self


#### `is_unverifiable()` (line 69)
**Args**: self


#### `has_header()` (line 72)
**Args**: self, name


#### `get_header()` (line 75)
**Args**: self, name, default


#### `add_header()` (line 78)
_cookiejar has no legitimate use for this method; add it back if you find one._

**Args**: self, key, val


#### `add_unredirected_header()` (line 84)
**Args**: self, name, value


#### `get_new_headers()` (line 87)
**Args**: self


#### `unverifiable()` (line 91)
**Args**: self


#### `origin_req_host()` (line 95)
**Args**: self


#### `host()` (line 99)
**Args**: self


#### `__init__()` (line 110)
_Make a MockResponse for `cookiejar` to read.

:param headers: a httplib.HTTPMessage or analogous carrying the headers_

**Args**: self, headers


#### `info()` (line 117)
**Args**: self


#### `getheaders()` (line 120)
**Args**: self, name


#### `extract_cookies_to_jar()` (line 124)
_Extract the cookies from the response into a CookieJar.

:param jar: http.cookiejar.CookieJar (not necessarily a RequestsCookieJar)
:param request: our own requests.Request object
:param response: urllib3.HTTPResponse object_

**Args**: jar, request, response


#### `get_cookie_header()` (line 140)
_Produce an appropriate Cookie header string to be sent with `request`, or None.

:rtype: str_

**Args**: jar, request


#### `remove_cookie_by_name()` (line 151)
_Unsets a cookie by name, by default over all domains and paths.

Wraps CookieJar.clear(), is O(n)._

**Args**: cookiejar, name, domain, path


#### `get()` (line 194)
_Dict-like get() that also supports optional domain and path args in
order to resolve naming collisions from using one cookie jar over
multiple domains.

.. warning:: operation is O(n), not O(1)._

**Args**: self, name, default, domain, path


#### `set()` (line 206)
_Dict-like set() that also supports optional domain and path args in
order to resolve naming collisions from using one cookie jar over
multiple domains._

**Args**: self, name, value


#### `iterkeys()` (line 225)
_Dict-like iterkeys() that returns an iterator of names of cookies
from the jar.

.. seealso:: itervalues() and iteritems()._

**Args**: self


#### `keys()` (line 234)
_Dict-like keys() that returns a list of names of cookies from the
jar.

.. seealso:: values() and items()._

**Args**: self


#### `itervalues()` (line 242)
_Dict-like itervalues() that returns an iterator of values of cookies
from the jar.

.. seealso:: iterkeys() and iteritems()._

**Args**: self


#### `values()` (line 251)
_Dict-like values() that returns a list of values of cookies from the
jar.

.. seealso:: keys() and items()._

**Args**: self


#### `iteritems()` (line 259)
_Dict-like iteritems() that returns an iterator of name-value tuples
from the jar.

.. seealso:: iterkeys() and itervalues()._

**Args**: self


#### `items()` (line 268)
_Dict-like items() that returns a list of name-value tuples from the
jar. Allows client-code to call ``dict(RequestsCookieJar)`` and get a
vanilla python dict of key value pairs.

.. seealso:: keys() and values()._

**Args**: self


#### `list_domains()` (line 277)
_Utility method to list all the domains in the jar._

**Args**: self


#### `list_paths()` (line 285)
_Utility method to list all the paths in the jar._

**Args**: self


#### `multiple_domains()` (line 293)
_Returns True if there are multiple domains in the jar.
Returns False otherwise.

:rtype: bool_

**Args**: self


#### `get_dict()` (line 306)
_Takes as an argument an optional domain and path and returns a plain
old Python dict of name-value pairs of cookies that meet the
requirements.

:rtype: dict_

**Args**: self, domain, path


#### `__contains__()` (line 321)
**Args**: self, name


#### `__getitem__()` (line 327)
_Dict-like __getitem__() for compatibility with client code. Throws
exception if there are more than one cookie with name. In that case,
use the more explicit get() method instead.

.. warning:: operation is O(n), not O(1)._

**Args**: self, name


#### `__setitem__()` (line 336)
_Dict-like __setitem__ for compatibility with client code. Throws
exception if there is already a cookie of that name in the jar. In that
case, use the more explicit set() method instead._

**Args**: self, name, value


#### `__delitem__()` (line 343)
_Deletes a cookie given a name. Wraps ``http.cookiejar.CookieJar``'s
``remove_cookie_by_name()``._

**Args**: self, name


#### `set_cookie()` (line 349)
**Args**: self, cookie


#### `update()` (line 358)
_Updates this jar with cookies from another CookieJar or dict-like_

**Args**: self, other


#### `_find()` (line 366)
_Requests uses this method internally to get cookie values.

If there are conflicting cookies, _find arbitrarily chooses one.
See _find_no_duplicates if you want an exception thrown if there are
conflicting cookies.

:param name: a string containing name of cookie
:param domain: (optional) string containing domain of cookie
:param path: (optional) string containing path of cookie
:return: cookie.value_

**Args**: self, name, domain, path


#### `_find_no_duplicates()` (line 386)
_Both ``__get_item__`` and ``get`` call this function: it's never
used elsewhere in Requests.

:param name: a string containing name of cookie
:param domain: (optional) string containing domain of cookie
:param path: (optional) string containing path of cookie
:raises KeyError: if cookie is not found
:raises CookieConflictError: if there are multiple cookies
    that match name and optionally domain and path
:return: cookie.value_

**Args**: self, name, domain, path


#### `__getstate__()` (line 415)
_Unlike a normal CookieJar, this class is pickleable._

**Args**: self


#### `__setstate__()` (line 422)
_Unlike a normal CookieJar, this class is pickleable._

**Args**: self, state


#### `copy()` (line 428)
_Return a copy of this RequestsCookieJar._

**Args**: self


#### `get_policy()` (line 435)
_Return the CookiePolicy instance used._

**Args**: self


#### `_copy_cookie_jar()` (line 440)
**Args**: jar


#### `create_cookie()` (line 455)
_Make a cookie from underspecified parameters.

By default, the pair of `name` and `value` will be set for the domain ''
and sent on every request (this is sometimes called a "supercookie")._

**Args**: name, value


#### `morsel_to_cookie()` (line 492)
_Convert a Morsel object into a Cookie containing the one k/v pair._

**Args**: morsel


#### `cookiejar_from_dict()` (line 521)
_Returns a CookieJar from a key/value dictionary.

:param cookie_dict: Dict of key/values to insert into CookieJar.
:param cookiejar: (optional) A cookiejar to add the cookies to.
:param overwrite: (optional) If False, will not replace cookies
    already in the jar with new ones.
:rtype: CookieJar_

**Args**: cookie_dict, cookiejar, overwrite


#### `merge_cookies()` (line 542)
_Add cookies to cookiejar and returns a merged CookieJar.

:param cookiejar: CookieJar object to add the cookies to.
:param cookies: Dictionary or CookieJar object to be added.
:rtype: CookieJar_

**Args**: cookiejar, cookies


### venv_new\Lib\site-packages\pip\_vendor\requests\exceptions.py

#### `__init__()` (line 17)
_Initialize RequestException with `request` and `response` objects._

**Args**: self


#### `__init__()` (line 34)
_Construct the JSONDecodeError instance first with all
args. Then use it's args to construct the IOError so that
the json specific args aren't used as IOError specific args
and the error message from JSONDecodeError is preserved._

**Args**: self


#### `__reduce__()` (line 44)
_The __reduce__ method called when pickling the object must
be the one from the JSONDecodeError (be it json/simplejson)
as it expects all the arguments for instantiation, not just
one like the IOError, and the MRO would by default call the
__reduce__ method from the IOError due to the inheritance order._

**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\requests\help.py

#### `_implementation()` (line 27)
_Return a dict with the Python implementation and version.

Provide both the name and the version of the Python implementation
currently running. For example, on CPython 3.10.3 it will return
{'name': 'CPython', 'version': '3.10.3'}.

This function works best on CPython and PyPy: in particular, it probably
doesn't work for Jython or IronPython. Future investigation should be done
to work out the correct shape of the code for those platforms._


#### `info()` (line 62)
_Generate information for a bug report._


#### `main()` (line 121)
_Pretty-print the bug information as JSON._


### venv_new\Lib\site-packages\pip\_vendor\requests\hooks.py

#### `default_hooks()` (line 15)

#### `dispatch_hook()` (line 22)
_Dispatches a hook dictionary on a given piece of data._

**Args**: key, hooks, hook_data


### venv_new\Lib\site-packages\pip\_vendor\requests\models.py

#### `path_url()` (line 86)
_Build the path URL to use._

**Args**: self


#### `_encode_params()` (line 107)
_Encode parameters in a piece of data.

Will successfully encode parameters when passed as a dict or a list of
2-tuples. Order is retained if data is a list of 2-tuples but arbitrary
if parameters are supplied as a dict._

**Args**: data


#### `_encode_files()` (line 137)
_Build the body for a multipart/form-data request.

Will successfully encode files when passed as a dict or a list of
tuples. Order is retained if data is a list of tuples but arbitrary
if parameters are supplied as a dict.
The tuples may be 2-tuples (filename, fileobj), 3-tuples (filename, fileobj, contentype)
or 4-tuples (filename, fileobj, contentype, custom_headers)._

**Args**: files, data


#### `register_hook()` (line 207)
_Properly register a hook._

**Args**: self, event, hook


#### `deregister_hook()` (line 218)
_Deregister a previously registered hook.
Returns True if the hook existed, False if not._

**Args**: self, event, hook


#### `__init__()` (line 258)
**Args**: self, method, url, headers, files, data, params, auth, cookies, hooks, json


#### `__repr__()` (line 292)
**Args**: self


#### `prepare()` (line 295)
_Constructs a :class:`PreparedRequest <PreparedRequest>` for transmission and returns it._

**Args**: self


#### `__init__()` (line 334)
**Args**: self


#### `prepare()` (line 351)
_Prepares the entire request with the given parameters._

**Args**: self, method, url, headers, files, data, params, auth, cookies, hooks, json


#### `__repr__()` (line 379)
**Args**: self


#### `copy()` (line 382)
**Args**: self


#### `prepare_method()` (line 393)
_Prepares the given HTTP method._

**Args**: self, method


#### `_get_idna_encoded_host()` (line 400)
**Args**: host


#### `prepare_url()` (line 409)
_Prepares the given HTTP URL._

**Args**: self, url, params


#### `prepare_headers()` (line 483)
_Prepares the given HTTP headers._

**Args**: self, headers


#### `prepare_body()` (line 494)
_Prepares the given HTTP body data._

**Args**: self, data, files, json


#### `prepare_content_length()` (line 572)
_Prepare Content-Length header based on request method and body_

**Args**: self, body


#### `prepare_auth()` (line 588)
_Prepares the given HTTP auth data._

**Args**: self, auth, url


#### `prepare_cookies()` (line 610)
_Prepares the given HTTP cookie data.

This function eventually generates a ``Cookie`` header from the
given cookies using cookielib. Due to cookielib's design, the header
will not be regenerated if it already exists, meaning this function
can only be called once for the life of the
:class:`PreparedRequest <PreparedRequest>` object. Any subsequent calls
to ``prepare_cookies`` will have no actual effect, unless the "Cookie"
header is removed beforehand._

**Args**: self, cookies


#### `prepare_hooks()` (line 630)
_Prepares the given hooks._

**Args**: self, hooks


#### `__init__()` (line 658)
**Args**: self


#### `__enter__()` (line 705)
**Args**: self


#### `__exit__()` (line 708)
**Args**: self


#### `__getstate__()` (line 711)
**Args**: self


#### `__setstate__()` (line 719)
**Args**: self, state


#### `__repr__()` (line 727)
**Args**: self


#### `__bool__()` (line 730)
_Returns True if :attr:`status_code` is less than 400.

This attribute checks if the status code of the response is between
400 and 600 to see if there was a client error or a server error. If
the status code, is between 200 and 400, this will return True. This
is **not** a check to see if the response code is ``200 OK``._

**Args**: self


#### `__nonzero__()` (line 740)
_Returns True if :attr:`status_code` is less than 400.

This attribute checks if the status code of the response is between
400 and 600 to see if there was a client error or a server error. If
the status code, is between 200 and 400, this will return True. This
is **not** a check to see if the response code is ``200 OK``._

**Args**: self


#### `__iter__()` (line 750)
_Allows you to use a response as an iterator._

**Args**: self


#### `ok()` (line 755)
_Returns True if :attr:`status_code` is less than 400, False if not.

This attribute checks if the status code of the response is between
400 and 600 to see if there was a client error or a server error. If
the status code is between 200 and 400, this will return True. This
is **not** a check to see if the response code is ``200 OK``._

**Args**: self


#### `is_redirect()` (line 770)
_True if this Response is a well-formed HTTP redirect that could have
been processed automatically (by :meth:`Session.resolve_redirects`)._

**Args**: self


#### `is_permanent_redirect()` (line 777)
_True if this Response one of the permanent versions of redirect._

**Args**: self


#### `next()` (line 785)
_Returns a PreparedRequest for the next request in a redirect chain, if there is one._

**Args**: self


#### `apparent_encoding()` (line 790)
_The apparent encoding, provided by the charset_normalizer or chardet libraries._

**Args**: self


#### `iter_content()` (line 799)
_Iterates over the response data.  When stream=True is set on the
request, this avoids reading the content at once into memory for
large responses.  The chunk size is the number of bytes it should
read into memory.  This is not necessarily the length of each item
returned as decoding can take place.

chunk_size must be of type int or None. A value of None will
function differently depending on the value of `stream`.
stream=True will read data as it arrives in whatever size the
chunks are received. If stream=False, data is returned as
a single chunk.

If decode_unicode is True, content will be decoded using the best
available encoding based on the response._

**Args**: self, chunk_size, decode_unicode


#### `generate()` (line 816)

#### `iter_lines()` (line 857)
_Iterates over the response data, one line at a time.  When
stream=True is set on the request, this avoids reading the
content at once into memory for large responses.

.. note:: This method is not reentrant safe._

**Args**: self, chunk_size, decode_unicode, delimiter


#### `content()` (line 891)
_Content of the response, in bytes._

**Args**: self


#### `text()` (line 910)
_Content of the response, in unicode.

If Response.encoding is None, encoding will be guessed using
``charset_normalizer`` or ``chardet``.

The encoding of the response content is determined based solely on HTTP
headers, following RFC 2616 to the letter. If you can take advantage of
non-HTTP knowledge to make a better guess at the encoding, you should
set ``r.encoding`` appropriately before accessing this property._

**Args**: self


#### `json()` (line 947)
_Returns the json-encoded content of a response, if any.

:param \*\*kwargs: Optional arguments that ``json.loads`` takes.
:raises requests.exceptions.JSONDecodeError: If the response body does not
    contain valid json._

**Args**: self


#### `links()` (line 981)
_Returns the parsed header links of the response, if any._

**Args**: self


#### `raise_for_status()` (line 997)
_Raises :class:`HTTPError`, if one occurred._

**Args**: self


#### `close()` (line 1026)
_Releases the connection back to the pool. Once this method has been
called the underlying ``raw`` object must not be accessed again.

*Note: Should not normally need to be called explicitly.*_

**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\requests\sessions.py

#### `merge_setting()` (line 61)
_Determines appropriate setting for a given request, taking into account
the explicit setting on that request, and the setting in the session. If a
setting is a dictionary, they will be merged together using `dict_class`_

**Args**: request_setting, session_setting, dict_class


#### `merge_hooks()` (line 91)
_Properly merges both requests and session hooks.

This is necessary because when request_hooks == {'response': []}, the
merge breaks Session hooks entirely._

**Args**: request_hooks, session_hooks, dict_class


#### `get_redirect_target()` (line 107)
_Receives a Response. Returns a redirect URI or ``None``_

**Args**: self, resp


#### `should_strip_auth()` (line 127)
_Decide whether Authorization header should be removed when redirecting_

**Args**: self, old_url, new_url


#### `resolve_redirects()` (line 159)
_Receives a Response. Returns a generator of Responses or Requests._

**Args**: self, resp, req, stream, timeout, verify, cert, proxies, yield_requests


#### `rebuild_auth()` (line 282)
_When being redirected we may want to strip authentication from the
request to avoid leaking credentials. This method intelligently removes
and reapplies authentication where possible to avoid credential loss._

**Args**: self, prepared_request, response


#### `rebuild_proxies()` (line 302)
_This method re-evaluates the proxy configuration by considering the
environment variables. If we are redirected to a URL covered by
NO_PROXY, we strip the proxy configuration. Otherwise, we set missing
proxy keys for this URL (in case they were stripped by a previous
redirect).

This method also replaces the Proxy-Authorization header where
necessary.

:rtype: dict_

**Args**: self, prepared_request, proxies


#### `rebuild_method()` (line 333)
_When being redirected we may want to change the method of the request
based on certain specs or browser behavior._

**Args**: self, prepared_request, response


#### `__init__()` (line 390)
**Args**: self


#### `__enter__()` (line 451)
**Args**: self


#### `__exit__()` (line 454)
**Args**: self


#### `prepare_request()` (line 457)
_Constructs a :class:`PreparedRequest <PreparedRequest>` for
transmission and returns it. The :class:`PreparedRequest` has settings
merged from the :class:`Request <Request>` instance and those of the
:class:`Session`.

:param request: :class:`Request` instance to prepare with this
    session's settings.
:rtype: requests.PreparedRequest_

**Args**: self, request


#### `request()` (line 500)
_Constructs a :class:`Request <Request>`, prepares it and sends it.
Returns :class:`Response <Response>` object.

:param method: method for the new :class:`Request` object.
:param url: URL for the new :class:`Request` object.
:param params: (optional) Dictionary or bytes to be sent in the query
    string for the :class:`Request`.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
    object to send in the body of the :class:`Request`.
:param json: (optional) json to send in the body of the
    :class:`Request`.
:param headers: (optional) Dictionary of HTTP Headers to send with the
    :class:`Request`.
:param cookies: (optional) Dict or CookieJar object to send with the
    :class:`Request`.
:param files: (optional) Dictionary of ``'filename': file-like-objects``
    for multipart encoding upload.
:param auth: (optional) Auth tuple or callable to enable
    Basic/Digest/Custom HTTP Auth.
:param timeout: (optional) How long to wait for the server to send
    data before giving up, as a float, or a :ref:`(connect timeout,
    read timeout) <timeouts>` tuple.
:type timeout: float or tuple
:param allow_redirects: (optional) Set to True by default.
:type allow_redirects: bool
:param proxies: (optional) Dictionary mapping protocol or protocol and
    hostname to the URL of the proxy.
:param hooks: (optional) Dictionary mapping hook name to one event or
    list of events, event must be callable.
:param stream: (optional) whether to immediately download the response
    content. Defaults to ``False``.
:param verify: (optional) Either a boolean, in which case it controls whether we verify
    the server's TLS certificate, or a string, in which case it must be a path
    to a CA bundle to use. Defaults to ``True``. When set to
    ``False``, requests will accept any TLS certificate presented by
    the server, and will ignore hostname mismatches and/or expired
    certificates, which will make your application vulnerable to
    man-in-the-middle (MitM) attacks. Setting verify to ``False``
    may be useful during local development or testing.
:param cert: (optional) if String, path to ssl client cert file (.pem).
    If Tuple, ('cert', 'key') pair.
:rtype: requests.Response_

**Args**: self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json


#### `get()` (line 593)
_Sends a GET request. Returns :class:`Response` object.

:param url: URL for the new :class:`Request` object.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:rtype: requests.Response_

**Args**: self, url


#### `options()` (line 604)
_Sends a OPTIONS request. Returns :class:`Response` object.

:param url: URL for the new :class:`Request` object.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:rtype: requests.Response_

**Args**: self, url


#### `head()` (line 615)
_Sends a HEAD request. Returns :class:`Response` object.

:param url: URL for the new :class:`Request` object.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:rtype: requests.Response_

**Args**: self, url


#### `post()` (line 626)
_Sends a POST request. Returns :class:`Response` object.

:param url: URL for the new :class:`Request` object.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
    object to send in the body of the :class:`Request`.
:param json: (optional) json to send in the body of the :class:`Request`.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:rtype: requests.Response_

**Args**: self, url, data, json


#### `put()` (line 639)
_Sends a PUT request. Returns :class:`Response` object.

:param url: URL for the new :class:`Request` object.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
    object to send in the body of the :class:`Request`.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:rtype: requests.Response_

**Args**: self, url, data


#### `patch()` (line 651)
_Sends a PATCH request. Returns :class:`Response` object.

:param url: URL for the new :class:`Request` object.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
    object to send in the body of the :class:`Request`.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:rtype: requests.Response_

**Args**: self, url, data


#### `delete()` (line 663)
_Sends a DELETE request. Returns :class:`Response` object.

:param url: URL for the new :class:`Request` object.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:rtype: requests.Response_

**Args**: self, url


#### `send()` (line 673)
_Send a given PreparedRequest.

:rtype: requests.Response_

**Args**: self, request


#### `merge_environment_settings()` (line 750)
_Check the environment and merge it with some settings.

:rtype: dict_

**Args**: self, url, proxies, stream, verify, cert


#### `get_adapter()` (line 781)
_Returns the appropriate connection adapter for the given URL.

:rtype: requests.adapters.BaseAdapter_

**Args**: self, url


#### `close()` (line 794)
_Closes all adapters and as such the session_

**Args**: self


#### `mount()` (line 799)
_Registers a connection adapter to a prefix.

Adapters are sorted in descending order by prefix length._

**Args**: self, prefix, adapter


#### `__getstate__()` (line 810)
**Args**: self


#### `__setstate__()` (line 814)
**Args**: self, state


#### `session()` (line 819)
_Returns a :class:`Session` for context-management.

.. deprecated:: 1.0.0

    This method has been deprecated since version 1.0.0 and is only kept for
    backwards compatibility. New code should use :class:`~requests.sessions.Session`
    to create a session. This may be removed at a future date.

:rtype: Session_


### venv_new\Lib\site-packages\pip\_vendor\requests\status_codes.py

#### `_init()` (line 109)

#### `doc()` (line 116)
**Args**: code


### venv_new\Lib\site-packages\pip\_vendor\requests\structures.py

#### `__init__()` (line 40)
**Args**: self, data


#### `__setitem__()` (line 46)
**Args**: self, key, value


#### `__getitem__()` (line 51)
**Args**: self, key


#### `__delitem__()` (line 54)
**Args**: self, key


#### `__iter__()` (line 57)
**Args**: self


#### `__len__()` (line 60)
**Args**: self


#### `lower_items()` (line 63)
_Like iteritems(), but with all lowercase keys._

**Args**: self


#### `__eq__()` (line 67)
**Args**: self, other


#### `copy()` (line 76)
**Args**: self


#### `__repr__()` (line 79)
**Args**: self


#### `__init__()` (line 86)
**Args**: self, name


#### `__repr__()` (line 90)
**Args**: self


#### `__getitem__()` (line 93)
**Args**: self, key


#### `get()` (line 98)
**Args**: self, key, default


### venv_new\Lib\site-packages\pip\_vendor\requests\utils.py

#### `proxy_bypass_registry()` (line 76)
**Args**: host


#### `proxy_bypass()` (line 114)
_Return True, if the host should be bypassed.

Checks proxy settings gathered from the environment, if specified,
or the registry._

**Args**: host


#### `dict_to_sequence()` (line 126)
_Returns an internal sequence dictionary update._

**Args**: d


#### `super_len()` (line 135)
**Args**: o


#### `get_netrc_auth()` (line 204)
_Returns the Requests tuple auth for a given url from netrc._

**Args**: url, raise_errors


#### `guess_filename()` (line 261)
_Tries to guess the filename of the given object._

**Args**: obj


#### `extract_zipped_paths()` (line 268)
_Replace nonexistent paths that look like they refer to a member of a zip
archive with the location of an extracted copy of the target, or else
just return the provided path unchanged._

**Args**: path


#### `atomic_open()` (line 306)
_Write a file to the disk in an atomic fashion_

**Args**: filename


#### `from_key_val_list()` (line 318)
_Take an object and test to see if it can be represented as a
dictionary. Unless it can not be represented as such, return an
OrderedDict, e.g.,

::

    >>> from_key_val_list([('key', 'val')])
    OrderedDict([('key', 'val')])
    >>> from_key_val_list('string')
    Traceback (most recent call last):
    ...
    ValueError: cannot encode objects that are not 2-tuples
    >>> from_key_val_list({'key': 'val'})
    OrderedDict([('key', 'val')])

:rtype: OrderedDict_

**Args**: value


#### `to_key_val_list()` (line 345)
_Take an object and test to see if it can be represented as a
dictionary. If it can be, return a list of tuples, e.g.,

::

    >>> to_key_val_list([('key', 'val')])
    [('key', 'val')]
    >>> to_key_val_list({'key': 'val'})
    [('key', 'val')]
    >>> to_key_val_list('string')
    Traceback (most recent call last):
    ...
    ValueError: cannot encode objects that are not 2-tuples

:rtype: list_

**Args**: value


#### `parse_list_header()` (line 375)
_Parse lists as described by RFC 2068 Section 2.

In particular, parse comma-separated lists where the elements of
the list may include quoted-strings.  A quoted-string could
contain a comma.  A non-quoted string could have quotes in the
middle.  Quotes are removed automatically after parsing.

It basically works like :func:`parse_set_header` just that items
may appear multiple times and case sensitivity is preserved.

The return value is a standard :class:`list`:

>>> parse_list_header('token, "quoted value"')
['token', 'quoted value']

To create a header from the :class:`list` again, use the
:func:`dump_header` function.

:param value: a string with a list header.
:return: :class:`list`
:rtype: list_

**Args**: value


#### `parse_dict_header()` (line 407)
_Parse lists of key, value pairs as described by RFC 2068 Section 2 and
convert them into a python dict:

>>> d = parse_dict_header('foo="is a fish", bar="as well"')
>>> type(d) is dict
True
>>> sorted(d.items())
[('bar', 'as well'), ('foo', 'is a fish')]

If there is no value for a key it will be `None`:

>>> parse_dict_header('key_without_value')
{'key_without_value': None}

To create a header from the :class:`dict` again, use the
:func:`dump_header` function.

:param value: a string with a dict header.
:return: :class:`dict`
:rtype: dict_

**Args**: value


#### `unquote_header_value()` (line 442)
_Unquotes a header value.  (Reversal of :func:`quote_header_value`).
This does not use the real unquoting but what browsers are actually
using for quoting.

:param value: the header value to unquote.
:rtype: str_

**Args**: value, is_filename


#### `dict_from_cookiejar()` (line 467)
_Returns a key/value dictionary from a CookieJar.

:param cj: CookieJar object to extract cookies from.
:rtype: dict_

**Args**: cj


#### `add_dict_to_cookiejar()` (line 478)
_Returns a CookieJar from a key/value dictionary.

:param cj: CookieJar to insert cookies into.
:param cookie_dict: Dict of key/values to insert into CookieJar.
:rtype: CookieJar_

**Args**: cj, cookie_dict


#### `get_encodings_from_content()` (line 489)
_Returns encodings from given content string.

:param content: bytestring to extract encodings from._

**Args**: content


#### `_parse_content_type_header()` (line 514)
_Returns content type and parameters from given header

:param header: string
:return: tuple containing content type and dictionary of
     parameters_

**Args**: header


#### `get_encoding_from_headers()` (line 539)
_Returns encodings from given HTTP Header Dict.

:param headers: dictionary to extract encoding from.
:rtype: str_

**Args**: headers


#### `stream_decode_response_unicode()` (line 564)
_Stream decodes an iterator._

**Args**: iterator, r


#### `iter_slices()` (line 581)
_Iterate over slices of a string._

**Args**: string, slice_length


#### `get_unicode_from_response()` (line 591)
_Returns the requested content back in unicode.

:param r: Response object to get unicode content from.

Tried:

1. charset from content-type
2. fall back and replace all unicode characters

:rtype: str_

**Args**: r


#### `unquote_unreserved()` (line 636)
_Un-escape any percent-escape sequences in a URI that are unreserved
characters. This leaves all reserved, illegal and non-ASCII bytes encoded.

:rtype: str_

**Args**: uri


#### `requote_uri()` (line 660)
_Re-quote the given URI.

This function passes the given URI through an unquote/quote cycle to
ensure that it is fully and consistently quoted.

:rtype: str_

**Args**: uri


#### `address_in_network()` (line 682)
_This function allows you to check if an IP belongs to a network subnet

Example: returns True if ip = 192.168.1.1 and net = 192.168.1.0/24
         returns False if ip = 192.168.1.1 and net = 192.168.100.0/24

:rtype: bool_

**Args**: ip, net


#### `dotted_netmask()` (line 697)
_Converts mask from /xx format to xxx.xxx.xxx.xxx

Example: if mask is 24 function returns 255.255.255.0

:rtype: str_

**Args**: mask


#### `is_ipv4_address()` (line 708)
_:rtype: bool_

**Args**: string_ip


#### `is_valid_cidr()` (line 719)
_Very simple check of the cidr format in no_proxy variable.

:rtype: bool_

**Args**: string_network


#### `set_environ()` (line 744)
_Set the environment variable 'env_name' to 'value'

Save previous value, yield, and then restore the previous value stored in
the environment variable 'env_name'.

If 'value' is None, do nothing_

**Args**: env_name, value


#### `should_bypass_proxies()` (line 765)
_Returns whether we should bypass proxies or not.

:rtype: bool_

**Args**: url, no_proxy


#### `get_proxy()` (line 774)
**Args**: key


#### `get_environ_proxies()` (line 826)
_Return a dict of environment proxies.

:rtype: dict_

**Args**: url, no_proxy


#### `select_proxy()` (line 838)
_Select a proxy for the url, if applicable.

:param url: The url being for the request
:param proxies: A dictionary of schemes or schemes and hosts to proxy URLs_

**Args**: url, proxies


#### `resolve_proxies()` (line 864)
_This method takes proxy information from a request and configuration
input to resolve a mapping of target proxies. This will consider settings
such as NO_PROXY to strip proxy configurations.

:param request: Request or PreparedRequest
:param proxies: A dictionary of schemes or schemes and hosts to proxy URLs
:param trust_env: Boolean declaring whether to trust environment configs

:rtype: dict_

**Args**: request, proxies, trust_env


#### `default_user_agent()` (line 891)
_Return a string representing the default user agent.

:rtype: str_

**Args**: name


#### `default_headers()` (line 900)
_:rtype: requests.structures.CaseInsensitiveDict_


#### `parse_header_links()` (line 914)
_Return a list of parsed link headers proxies.

i.e. Link: <http:/.../front.jpeg>; rel=front; type="image/jpeg",<http://.../back.jpeg>; rel=back;type="image/jpeg"

:rtype: list_

**Args**: value


#### `guess_json_utf()` (line 957)
_:rtype: str_

**Args**: data


#### `prepend_scheme_if_needed()` (line 989)
_Given a URL that may or may not have a scheme, prepend the given scheme.
Does not replace a present scheme with the one provided as an argument.

:rtype: str_

**Args**: url, new_scheme


#### `get_auth_from_url()` (line 1018)
_Given a url with authentication components, extract them into a tuple of
username,password.

:rtype: (str,str)_

**Args**: url


#### `check_header_validity()` (line 1034)
_Verifies that header parts don't contain leading whitespace
reserved characters, or return characters.

:param header: tuple, in the format (name, value)._

**Args**: header


#### `_validate_header_part()` (line 1045)
**Args**: header, header_part, header_validator_index


#### `urldefragauth()` (line 1064)
_Given a url remove the fragment and the authentication part.

:rtype: str_

**Args**: url


#### `rewind_body()` (line 1081)
_Move file pointer back to its recorded starting position
so it can be read again on redirect._

**Args**: prepared_request


### venv_new\Lib\site-packages\pip\_vendor\resolvelib\providers.py

#### `identify()` (line 4)
_Given a requirement, return an identifier for it.

This is used to identify a requirement, e.g. whether two requirements
should have their specifier parts merged._

**Args**: self, requirement_or_candidate


#### `get_preference()` (line 12)
_Produce a sort key for given requirement based on preference.

The preference is defined as "I think this requirement should be
resolved first". The lower the return value is, the more preferred
this group of arguments is.

:param identifier: An identifier as returned by ``identify()``. This
    identifies the dependency matches which should be returned.
:param resolutions: Mapping of candidates currently pinned by the
    resolver. Each key is an identifier, and the value is a candidate.
    The candidate may conflict with requirements from ``information``.
:param candidates: Mapping of each dependency's possible candidates.
    Each value is an iterator of candidates.
:param information: Mapping of requirement information of each package.
    Each value is an iterator of *requirement information*.
:param backtrack_causes: Sequence of requirement information that were
    the requirements that caused the resolver to most recently backtrack.

A *requirement information* instance is a named tuple with two members:

* ``requirement`` specifies a requirement contributing to the current
  list of candidates.
* ``parent`` specifies the candidate that provides (depended on) the
  requirement, or ``None`` to indicate a root requirement.

The preference could depend on various issues, including (not
necessarily in this order):

* Is this package pinned in the current resolution result?
* How relaxed is the requirement? Stricter ones should probably be
  worked on first? (I don't know, actually.)
* How many possibilities are there to satisfy this requirement? Those
  with few left should likely be worked on first, I guess?
* Are there any known conflicts for this requirement? We should
  probably work on those with the most known conflicts.

A sortable value should be returned (this will be used as the ``key``
parameter of the built-in sorting function). The smaller the value is,
the more preferred this requirement is (i.e. the sorting function
is called with ``reverse=False``)._

**Args**: self, identifier, resolutions, candidates, information, backtrack_causes


#### `find_matches()` (line 63)
_Find all possible candidates that satisfy the given constraints.

:param identifier: An identifier as returned by ``identify()``. This
    identifies the dependency matches of which should be returned.
:param requirements: A mapping of requirements that all returned
    candidates must satisfy. Each key is an identifier, and the value
    an iterator of requirements for that dependency.
:param incompatibilities: A mapping of known incompatibilities of
    each dependency. Each key is an identifier, and the value an
    iterator of incompatibilities known to the resolver. All
    incompatibilities *must* be excluded from the return value.

This should try to get candidates based on the requirements' types.
For VCS, local, and archive requirements, the one-and-only match is
returned, and for a "named" requirement, the index(es) should be
consulted to find concrete candidates for this requirement.

The return value should produce candidates ordered by preference; the
most preferred candidate should come first. The return type may be one
of the following:

* A callable that returns an iterator that yields candidates.
* An collection of candidates.
* An iterable of candidates. This will be consumed immediately into a
  list of candidates._

**Args**: self, identifier, requirements, incompatibilities


#### `is_satisfied_by()` (line 92)
_Whether the given requirement can be satisfied by a candidate.

The candidate is guaranteed to have been generated from the
requirement.

A boolean should be returned to indicate whether ``candidate`` is a
viable solution to the requirement._

**Args**: self, requirement, candidate


#### `get_dependencies()` (line 103)
_Get dependencies of a candidate.

This should return a collection of requirements that `candidate`
specifies as its dependencies._

**Args**: self, candidate


#### `__init__()` (line 117)
**Args**: self, provider, reporter


#### `resolve()` (line 121)
_Take a collection of constraints, spit out the resolution result.

This returns a representation of the final resolution state, with one
guarenteed attribute ``mapping`` that contains resolved candidates as
values. The keys are their respective identifiers.

:param requirements: A collection of constraints.
:param kwargs: Additional keyword arguments that subclasses may accept.

:raises: ``self.base_exception`` or its subclass._

**Args**: self, requirements


### venv_new\Lib\site-packages\pip\_vendor\resolvelib\reporters.py

#### `starting()` (line 4)
_Called before the resolution actually starts._

**Args**: self


#### `starting_round()` (line 7)
_Called before each round of resolution starts.

The index is zero-based._

**Args**: self, index


#### `ending_round()` (line 13)
_Called before each round of resolution ends.

This is NOT called if the resolution ends at this round. Use `ending`
if you want to report finalization. The index is zero-based._

**Args**: self, index, state


#### `ending()` (line 20)
_Called before the resolution ends successfully._

**Args**: self, state


#### `adding_requirement()` (line 23)
_Called when adding a new requirement into the resolve criteria.

:param requirement: The additional requirement to be applied to filter
    the available candidaites.
:param parent: The candidate that requires ``requirement`` as a
    dependency, or None if ``requirement`` is one of the root
    requirements passed in from ``Resolver.resolve()``._

**Args**: self, requirement, parent


#### `resolving_conflicts()` (line 33)
_Called when starting to attempt requirement conflict resolution.

:param causes: The information on the collision that caused the backtracking._

**Args**: self, causes


#### `rejecting_candidate()` (line 39)
_Called when rejecting a candidate during backtracking._

**Args**: self, criterion, candidate


#### `pinning()` (line 42)
_Called when adding a candidate to the potential solution._

**Args**: self, candidate


### venv_new\Lib\site-packages\pip\_vendor\resolvelib\resolvers.py

#### `__init__()` (line 22)
**Args**: self, criterion


#### `__str__()` (line 26)
**Args**: self


#### `__init__()` (line 33)
**Args**: self, candidate, criterion


#### `__str__()` (line 38)
**Args**: self


#### `__init__()` (line 65)
**Args**: self, candidates, information, incompatibilities


#### `__repr__()` (line 70)
**Args**: self


#### `iter_requirement()` (line 77)
**Args**: self


#### `iter_parent()` (line 80)
**Args**: self


#### `__init__()` (line 89)
**Args**: self, causes


#### `__init__()` (line 96)
**Args**: self, round_count


#### `__init__()` (line 112)
**Args**: self, provider, reporter


#### `state()` (line 118)
**Args**: self


#### `_push_new_state()` (line 124)
_Push a new state into history.

This new state will be used to hold resolution results of the next
coming round._

**Args**: self


#### `_add_to_criteria()` (line 138)
**Args**: self, criteria, requirement, parent


#### `_remove_information_from_criteria()` (line 177)
_Remove information from parents of criteria.

Concretely, removes all values from each criterion's ``information``
field that have one of ``parents`` as provider of the requirement.

:param criteria: The criteria to update.
:param parents: Identifiers for which to remove information from all criteria._

**Args**: self, criteria, parents


#### `_get_preference()` (line 202)
**Args**: self, name


#### `_is_current_pin_satisfying()` (line 217)
**Args**: self, name, criterion


#### `_get_updated_criteria()` (line 227)
**Args**: self, candidate


#### `_attempt_to_pin_criterion()` (line 233)
**Args**: self, name


#### `_backjump()` (line 270)
_Perform backjumping.

When we enter here, the stack is like this::

    [ state Z ]
    [ state Y ]
    [ state X ]
    .... earlier states are irrelevant.

1. No pins worked for Z, so it does not have a pin.
2. We want to reset state Y to unpinned, and pin another candidate.
3. State X holds what state Y was before the pin, but does not
   have the incompatibility information gathered in state Y.

Each iteration of the loop will:

1.  Identify Z. The incompatibility is not always caused by the latest
    state. For example, given three requirements A, B and C, with
    dependencies A1, B1 and C1, where A1 and B1 are incompatible: the
    last state might be related to C, so we want to discard the
    previous state.
2.  Discard Z.
3.  Discard Y but remember its incompatibility information gathered
    previously, and the failure we're dealing with right now.
4.  Push a new state Y' based on X, and apply the incompatibility
    information from Y to Y'.
5a. If this causes Y' to conflict, we need to backtrack again. Make Y'
    the new Z and go back to step 2.
5b. If the incompatibilities apply cleanly, end backtracking._

**Args**: self, causes


#### `_patch_criteria()` (line 337)

#### `resolve()` (line 381)
**Args**: self, requirements, max_rounds


#### `_has_route_to_root()` (line 460)
**Args**: criteria, key, all_keys, connected


#### `_build_result()` (line 482)
**Args**: state


#### `resolve()` (line 517)
_Take a collection of constraints, spit out the resolution result.

The return value is a representation to the final resolution result. It
is a tuple subclass with three public members:

* `mapping`: A dict of resolved candidates. Each key is an identifier
    of a requirement (as returned by the provider's `identify` method),
    and the value is the resolved candidate.
* `graph`: A `DirectedGraph` instance representing the dependency tree.
    The vertices are keys of `mapping`, and each edge represents *why*
    a particular package is included. A special vertex `None` is
    included to represent parents of user-supplied requirements.
* `criteria`: A dict of "criteria" that hold detailed information on
    how edges in the graph are derived. Each key is an identifier of a
    requirement, and the value is a `Criterion` instance.

The following exceptions may be raised if a resolution cannot be found:

* `ResolutionImpossible`: A resolution cannot be found for the given
    combination of requirements. The `causes` attribute of the
    exception is a list of (requirement, parent), giving the
    requirements that could not be satisfied.
* `ResolutionTooDeep`: The dependency tree is too deeply nested and
    the resolver gave up. This is usually caused by a circular
    dependency, but you can try to resolve this by increasing the
    `max_rounds` argument._

**Args**: self, requirements, max_rounds


### venv_new\Lib\site-packages\pip\_vendor\resolvelib\structs.py

#### `__init__()` (line 9)
**Args**: self


#### `__iter__()` (line 14)
**Args**: self


#### `__len__()` (line 17)
**Args**: self


#### `__contains__()` (line 20)
**Args**: self, key


#### `copy()` (line 23)
_Return a shallow copy of this graph._

**Args**: self


#### `add()` (line 31)
_Add a new vertex to the graph._

**Args**: self, key


#### `remove()` (line 39)
_Remove a vertex from the graph, disconnecting all edges from/to it._

**Args**: self, key


#### `connected()` (line 47)
**Args**: self, f, t


#### `connect()` (line 50)
_Connect two existing vertices.

Nothing happens if the vertices are already connected._

**Args**: self, f, t


#### `iter_edges()` (line 60)
**Args**: self


#### `iter_children()` (line 65)
**Args**: self, key


#### `iter_parents()` (line 68)
**Args**: self, key


#### `__init__()` (line 73)
**Args**: self, mapping, accessor, appends


#### `__repr__()` (line 78)
**Args**: self


#### `__bool__()` (line 85)
**Args**: self


#### `__contains__()` (line 90)
**Args**: self, key


#### `__getitem__()` (line 93)
**Args**: self, k


#### `__iter__()` (line 100)
**Args**: self


#### `__len__()` (line 104)
**Args**: self


#### `__init__()` (line 118)
**Args**: self, factory


#### `__repr__()` (line 122)
**Args**: self


#### `__bool__()` (line 125)
**Args**: self


#### `__iter__()` (line 134)
**Args**: self


#### `__init__()` (line 149)
**Args**: self, sequence


#### `__repr__()` (line 152)
**Args**: self


#### `__bool__()` (line 155)
**Args**: self


#### `__iter__()` (line 160)
**Args**: self


#### `build_iter_view()` (line 164)
_Build an iterable view from the value returned by `find_matches()`._

**Args**: matches


### venv_new\Lib\site-packages\pip\_vendor\rich\__init__.py

#### `get_console()` (line 23)
_Get a global :class:`~rich.console.Console` instance. This function is used when Rich requires a Console,
and hasn't been explicitly given one.

Returns:
    Console: A console instance._


#### `reconfigure()` (line 39)
_Reconfigures the global console by replacing it with another.

Args:
    *args (Any): Positional arguments for the replacement :class:`~rich.console.Console`.
    **kwargs (Any): Keyword arguments for the replacement :class:`~rich.console.Console`._


#### `print()` (line 53)
_Print object(s) supplied via positional arguments.
This function has an identical signature to the built-in print.
For more advanced features, see the :class:`~rich.console.Console` class.

Args:
    sep (str, optional): Separator between printed objects. Defaults to " ".
    end (str, optional): Character to write at end of output. Defaults to "\\n".
    file (IO[str], optional): File to write to, or None for stdout. Defaults to None.
    flush (bool, optional): Has no effect as Rich always flushes output. Defaults to False._


#### `print_json()` (line 77)
_Pretty prints JSON. Output will be valid JSON.

Args:
    json (str): A string containing JSON.
    data (Any): If json is not supplied, then encode this data.
    indent (int, optional): Number of spaces to indent. Defaults to 2.
    highlight (bool, optional): Enable highlighting of output: Defaults to True.
    skip_keys (bool, optional): Skip keys not of a basic type. Defaults to False.
    ensure_ascii (bool, optional): Escape all non-ascii characters. Defaults to False.
    check_circular (bool, optional): Check for circular references. Defaults to True.
    allow_nan (bool, optional): Allow NaN and Infinity values. Defaults to True.
    default (Callable, optional): A callable that converts values that can not be encoded
        in to something that can be JSON encoded. Defaults to None.
    sort_keys (bool, optional): Sort dictionary keys. Defaults to False._

**Args**: json


#### `inspect()` (line 120)
_Inspect any Python object.

* inspect(<OBJECT>) to see summarized info.
* inspect(<OBJECT>, methods=True) to see methods.
* inspect(<OBJECT>, help=True) to see full (non-abbreviated) help.
* inspect(<OBJECT>, private=True) to see private attributes (single underscore).
* inspect(<OBJECT>, dunder=True) to see attributes beginning with double underscore.
* inspect(<OBJECT>, all=True) to see all attributes.

Args:
    obj (Any): An object to inspect.
    title (str, optional): Title to display over inspect result, or None use type. Defaults to None.
    help (bool, optional): Show full help text rather than just first paragraph. Defaults to False.
    methods (bool, optional): Enable inspection of callables. Defaults to False.
    docs (bool, optional): Also render doc strings. Defaults to True.
    private (bool, optional): Show private attributes (beginning with underscore). Defaults to False.
    dunder (bool, optional): Show attributes starting with double underscore. Defaults to False.
    sort (bool, optional): Sort attributes alphabetically. Defaults to True.
    all (bool, optional): Show all attributes. Defaults to False.
    value (bool, optional): Pretty print value. Defaults to True._

**Args**: obj


### venv_new\Lib\site-packages\pip\_vendor\rich\__main__.py

#### `__rich_console__()` (line 19)
**Args**: self, console, options


#### `__rich_measure__()` (line 33)
**Args**: self, console, options


#### `make_test_card()` (line 39)
_Get a renderable that demonstrates a number of features._


#### `comparison()` (line 90)
**Args**: renderable1, renderable2


### venv_new\Lib\site-packages\pip\_vendor\rich\_emoji_replace.py

#### `_emoji_replace()` (line 12)
_Replace emoji code in text._

**Args**: text, default_variant, _emoji_sub


#### `do_replace()` (line 23)
**Args**: match


### venv_new\Lib\site-packages\pip\_vendor\rich\_extension.py

#### `load_ipython_extension()` (line 4)
**Args**: ip


### venv_new\Lib\site-packages\pip\_vendor\rich\_fileno.py

#### `get_fileno()` (line 6)
_Get fileno() from a file, accounting for poorly implemented file-like objects.

Args:
    file_like (IO): A file-like object.

Returns:
    int | None: The result of fileno if available, or None if operation failed._

**Args**: file_like


### venv_new\Lib\site-packages\pip\_vendor\rich\_inspect.py

#### `_first_paragraph()` (line 15)
_Get the first paragraph from a docstring._

**Args**: doc


#### `__init__()` (line 37)
**Args**: self, obj


#### `_make_title()` (line 64)
_Make a default title._

**Args**: self, obj


#### `__rich__()` (line 74)
**Args**: self


#### `_get_signature()` (line 82)
_Get a signature for a callable._

**Args**: self, name, obj


#### `_render()` (line 121)
_Render object._

**Args**: self


#### `sort_items()` (line 124)
**Args**: item


#### `safe_getattr()` (line 128)
_Get attribute or any exception._

**Args**: attr_name


#### `_get_formatted_doc()` (line 214)
_Extract the docstring of an object, process it and returns it.
The processing consists in cleaning up the doctring's indentation,
taking only its 1st paragraph if `self.help` is not True,
and escape its control codes.

Args:
    object_ (Any): the object to get the docstring from.

Returns:
    Optional[str]: the processed docstring, or None if no docstring was found._

**Args**: self, object_


#### `get_object_types_mro()` (line 236)
_Returns the MRO of an object's class, or of the object itself if it's a class._

**Args**: obj


#### `get_object_types_mro_as_strings()` (line 245)
_Returns the MRO of an object's class as full qualified names, or of the object itself if it's a class.

Examples:
    `object_types_mro_as_strings(JSONDecoder)` will return `['json.decoder.JSONDecoder', 'builtins.object']`_

**Args**: obj


#### `is_object_one_of_types()` (line 258)
_Returns `True` if the given object's class (or the object itself, if it's a class) has one of the
fully qualified names in its MRO._

**Args**: obj, fully_qualified_types_names


### venv_new\Lib\site-packages\pip\_vendor\rich\_log_render.py

#### `__init__()` (line 15)
**Args**: self, show_time, show_level, show_path, time_format, omit_repeated_times, level_width


#### `__call__()` (line 32)
**Args**: self, console, renderables, log_time, time_format, level, path, line_no, link_path


### venv_new\Lib\site-packages\pip\_vendor\rich\_loop.py

#### `loop_first()` (line 6)
_Iterate and generate a tuple with a flag for first value._

**Args**: values


#### `loop_last()` (line 18)
_Iterate and generate a tuple with a flag for last value._

**Args**: values


#### `loop_first_last()` (line 31)
_Iterate and generate a tuple with a flag for first and last value._

**Args**: values


### venv_new\Lib\site-packages\pip\_vendor\rich\_null_file.py

#### `close()` (line 6)
**Args**: self


#### `isatty()` (line 9)
**Args**: self


#### `read()` (line 12)
**Args**: self, __n


#### `readable()` (line 15)
**Args**: self


#### `readline()` (line 18)
**Args**: self, __limit


#### `readlines()` (line 21)
**Args**: self, __hint


#### `seek()` (line 24)
**Args**: self, __offset, __whence


#### `seekable()` (line 27)
**Args**: self


#### `tell()` (line 30)
**Args**: self


#### `truncate()` (line 33)
**Args**: self, __size


#### `writable()` (line 36)
**Args**: self


#### `writelines()` (line 39)
**Args**: self, __lines


#### `__next__()` (line 42)
**Args**: self


#### `__iter__()` (line 45)
**Args**: self


#### `__enter__()` (line 48)
**Args**: self


#### `__exit__()` (line 51)
**Args**: self, __t, __value, __traceback


#### `write()` (line 59)
**Args**: self, text


#### `flush()` (line 62)
**Args**: self


#### `fileno()` (line 65)
**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\rich\_pick.py

#### `pick_bool()` (line 4)
_Pick the first non-none bool or return the last value.

Args:
    *values (bool): Any number of boolean or None values.

Returns:
    bool: First non-none boolean._


### venv_new\Lib\site-packages\pip\_vendor\rich\_ratio.py

#### `ratio_resolve()` (line 20)
_Divide total space to satisfy size, ratio, and minimum_size, constraints.

The returned list of integers should add up to total in most cases, unless it is
impossible to satisfy all the constraints. For instance, if there are two edges
with a minimum size of 20 each and `total` is 30 then the returned list will be
greater than total. In practice, this would mean that a Layout object would
clip the rows that would overflow the screen height.

Args:
    total (int): Total number of characters.
    edges (List[Edge]): Edges within total space.

Returns:
    List[int]: Number of characters for each edge._

**Args**: total, edges


#### `ratio_reduce()` (line 81)
_Divide an integer total in to parts based on ratios.

Args:
    total (int): The total to divide.
    ratios (List[int]): A list of integer ratios.
    maximums (List[int]): List of maximums values for each slot.
    values (List[int]): List of values

Returns:
    List[int]: A list of integers guaranteed to sum to total._

**Args**: total, ratios, maximums, values


#### `ratio_distribute()` (line 113)
_Distribute an integer total in to parts based on ratios.

Args:
    total (int): The total to divide.
    ratios (List[int]): A list of integer ratios.
    minimums (List[int]): List of minimum values for each slot.

Returns:
    List[int]: A list of integers guaranteed to sum to total._

**Args**: total, ratios, minimums


### venv_new\Lib\site-packages\pip\_vendor\rich\_stack.py

#### `top()` (line 10)
_Get top of stack._

**Args**: self


#### `push()` (line 14)
_Push an item on to the stack (append in stack nomenclature)._

**Args**: self, item


### venv_new\Lib\site-packages\pip\_vendor\rich\_timer.py

#### `timer()` (line 13)
_print the elapsed time. (only used in debugging)_

**Args**: subject


### venv_new\Lib\site-packages\pip\_vendor\rich\_win32_console.py

#### `from_param()` (line 44)
_Converts a WindowsCoordinates into a wintypes _COORD structure.
This classmethod is internally called by ctypes to perform the conversion.

Args:
    value (WindowsCoordinates): The input coordinates to convert.

Returns:
    wintypes._COORD: The converted coordinates struct._

**Args**: cls, value


#### `GetStdHandle()` (line 78)
_Retrieves a handle to the specified standard device (standard input, standard output, or standard error).

Args:
    handle (int): Integer identifier for the handle. Defaults to -11 (stdout).

Returns:
    wintypes.HANDLE: The handle_

**Args**: handle


#### `GetConsoleMode()` (line 95)
_Retrieves the current input mode of a console's input buffer
or the current output mode of a console screen buffer.

Args:
    std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.

Raises:
    LegacyWindowsError: If any error occurs while calling the Windows console API.

Returns:
    int: Value representing the current console mode as documented at
        https://docs.microsoft.com/en-us/windows/console/getconsolemode#parameters_

**Args**: std_handle


#### `FillConsoleOutputCharacter()` (line 128)
_Writes a character to the console screen buffer a specified number of times, beginning at the specified coordinates.

Args:
    std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
    char (str): The character to write. Must be a string of length 1.
    length (int): The number of times to write the character.
    start (WindowsCoordinates): The coordinates to start writing at.

Returns:
    int: The number of characters written._

**Args**: std_handle, char, length, start


#### `FillConsoleOutputAttribute()` (line 169)
_Sets the character attributes for a specified number of character cells,
beginning at the specified coordinates in a screen buffer.

Args:
    std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
    attributes (int): Integer value representing the foreground and background colours of the cells.
    length (int): The number of cells to set the output attribute of.
    start (WindowsCoordinates): The coordinates of the first cell whose attributes are to be set.

Returns:
    int: The number of cells whose attributes were actually set._

**Args**: std_handle, attributes, length, start


#### `SetConsoleTextAttribute()` (line 204)
_Set the colour attributes for all text written after this function is called.

Args:
    std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
    attributes (int): Integer value representing the foreground and background colours.


Returns:
    bool: True if the attribute was set successfully, otherwise False._

**Args**: std_handle, attributes


#### `GetConsoleScreenBufferInfo()` (line 228)
_Retrieves information about the specified console screen buffer.

Args:
    std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.

Returns:
    CONSOLE_SCREEN_BUFFER_INFO: A CONSOLE_SCREEN_BUFFER_INFO ctype struct contain information about
        screen size, cursor position, colour attributes, and more._

**Args**: std_handle


#### `SetConsoleCursorPosition()` (line 252)
_Set the position of the cursor in the console screen

Args:
    std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
    coords (WindowsCoordinates): The coordinates to move the cursor to.

Returns:
    bool: True if the function succeeds, otherwise False._

**Args**: std_handle, coords


#### `GetConsoleCursorInfo()` (line 275)
_Get the cursor info - used to get cursor visibility and width

Args:
    std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
    cursor_info (CONSOLE_CURSOR_INFO): CONSOLE_CURSOR_INFO ctype struct that receives information
        about the console's cursor.

Returns:
      bool: True if the function succeeds, otherwise False._

**Args**: std_handle, cursor_info


#### `SetConsoleCursorInfo()` (line 299)
_Set the cursor info - used for adjusting cursor visibility and width

Args:
    std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
    cursor_info (CONSOLE_CURSOR_INFO): CONSOLE_CURSOR_INFO ctype struct containing the new cursor info.

Returns:
      bool: True if the function succeeds, otherwise False._

**Args**: std_handle, cursor_info


#### `SetConsoleTitle()` (line 319)
_Sets the title of the current console window

Args:
    title (str): The new title of the console window.

Returns:
    bool: True if the function succeeds, otherwise False._

**Args**: title


#### `__init__()` (line 362)
**Args**: self, file


#### `cursor_position()` (line 377)
_Returns the current position of the cursor (0-based)

Returns:
    WindowsCoordinates: The current cursor position._

**Args**: self


#### `screen_size()` (line 387)
_Returns the current size of the console screen buffer, in character columns and rows

Returns:
    WindowsCoordinates: The width and height of the screen as WindowsCoordinates._

**Args**: self


#### `write_text()` (line 396)
_Write text directly to the terminal without any modification of styles

Args:
    text (str): The text to write to the console_

**Args**: self, text


#### `write_styled()` (line 405)
_Write styled text to the terminal.

Args:
    text (str): The text to write
    style (Style): The style of the text_

**Args**: self, text, style


#### `move_cursor_to()` (line 444)
_Set the position of the cursor

Args:
    new_position (WindowsCoordinates): The WindowsCoordinates representing the new position of the cursor._

**Args**: self, new_position


#### `erase_line()` (line 454)
_Erase all content on the line the cursor is currently located at_

**Args**: self


#### `erase_end_of_line()` (line 470)
_Erase all content from the cursor position to the end of that line_

**Args**: self


#### `erase_start_of_line()` (line 484)
_Erase all content from the cursor position to the start of that line_

**Args**: self


#### `move_cursor_up()` (line 493)
_Move the cursor up a single cell_

**Args**: self


#### `move_cursor_down()` (line 503)
_Move the cursor down a single cell_

**Args**: self


#### `move_cursor_forward()` (line 514)
_Move the cursor forward a single cell. Wrap to the next line if required._

**Args**: self


#### `move_cursor_to_column()` (line 526)
_Move cursor to the column specified by the zero-based column index, staying on the same row

Args:
    column (int): The zero-based column index to move the cursor to._

**Args**: self, column


#### `move_cursor_backward()` (line 535)
_Move the cursor backward a single cell. Wrap to the previous line if required._

**Args**: self


#### `hide_cursor()` (line 547)
_Hide the cursor_

**Args**: self


#### `show_cursor()` (line 553)
_Show the cursor_

**Args**: self


#### `set_title()` (line 559)
_Set the title of the terminal window

Args:
    title (str): The new title of the console window_

**Args**: self, title


#### `_get_cursor_size()` (line 568)
_Get the percentage of the character cell that is filled by the cursor_

**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\rich\_windows.py

#### `get_windows_console_features()` (line 34)

#### `get_windows_console_features()` (line 40)
_Get windows console features.

Returns:
    WindowsConsoleFeatures: An instance of WindowsConsoleFeatures._


### venv_new\Lib\site-packages\pip\_vendor\rich\_windows_renderer.py

#### `legacy_windows_render()` (line 7)
_Makes appropriate Windows Console API calls based on the segments in the buffer.

Args:
    buffer (Iterable[Segment]): Iterable of Segments to convert to Win32 API calls.
    term (LegacyWindowsTerm): Used to call the Windows Console API._

**Args**: buffer, term


### venv_new\Lib\site-packages\pip\_vendor\rich\_wrap.py

#### `words()` (line 12)
_Yields each word from the text as a tuple
containing (start_index, end_index, word). A "word" in this context may
include the actual word and any whitespace to the right._

**Args**: text


#### `divide_line()` (line 26)
_Given a string of text, and a width (measured in cells), return a list
of cell offsets which the string should be split at in order for it to fit
within the given width.

Args:
    text: The text to examine.
    width: The available cell width.
    fold: If True, words longer than `width` will be folded onto a new line.

Returns:
    A list of indices to break the line at._

**Args**: text, width, fold


### venv_new\Lib\site-packages\pip\_vendor\rich\abc.py

#### `__subclasshook__()` (line 16)
_Check if this class supports the rich render protocol._

**Args**: cls, other


### venv_new\Lib\site-packages\pip\_vendor\rich\align.py

#### `__init__()` (line 39)
**Args**: self, renderable, align, style


#### `__repr__()` (line 66)
**Args**: self


#### `left()` (line 70)
_Align a renderable to the left._

**Args**: cls, renderable, style


#### `center()` (line 92)
_Align a renderable to the center._

**Args**: cls, renderable, style


#### `right()` (line 114)
_Align a renderable to the right._

**Args**: cls, renderable, style


#### `__rich_console__()` (line 135)
**Args**: self, console, options


#### `generate_segments()` (line 153)

#### `blank_lines()` (line 198)
**Args**: count


#### `__rich_measure__()` (line 227)
**Args**: self, console, options


#### `__init__()` (line 246)
**Args**: self, renderable, style


#### `__repr__()` (line 254)
**Args**: self


#### `__rich_console__()` (line 257)
**Args**: self, console, options


#### `blank_lines()` (line 271)
**Args**: count


#### `__rich_measure__()` (line 284)
**Args**: self, console, options


### venv_new\Lib\site-packages\pip\_vendor\rich\ansi.py

#### `_ansi_tokenize()` (line 28)
_Tokenize a string in to plain text and ANSI codes.

Args:
    ansi_text (str): A String containing ANSI codes.

Yields:
    AnsiToken: A named tuple of (plain, sgr, osc)_

**Args**: ansi_text


#### `__init__()` (line 123)
**Args**: self


#### `decode()` (line 126)
_Decode ANSI codes in an iterable of lines.

Args:
    lines (Iterable[str]): An iterable of lines of terminal output.

Yields:
    Text: Marked up Text._

**Args**: self, terminal_text


#### `decode_line()` (line 138)
_Decode a line containing ansi codes.

Args:
    line (str): A line of terminal output.

Returns:
    Text: A Text instance marked up according to ansi codes._

**Args**: self, line


#### `read()` (line 224)
**Args**: fd


### venv_new\Lib\site-packages\pip\_vendor\rich\bar.py

#### `__init__()` (line 29)
**Args**: self, size, begin, end


#### `__repr__()` (line 45)
**Args**: self


#### `__rich_console__()` (line 48)
**Args**: self, console, options


#### `__rich_measure__()` (line 86)
**Args**: self, console, options


### venv_new\Lib\site-packages\pip\_vendor\rich\box.py

#### `__init__()` (line 33)
**Args**: self, box


#### `__repr__()` (line 67)
**Args**: self


#### `__str__()` (line 70)
**Args**: self


#### `substitute()` (line 73)
_Substitute this box for another if it won't render due to platform issues.

Args:
    options (ConsoleOptions): Console options used in rendering.
    safe (bool, optional): Substitute this for another Box if there are known problems
        displaying on the platform (currently only relevant on Windows). Default is True.

Returns:
    Box: A different Box or the same Box._

**Args**: self, options, safe


#### `get_plain_headed_box()` (line 91)
_If this box uses special characters for the borders of the header, then
return the equivalent box that does not.

Returns:
    Box: The most similar Box that doesn't use header-specific box characters.
        If the current Box already satisfies this criterion, then it's returned._

**Args**: self


#### `get_top()` (line 101)
_Get the top of a simple box.

Args:
    widths (List[int]): Widths of columns.

Returns:
    str: A string of box characters._

**Args**: self, widths


#### `get_row()` (line 121)
_Get the top of a simple box.

Args:
    width (List[int]): Widths of columns.

Returns:
    str: A string of box characters._

**Args**: self, widths, level, edge


#### `get_bottom()` (line 170)
_Get the bottom of a simple box.

Args:
    widths (List[int]): Widths of columns.

Returns:
    str: A string of box characters._

**Args**: self, widths


### venv_new\Lib\site-packages\pip\_vendor\rich\cells.py

#### `cached_cell_len()` (line 34)
_Get the number of cells required to display text.

This method always caches, which may use up a lot of memory. It is recommended to use
`cell_len` over this method.

Args:
    text (str): Text to display.

Returns:
    int: Get the number of cells required to display text._

**Args**: text


#### `cell_len()` (line 51)
_Get the number of cells required to display text.

Args:
    text (str): Text to display.

Returns:
    int: Get the number of cells required to display text._

**Args**: text, _cell_len


#### `get_character_cell_size()` (line 68)
_Get the cell size of a character.

Args:
    character (str): A single character.

Returns:
    int: Number of cells (0, 1 or 2) occupied by that character._

**Args**: character


#### `set_cell_size()` (line 96)
_Set the length of a string to fit within given number of cells._

**Args**: text, total


#### `chop_cells()` (line 131)
_Split text into lines such that each line fits within the available (cell) width.

Args:
    text: The text to fold such that it fits in the given width.
    width: The width available (number of cells).

Returns:
    A list of strings such that each string in the list has cell width
    less than or equal to the available width._

**Args**: text, width


### venv_new\Lib\site-packages\pip\_vendor\rich\color.py

#### `__repr__()` (line 29)
**Args**: self


#### `__str__()` (line 32)
**Args**: self


#### `__repr__()` (line 45)
**Args**: self


#### `__rich__()` (line 315)
_Displays the actual color if Rich printed._

**Args**: self


#### `__rich_repr__()` (line 326)
**Args**: self


#### `system()` (line 333)
_Get the native color system for this color._

**Args**: self


#### `is_system_defined()` (line 340)
_Check if the color is ultimately defined by the system._

**Args**: self


#### `is_default()` (line 345)
_Check if the color is a default color._

**Args**: self


#### `get_truecolor()` (line 349)
_Get an equivalent color triplet for this color.

Args:
    theme (TerminalTheme, optional): Optional terminal theme, or None to use default. Defaults to None.
    foreground (bool, optional): True for a foreground color, or False for background. Defaults to True.

Returns:
    ColorTriplet: A color triplet containing RGB components._

**Args**: self, theme, foreground


#### `from_ansi()` (line 381)
_Create a Color number from it's 8-bit ansi number.

Args:
    number (int): A number between 0-255 inclusive.

Returns:
    Color: A new Color instance._

**Args**: cls, number


#### `from_triplet()` (line 397)
_Create a truecolor RGB color from a triplet of values.

Args:
    triplet (ColorTriplet): A color triplet containing red, green and blue components.

Returns:
    Color: A new color object._

**Args**: cls, triplet


#### `from_rgb()` (line 409)
_Create a truecolor from three color components in the range(0->255).

Args:
    red (float): Red component in range 0-255.
    green (float): Green component in range 0-255.
    blue (float): Blue component in range 0-255.

Returns:
    Color: A new color object._

**Args**: cls, red, green, blue


#### `default()` (line 423)
_Get a Color instance representing the default color.

Returns:
    Color: Default color._

**Args**: cls


#### `parse()` (line 433)
_Parse a color definition._

**Args**: cls, color


#### `get_ansi_codes()` (line 485)
_Get the ANSI escape codes for this color._

**Args**: self, foreground


#### `downgrade()` (line 513)
_Downgrade a color system to a system with fewer colors._

**Args**: self, system


#### `parse_rgb_hex()` (line 571)
_Parse six hex characters in to RGB triplet._

**Args**: hex_color


#### `blend_rgb()` (line 580)
_Blend one RGB color in to another._

**Args**: color1, color2, cross_fade


### venv_new\Lib\site-packages\pip\_vendor\rich\color_triplet.py

#### `hex()` (line 15)
_get the color triplet in CSS style._

**Args**: self


#### `rgb()` (line 21)
_The color in RGB format.

Returns:
    str: An rgb color, e.g. ``"rgb(100,23,255)"``._

**Args**: self


#### `normalized()` (line 31)
_Convert components into floats between 0 and 1.

Returns:
    Tuple[float, float, float]: A tuple of three normalized colour components._

**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\rich\columns.py

#### `__init__()` (line 31)
**Args**: self, renderables, padding


#### `add_renderable()` (line 54)
_Add a renderable to the columns.

Args:
    renderable (RenderableType): Any renderable object._

**Args**: self, renderable


#### `__rich_console__()` (line 62)
**Args**: self, console, options


#### `iter_renderables()` (line 86)
**Args**: column_count


### venv_new\Lib\site-packages\pip\_vendor\rich\console.py

#### `ascii_only()` (line 155)
_Check if renderables should use ascii only._

**Args**: self


#### `copy()` (line 159)
_Return a copy of the options.

Returns:
    ConsoleOptions: a copy of self._

**Args**: self


#### `update()` (line 169)
_Update values, return a copy._

**Args**: self


#### `update_width()` (line 206)
_Update just the width, return a copy.

Args:
    width (int): New width (sets both min_width and max_width)

Returns:
    ~ConsoleOptions: New console options instance._

**Args**: self, width


#### `update_height()` (line 219)
_Update the height, and return a copy.

Args:
    height (int): New height

Returns:
    ~ConsoleOptions: New Console options instance._

**Args**: self, height


#### `reset_height()` (line 232)
_Return a copy of the options with height set to ``None``.

Returns:
    ~ConsoleOptions: New console options instance._

**Args**: self


#### `update_dimensions()` (line 242)
_Update the width and height, and return a copy.

Args:
    width (int): New width (sets both min_width and max_width).
    height (int): New height.

Returns:
    ~ConsoleOptions: New console options instance._

**Args**: self, width, height


#### `__rich__()` (line 262)
**Args**: self


#### `__rich_console__()` (line 272)
**Args**: self, console, options


#### `__init__()` (line 295)
**Args**: self, count


#### `__rich_console__()` (line 298)
**Args**: self, console, options


#### `__init__()` (line 307)
**Args**: self, lines, x, y


#### `__rich_console__()` (line 312)
**Args**: self, console, options


#### `__init__()` (line 330)
**Args**: self, console


#### `__enter__()` (line 334)
**Args**: self


#### `__exit__()` (line 338)
**Args**: self, exc_type, exc_val, exc_tb


#### `get()` (line 346)
_Get the result of the capture._

**Args**: self


#### `__init__()` (line 358)
**Args**: self, console, theme, inherit


#### `__enter__()` (line 363)
**Args**: self


#### `__exit__()` (line 367)
**Args**: self, exc_type, exc_val, exc_tb


#### `__init__()` (line 379)
**Args**: self, console, pager, styles, links


#### `__enter__()` (line 391)
**Args**: self


#### `__exit__()` (line 395)
**Args**: self, exc_type, exc_val, exc_tb


#### `__init__()` (line 418)
**Args**: self, console, hide_cursor, style


#### `update()` (line 426)
_Update the screen.

Args:
    renderable (RenderableType, optional): Optional renderable to replace current renderable,
        or None for no change. Defaults to None.
    style: (Style, optional): Replacement style, or None for no change. Defaults to None._

**Args**: self


#### `__enter__()` (line 444)
**Args**: self


#### `__exit__()` (line 450)
**Args**: self, exc_type, exc_val, exc_tb


#### `__init__()` (line 470)
**Args**: self


#### `renderables()` (line 476)
**Args**: self


#### `__rich_measure__()` (line 481)
**Args**: self, console, options


#### `__rich_console__()` (line 489)
**Args**: self, console, options


#### `group()` (line 495)
_A decorator that turns an iterable of renderables in to a group.

Args:
    fit (bool, optional): Fit dimension of group to contents, or fill available space. Defaults to True._

**Args**: fit


#### `decorator()` (line 502)
_Convert a method that returns an iterable of renderables in to a Group._

**Args**: method


#### `_replace()` (line 508)

#### `_is_jupyter()` (line 517)
_Check if we're running in a Jupyter notebook._


#### `process_renderables()` (line 560)
_Called with a list of objects to render.

This method can return a new list of renderables, or modify and return the same list.

Args:
    renderables (List[ConsoleRenderable]): A number of renderable objects.

Returns:
    List[ConsoleRenderable]: A replacement list of renderables._

**Args**: self, renderables


#### `get_windows_console_features()` (line 578)

#### `detect_legacy_windows()` (line 588)
_Detect legacy Windows._


#### `__init__()` (line 631)
**Args**: self


#### `__repr__()` (line 755)
**Args**: self


#### `file()` (line 759)
_Get the file object to write to._

**Args**: self


#### `file()` (line 768)
_Set a new file object._

**Args**: self, new_file


#### `_buffer()` (line 773)
_Get a thread local buffer._

**Args**: self


#### `_buffer_index()` (line 778)
_Get a thread local buffer._

**Args**: self


#### `_buffer_index()` (line 783)
**Args**: self, value


#### `_theme_stack()` (line 787)
_Get the thread local theme stack._

**Args**: self


#### `_detect_color_system()` (line 791)
_Detect color system from env vars._

**Args**: self


#### `_enter_buffer()` (line 815)
_Enter in to a buffer context, and buffer all output._

**Args**: self


#### `_exit_buffer()` (line 819)
_Leave buffer context, and render content if required._

**Args**: self


#### `set_live()` (line 824)
_Set Live instance. Used by Live context manager.

Args:
    live (Live): Live instance using this Console.

Raises:
    errors.LiveError: If this Console has a Live context currently active._

**Args**: self, live


#### `clear_live()` (line 838)
_Clear the Live instance._

**Args**: self


#### `push_render_hook()` (line 843)
_Add a new render hook to the stack.

Args:
    hook (RenderHook): Render hook instance._

**Args**: self, hook


#### `pop_render_hook()` (line 852)
_Pop the last renderhook from the stack._

**Args**: self


#### `__enter__()` (line 857)
_Own context manager to enter buffer context._

**Args**: self


#### `__exit__()` (line 862)
_Exit buffer context._

**Args**: self, exc_type, exc_value, traceback


#### `begin_capture()` (line 866)
_Begin capturing console output. Call :meth:`end_capture` to exit capture mode and return output._

**Args**: self


#### `end_capture()` (line 870)
_End capture mode and return captured string.

Returns:
    str: Console output._

**Args**: self


#### `push_theme()` (line 881)
_Push a new theme on to the top of the stack, replacing the styles from the previous theme.
Generally speaking, you should call :meth:`~rich.console.Console.use_theme` to get a context manager, rather
than calling this method directly.

Args:
    theme (Theme): A theme instance.
    inherit (bool, optional): Inherit existing styles. Defaults to True._

**Args**: self, theme


#### `pop_theme()` (line 892)
_Remove theme from top of stack, restoring previous theme._

**Args**: self


#### `use_theme()` (line 896)
_Use a different theme for the duration of the context manager.

Args:
    theme (Theme): Theme instance to user.
    inherit (bool, optional): Inherit existing console styles. Defaults to True.

Returns:
    ThemeContext: [description]_

**Args**: self, theme


#### `color_system()` (line 909)
_Get color system string.

Returns:
    Optional[str]: "standard", "256" or "truecolor"._

**Args**: self


#### `encoding()` (line 922)
_Get the encoding of the console file, e.g. ``"utf-8"``.

Returns:
    str: A standard encoding string._

**Args**: self


#### `is_terminal()` (line 931)
_Check if the console is writing to a terminal.

Returns:
    bool: True if the console writing to a device capable of
    understanding terminal codes, otherwise False._

**Args**: self


#### `is_dumb_terminal()` (line 967)
_Detect dumb terminal.

Returns:
    bool: True if writing to a dumb terminal, otherwise False._

**Args**: self


#### `options()` (line 979)
_Get default console options._

**Args**: self


#### `size()` (line 992)
_Get the size of the console.

Returns:
    ConsoleDimensions: A named tuple containing the dimensions._

**Args**: self


#### `size()` (line 1033)
_Set a new size for the terminal.

Args:
    new_size (Tuple[int, int]): New width and height._

**Args**: self, new_size


#### `width()` (line 1044)
_Get the width of the console.

Returns:
    int: The width (in characters) of the console._

**Args**: self


#### `width()` (line 1053)
_Set width.

Args:
    width (int): New width._

**Args**: self, width


#### `height()` (line 1062)
_Get the height of the console.

Returns:
    int: The height (in lines) of the console._

**Args**: self


#### `height()` (line 1071)
_Set height.

Args:
    height (int): new height._

**Args**: self, height


#### `bell()` (line 1079)
_Play a 'bell' sound (if supported by the terminal)._

**Args**: self


#### `capture()` (line 1083)
_A context manager to *capture* the result of print() or log() in a string,
rather than writing it to the console.

Example:
    >>> from rich.console import Console
    >>> console = Console()
    >>> with console.capture() as capture:
    ...     console.print("[bold magenta]Hello World[/]")
    >>> print(capture.get())

Returns:
    Capture: Context manager with disables writing to the terminal._

**Args**: self


#### `pager()` (line 1100)
_A context manager to display anything printed within a "pager". The pager application
is defined by the system and will typically support at least pressing a key to scroll.

Args:
    pager (Pager, optional): A pager object, or None to use :class:`~rich.pager.SystemPager`. Defaults to None.
    styles (bool, optional): Show styles in pager. Defaults to False.
    links (bool, optional): Show links in pager. Defaults to False.

Example:
    >>> from rich.console import Console
    >>> from rich.__main__ import make_test_card
    >>> console = Console()
    >>> with console.pager():
            console.print(make_test_card())

Returns:
    PagerContext: A context manager._

**Args**: self, pager, styles, links


#### `line()` (line 1123)
_Write new line(s).

Args:
    count (int, optional): Number of new lines. Defaults to 1._

**Args**: self, count


#### `clear()` (line 1133)
_Clear the screen.

Args:
    home (bool, optional): Also move the cursor to 'home' position. Defaults to True._

**Args**: self, home


#### `status()` (line 1144)
_Display a status and spinner.

Args:
    status (RenderableType): A status renderable (str or Text typically).
    spinner (str, optional): Name of spinner animation (see python -m rich.spinner). Defaults to "dots".
    spinner_style (StyleType, optional): Style of spinner. Defaults to "status.spinner".
    speed (float, optional): Speed factor for spinner animation. Defaults to 1.0.
    refresh_per_second (float, optional): Number of refreshes per second. Defaults to 12.5.

Returns:
    Status: A Status object that may be used as a context manager._

**Args**: self, status


#### `show_cursor()` (line 1177)
_Show or hide the cursor.

Args:
    show (bool, optional): Set visibility of the cursor._

**Args**: self, show


#### `set_alt_screen()` (line 1188)
_Enables alternative screen mode.

Note, if you enable this mode, you should ensure that is disabled before
the application exits. See :meth:`~rich.Console.screen` for a context manager
that handles this for you.

Args:
    enable (bool, optional): Enable (True) or disable (False) alternate screen. Defaults to True.

Returns:
    bool: True if the control codes were written._

**Args**: self, enable


#### `is_alt_screen()` (line 1210)
_Check if the alt screen was enabled.

Returns:
    bool: True if the alt screen was enabled, otherwise False._

**Args**: self


#### `set_window_title()` (line 1218)
_Set the title of the console terminal window.

Warning: There is no means within Rich of "resetting" the window title to its
previous value, meaning the title you set will persist even after your application
exits.

``fish`` shell resets the window title before and after each command by default,
negating this issue. Windows Terminal and command prompt will also reset the title for you.
Most other shells and terminals, however, do not do this.

Some terminals may require configuration changes before you can set the title.
Some terminals may not support setting the title at all.

Other software (including the terminal itself, the shell, custom prompts, plugins, etc.)
may also set the terminal window title. This could result in whatever value you write
using this method being overwritten.

Args:
    title (str): The new title of the terminal window.

Returns:
    bool: True if the control code to change the terminal title was
        written, otherwise False. Note that a return value of True
        does not guarantee that the window title has actually changed,
        since the feature may be unsupported/disabled in some terminals._

**Args**: self, title


#### `screen()` (line 1250)
_Context manager to enable and disable 'alternative screen' mode.

Args:
    hide_cursor (bool, optional): Also hide the cursor. Defaults to False.
    style (Style, optional): Optional style for screen. Defaults to None.

Returns:
    ~ScreenContext: Context which enables alternate screen on enter, and disables it on exit._

**Args**: self, hide_cursor, style


#### `measure()` (line 1264)
_Measure a renderable. Returns a :class:`~rich.measure.Measurement` object which contains
information regarding the number of characters required to print the renderable.

Args:
    renderable (RenderableType): Any renderable or string.
    options (Optional[ConsoleOptions], optional): Options to use when measuring, or None
        to use default options. Defaults to None.

Returns:
    Measurement: A measurement of the renderable._

**Args**: self, renderable


#### `render()` (line 1281)
_Render an object in to an iterable of `Segment` instances.

This method contains the logic for rendering objects with the console protocol.
You are unlikely to need to use it directly, unless you are extending the library.

Args:
    renderable (RenderableType): An object supporting the console protocol, or
        an object that may be converted to a string.
    options (ConsoleOptions, optional): An options object, or None to use self.options. Defaults to None.

Returns:
    Iterable[Segment]: An iterable of segments that may be rendered._

**Args**: self, renderable, options


#### `render_lines()` (line 1332)
_Render objects in to a list of lines.

        The output of render_lines is useful when further formatting of rendered console text
        is required, such as the Panel class which draws a border around any renderable object.

        Args:
            renderable (RenderableType): Any object renderable in the console.
            options (Optional[ConsoleOptions], optional): Console options, or None to use self.options. Default to ``None``.
            style (Style, optional): Optional style to apply to renderables. Defaults to ``None``.
            pad (bool, optional): Pad lines shorter than render width. Defaults to ``True``.
            new_lines (bool, optional): Include "
" characters at end of lines.

        Returns:
            List[List[Segment]]: A list of lines, where a line is a list of Segment objects.
        _

**Args**: self, renderable, options


#### `render_str()` (line 1396)
_Convert a string to a Text instance. This is called automatically if
you print or log a string.

Args:
    text (str): Text to render.
    style (Union[str, Style], optional): Style to apply to rendered text.
    justify (str, optional): Justify method: "default", "left", "center", "full", or "right". Defaults to ``None``.
    overflow (str, optional): Overflow method: "crop", "fold", or "ellipsis". Defaults to ``None``.
    emoji (Optional[bool], optional): Enable emoji, or ``None`` to use Console default.
    markup (Optional[bool], optional): Enable markup, or ``None`` to use Console default.
    highlight (Optional[bool], optional): Enable highlighting, or ``None`` to use Console default.
    highlighter (HighlighterType, optional): Optional highlighter to apply.
Returns:
    ConsoleRenderable: Renderable object._

**Args**: self, text


#### `get_style()` (line 1457)
_Get a Style instance by its theme name or parse a definition.

Args:
    name (str): The name of a style or a style definition.

Returns:
    Style: A Style object.

Raises:
    MissingStyle: If no style could be parsed from name._

**Args**: self, name


#### `_collect_renderables()` (line 1487)
_Combine a number of renderables and text into one renderable.

Args:
    objects (Iterable[Any]): Anything that Rich can render.
    sep (str): String to write between print data.
    end (str): String to write at end of print data.
    justify (str, optional): One of "left", "right", "center", or "full". Defaults to ``None``.
    emoji (Optional[bool], optional): Enable emoji code, or ``None`` to use console default.
    markup (Optional[bool], optional): Enable markup, or ``None`` to use console default.
    highlight (Optional[bool], optional): Enable automatic highlighting, or ``None`` to use console default.

Returns:
    List[ConsoleRenderable]: A list of things to render._

**Args**: self, objects, sep, end


#### `align_append()` (line 1520)
**Args**: renderable


#### `check_text()` (line 1529)

#### `rule()` (line 1566)
_Draw a line with optional centered title.

Args:
    title (str, optional): Text to render over the rule. Defaults to "".
    characters (str, optional): Character(s) to form the line. Defaults to "‚îÄ".
    style (str, optional): Style of line. Defaults to "rule.line".
    align (str, optional): How to align the title, one of "left", "center", or "right". Defaults to "center"._

**Args**: self, title


#### `control()` (line 1587)
_Insert non-printing control codes.

Args:
    control_codes (str): Control codes, such as those that may move the cursor._

**Args**: self


#### `out()` (line 1597)
_Output to the terminal. This is a low-level way of writing to the terminal which unlike
:meth:`~rich.console.Console.print` won't pretty print, wrap text, or apply markup, but will
optionally apply highlighting and a basic style.

Args:
    sep (str, optional): String to write between print data. Defaults to " ".
    end (str, optional): String to write at end of print data. Defaults to "\\n".
    style (Union[str, Style], optional): A style to apply to output. Defaults to None.
    highlight (Optional[bool], optional): Enable automatic highlighting, or ``None`` to use
        console default. Defaults to ``None``._

**Args**: self


#### `print()` (line 1629)
_Print to the console.

Args:
    objects (positional args): Objects to log to the terminal.
    sep (str, optional): String to write between print data. Defaults to " ".
    end (str, optional): String to write at end of print data. Defaults to "\\n".
    style (Union[str, Style], optional): A style to apply to output. Defaults to None.
    justify (str, optional): Justify method: "default", "left", "right", "center", or "full". Defaults to ``None``.
    overflow (str, optional): Overflow method: "ignore", "crop", "fold", or "ellipsis". Defaults to None.
    no_wrap (Optional[bool], optional): Disable word wrapping. Defaults to None.
    emoji (Optional[bool], optional): Enable emoji code, or ``None`` to use console default. Defaults to ``None``.
    markup (Optional[bool], optional): Enable markup, or ``None`` to use console default. Defaults to ``None``.
    highlight (Optional[bool], optional): Enable automatic highlighting, or ``None`` to use console default. Defaults to ``None``.
    width (Optional[int], optional): Width of output, or ``None`` to auto-detect. Defaults to ``None``.
    crop (Optional[bool], optional): Crop output to width of terminal. Defaults to True.
    soft_wrap (bool, optional): Enable soft wrap mode which disables word wrapping and cropping of text or ``None`` for
        Console default. Defaults to ``None``.
    new_line_start (bool, False): Insert a new line at the start if the output contains more than one line. Defaults to ``False``._

**Args**: self


#### `print_json()` (line 1728)
_Pretty prints JSON. Output will be valid JSON.

Args:
    json (Optional[str]): A string containing JSON.
    data (Any): If json is not supplied, then encode this data.
    indent (Union[None, int, str], optional): Number of spaces to indent. Defaults to 2.
    highlight (bool, optional): Enable highlighting of output: Defaults to True.
    skip_keys (bool, optional): Skip keys not of a basic type. Defaults to False.
    ensure_ascii (bool, optional): Escape all non-ascii characters. Defaults to False.
    check_circular (bool, optional): Check for circular references. Defaults to True.
    allow_nan (bool, optional): Allow NaN and Infinity values. Defaults to True.
    default (Callable, optional): A callable that converts values that can not be encoded
        in to something that can be JSON encoded. Defaults to None.
    sort_keys (bool, optional): Sort dictionary keys. Defaults to False._

**Args**: self, json


#### `update_screen()` (line 1789)
_Update the screen at a given offset.

Args:
    renderable (RenderableType): A Rich renderable.
    region (Region, optional): Region of screen to update, or None for entire screen. Defaults to None.
    x (int, optional): x offset. Defaults to 0.
    y (int, optional): y offset. Defaults to 0.

Raises:
    errors.NoAltScreen: If the Console isn't in alt screen mode._

**Args**: self, renderable


#### `update_screen_lines()` (line 1823)
_Update lines of the screen at a given offset.

Args:
    lines (List[List[Segment]]): Rendered lines (as produced by :meth:`~rich.Console.render_lines`).
    x (int, optional): x offset (column no). Defaults to 0.
    y (int, optional): y offset (column no). Defaults to 0.

Raises:
    errors.NoAltScreen: If the Console isn't in alt screen mode._

**Args**: self, lines, x, y


#### `print_exception()` (line 1843)
_Prints a rich render of the last exception and traceback.

Args:
    width (Optional[int], optional): Number of characters used to render code. Defaults to 100.
    extra_lines (int, optional): Additional lines of code to render. Defaults to 3.
    theme (str, optional): Override pygments theme used in traceback
    word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.
    show_locals (bool, optional): Enable display of local variables. Defaults to False.
    suppress (Iterable[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.
    max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100._

**Args**: self


#### `_caller_frame_info()` (line 1879)
_Get caller frame information.

Args:
    offset (int): the caller offset within the current frame stack.
    currentframe (Callable[[], Optional[FrameType]], optional): the callable to use to
        retrieve the current frame. Defaults to ``inspect.currentframe``.

Returns:
    Tuple[str, int, Dict[str, Any]]: A tuple containing the filename, the line number and
        the dictionary of local variables associated with the caller frame.

Raises:
    RuntimeError: If the stack offset is invalid._

**Args**: offset, currentframe


#### `log()` (line 1913)
_Log rich content to the terminal.

Args:
    objects (positional args): Objects to log to the terminal.
    sep (str, optional): String to write between print data. Defaults to " ".
    end (str, optional): String to write at end of print data. Defaults to "\\n".
    style (Union[str, Style], optional): A style to apply to output. Defaults to None.
    justify (str, optional): One of "left", "right", "center", or "full". Defaults to ``None``.
    emoji (Optional[bool], optional): Enable emoji code, or ``None`` to use console default. Defaults to None.
    markup (Optional[bool], optional): Enable markup, or ``None`` to use console default. Defaults to None.
    highlight (Optional[bool], optional): Enable automatic highlighting, or ``None`` to use console default. Defaults to None.
    log_locals (bool, optional): Boolean to enable logging of locals where ``log()``
        was called. Defaults to False.
    _stack_offset (int, optional): Offset of caller from end of call stack. Defaults to 1._

**Args**: self


#### `on_broken_pipe()` (line 1994)
_This function is called when a `BrokenPipeError` is raised.

This can occur when piping Textual output in Linux and macOS.
The default implementation is to exit the app, but you could implement
this method in a subclass to change the behavior.

See https://docs.python.org/3/library/signal.html#note-on-sigpipe for details._

**Args**: self


#### `_check_buffer()` (line 2008)
_Check if the buffer may be rendered. Render it if it can (e.g. Console.quiet is False)
Rendering is supported on Windows, Unix and Jupyter environments. For
legacy Windows consoles, the win32 API is called directly.
This method will also record what it renders if recording is enabled via Console.record._

**Args**: self


#### `_write_buffer()` (line 2023)
_Write the buffer to the output file._

**Args**: self


#### `_render_buffer()` (line 2096)
_Render buffered output, and clear buffer._

**Args**: self, buffer


#### `input()` (line 2120)
_Displays a prompt and waits for input from the user. The prompt may contain color / style.

It works in the same way as Python's builtin :func:`input` function and provides elaborate line editing and history features if Python's builtin :mod:`readline` module is previously loaded.

Args:
    prompt (Union[str, Text]): Text to render in the prompt.
    markup (bool, optional): Enable console markup (requires a str prompt). Defaults to True.
    emoji (bool, optional): Enable emoji (requires a str prompt). Defaults to True.
    password: (bool, optional): Hide typed text. Defaults to False.
    stream: (TextIO, optional): Optional file to read input from (rather than stdin). Defaults to None.

Returns:
    str: Text read from stdin._

**Args**: self, prompt


#### `export_text()` (line 2154)
_Generate text from console contents (requires record=True argument in constructor).

Args:
    clear (bool, optional): Clear record buffer after exporting. Defaults to ``True``.
    styles (bool, optional): If ``True``, ansi escape codes will be included. ``False`` for plain text.
        Defaults to ``False``.

Returns:
    str: String containing console contents._

**Args**: self


#### `save_text()` (line 2186)
_Generate text from console and save to a given location (requires record=True argument in constructor).

Args:
    path (str): Path to write text files.
    clear (bool, optional): Clear record buffer after exporting. Defaults to ``True``.
    styles (bool, optional): If ``True``, ansi style codes will be included. ``False`` for plain text.
        Defaults to ``False``._

**Args**: self, path


#### `export_html()` (line 2200)
_Generate HTML from console contents (requires record=True argument in constructor).

Args:
    theme (TerminalTheme, optional): TerminalTheme object containing console colors.
    clear (bool, optional): Clear record buffer after exporting. Defaults to ``True``.
    code_format (str, optional): Format string to render HTML. In addition to '{foreground}',
        '{background}', and '{code}', should contain '{stylesheet}' if inline_styles is ``False``.
    inline_styles (bool, optional): If ``True`` styles will be inlined in to spans, which makes files
        larger but easier to cut and paste markup. If ``False``, styles will be embedded in a style tag.
        Defaults to False.

Returns:
    str: String containing console contents as HTML._

**Args**: self


#### `save_html()` (line 2275)
_Generate HTML from console contents and write to a file (requires record=True argument in constructor).

Args:
    path (str): Path to write html file.
    theme (TerminalTheme, optional): TerminalTheme object containing console colors.
    clear (bool, optional): Clear record buffer after exporting. Defaults to ``True``.
    code_format (str, optional): Format string to render HTML. In addition to '{foreground}',
        '{background}', and '{code}', should contain '{stylesheet}' if inline_styles is ``False``.
    inline_styles (bool, optional): If ``True`` styles will be inlined in to spans, which makes files
        larger but easier to cut and paste markup. If ``False``, styles will be embedded in a style tag.
        Defaults to False._

**Args**: self, path


#### `export_svg()` (line 2306)
_Generate an SVG from the console contents (requires record=True in Console constructor).

Args:
    title (str, optional): The title of the tab in the output image
    theme (TerminalTheme, optional): The ``TerminalTheme`` object to use to style the terminal
    clear (bool, optional): Clear record buffer after exporting. Defaults to ``True``
    code_format (str, optional): Format string used to generate the SVG. Rich will inject a number of variables
        into the string in order to form the final SVG output. The default template used and the variables
        injected by Rich can be found by inspecting the ``console.CONSOLE_SVG_FORMAT`` variable.
    font_aspect_ratio (float, optional): The width to height ratio of the font used in the ``code_format``
        string. Defaults to 0.61, which is the width to height ratio of Fira Code (the default font).
        If you aren't specifying a different font inside ``code_format``, you probably don't need this.
    unique_id (str, optional): unique id that is used as the prefix for various elements (CSS styles, node
        ids). If not set, this defaults to a computed value based on the recorded content._

**Args**: self


#### `get_svg_style()` (line 2337)
_Convert a Style to CSS rules for SVG._

**Args**: style


#### `escape_text()` (line 2397)
_HTML escape text and replace spaces with nbsp._

**Args**: text


#### `make_tag()` (line 2401)
_Make a tag from name, content, and attributes._

**Args**: name, content


#### `stringify()` (line 2406)
**Args**: value


#### `save_svg()` (line 2557)
_Generate an SVG file from the console contents (requires record=True in Console constructor).

Args:
    path (str): The path to write the SVG to.
    title (str, optional): The title of the tab in the output image
    theme (TerminalTheme, optional): The ``TerminalTheme`` object to use to style the terminal
    clear (bool, optional): Clear record buffer after exporting. Defaults to ``True``
    code_format (str, optional): Format string used to generate the SVG. Rich will inject a number of variables
        into the string in order to form the final SVG output. The default template used and the variables
        injected by Rich can be found by inspecting the ``console.CONSOLE_SVG_FORMAT`` variable.
    font_aspect_ratio (float, optional): The width to height ratio of the font used in the ``code_format``
        string. Defaults to 0.61, which is the width to height ratio of Fira Code (the default font).
        If you aren't specifying a different font inside ``code_format``, you probably don't need this.
    unique_id (str, optional): unique id that is used as the prefix for various elements (CSS styles, node
        ids). If not set, this defaults to a computed value based on the recorded content._

**Args**: self, path


#### `_svg_hash()` (line 2596)
_Returns a unique hash for the given SVG main code.

Args:
    svg_main_code (str): The content we're going to inject in the SVG envelope.

Returns:
    str: a hash of the given content_

**Args**: svg_main_code


### venv_new\Lib\site-packages\pip\_vendor\rich\constrain.py

#### `__init__()` (line 18)
**Args**: self, renderable, width


#### `__rich_console__()` (line 22)
**Args**: self, console, options


#### `__rich_measure__()` (line 31)
**Args**: self, console, options


### venv_new\Lib\site-packages\pip\_vendor\rich\containers.py

#### `__init__()` (line 33)
**Args**: self, renderables


#### `__rich_console__()` (line 40)
_Console render method to insert line-breaks._

**Args**: self, console, options


#### `__rich_measure__()` (line 46)
**Args**: self, console, options


#### `append()` (line 59)
**Args**: self, renderable


#### `__iter__()` (line 62)
**Args**: self


#### `__init__()` (line 69)
**Args**: self, lines


#### `__repr__()` (line 72)
**Args**: self


#### `__iter__()` (line 75)
**Args**: self


#### `__getitem__()` (line 79)
**Args**: self, index


#### `__getitem__()` (line 83)
**Args**: self, index


#### `__getitem__()` (line 86)
**Args**: self, index


#### `__setitem__()` (line 89)
**Args**: self, index, value


#### `__len__()` (line 93)
**Args**: self


#### `__rich_console__()` (line 96)
_Console render method to insert line-breaks._

**Args**: self, console, options


#### `append()` (line 102)
**Args**: self, line


#### `extend()` (line 105)
**Args**: self, lines


#### `pop()` (line 108)
**Args**: self, index


#### `justify()` (line 111)
_Justify and overflow text to a given width.

Args:
    console (Console): Console instance.
    width (int): Number of cells available per line.
    justify (str, optional): Default justify method for text: "left", "center", "full" or "right". Defaults to "left".
    overflow (str, optional): Default overflow for text: "crop", "fold", or "ellipsis". Defaults to "fold"._

**Args**: self, console, width, justify, overflow


### venv_new\Lib\site-packages\pip\_vendor\rich\control.py

#### `__init__()` (line 64)
**Args**: self


#### `bell()` (line 75)
_Ring the 'bell'._

**Args**: cls


#### `home()` (line 80)
_Move cursor to 'home' position._

**Args**: cls


#### `move()` (line 85)
_Move cursor relative to current position.

Args:
    x (int): X offset.
    y (int): Y offset.

Returns:
    ~Control: Control object._

**Args**: cls, x, y


#### `get_codes()` (line 97)

#### `move_to_column()` (line 114)
_Move to the given column, optionally add offset to row.

Returns:
    x (int): absolute x (column)
    y (int): optional y offset (row)

Returns:
    ~Control: Control object._

**Args**: cls, x, y


#### `move_to()` (line 138)
_Move cursor to absolute position.

Args:
    x (int): x offset (column)
    y (int): y offset (row)

Returns:
    ~Control: Control object._

**Args**: cls, x, y


#### `clear()` (line 151)
_Clear the screen._

**Args**: cls


#### `show_cursor()` (line 156)
_Show or hide the cursor._

**Args**: cls, show


#### `alt_screen()` (line 161)
_Enable or disable alt screen._

**Args**: cls, enable


#### `title()` (line 169)
_Set the terminal window title

Args:
    title (str): The new terminal window title_

**Args**: cls, title


#### `__str__()` (line 177)
**Args**: self


#### `__rich_console__()` (line 180)
**Args**: self, console, options


#### `strip_control_codes()` (line 187)
_Remove control codes from text.

Args:
    text (str): A string possibly contain control codes.

Returns:
    str: String with control codes removed._

**Args**: text, _translate_table


#### `escape_control_codes()` (line 201)
_Replace control codes with their "escaped" equivalent in the given text.
(e.g. "" becomes "\b")

Args:
    text (str): A string possibly containing control codes.

Returns:
    str: String with control codes replaced with their escaped version._

**Args**: text, _translate_table


### venv_new\Lib\site-packages\pip\_vendor\rich\diagnose.py

#### `report()` (line 10)
_Print a report to the terminal with debugging information_


### venv_new\Lib\site-packages\pip\_vendor\rich\emoji.py

#### `__init__()` (line 32)
_A single emoji character.

Args:
    name (str): Name of emoji.
    style (Union[str, Style], optional): Optional style. Defaults to None.

Raises:
    NoEmoji: If the emoji doesn't exist._

**Args**: self, name, style, variant


#### `replace()` (line 58)
_Replace emoji markup with corresponding unicode characters.

Args:
    text (str): A string with emojis codes, e.g. "Hello :smiley:!"

Returns:
    str: A string with emoji codes replaces with actual emoji._

**Args**: cls, text


#### `__repr__()` (line 69)
**Args**: self


#### `__str__()` (line 72)
**Args**: self


#### `__rich_console__()` (line 75)
**Args**: self, console, options


### venv_new\Lib\site-packages\pip\_vendor\rich\file_proxy.py

#### `__init__()` (line 14)
**Args**: self, console, file


#### `rich_proxied_file()` (line 21)
_Get proxied file._

**Args**: self


#### `__getattr__()` (line 25)
**Args**: self, name


#### `write()` (line 28)
**Args**: self, text


#### `flush()` (line 50)
**Args**: self


#### `fileno()` (line 56)
**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\rich\filesize.py

#### `_to_str()` (line 18)
**Args**: size, suffixes, base


#### `pick_unit_and_suffix()` (line 43)
_Pick a suffix and base for the given size._

**Args**: size, suffixes, base


#### `decimal()` (line 52)
_Convert a filesize in to a string (powers of 1000, SI prefixes).

In this convention, ``1000 B = 1 kB``.

This is typically the format used to advertise the storage
capacity of USB flash drives and the like (*256 MB* meaning
actually a storage capacity of more than *256 000 000 B*),
or used by **Mac OS X** since v10.6 to report file sizes.

Arguments:
    int (size): A file size.
    int (precision): The number of decimal places to include (default = 1).
    str (separator): The string to separate the value from the units (default = " ").

Returns:
    `str`: A string containing a abbreviated file size and units.

Example:
    >>> filesize.decimal(30000)
    '30.0 kB'
    >>> filesize.decimal(30000, precision=2, separator="")
    '30.00kB'_

**Args**: size


### venv_new\Lib\site-packages\pip\_vendor\rich\highlighter.py

#### `_combine_regex()` (line 8)
_Combine a number of regexes in to a single regex.

Returns:
    str: New regex with all regexes ORed together._


#### `__call__()` (line 20)
_Highlight a str or Text instance.

Args:
    text (Union[str, ~Text]): Text to highlight.

Raises:
    TypeError: If not called with text or str.

Returns:
    Text: A test instance with highlighting applied._

**Args**: self, text


#### `highlight()` (line 42)
_Apply highlighting in place to text.

Args:
    text (~Text): A text object highlight._

**Args**: self, text


#### `highlight()` (line 57)
_Nothing to do_

**Args**: self, text


#### `highlight()` (line 67)
_Highlight :class:`rich.text.Text` using regular expressions.

Args:
    text (~Text): Text to highlighted._

**Args**: self, text


#### `highlight()` (line 123)
**Args**: self, text


### venv_new\Lib\site-packages\pip\_vendor\rich\json.py

#### `__init__()` (line 25)
**Args**: self, json, indent, highlight, skip_keys, ensure_ascii, check_circular, allow_nan, default, sort_keys


#### `from_data()` (line 54)
_Encodes a JSON object from arbitrary data.

Args:
    data (Any): An object that may be encoded in to JSON
    indent (Union[None, int, str], optional): Number of characters to indent by. Defaults to 2.
    highlight (bool, optional): Enable highlighting. Defaults to True.
    default (Callable, optional): Optional callable which will be called for objects that cannot be serialized. Defaults to None.
    skip_keys (bool, optional): Skip keys not of a basic type. Defaults to False.
    ensure_ascii (bool, optional): Escape all non-ascii characters. Defaults to False.
    check_circular (bool, optional): Check for circular references. Defaults to True.
    allow_nan (bool, optional): Allow NaN and Infinity values. Defaults to True.
    default (Callable, optional): A callable that converts values that can not be encoded
        in to something that can be JSON encoded. Defaults to None.
    sort_keys (bool, optional): Sort dictionary keys. Defaults to False.

Returns:
    JSON: New JSON object from the given data._

**Args**: cls, data, indent, highlight, skip_keys, ensure_ascii, check_circular, allow_nan, default, sort_keys


#### `__rich__()` (line 101)
**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\rich\jupyter.py

#### `__init__()` (line 21)
**Args**: self, html, text


#### `_repr_mimebundle_()` (line 25)
**Args**: self, include, exclude


#### `_repr_mimebundle_()` (line 41)
**Args**: self, include, exclude


#### `_render_segments()` (line 59)
**Args**: segments


#### `escape()` (line 60)
_Escape html._

**Args**: text


#### `display()` (line 84)
_Render segments to Jupyter._

**Args**: segments, text


#### `print()` (line 98)
_Proxy for Console print._


### venv_new\Lib\site-packages\pip\_vendor\rich\layout.py

#### `__init__()` (line 56)
**Args**: self, layout, style


#### `__rich_console__()` (line 60)
**Args**: self, console, options


#### `get_tree_icon()` (line 86)
_Get the icon (emoji) used in layout.tree_

**Args**: self


#### `divide()` (line 90)
_Divide a region amongst several child layouts.

Args:
    children (Sequence(Layout)): A number of child layouts.
    region (Region): A rectangular region to divide._

**Args**: self, children, region


#### `get_tree_icon()` (line 106)
**Args**: self


#### `divide()` (line 109)
**Args**: self, children, region


#### `get_tree_icon()` (line 126)
**Args**: self


#### `divide()` (line 129)
**Args**: self, children, region


#### `__init__()` (line 156)
**Args**: self, renderable


#### `__rich_repr__()` (line 177)
**Args**: self


#### `renderable()` (line 184)
_Layout renderable._

**Args**: self


#### `children()` (line 189)
_Gets (visible) layout children._

**Args**: self


#### `map()` (line 194)
_Get a map of the last render._

**Args**: self


#### `get()` (line 198)
_Get a named layout, or None if it doesn't exist.

Args:
    name (str): Name of layout.

Returns:
    Optional[Layout]: Layout instance or None if no layout was found._

**Args**: self, name


#### `__getitem__()` (line 216)
**Args**: self, name


#### `tree()` (line 223)
_Get a tree renderable to show layout structure._

**Args**: self


#### `summary()` (line 229)
**Args**: layout


#### `recurse()` (line 248)
**Args**: tree, layout


#### `split()` (line 261)
_Split the layout in to multiple sub-layouts.

Args:
    *layouts (Layout): Positional arguments should be (sub) Layout instances.
    splitter (Union[Splitter, str]): Splitter instance or name of splitter._

**Args**: self


#### `add_split()` (line 286)
_Add a new layout(s) to existing split.

Args:
    *layouts (Union[Layout, RenderableType]): Positional arguments should be renderables or (sub) Layout instances._

**Args**: self


#### `split_row()` (line 299)
_Split the layout in to a row (layouts side by side).

Args:
    *layouts (Layout): Positional arguments should be (sub) Layout instances._

**Args**: self


#### `split_column()` (line 307)
_Split the layout in to a column (layouts stacked on top of each other).

Args:
    *layouts (Layout): Positional arguments should be (sub) Layout instances._

**Args**: self


#### `unsplit()` (line 315)
_Reset splits to initial state._

**Args**: self


#### `update()` (line 319)
_Update renderable.

Args:
    renderable (RenderableType): New renderable object._

**Args**: self, renderable


#### `refresh_screen()` (line 328)
_Refresh a sub-layout.

Args:
    console (Console): Console instance where Layout is to be rendered.
    layout_name (str): Name of layout._

**Args**: self, console, layout_name


#### `_make_region_map()` (line 345)
_Create a dict that maps layout on to Region._

**Args**: self, width, height


#### `render()` (line 366)
_Render the sub_layouts.

Args:
    console (Console): Console instance.
    options (ConsoleOptions): Console options.

Returns:
    RenderMap: A dict that maps Layout on to a tuple of Region, lines_

**Args**: self, console, options


#### `__rich_console__()` (line 395)
**Args**: self, console, options


### venv_new\Lib\site-packages\pip\_vendor\rich\live.py

#### `__init__()` (line 19)
**Args**: self, live, refresh_per_second


#### `stop()` (line 25)
**Args**: self


#### `run()` (line 28)
**Args**: self


#### `__init__()` (line 51)
**Args**: self, renderable


#### `is_started()` (line 92)
_Check if live display has been started._

**Args**: self


#### `get_renderable()` (line 96)
**Args**: self


#### `start()` (line 104)
_Start live rendering display.

Args:
    refresh (bool, optional): Also refresh. Defaults to False._

**Args**: self, refresh


#### `stop()` (line 134)
_Stop live rendering display._

**Args**: self


#### `__enter__()` (line 165)
**Args**: self


#### `__exit__()` (line 169)
**Args**: self, exc_type, exc_val, exc_tb


#### `_enable_redirect_io()` (line 177)
_Enable redirecting of stdout / stderr._

**Args**: self


#### `_disable_redirect_io()` (line 187)
_Disable redirecting of stdout / stderr._

**Args**: self


#### `renderable()` (line 197)
_Get the renderable that is being displayed

Returns:
    RenderableType: Displayed renderable._

**Args**: self


#### `update()` (line 206)
_Update the renderable that is being displayed

Args:
    renderable (RenderableType): New renderable to use.
    refresh (bool, optional): Refresh the display. Defaults to False._

**Args**: self, renderable


#### `refresh()` (line 220)
_Update the display of the Live Render._

**Args**: self


#### `process_renderables()` (line 249)
_Process renderables to restore cursor and display progress._

**Args**: self, renderables


### venv_new\Lib\site-packages\pip\_vendor\rich\live_render.py

#### `__init__()` (line 28)
**Args**: self, renderable, style, vertical_overflow


#### `set_renderable()` (line 39)
_Set a new renderable.

Args:
    renderable (RenderableType): Any renderable object, including str._

**Args**: self, renderable


#### `position_cursor()` (line 47)
_Get control codes to move cursor to beginning of live render.

Returns:
    Control: A control instance that may be printed._

**Args**: self


#### `restore_cursor()` (line 68)
_Get control codes to clear the render and restore the cursor to its previous position.

Returns:
    Control: A Control instance that may be printed._

**Args**: self


#### `__rich_console__()` (line 82)
**Args**: self, console, options


### venv_new\Lib\site-packages\pip\_vendor\rich\logging.py

#### `__init__()` (line 65)
**Args**: self, level, console


#### `get_level_text()` (line 117)
_Get the level name from the record.

Args:
    record (LogRecord): LogRecord instance.

Returns:
    Text: A tuple of the style and level name._

**Args**: self, record


#### `emit()` (line 132)
_Invoked by logging._

**Args**: self, record


#### `render_message()` (line 182)
_Render message text in to Text.

Args:
    record (LogRecord): logging Record.
    message (str): String containing log message.

Returns:
    ConsoleRenderable: Renderable to display log message._

**Args**: self, record, message


#### `render()` (line 207)
_Render log for display.

Args:
    record (LogRecord): logging Record.
    traceback (Optional[Traceback]): Traceback instance or None for no Traceback.
    message_renderable (ConsoleRenderable): Renderable (typically Text) containing log message contents.

Returns:
    ConsoleRenderable: Renderable to display log._

**Args**: self


#### `divide()` (line 283)

### venv_new\Lib\site-packages\pip\_vendor\rich\markup.py

#### `__str__()` (line 28)
**Args**: self


#### `markup()` (line 34)
_Get the string representation of this tag._

**Args**: self


#### `escape()` (line 48)
_Escapes text so that it won't be interpreted as markup.

Args:
    markup (str): Content to be inserted in to markup.

Returns:
    str: Markup with square brackets escaped._

**Args**: markup, _escape


#### `escape_backslashes()` (line 61)
_Called by re.sub replace matches._

**Args**: match


#### `_parse()` (line 73)
_Parse markup in to an iterable of tuples of (position, text, tag).

Args:
    markup (str): A string containing console markup_

**Args**: markup


#### `render()` (line 106)
_Render console markup in to a Text instance.

Args:
    markup (str): A string containing console markup.
    style: (Union[str, Style]): The style to use.
    emoji (bool, optional): Also render emoji code. Defaults to True.
    emoji_variant (str, optional): Optional emoji variant, either "text" or "emoji". Defaults to None.


Raises:
    MarkupError: If there is a syntax error in the markup.

Returns:
    Text: A test instance._

**Args**: markup, style, emoji, emoji_variant


#### `pop_style()` (line 146)
_Pop tag matching given style name._

**Args**: style_name


### venv_new\Lib\site-packages\pip\_vendor\rich\measure.py

#### `span()` (line 20)
_Get difference between maximum and minimum._

**Args**: self


#### `normalize()` (line 24)
_Get measurement that ensures that minimum <= maximum and minimum >= 0

Returns:
    Measurement: A normalized measurement._

**Args**: self


#### `with_maximum()` (line 34)
_Get a RenderableWith where the widths are <= width.

Args:
    width (int): Maximum desired width.

Returns:
    Measurement: New Measurement object._

**Args**: self, width


#### `with_minimum()` (line 46)
_Get a RenderableWith where the widths are >= width.

Args:
    width (int): Minimum desired width.

Returns:
    Measurement: New Measurement object._

**Args**: self, width


#### `clamp()` (line 59)
_Clamp a measurement within the specified range.

Args:
    min_width (int): Minimum desired width, or ``None`` for no minimum. Defaults to None.
    max_width (int): Maximum desired width, or ``None`` for no maximum. Defaults to None.

Returns:
    Measurement: New Measurement object._

**Args**: self, min_width, max_width


#### `get()` (line 79)
_Get a measurement for a renderable.

Args:
    console (~rich.console.Console): Console instance.
    options (~rich.console.ConsoleOptions): Console options.
    renderable (RenderableType): An object that may be rendered with Rich.

Raises:
    errors.NotRenderableError: If the object is not renderable.

Returns:
    Measurement: Measurement object containing range of character widths required to render the object._

**Args**: cls, console, options, renderable


#### `measure_renderables()` (line 125)
_Get a measurement that would fit a number of renderables.

Args:
    console (~rich.console.Console): Console instance.
    options (~rich.console.ConsoleOptions): Console options.
    renderables (Iterable[RenderableType]): One or more renderable objects.

Returns:
    Measurement: Measurement object containing range of character widths required to
        contain all given renderables._

**Args**: console, options, renderables


### venv_new\Lib\site-packages\pip\_vendor\rich\padding.py

#### `__init__()` (line 33)
**Args**: self, renderable, pad


#### `indent()` (line 47)
_Make padding instance to render an indent.

Args:
    renderable (RenderableType): String or other renderable.
    level (int): Number of characters to indent.

Returns:
    Padding: A Padding instance._

**Args**: cls, renderable, level


#### `unpack()` (line 61)
_Unpack padding specified in CSS style._

**Args**: pad


#### `__repr__()` (line 76)
**Args**: self


#### `__rich_console__()` (line 79)
**Args**: self, console, options


#### `__rich_measure__()` (line 125)
**Args**: self, console, options


### venv_new\Lib\site-packages\pip\_vendor\rich\pager.py

#### `show()` (line 9)
_Show content in pager.

Args:
    content (str): Content to be displayed._

**Args**: self, content


#### `_pager()` (line 20)
**Args**: self, content


#### `show()` (line 23)
_Use the same pager used by pydoc._

**Args**: self, content


### venv_new\Lib\site-packages\pip\_vendor\rich\palette.py

#### `__init__()` (line 14)
**Args**: self, colors


#### `__getitem__()` (line 17)
**Args**: self, number


#### `__rich__()` (line 20)
**Args**: self


#### `match()` (line 45)
_Find a color from a palette that most closely matches a given color.

Args:
    color (Tuple[int, int, int]): RGB components in range 0 > 255.

Returns:
    int: Index of closes matching color._

**Args**: self, color


#### `get_color_distance()` (line 58)
_Get the distance to a color._

**Args**: index


#### `__rich_console__()` (line 84)
**Args**: self, console, options


### venv_new\Lib\site-packages\pip\_vendor\rich\panel.py

#### `__init__()` (line 40)
**Args**: self, renderable, box


#### `fit()` (line 74)
_An alternative constructor that sets expand=False._

**Args**: cls, renderable, box


#### `_title()` (line 110)
**Args**: self


#### `_subtitle()` (line 126)
**Args**: self


#### `__rich_console__()` (line 141)
**Args**: self, console, options


#### `align_text()` (line 160)
_Gets new aligned text.

Args:
    text (Text): Title or subtitle text.
    width (int): Desired width.
    align (str): Alignment.
    character (str): Character for alignment.
    style (Style): Border style

Returns:
    Text: New text instance_

**Args**: text, width, align, character, style


#### `__rich_measure__()` (line 278)
**Args**: self, console, options


### venv_new\Lib\site-packages\pip\_vendor\rich\pretty.py

#### `_is_attr_object()` (line 60)
_Check if an object was created with attrs module._

**Args**: obj


#### `_get_attr_fields()` (line 65)
_Get fields for an attrs object._

**Args**: obj


#### `_is_dataclass_repr()` (line 70)
_Check if an instance of a dataclass contains the default repr.

Args:
    obj (object): A dataclass instance.

Returns:
    bool: True if the default repr is used, False if there is a custom repr._

**Args**: obj


#### `_has_default_namedtuple_repr()` (line 93)
_Check if an instance of namedtuple contains the default repr

Args:
    obj (object): A namedtuple

Returns:
    bool: True if the default repr is used, False if there's a custom repr._

**Args**: obj


#### `_ipy_display_hook()` (line 113)
**Args**: value, console, overflow, crop, indent_guides, max_length, max_string, max_depth, expand_all


#### `_safe_isinstance()` (line 161)
_isinstance can fail in rare cases, for example types with no __class___

**Args**: obj, class_or_tuple


#### `install()` (line 171)
_Install automatic pretty printing in the Python REPL.

Args:
    console (Console, optional): Console instance or ``None`` to use global console. Defaults to None.
    overflow (Optional[OverflowMethod], optional): Overflow method. Defaults to "ignore".
    crop (Optional[bool], optional): Enable cropping of long lines. Defaults to False.
    indent_guides (bool, optional): Enable indentation guides. Defaults to False.
    max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
        Defaults to None.
    max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to None.
    max_depth (int, optional): Maximum depth of nested data structures, or None for no maximum. Defaults to None.
    expand_all (bool, optional): Expand all containers. Defaults to False.
    max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100._

**Args**: console, overflow, crop, indent_guides, max_length, max_string, max_depth, expand_all


#### `display_hook()` (line 200)
_Replacement sys.displayhook which prettifies objects with Rich._

**Args**: value


#### `__call__()` (line 233)
**Args**: self, value


#### `__init__()` (line 273)
**Args**: self, _object, highlighter


#### `__rich_console__()` (line 304)
**Args**: self, console, options


#### `__rich_measure__()` (line 339)
**Args**: self, console, options


#### `_get_braces_for_defaultdict()` (line 357)
**Args**: _object


#### `_get_braces_for_deque()` (line 365)
**Args**: _object


#### `_get_braces_for_array()` (line 375)
**Args**: _object


#### `is_expandable()` (line 398)
_Check if an object may be expanded by pretty print._

**Args**: obj


#### `iter_tokens()` (line 424)
_Generate tokens for this node._

**Args**: self


#### `check_length()` (line 446)
_Check the length fits within a limit.

Args:
    start_length (int): Starting length of the line (indent, prefix, suffix).
    max_length (int): Maximum length.

Returns:
    bool: True if the node can be rendered within max length, otherwise False._

**Args**: self, start_length, max_length


#### `__str__()` (line 463)
**Args**: self


#### `render()` (line 467)
_Render the node to a pretty repr.

Args:
    max_width (int, optional): Maximum width of the repr. Defaults to 80.
    indent_size (int, optional): Size of indents. Defaults to 4.
    expand_all (bool, optional): Expand all levels. Defaults to False.

Returns:
    str: A repr string of the original object._

**Args**: self, max_width, indent_size, expand_all


#### `expandable()` (line 507)
_Check if the line may be expanded._

**Args**: self


#### `check_length()` (line 511)
_Check this line fits within a given number of cells._

**Args**: self, max_length


#### `expand()` (line 519)
_Expand this line by adding children on their own line._

**Args**: self, indent_size


#### `__str__()` (line 552)
**Args**: self


#### `_is_namedtuple()` (line 561)
_Checks if an object is most likely a namedtuple. It is possible
to craft an object that passes this check and isn't a namedtuple, but
there is only a minuscule chance of this happening unintentionally.

Args:
    obj (Any): The object to test

Returns:
    bool: True if the object is a namedtuple. False otherwise._

**Args**: obj


#### `traverse()` (line 580)
_Traverse object and generate a tree.

Args:
    _object (Any): Object to be traversed.
    max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
        Defaults to None.
    max_string (int, optional): Maximum length of string before truncating, or None to disable truncating.
        Defaults to None.
    max_depth (int, optional): Maximum depth of data structures, or None for no maximum.
        Defaults to None.

Returns:
    Node: The root of a tree structure which can be used to render a pretty repr._

**Args**: _object, max_length, max_string, max_depth


#### `to_repr()` (line 601)
_Get repr string for an object, but catch errors._

**Args**: obj


#### `_traverse()` (line 621)
_Walk the object depth first._

**Args**: obj, root, depth


#### `iter_rich_args()` (line 633)
**Args**: rich_args


#### `iter_attrs()` (line 731)
_Iterate over attr fields and values._


#### `pretty_repr()` (line 878)
_Prettify repr string by expanding on to new lines to fit within a given width.

Args:
    _object (Any): Object to repr.
    max_width (int, optional): Desired maximum width of repr string. Defaults to 80.
    indent_size (int, optional): Number of spaces to indent. Defaults to 4.
    max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
        Defaults to None.
    max_string (int, optional): Maximum length of string before truncating, or None to disable truncating.
        Defaults to None.
    max_depth (int, optional): Maximum depth of nested data structure, or None for no depth.
        Defaults to None.
    expand_all (bool, optional): Expand all containers regardless of available width. Defaults to False.

Returns:
    str: A possibly multi-line representation of the object._

**Args**: _object


#### `pprint()` (line 918)
_A convenience function for pretty printing.

Args:
    _object (Any): Object to pretty print.
    console (Console, optional): Console instance, or None to use default. Defaults to None.
    max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
        Defaults to None.
    max_string (int, optional): Maximum length of strings before truncating, or None to disable. Defaults to None.
    max_depth (int, optional): Maximum depth for nested data structures, or None for unlimited depth. Defaults to None.
    indent_guides (bool, optional): Enable indentation guides. Defaults to True.
    expand_all (bool, optional): Expand all containers. Defaults to False._

**Args**: _object


#### `__repr__()` (line 958)
**Args**: self


#### `__repr__()` (line 1013)
**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\rich\progress.py

#### `__init__()` (line 71)
**Args**: self, progress, task_id, update_period


#### `run()` (line 80)
**Args**: self


#### `__enter__()` (line 94)
**Args**: self


#### `__exit__()` (line 98)
**Args**: self, exc_type, exc_val, exc_tb


#### `track()` (line 108)
_Track progress by iterating over a sequence.

Args:
    sequence (Iterable[ProgressType]): A sequence (must support "len") you wish to iterate over.
    description (str, optional): Description of task show next to progress bar. Defaults to "Working".
    total: (float, optional): Total number of steps. Default is len(sequence).
    completed (int, optional): Number of steps completed so far. Defaults to 0.
    auto_refresh (bool, optional): Automatic refresh, disable to force a refresh after each iteration. Default is True.
    transient: (bool, optional): Clear the progress on exit. Defaults to False.
    console (Console, optional): Console to write to. Default creates internal Console instance.
    refresh_per_second (float): Number of times per second to refresh the progress information. Defaults to 10.
    style (StyleType, optional): Style for the bar background. Defaults to "bar.back".
    complete_style (StyleType, optional): Style for the completed bar. Defaults to "bar.complete".
    finished_style (StyleType, optional): Style for a finished bar. Defaults to "bar.finished".
    pulse_style (StyleType, optional): Style for pulsing bars. Defaults to "bar.pulse".
    update_period (float, optional): Minimum time (in seconds) between calls to update(). Defaults to 0.1.
    disable (bool, optional): Disable display of progress.
    show_speed (bool, optional): Show speed if total isn't known. Defaults to True.
Returns:
    Iterable[ProgressType]: An iterable of the values in the sequence._

**Args**: sequence, description, total, completed, auto_refresh, console, transient, get_time, refresh_per_second, style, complete_style, finished_style, pulse_style, update_period, disable, show_speed


#### `__init__()` (line 187)
**Args**: self, handle, progress, task, close_handle


#### `__enter__()` (line 200)
**Args**: self


#### `__exit__()` (line 204)
**Args**: self, exc_type, exc_val, exc_tb


#### `__iter__()` (line 212)
**Args**: self


#### `__next__()` (line 215)
**Args**: self


#### `closed()` (line 221)
**Args**: self


#### `fileno()` (line 224)
**Args**: self


#### `isatty()` (line 227)
**Args**: self


#### `mode()` (line 231)
**Args**: self


#### `name()` (line 235)
**Args**: self


#### `readable()` (line 238)
**Args**: self


#### `seekable()` (line 241)
**Args**: self


#### `writable()` (line 244)
**Args**: self


#### `read()` (line 247)
**Args**: self, size


#### `readinto()` (line 252)
**Args**: self, b


#### `readline()` (line 257)
**Args**: self, size


#### `readlines()` (line 262)
**Args**: self, hint


#### `close()` (line 267)
**Args**: self


#### `seek()` (line 272)
**Args**: self, offset, whence


#### `tell()` (line 277)
**Args**: self


#### `write()` (line 280)
**Args**: self, s


#### `writelines()` (line 283)
**Args**: self, lines


#### `__init__()` (line 290)
**Args**: self, progress, reader


#### `__enter__()` (line 294)
**Args**: self


#### `__exit__()` (line 298)
**Args**: self, exc_type, exc_val, exc_tb


#### `wrap_file()` (line 308)
_Read bytes from a file while tracking progress.

Args:
    file (Union[str, PathLike[str], BinaryIO]): The path to the file to read, or a file-like object in binary mode.
    total (int): Total number of bytes to read.
    description (str, optional): Description of task show next to progress bar. Defaults to "Reading".
    auto_refresh (bool, optional): Automatic refresh, disable to force a refresh after each iteration. Default is True.
    transient: (bool, optional): Clear the progress on exit. Defaults to False.
    console (Console, optional): Console to write to. Default creates internal Console instance.
    refresh_per_second (float): Number of times per second to refresh the progress information. Defaults to 10.
    style (StyleType, optional): Style for the bar background. Defaults to "bar.back".
    complete_style (StyleType, optional): Style for the completed bar. Defaults to "bar.complete".
    finished_style (StyleType, optional): Style for a finished bar. Defaults to "bar.finished".
    pulse_style (StyleType, optional): Style for pulsing bars. Defaults to "bar.pulse".
    disable (bool, optional): Disable display of progress.
Returns:
    ContextManager[BinaryIO]: A context manager yielding a progress reader._

**Args**: file, total


#### `open()` (line 374)
**Args**: file, mode, buffering, encoding, errors, newline


#### `open()` (line 399)
**Args**: file, mode, buffering, encoding, errors, newline


#### `open()` (line 423)
_Read bytes from a file while tracking progress.

Args:
    path (Union[str, PathLike[str], BinaryIO]): The path to the file to read, or a file-like object in binary mode.
    mode (str): The mode to use to open the file. Only supports "r", "rb" or "rt".
    buffering (int): The buffering strategy to use, see :func:`io.open`.
    encoding (str, optional): The encoding to use when reading in text mode, see :func:`io.open`.
    errors (str, optional): The error handling strategy for decoding errors, see :func:`io.open`.
    newline (str, optional): The strategy for handling newlines in text mode, see :func:`io.open`
    total: (int, optional): Total number of bytes to read. Must be provided if reading from a file handle. Default for a path is os.stat(file).st_size.
    description (str, optional): Description of task show next to progress bar. Defaults to "Reading".
    auto_refresh (bool, optional): Automatic refresh, disable to force a refresh after each iteration. Default is True.
    transient: (bool, optional): Clear the progress on exit. Defaults to False.
    console (Console, optional): Console to write to. Default creates internal Console instance.
    refresh_per_second (float): Number of times per second to refresh the progress information. Defaults to 10.
    style (StyleType, optional): Style for the bar background. Defaults to "bar.back".
    complete_style (StyleType, optional): Style for the completed bar. Defaults to "bar.complete".
    finished_style (StyleType, optional): Style for a finished bar. Defaults to "bar.finished".
    pulse_style (StyleType, optional): Style for pulsing bars. Defaults to "bar.pulse".
    disable (bool, optional): Disable display of progress.
    encoding (str, optional): The encoding to use when reading in text mode.

Returns:
    ContextManager[BinaryIO]: A context manager yielding a progress reader._

**Args**: file, mode, buffering, encoding, errors, newline


#### `__init__()` (line 514)
**Args**: self, table_column


#### `get_table_column()` (line 519)
_Get a table column, used to build tasks table._

**Args**: self


#### `__call__()` (line 523)
_Called by the Progress object to return a renderable for the given task.

Args:
    task (Task): An object containing information regarding the task.

Returns:
    RenderableType: Anything renderable (including str)._

**Args**: self, task


#### `render()` (line 547)
_Should return a renderable object._

**Args**: self, task


#### `__init__()` (line 558)
**Args**: self, renderable


#### `render()` (line 564)
**Args**: self, task


#### `__init__()` (line 578)
**Args**: self, spinner_name, style, speed, finished_text, table_column


#### `set_spinner()` (line 594)
_Set a new spinner.

Args:
    spinner_name (str): Spinner name, see python -m rich.spinner.
    spinner_style (Optional[StyleType], optional): Spinner style. Defaults to "progress.spinner".
    speed (float, optional): Speed factor of spinner. Defaults to 1.0._

**Args**: self, spinner_name, spinner_style, speed


#### `render()` (line 609)
**Args**: self, task


#### `__init__()` (line 621)
**Args**: self, text_format, style, justify, markup, highlighter, table_column


#### `render()` (line 637)
**Args**: self, task


#### `__init__()` (line 659)
**Args**: self, bar_width, style, complete_style, finished_style, pulse_style, table_column


#### `render()` (line 675)
_Gets a progress bar widget for a task._

**Args**: self, task


#### `render()` (line 693)
_Show time elapsed._

**Args**: self, task


#### `__init__()` (line 716)
**Args**: self, text_format, text_format_no_percentage, style, justify, markup, highlighter, table_column, show_speed


#### `render_speed()` (line 739)
_Render the speed in iterations per second.

Args:
    task (Task): A Task object.

Returns:
    Text: Text object containing the task speed._

**Args**: cls, speed


#### `render()` (line 758)
**Args**: self, task


#### `__init__()` (line 785)
**Args**: self, compact, elapsed_when_finished, table_column


#### `render()` (line 795)
_Show time remaining._

**Args**: self, task


#### `render()` (line 825)
_Show data completed._

**Args**: self, task


#### `render()` (line 834)
_Show data completed._

**Args**: self, task


#### `__init__()` (line 852)
**Args**: self, separator, table_column


#### `render()` (line 856)
_Show completed/total._

**Args**: self, task


#### `__init__()` (line 874)
**Args**: self, binary_units, table_column


#### `render()` (line 880)
_Calculate common unit for completed and total._

**Args**: self, task


#### `render()` (line 919)
_Show data transfer speed._

**Args**: self, task


#### `get_time()` (line 985)
_float: Get the current time, in seconds._

**Args**: self


#### `started()` (line 990)
_bool: Check if the task as started._

**Args**: self


#### `remaining()` (line 995)
_Optional[float]: Get the number of steps remaining, if a non-None total was set._

**Args**: self


#### `elapsed()` (line 1002)
_Optional[float]: Time elapsed since task was started, or ``None`` if the task hasn't started._

**Args**: self


#### `finished()` (line 1011)
_Check if the task has finished._

**Args**: self


#### `percentage()` (line 1016)
_float: Get progress of task as a percentage. If a None total was set, returns 0_

**Args**: self


#### `speed()` (line 1025)
_Optional[float]: Get the estimated speed in steps per second._

**Args**: self


#### `time_remaining()` (line 1043)
_Optional[float]: Get estimated time to completion, or ``None`` if no data._

**Args**: self


#### `_reset()` (line 1056)
_Reset progress._

**Args**: self


#### `__init__()` (line 1079)
**Args**: self


#### `get_default_columns()` (line 1116)
_Get the default columns used for a new Progress instance:
   - a text column for the description (TextColumn)
   - the bar itself (BarColumn)
   - a text column showing completion percentage (TextColumn)
   - an estimated-time-remaining column (TimeRemainingColumn)
If the Progress instance is created without passing a columns argument,
the default columns defined here will be used.

You can also create a Progress instance using custom columns before
and/or after the defaults, as in this example:

    progress = Progress(
        SpinnerColumn(),
        *Progress.get_default_columns(),
        "Elapsed:",
        TimeElapsedColumn(),
    )

This code shows the creation of a Progress display, containing
a spinner to the left, the default columns, and a labeled elapsed
time column._

**Args**: cls


#### `console()` (line 1147)
**Args**: self


#### `tasks()` (line 1151)
_Get a list of Task instances._

**Args**: self


#### `task_ids()` (line 1157)
_A list of task IDs._

**Args**: self


#### `finished()` (line 1163)
_Check if all tasks have been completed._

**Args**: self


#### `start()` (line 1170)
_Start the progress display._

**Args**: self


#### `stop()` (line 1175)
_Stop the progress display._

**Args**: self


#### `__enter__()` (line 1181)
**Args**: self


#### `__exit__()` (line 1185)
**Args**: self, exc_type, exc_val, exc_tb


#### `track()` (line 1193)
_Track progress by iterating over a sequence.

Args:
    sequence (Sequence[ProgressType]): A sequence of values you want to iterate over and track progress.
    total: (float, optional): Total number of steps. Default is len(sequence).
    completed (int, optional): Number of steps completed so far. Defaults to 0.
    task_id: (TaskID): Task to track. Default is new task.
    description: (str, optional): Description of task, if new task is created.
    update_period (float, optional): Minimum time (in seconds) between calls to update(). Defaults to 0.1.

Returns:
    Iterable[ProgressType]: An iterable of values taken from the provided sequence._

**Args**: self, sequence, total, completed, task_id, description, update_period


#### `wrap_file()` (line 1236)
_Track progress file reading from a binary file.

Args:
    file (BinaryIO): A file-like object opened in binary mode.
    total (int, optional): Total number of bytes to read. This must be provided unless a task with a total is also given.
    task_id (TaskID): Task to track. Default is new task.
    description (str, optional): Description of task, if new task is created.

Returns:
    BinaryIO: A readable file-like object in binary mode.

Raises:
    ValueError: When no total value can be extracted from the arguments or the task._

**Args**: self, file, total


#### `open()` (line 1279)
**Args**: self, file, mode, buffering, encoding, errors, newline


#### `open()` (line 1295)
**Args**: self, file, mode, buffering, encoding, errors, newline


#### `open()` (line 1310)
_Track progress while reading from a binary file.

Args:
    path (Union[str, PathLike[str]]): The path to the file to read.
    mode (str): The mode to use to open the file. Only supports "r", "rb" or "rt".
    buffering (int): The buffering strategy to use, see :func:`io.open`.
    encoding (str, optional): The encoding to use when reading in text mode, see :func:`io.open`.
    errors (str, optional): The error handling strategy for decoding errors, see :func:`io.open`.
    newline (str, optional): The strategy for handling newlines in text mode, see :func:`io.open`.
    total (int, optional): Total number of bytes to read. If none given, os.stat(path).st_size is used.
    task_id (TaskID): Task to track. Default is new task.
    description (str, optional): Description of task, if new task is created.

Returns:
    BinaryIO: A readable file-like object in binary mode.

Raises:
    ValueError: When an invalid mode is given._

**Args**: self, file, mode, buffering, encoding, errors, newline


#### `start_task()` (line 1387)
_Start a task.

Starts a task (used when calculating elapsed time). You may need to call this manually,
if you called ``add_task`` with ``start=False``.

Args:
    task_id (TaskID): ID of task._

**Args**: self, task_id


#### `stop_task()` (line 1401)
_Stop a task.

This will freeze the elapsed time on the task.

Args:
    task_id (TaskID): ID of task._

**Args**: self, task_id


#### `update()` (line 1416)
_Update information associated with a task.

Args:
    task_id (TaskID): Task id (returned by add_task).
    total (float, optional): Updates task.total if not None.
    completed (float, optional): Updates task.completed if not None.
    advance (float, optional): Add a value to task.completed if not None.
    description (str, optional): Change task description if not None.
    visible (bool, optional): Set visible flag if not None.
    refresh (bool): Force a refresh of progress information. Default is False.
    **fields (Any): Additional data fields required for rendering._

**Args**: self, task_id


#### `reset()` (line 1477)
_Reset a task so completed is 0 and the clock is reset.

Args:
    task_id (TaskID): ID of task.
    start (bool, optional): Start the task after reset. Defaults to True.
    total (float, optional): New total steps in task, or None to use current total. Defaults to None.
    completed (int, optional): Number of steps completed. Defaults to 0.
    visible (bool, optional): Enable display of the task. Defaults to True.
    description (str, optional): Change task description if not None. Defaults to None.
    **fields (str): Additional data fields required for rendering._

**Args**: self, task_id


#### `advance()` (line 1516)
_Advance task by a number of steps.

Args:
    task_id (TaskID): ID of task.
    advance (float): Number of steps to advance. Default is 1._

**Args**: self, task_id, advance


#### `refresh()` (line 1546)
_Refresh (render) the progress information._

**Args**: self


#### `get_renderable()` (line 1551)
_Get a renderable for the progress display._

**Args**: self


#### `get_renderables()` (line 1556)
_Get a number of renderables for the progress display._

**Args**: self


#### `make_tasks_table()` (line 1561)
_Get a table to render the Progress display.

Args:
    tasks (Iterable[Task]): An iterable of Task instances, one per row of the table.

Returns:
    Table: A table instance._

**Args**: self, tasks


#### `__rich__()` (line 1594)
_Makes the Progress class itself renderable._

**Args**: self


#### `add_task()` (line 1599)
_Add a new 'task' to the Progress display.

Args:
    description (str): A description of the task.
    start (bool, optional): Start the task immediately (to calculate elapsed time). If set to False,
        you will need to call `start` manually. Defaults to True.
    total (float, optional): Number of total steps in the progress if known.
        Set to None to render a pulsing animation. Defaults to 100.
    completed (int, optional): Number of steps completed so far. Defaults to 0.
    visible (bool, optional): Enable display of the task. Defaults to True.
    **fields (str): Additional data fields required for rendering.

Returns:
    TaskID: An ID you can use when calling `update`._

**Args**: self, description, start, total, completed, visible


#### `remove_task()` (line 1642)
_Delete a task if it exists.

Args:
    task_id (TaskID): A task ID._

**Args**: self, task_id


### venv_new\Lib\site-packages\pip\_vendor\rich\progress_bar.py

#### `__init__()` (line 33)
**Args**: self, total, completed, width, pulse, style, complete_style, finished_style, pulse_style, animation_time


#### `__repr__()` (line 57)
**Args**: self


#### `percentage_completed()` (line 61)
_Calculate percentage complete._

**Args**: self


#### `_get_pulse_segments()` (line 70)
_Get a list of segments to render a pulse animation.

Returns:
    List[Segment]: A list of segments, one segment per character._

**Args**: self, fore_style, back_style, color_system, no_color, ascii


#### `update()` (line 116)
_Update progress with new values.

Args:
    completed (float): Number of steps completed.
    total (float, optional): Total number of steps, or ``None`` to not change. Defaults to None._

**Args**: self, completed, total


#### `_render_pulse()` (line 126)
_Renders the pulse animation.

Args:
    console (Console): Console instance.
    width (int): Width in characters of pulse animation.

Returns:
    RenderResult: [description]

Yields:
    Iterator[Segment]: Segments to render pulse_

**Args**: self, console, width, ascii


#### `__rich_console__()` (line 156)
**Args**: self, console, options


#### `__rich_measure__()` (line 200)
**Args**: self, console, options


### venv_new\Lib\site-packages\pip\_vendor\rich\prompt.py

#### `__init__()` (line 23)
**Args**: self, message


#### `__rich__()` (line 26)
**Args**: self


#### `__init__()` (line 54)
**Args**: self, prompt


#### `ask()` (line 80)
**Args**: cls, prompt


#### `ask()` (line 97)
**Args**: cls, prompt


#### `ask()` (line 112)
_Shortcut to construct and run a prompt loop and return the result.

Example:
    >>> filename = Prompt.ask("Enter a filename")

Args:
    prompt (TextType, optional): Prompt text. Defaults to "".
    console (Console, optional): A Console instance or None to use global console. Defaults to None.
    password (bool, optional): Enable password input. Defaults to False.
    choices (List[str], optional): A list of valid choices. Defaults to None.
    case_sensitive (bool, optional): Matching of choices should be case-sensitive. Defaults to True.
    show_default (bool, optional): Show default in prompt. Defaults to True.
    show_choices (bool, optional): Show choices in prompt. Defaults to True.
    stream (TextIO, optional): Optional text file open for reading to get input. Defaults to None._

**Args**: cls, prompt


#### `render_default()` (line 151)
_Turn the supplied default in to a Text instance.

Args:
    default (DefaultType): Default value.

Returns:
    Text: Text containing rendering of default value._

**Args**: self, default


#### `make_prompt()` (line 162)
_Make prompt text.

Args:
    default (DefaultType): Default value.

Returns:
    Text: Text to display in prompt._

**Args**: self, default


#### `get_input()` (line 194)
_Get input from user.

Args:
    console (Console): Console instance.
    prompt (TextType): Prompt text.
    password (bool): Enable password entry.

Returns:
    str: String from user._

**Args**: cls, console, prompt, password, stream


#### `check_choice()` (line 213)
_Check value is in the list of valid choices.

Args:
    value (str): Value entered by user.

Returns:
    bool: True if choice was valid, otherwise False._

**Args**: self, value


#### `process_response()` (line 227)
_Process response from user, convert to prompt type.

Args:
    value (str): String typed by user.

Raises:
    InvalidResponse: If ``value`` is invalid.

Returns:
    PromptType: The value to be returned from ask method._

**Args**: self, value


#### `on_validate_error()` (line 258)
_Called to handle validation error.

Args:
    value (str): String entered by user.
    error (InvalidResponse): Exception instance the initiated the error._

**Args**: self, value, error


#### `pre_prompt()` (line 267)
_Hook to display something before the prompt._

**Args**: self


#### `__call__()` (line 271)
**Args**: self


#### `__call__()` (line 275)
**Args**: self


#### `__call__()` (line 280)
_Run the prompt loop.

Args:
    default (Any, optional): Optional default value.

Returns:
    PromptType: Processed value._

**Args**: self


#### `render_default()` (line 353)
_Render the default as (y) or (n) rather than True/False._

**Args**: self, default


#### `process_response()` (line 358)
_Convert choices to a bool._

**Args**: self, value


### venv_new\Lib\site-packages\pip\_vendor\rich\protocol.py

#### `is_renderable()` (line 10)
_Check if an object may be rendered by Rich._

**Args**: check_object


#### `rich_cast()` (line 19)
_Cast an object to a renderable by calling __rich__ if present.

Args:
    renderable (object): A potentially renderable object

Returns:
    object: The result of recursively calling __rich__._

**Args**: renderable


### venv_new\Lib\site-packages\pip\_vendor\rich\repr.py

#### `auto()` (line 28)
**Args**: cls


#### `auto()` (line 33)

#### `auto()` (line 37)
_Class decorator to create __repr__ from __rich_repr___

**Args**: cls


#### `do_replace()` (line 42)
**Args**: cls, angular


#### `auto_repr()` (line 43)
_Create repr string from __rich_repr___

**Args**: self


#### `auto_rich_repr()` (line 68)
_Auto generate __rich_rep__ from signature of __init___

**Args**: self


#### `rich_repr()` (line 105)
**Args**: cls


#### `rich_repr()` (line 110)

#### `rich_repr()` (line 114)
**Args**: cls


#### `__rich_repr__()` (line 127)
**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\rich\rule.py

#### `__init__()` (line 23)
**Args**: self, title


#### `__repr__()` (line 46)
**Args**: self


#### `__rich_console__()` (line 49)
**Args**: self, console, options


#### `_rule_line()` (line 105)
**Args**: self, chars_len, width


#### `__rich_measure__()` (line 111)
**Args**: self, console, options


### venv_new\Lib\site-packages\pip\_vendor\rich\scope.py

#### `render_scope()` (line 14)
_Render python variables in a given scope.

Args:
    scope (Mapping): A mapping containing variable names and values.
    title (str, optional): Optional title. Defaults to None.
    sort_keys (bool, optional): Enable sorting of items. Defaults to True.
    indent_guides (bool, optional): Enable indentation guides. Defaults to False.
    max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
        Defaults to None.
    max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to None.

Returns:
    ConsoleRenderable: A renderable object._

**Args**: scope


#### `sort_items()` (line 41)
_Sort special variables first, then alphabetically._

**Args**: item


#### `test()` (line 75)
**Args**: foo, bar


### venv_new\Lib\site-packages\pip\_vendor\rich\screen.py

#### `__init__()` (line 28)
**Args**: self


#### `__rich_console__()` (line 40)
**Args**: self, console, options


### venv_new\Lib\site-packages\pip\_vendor\rich\segment.py

#### `cell_length()` (line 82)
_The number of terminal cells required to display self.text.

Returns:
    int: A number of cells._

**Args**: self


#### `__rich_repr__()` (line 91)
**Args**: self


#### `__bool__()` (line 100)
_Check if the segment contains text._

**Args**: self


#### `is_control()` (line 105)
_Check if the segment contains control codes._

**Args**: self


#### `_split_cells()` (line 111)
_Split a segment in to two at a given cell position.

Note that splitting a double-width character, may result in that character turning
into two spaces.

Args:
    segment (Segment): A segment to split.
    cut (int): A cell position to cut on.

Returns:
    A tuple of two segments._

**Args**: cls, segment, cut


#### `split_cells()` (line 158)
_Split segment in to two segments at the specified column.

If the cut point falls in the middle of a 2-cell wide character then it is replaced
by two spaces, to preserve the display width of the parent segment.

Args:
    cut (int): Offset within the segment to cut.

Returns:
    Tuple[Segment, Segment]: Two segments._

**Args**: self, cut


#### `line()` (line 185)
_Make a new line segment._

**Args**: cls


#### `apply_style()` (line 190)
_Apply style(s) to an iterable of segments.

Returns an iterable of segments where the style is replaced by ``style + segment.style + post_style``.

Args:
    segments (Iterable[Segment]): Segments to process.
    style (Style, optional): Base style. Defaults to None.
    post_style (Style, optional): Style to apply on top of segment style. Defaults to None.

Returns:
    Iterable[Segments]: A new iterable of segments (possibly the same iterable)._

**Args**: cls, segments, style, post_style


#### `filter_control()` (line 231)
_Filter segments by ``is_control`` attribute.

Args:
    segments (Iterable[Segment]): An iterable of Segment instances.
    is_control (bool, optional): is_control flag to match in search.

Returns:
    Iterable[Segment]: And iterable of Segment instances._

**Args**: cls, segments, is_control


#### `split_lines()` (line 250)
_Split a sequence of segments in to a list of lines.

Args:
    segments (Iterable[Segment]): Segments potentially containing line feeds.

Yields:
    Iterable[List[Segment]]: Iterable of segment lists, one per line._

**Args**: cls, segments


#### `split_and_crop_lines()` (line 279)
_Split segments in to lines, and crop lines greater than a given length.

Args:
    segments (Iterable[Segment]): An iterable of segments, probably
        generated from console.render.
    length (int): Desired line length.
    style (Style, optional): Style to use for any padding.
    pad (bool): Enable padding of lines that are less than `length`.

Returns:
    Iterable[List[Segment]]: An iterable of lines of segments._

**Args**: cls, segments, length, style, pad, include_new_lines


#### `adjust_line_length()` (line 326)
_Adjust a line to a given width (cropping or padding as required).

Args:
    segments (Iterable[Segment]): A list of segments in a single line.
    length (int): The desired width of the line.
    style (Style, optional): The style of padding if used (space on the end). Defaults to None.
    pad (bool, optional): Pad lines with spaces if they are shorter than `length`. Defaults to True.

Returns:
    List[Segment]: A line of segments with the desired length._

**Args**: cls, line, length, style, pad


#### `get_line_length()` (line 371)
_Get the length of list of segments.

Args:
    line (List[Segment]): A line encoded as a list of Segments (assumes no '\\n' characters),

Returns:
    int: The length of the line._

**Args**: cls, line


#### `get_shape()` (line 384)
_Get the shape (enclosing rectangle) of a list of lines.

Args:
    lines (List[List[Segment]]): A list of lines (no '\\n' characters).

Returns:
    Tuple[int, int]: Width and height in characters._

**Args**: cls, lines


#### `set_shape()` (line 398)
_Set the shape of a list of lines (enclosing rectangle).

        Args:
            lines (List[List[Segment]]): A list of lines.
            width (int): Desired width.
            height (int, optional): Desired height or None for no change.
            style (Style, optional): Style of any padding added.
            new_lines (bool, optional): Padded lines should include "
". Defaults to False.

        Returns:
            List[List[Segment]]: New list of lines.
        _

**Args**: cls, lines, width, height, style, new_lines


#### `align_top()` (line 434)
_Aligns lines to top (adds extra lines to bottom as required).

        Args:
            lines (List[List[Segment]]): A list of lines.
            width (int): Desired width.
            height (int, optional): Desired height or None for no change.
            style (Style): Style of any padding added.
            new_lines (bool, optional): Padded lines should include "
". Defaults to False.

        Returns:
            List[List[Segment]]: New list of lines.
        _

**Args**: cls, lines, width, height, style, new_lines


#### `align_bottom()` (line 463)
_Aligns render to bottom (adds extra lines above as required).

        Args:
            lines (List[List[Segment]]): A list of lines.
            width (int): Desired width.
            height (int, optional): Desired height or None for no change.
            style (Style): Style of any padding added. Defaults to None.
            new_lines (bool, optional): Padded lines should include "
". Defaults to False.

        Returns:
            List[List[Segment]]: New list of lines.
        _

**Args**: cls, lines, width, height, style, new_lines


#### `align_middle()` (line 492)
_Aligns lines to middle (adds extra lines to above and below as required).

        Args:
            lines (List[List[Segment]]): A list of lines.
            width (int): Desired width.
            height (int, optional): Desired height or None for no change.
            style (Style): Style of any padding added.
            new_lines (bool, optional): Padded lines should include "
". Defaults to False.

        Returns:
            List[List[Segment]]: New list of lines.
        _

**Args**: cls, lines, width, height, style, new_lines


#### `simplify()` (line 523)
_Simplify an iterable of segments by combining contiguous segments with the same style.

Args:
    segments (Iterable[Segment]): An iterable of segments.

Returns:
    Iterable[Segment]: A possibly smaller iterable of segments that will render the same way._

**Args**: cls, segments


#### `strip_links()` (line 550)
_Remove all links from an iterable of styles.

Args:
    segments (Iterable[Segment]): An iterable segments.

Yields:
    Segment: Segments with link removed._

**Args**: cls, segments


#### `strip_styles()` (line 567)
_Remove all styles from an iterable of segments.

Args:
    segments (Iterable[Segment]): An iterable segments.

Yields:
    Segment: Segments with styles replace with None_

**Args**: cls, segments


#### `remove_color()` (line 580)
_Remove all color from an iterable of segments.

Args:
    segments (Iterable[Segment]): An iterable segments.

Yields:
    Segment: Segments with colorless style._

**Args**: cls, segments


#### `divide()` (line 602)
_Divides an iterable of segments in to portions.

Args:
    cuts (Iterable[int]): Cell positions where to divide.

Yields:
    [Iterable[List[Segment]]]: An iterable of Segments in List._

**Args**: cls, segments, cuts


#### `__init__()` (line 680)
**Args**: self, segments, new_lines


#### `__rich_console__()` (line 684)
**Args**: self, console, options


#### `__init__()` (line 697)
_A simple renderable containing a number of lines of segments. May be used as an intermediate
in rendering process.

Args:
    lines (Iterable[List[Segment]]): Lists of segments forming lines.
    new_lines (bool, optional): Insert new lines after each line. Defaults to False._

**Args**: self, lines, new_lines


#### `__rich_console__()` (line 708)
**Args**: self, console, options


### venv_new\Lib\site-packages\pip\_vendor\rich\spinner.py

#### `__init__()` (line 26)
**Args**: self, name, text


#### `__rich_console__()` (line 50)
**Args**: self, console, options


#### `__rich_measure__()` (line 55)
**Args**: self, console, options


#### `render()` (line 61)
_Render the spinner for a given time.

Args:
    time (float): Time in seconds.

Returns:
    RenderableType: A renderable containing animation frame._

**Args**: self, time


#### `update()` (line 95)
_Updates attributes of a spinner after it has been started.

Args:
    text (RenderableType, optional): A renderable to display at the right of the spinner (str or Text typically). Defaults to "".
    style (StyleType, optional): Style for spinner animation. Defaults to None.
    speed (float, optional): Speed factor for animation. Defaults to None._

**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\rich\status.py

#### `__init__()` (line 23)
**Args**: self, status


#### `renderable()` (line 45)
**Args**: self


#### `console()` (line 49)
_Get the Console used by the Status objects._

**Args**: self


#### `update()` (line 53)
_Update status.

Args:
    status (Optional[RenderableType], optional): New status renderable or None for no change. Defaults to None.
    spinner (Optional[str], optional): New spinner or None for no change. Defaults to None.
    spinner_style (Optional[StyleType], optional): New spinner style or None for no change. Defaults to None.
    speed (Optional[float], optional): Speed factor for spinner animation or None for no change. Defaults to None._

**Args**: self, status


#### `start()` (line 85)
_Start the status animation._

**Args**: self


#### `stop()` (line 89)
_Stop the spinner animation._

**Args**: self


#### `__rich__()` (line 93)
**Args**: self


#### `__enter__()` (line 96)
**Args**: self


#### `__exit__()` (line 100)
**Args**: self, exc_type, exc_val, exc_tb


### venv_new\Lib\site-packages\pip\_vendor\rich\style.py

#### `__init__()` (line 21)
**Args**: self, bit_no


#### `__get__()` (line 24)
**Args**: self, obj, objtype


#### `__init__()` (line 122)
**Args**: self


#### `_make_color()` (line 146)
**Args**: color


#### `null()` (line 199)
_Create an 'null' style, equivalent to Style(), but more performant._

**Args**: cls


#### `from_color()` (line 204)
_Create a new style with colors and no attributes.

Returns:
    color (Optional[Color]): A (foreground) color, or None for no color. Defaults to None.
    bgcolor (Optional[Color]): A (background) color, or None for no color. Defaults to None._

**Args**: cls, color, bgcolor


#### `from_meta()` (line 228)
_Create a new style with meta data.

Returns:
    meta (Optional[Dict[str, Any]]): A dictionary of meta data. Defaults to None._

**Args**: cls, meta


#### `on()` (line 249)
_Create a blank style with meta information.

Example:
    style = Style.on(click=self.on_click)

Args:
    meta (Optional[Dict[str, Any]], optional): An optional dict of meta information.
    **handlers (Any): Keyword arguments are translated in to handlers.

Returns:
    Style: A Style with meta information attached._

**Args**: cls, meta


#### `link_id()` (line 281)
_Get a link id, used in ansi code for links._

**Args**: self


#### `__str__()` (line 285)
_Re-generate style definition from attributes._

**Args**: self


#### `__bool__()` (line 331)
_A Style is false if it has no attributes, colors, or links._

**Args**: self


#### `_make_ansi_codes()` (line 335)
_Generate ANSI codes for this style.

Args:
    color_system (ColorSystem): Color system.

Returns:
    str: String containing codes._

**Args**: self, color_system


#### `normalize()` (line 380)
_Normalize a style definition so that styles with the same effect have the same string
representation.

Args:
    style (str): A style definition.

Returns:
    str: Normal form of style definition._

**Args**: cls, style


#### `pick_first()` (line 396)
_Pick first non-None style._

**Args**: cls


#### `__rich_repr__()` (line 403)
**Args**: self


#### `__eq__()` (line 422)
**Args**: self, other


#### `__ne__()` (line 427)
**Args**: self, other


#### `__hash__()` (line 432)
**Args**: self


#### `color()` (line 448)
_The foreground color or None if it is not set._

**Args**: self


#### `bgcolor()` (line 453)
_The background color or None if it is not set._

**Args**: self


#### `link()` (line 458)
_Link text, if set._

**Args**: self


#### `transparent_background()` (line 463)
_Check if the style specified a transparent background._

**Args**: self


#### `background_style()` (line 468)
_A Style with background only._

**Args**: self


#### `meta()` (line 473)
_Get meta information (can not be changed after construction)._

**Args**: self


#### `without_color()` (line 478)
_Get a copy of the style with color removed._

**Args**: self


#### `parse()` (line 498)
_Parse a style definition.

Args:
    style_definition (str): A string containing a style.

Raises:
    errors.StyleSyntaxError: If the style definition syntax is invalid.

Returns:
    `Style`: A Style instance._

**Args**: cls, style_definition


#### `get_html_style()` (line 564)
_Get a CSS style rule._

**Args**: self, theme


#### `combine()` (line 601)
_Combine styles and get result.

Args:
    styles (Iterable[Style]): Styles to combine.

Returns:
    Style: A new style instance._

**Args**: cls, styles


#### `chain()` (line 614)
_Combine styles from positional argument in to a single style.

Args:
    *styles (Iterable[Style]): Styles to combine.

Returns:
    Style: A new style instance._

**Args**: cls


#### `copy()` (line 626)
_Get a copy of this style.

Returns:
    Style: A new Style instance with identical attributes._

**Args**: self


#### `clear_meta_and_links()` (line 649)
_Get a copy of this style with link and meta information removed.

Returns:
    Style: New style object._

**Args**: self


#### `update_link()` (line 671)
_Get a copy with a different value for link.

Args:
    link (str, optional): New value for link. Defaults to None.

Returns:
    Style: A new Style instance._

**Args**: self, link


#### `render()` (line 694)
_Render the ANSI codes for the style.

Args:
    text (str, optional): A string to style. Defaults to "".
    color_system (Optional[ColorSystem], optional): Color system to render to. Defaults to ColorSystem.TRUECOLOR.

Returns:
    str: A string containing ANSI style codes._

**Args**: self, text


#### `test()` (line 720)
_Write text with style directly to terminal.

This method is for testing purposes only.

Args:
    text (Optional[str], optional): Text to style or None for style name._

**Args**: self, text


#### `_add()` (line 733)
**Args**: self, style


#### `__add__()` (line 757)
**Args**: self, style


#### `__init__()` (line 770)
**Args**: self, default_style


#### `__repr__()` (line 773)
**Args**: self


#### `current()` (line 777)
_Get the Style at the top of the stack._

**Args**: self


#### `push()` (line 781)
_Push a new style on to the stack.

Args:
    style (Style): New style to combine with current style._

**Args**: self, style


#### `pop()` (line 789)
_Pop last style and discard.

Returns:
    Style: New current style (also available as stack.current)_

**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\rich\styled.py

#### `__init__()` (line 19)
**Args**: self, renderable, style


#### `__rich_console__()` (line 23)
**Args**: self, console, options


#### `__rich_measure__()` (line 31)
**Args**: self, console, options


### venv_new\Lib\site-packages\pip\_vendor\rich\syntax.py

#### `get_style_for_token()` (line 126)
_Get a style for a given Pygments token._

**Args**: self, token_type


#### `get_background_style()` (line 131)
_Get the background color._

**Args**: self


#### `__init__()` (line 139)
**Args**: self, theme


#### `get_style_for_token()` (line 152)
_Get a style from a Pygments class._

**Args**: self, token_type


#### `get_background_style()` (line 174)
**Args**: self


#### `__init__()` (line 181)
**Args**: self, style_map


#### `get_style_for_token()` (line 187)
_Look up style in the style map._

**Args**: self, token_type


#### `get_background_style()` (line 207)
**Args**: self


#### `get_theme()` (line 252)
_Get a syntax theme instance._

**Args**: cls, name


#### `__init__()` (line 263)
**Args**: self, code, lexer


#### `from_path()` (line 302)
_Construct a Syntax object from a file.

Args:
    path (str): Path to file to highlight.
    encoding (str): Encoding of file.
    lexer (str | Lexer, optional): Lexer to use. If None, lexer will be auto-detected from path/file content.
    theme (str, optional): Color theme, aka Pygments style (see https://pygments.org/docs/styles/#getting-a-list-of-available-styles). Defaults to "emacs".
    dedent (bool, optional): Enable stripping of initial whitespace. Defaults to True.
    line_numbers (bool, optional): Enable rendering of line numbers. Defaults to False.
    start_line (int, optional): Starting number for line numbers. Defaults to 1.
    line_range (Tuple[int, int], optional): If given should be a tuple of the start and end line to render.
    highlight_lines (Set[int]): A set of line numbers to highlight.
    code_width: Width of code to render (not including line numbers), or ``None`` to use all available width.
    tab_size (int, optional): Size of tabs. Defaults to 4.
    word_wrap (bool, optional): Enable word wrapping of code.
    background_color (str, optional): Optional background color, or None to use theme color. Defaults to None.
    indent_guides (bool, optional): Show indent guides. Defaults to False.
    padding (PaddingDimensions): Padding to apply around the syntax. Defaults to 0 (no padding).

Returns:
    [Syntax]: A Syntax object that may be printed to the console_

**Args**: cls, path, encoding, lexer, theme, dedent, line_numbers, line_range, start_line, highlight_lines, code_width, tab_size, word_wrap, background_color, indent_guides, padding


#### `guess_lexer()` (line 365)
_Guess the alias of the Pygments lexer to use based on a path and an optional string of code.
If code is supplied, it will use a combination of the code and the filename to determine the
best lexer to use. For example, if the file is ``index.html`` and the file contains Django
templating syntax, then "html+django" will be returned. If the file is ``index.html``, and no
templating language is used, the "html" lexer will be used. If no string of code
is supplied, the lexer will be chosen based on the file extension..

Args:
     path (AnyStr): The path to the file containing the code you wish to know the lexer for.
     code (str, optional): Optional string of code that will be used as a fallback if no lexer
        is found for the supplied path.

Returns:
    str: The name of the Pygments lexer that best matches the supplied path/code._

**Args**: cls, path, code


#### `_get_base_style()` (line 406)
_Get the base style._

**Args**: self


#### `_get_token_color()` (line 411)
_Get a color (if any) for the given token.

Args:
    token_type (TokenType): A token type tuple from Pygments.

Returns:
    Optional[Color]: Color from theme, or None for no color._

**Args**: self, token_type


#### `lexer()` (line 424)
_The lexer for this syntax, or None if no lexer was found.

Tries to find the lexer by name if a string was passed to the constructor._

**Args**: self


#### `default_lexer()` (line 443)
_A Pygments Lexer to use if one is not specified or invalid._

**Args**: self


#### `highlight()` (line 452)
_Highlight code and return a Text instance.

Args:
    code (str): Code to highlight.
    line_range(Tuple[int, int], optional): Optional line range to highlight.

Returns:
    Text: A text instance containing highlighted syntax._

**Args**: self, code, line_range


#### `line_tokenize()` (line 490)
_Split tokens to one per line._


#### `tokens_to_spans()` (line 499)
_Convert tokens to spans._


#### `stylize_range()` (line 537)
_Adds a custom style on a part of the code, that will be applied to the syntax display when it's rendered.
Line numbers are 1-based, while column indexes are 0-based.

Args:
    style (StyleType): The style to apply.
    start (Tuple[int, int]): The start of the range, in the form `[line number, column index]`.
    end (Tuple[int, int]): The end of the range, in the form `[line number, column index]`.
    style_before (bool): Apply the style before any existing styles._

**Args**: self, style, start, end, style_before


#### `_get_line_numbers_color()` (line 558)
**Args**: self, blend


#### `_numbers_column_width()` (line 574)
_Get the number of characters used to render the numbers column._

**Args**: self


#### `_get_number_styles()` (line 584)
_Get background, number, and highlight styles for line numbers._

**Args**: self, console


#### `__rich_measure__()` (line 607)
**Args**: self, console, options


#### `__rich_console__()` (line 625)
**Args**: self, console, options


#### `_get_syntax()` (line 634)
_Get the Segments for the Syntax object, excluding any vertical/horizontal padding_

**Args**: self, console, options


#### `_apply_stylized_ranges()` (line 768)
_Apply stylized ranges to a text instance,
using the given code to determine the right portion to apply the style to.

Args:
    text (Text): Text instance to apply the style to._

**Args**: self, text


#### `_process_code()` (line 801)
_Applies various processing to a raw code string
(normalises it so it always ends with a line return, dedents it if necessary, etc.)

Args:
    code (str): The raw code string to process

Returns:
    Tuple[bool, str]: the boolean indicates whether the raw code ends with a line return,
        while the string is the processed code._

**Args**: self, code


#### `_get_code_index_for_syntax_position()` (line 822)
_Returns the index of the code string for the given positions.

Args:
    newlines_offsets (Sequence[int]): The offset of each newline character found in the code snippet.
    position (SyntaxPosition): The position to search for.

Returns:
    Optional[int]: The index of the code string for this position, or `None`
        if the given position's line number is out of range (if it's the column that is out of range
        we silently clamp its value so that it reaches the end of the line)_

**Args**: newlines_offsets, position


### venv_new\Lib\site-packages\pip\_vendor\rich\table.py

#### `copy()` (line 117)
_Return a copy of this Column._

**Args**: self


#### `cells()` (line 122)
_Get all cells in the column, not including header._

**Args**: self


#### `flexible()` (line 127)
_Check if this column is flexible._

**Args**: self


#### `__init__()` (line 189)
**Args**: self


#### `grid()` (line 254)
_Get a table with no lines, headers, or footer.

Args:
    *headers (Union[Column, str]): Column headers, either as a string, or :class:`~rich.table.Column` instance.
    padding (PaddingDimensions, optional): Get padding around cells. Defaults to 0.
    collapse_padding (bool, optional): Enable collapsing of padding around cells. Defaults to True.
    pad_edge (bool, optional): Enable padding around edges of table. Defaults to False.
    expand (bool, optional): Expand the table to fit the available space if ``True``, otherwise the table width will be auto-calculated. Defaults to False.

Returns:
    Table: A table instance._

**Args**: cls


#### `expand()` (line 287)
_Setting a non-None self.width implies expand._

**Args**: self


#### `expand()` (line 292)
_Set expand._

**Args**: self, expand


#### `_extra_width()` (line 297)
_Get extra width to add to cell content._

**Args**: self


#### `row_count()` (line 307)
_Get the current number of rows._

**Args**: self


#### `get_row_style()` (line 311)
_Get the current row style._

**Args**: self, console, index


#### `__rich_measure__()` (line 321)
**Args**: self, console, options


#### `padding()` (line 355)
_Get cell padding._

**Args**: self


#### `padding()` (line 360)
_Set cell padding._

**Args**: self, padding


#### `add_column()` (line 365)
_Add a column to the table.

Args:
    header (RenderableType, optional): Text or renderable for the header.
        Defaults to "".
    footer (RenderableType, optional): Text or renderable for the footer.
        Defaults to "".
    header_style (Union[str, Style], optional): Style for the header, or None for default. Defaults to None.
    highlight (bool, optional): Whether to highlight the text. The default of None uses the value of the table (self) object.
    footer_style (Union[str, Style], optional): Style for the footer, or None for default. Defaults to None.
    style (Union[str, Style], optional): Style for the column cells, or None for default. Defaults to None.
    justify (JustifyMethod, optional): Alignment for cells. Defaults to "left".
    vertical (VerticalAlignMethod, optional): Vertical alignment, one of "top", "middle", or "bottom". Defaults to "top".
    overflow (OverflowMethod): Overflow method: "crop", "fold", "ellipsis". Defaults to "ellipsis".
    width (int, optional): Desired width of column in characters, or None to fit to contents. Defaults to None.
    min_width (Optional[int], optional): Minimum width of column, or ``None`` for no minimum. Defaults to None.
    max_width (Optional[int], optional): Maximum width of column, or ``None`` for no maximum. Defaults to None.
    ratio (int, optional): Flexible ratio for the column (requires ``Table.expand`` or ``Table.width``). Defaults to None.
    no_wrap (bool, optional): Set to ``True`` to disable wrapping of this column._

**Args**: self, header, footer


#### `add_row()` (line 423)
_Add a row of renderables.

Args:
    *renderables (None or renderable): Each cell in a row must be a renderable object (including str),
        or ``None`` for a blank cell.
    style (StyleType, optional): An optional style to apply to the entire row. Defaults to None.
    end_section (bool, optional): End a section and draw a line. Defaults to False.

Raises:
    errors.NotRenderableError: If you add something that can't be rendered._

**Args**: self


#### `add_cell()` (line 441)
**Args**: column, renderable


#### `add_section()` (line 470)
_Add a new section (draw a line after current row)._

**Args**: self


#### `__rich_console__()` (line 476)
**Args**: self, console, options


#### `render_annotation()` (line 497)
**Args**: text, style, justify


#### `_calculate_column_widths()` (line 523)
_Calculate the widths of each column, including padding, not including borders._

**Args**: self, console, options


#### `_collapse_widths()` (line 588)
_Reduce widths so that the total is under max_width.

Args:
    widths (List[int]): List of widths.
    wrapable (List[bool]): List of booleans that indicate if a column may shrink.
    max_width (int): Maximum width to reduce to.

Returns:
    List[int]: A new list of widths._

**Args**: cls, widths, wrapable, max_width


#### `_get_cells()` (line 626)
_Get all the cells with padding and optional header._

**Args**: self, console, column_index, column


#### `get_padding()` (line 641)
**Args**: first_row, last_row


#### `_get_padding_width()` (line 699)
_Get extra width from padding._

**Args**: self, column_index


#### `_measure_column()` (line 707)
_Get the minimum and maximum width of the column._

**Args**: self, console, options, column


#### `_render()` (line 747)
**Args**: self, console, options, widths


#### `align_cell()` (line 839)
**Args**: cell, vertical, width, style


#### `header()` (line 968)
**Args**: text


### venv_new\Lib\site-packages\pip\_vendor\rich\terminal_theme.py

#### `__init__()` (line 20)
**Args**: self, background, foreground, normal, bright


### venv_new\Lib\site-packages\pip\_vendor\rich\text.py

#### `__repr__()` (line 57)
**Args**: self


#### `__bool__()` (line 60)
**Args**: self


#### `split()` (line 63)
_Split a span in to 2 from a given offset._

**Args**: self, offset


#### `move()` (line 76)
_Move start and end by a given offset.

Args:
    offset (int): Number of characters to add to start and end.

Returns:
    TextSpan: A new TextSpan with adjusted position._

**Args**: self, offset


#### `right_crop()` (line 88)
_Crop the span at the given offset.

Args:
    offset (int): A value between start and end.

Returns:
    Span: A new (possibly smaller) span._

**Args**: self, offset


#### `extend()` (line 102)
_Extend the span by the given number of cells.

Args:
    cells (int): Additional space to add to end of span.

Returns:
    Span: A span._

**Args**: self, cells


#### `__init__()` (line 144)
**Args**: self, text, style


#### `__len__()` (line 167)
**Args**: self


#### `__bool__()` (line 170)
**Args**: self


#### `__str__()` (line 173)
**Args**: self


#### `__repr__()` (line 176)
**Args**: self


#### `__add__()` (line 179)
**Args**: self, other


#### `__eq__()` (line 186)
**Args**: self, other


#### `__contains__()` (line 191)
**Args**: self, other


#### `__getitem__()` (line 198)
**Args**: self, slice


#### `get_text_at()` (line 199)
**Args**: offset


#### `cell_len()` (line 225)
_Get the number of cells required to render this text._

**Args**: self


#### `markup()` (line 230)
_Get console markup to render this Text.

Returns:
    str: A string potentially creating markup tags._

**Args**: self


#### `from_markup()` (line 260)
_Create Text instance from markup.

Args:
    text (str): A string containing console markup.
    style (Union[str, Style], optional): Base style for text. Defaults to "".
    emoji (bool, optional): Also render emoji code. Defaults to True.
    emoji_variant (str, optional): Optional emoji variant, either "text" or "emoji". Defaults to None.
    justify (str, optional): Justify method: "left", "center", "full", "right". Defaults to None.
    overflow (str, optional): Overflow method: "crop", "fold", "ellipsis". Defaults to None.
    end (str, optional): Character to end text with. Defaults to "\\n".

Returns:
    Text: A Text instance with markup rendered._

**Args**: cls, text


#### `from_ansi()` (line 294)
_Create a Text object from a string containing ANSI escape codes.

Args:
    text (str): A string containing escape codes.
    style (Union[str, Style], optional): Base style for text. Defaults to "".
    justify (str, optional): Justify method: "left", "center", "full", "right". Defaults to None.
    overflow (str, optional): Overflow method: "crop", "fold", "ellipsis". Defaults to None.
    no_wrap (bool, optional): Disable text wrapping, or None for default. Defaults to None.
    end (str, optional): Character to end text with. Defaults to "\\n".
    tab_size (int): Number of spaces per tab, or ``None`` to use ``console.tab_size``. Defaults to None._

**Args**: cls, text


#### `styled()` (line 332)
_Construct a Text instance with a pre-applied styled. A style applied in this way won't be used
to pad the text when it is justified.

Args:
    text (str): A string containing console markup.
    style (Union[str, Style]): Style to apply to the text. Defaults to "".
    justify (str, optional): Justify method: "left", "center", "full", "right". Defaults to None.
    overflow (str, optional): Overflow method: "crop", "fold", "ellipsis". Defaults to None.

Returns:
    Text: A text instance with a style applied to the entire string._

**Args**: cls, text, style


#### `assemble()` (line 357)
_Construct a text instance by combining a sequence of strings with optional styles.
The positional arguments should be either strings, or a tuple of string + style.

Args:
    style (Union[str, Style], optional): Base style for text. Defaults to "".
    justify (str, optional): Justify method: "left", "center", "full", "right". Defaults to None.
    overflow (str, optional): Overflow method: "crop", "fold", "ellipsis". Defaults to None.
    no_wrap (bool, optional): Disable text wrapping, or None for default. Defaults to None.
    end (str, optional): Character to end text with. Defaults to "\\n".
    tab_size (int): Number of spaces per tab, or ``None`` to use ``console.tab_size``. Defaults to None.
    meta (Dict[str, Any], optional). Meta data to apply to text, or None for no meta data. Default to None

Returns:
    Text: A new text instance._

**Args**: cls


#### `plain()` (line 403)
_Get the text as a single string._

**Args**: self


#### `plain()` (line 410)
_Set the text to a new value._

**Args**: self, new_text


#### `spans()` (line 421)
_Get a reference to the internal list of spans._

**Args**: self


#### `spans()` (line 426)
_Set spans._

**Args**: self, spans


#### `blank_copy()` (line 430)
_Return a new Text instance with copied metadata (but not the string or spans)._

**Args**: self, plain


#### `copy()` (line 443)
_Return a copy of this instance._

**Args**: self


#### `stylize()` (line 457)
_Apply a style to the text, or a portion of the text.

Args:
    style (Union[str, Style]): Style instance or style definition to apply.
    start (int): Start offset (negative indexing is supported). Defaults to 0.
    end (Optional[int], optional): End offset (negative indexing is supported), or None for end of text. Defaults to None._

**Args**: self, style, start, end


#### `stylize_before()` (line 483)
_Apply a style to the text, or a portion of the text. Styles will be applied before other styles already present.

Args:
    style (Union[str, Style]): Style instance or style definition to apply.
    start (int): Start offset (negative indexing is supported). Defaults to 0.
    end (Optional[int], optional): End offset (negative indexing is supported), or None for end of text. Defaults to None._

**Args**: self, style, start, end


#### `apply_meta()` (line 509)
_Apply metadata to the text, or a portion of the text.

Args:
    meta (Dict[str, Any]): A dict of meta information.
    start (int): Start offset (negative indexing is supported). Defaults to 0.
    end (Optional[int], optional): End offset (negative indexing is supported), or None for end of text. Defaults to None._

**Args**: self, meta, start, end


#### `on()` (line 523)
_Apply event handlers (used by Textual project).

Example:
    >>> from rich.text import Text
    >>> text = Text("hello world")
    >>> text.on(click="view.toggle('world')")

Args:
    meta (Dict[str, Any]): Mapping of meta information.
    **handlers: Keyword args are prefixed with "@" to defined handlers.

Returns:
    Text: Self is returned to method may be chained._

**Args**: self, meta


#### `remove_suffix()` (line 543)
_Remove a suffix if it exists.

Args:
    suffix (str): Suffix to remove._

**Args**: self, suffix


#### `get_style_at_offset()` (line 552)
_Get the style of a character at give offset.

Args:
    console (~Console): Console where text will be rendered.
    offset (int): Offset in to text (negative indexing supported)

Returns:
    Style: A Style instance._

**Args**: self, console, offset


#### `extend_style()` (line 572)
_Extend the Text given number of spaces where the spaces have the same style as the last character.

Args:
    spaces (int): Number of spaces to add to the Text._

**Args**: self, spaces


#### `highlight_regex()` (line 593)
_Highlight text with a regular expression, where group names are
translated to styles.

Args:
    re_highlight (Union[re.Pattern, str]): A regular expression object or string.
    style (Union[GetStyleCallable, StyleType]): Optional style to apply to whole match, or a callable
        which accepts the matched text and returns a style. Defaults to None.
    style_prefix (str, optional): Optional prefix to add to style group names.

Returns:
    int: Number of regex matches_

**Args**: self, re_highlight, style


#### `highlight_words()` (line 633)
_Highlight words with a style.

Args:
    words (Iterable[str]): Words to highlight.
    style (Union[str, Style]): Style to apply.
    case_sensitive (bool, optional): Enable case sensitive matching. Defaults to True.

Returns:
    int: Number of words highlighted._

**Args**: self, words, style


#### `rstrip()` (line 662)
_Strip whitespace from end of text._

**Args**: self


#### `rstrip_end()` (line 666)
_Remove whitespace beyond a certain width at the end of the text.

Args:
    size (int): The desired size of the text._

**Args**: self, size


#### `set_length()` (line 680)
_Set new length of the text, clipping or padding is required._

**Args**: self, new_length


#### `__rich_console__()` (line 689)
**Args**: self, console, options


#### `__rich_measure__()` (line 708)
**Args**: self, console, options


#### `render()` (line 720)
_Render the text as Segments.

Args:
    console (Console): Console instance.
    end (Optional[str], optional): Optional end character.

Returns:
    Iterable[Segment]: Result of render that may be written to the console._

**Args**: self, console, end


#### `get_current_style()` (line 759)
_Construct current style from stack._


#### `join()` (line 779)
_Join text together with this instance as the separator.

Args:
    lines (Iterable[Text]): An iterable of Text instances to join.

Returns:
    Text: A new text instance containing join text._

**Args**: self, lines


#### `iter_text()` (line 791)

#### `expand_tabs()` (line 818)
_Converts tabs to spaces.

Args:
    tab_size (int, optional): Size of tabs. Defaults to 8._

**Args**: self, tab_size


#### `truncate()` (line 860)
_Truncate text if it is longer that a given width.

Args:
    max_width (int): Maximum number of characters in text.
    overflow (str, optional): Overflow method: "crop", "fold", or "ellipsis". Defaults to None, to use self.overflow.
    pad (bool, optional): Pad with spaces if the length is less than max_width. Defaults to False._

**Args**: self, max_width


#### `_trim_spans()` (line 887)
_Remove or modify any spans that are over the end of the text._

**Args**: self


#### `pad()` (line 901)
_Pad left and right with a given number of characters.

Args:
    count (int): Width of padding.
    character (str): The character to pad with. Must be a string of length 1._

**Args**: self, count, character


#### `pad_left()` (line 918)
_Pad the left with a given character.

Args:
    count (int): Number of characters to pad.
    character (str, optional): Character to pad with. Defaults to " "._

**Args**: self, count, character


#### `pad_right()` (line 934)
_Pad the right with a given character.

Args:
    count (int): Number of characters to pad.
    character (str, optional): Character to pad with. Defaults to " "._

**Args**: self, count, character


#### `align()` (line 945)
_Align text to a given width.

Args:
    align (AlignMethod): One of "left", "center", or "right".
    width (int): Desired width.
    character (str, optional): Character to pad with. Defaults to " "._

**Args**: self, align, width, character


#### `append()` (line 965)
_Add text with an optional style.

Args:
    text (Union[Text, str]): A str or Text to append.
    style (str, optional): A style name. Defaults to None.

Returns:
    Text: Returns self for chaining._

**Args**: self, text, style


#### `append_text()` (line 1009)
_Append another Text instance. This method is more performant that Text.append, but
only works for Text.

Args:
    text (Text): The Text instance to append to this instance.

Returns:
    Text: Returns self for chaining._

**Args**: self, text


#### `append_tokens()` (line 1031)
_Append iterable of str and style. Style may be a Style instance or a str style definition.

Args:
    tokens (Iterable[Tuple[str, Optional[StyleType]]]): An iterable of tuples containing str content and style.

Returns:
    Text: Returns self for chaining._

**Args**: self, tokens


#### `copy_styles()` (line 1055)
_Copy styles from another Text instance.

Args:
    text (Text): A Text instance to copy styles from, must be the same length._

**Args**: self, text


#### `split()` (line 1063)
_Split rich text in to lines, preserving styles.

Args:
    separator (str, optional): String to split on. Defaults to "\\n".
    include_separator (bool, optional): Include the separator in the lines. Defaults to False.
    allow_blank (bool, optional): Return a blank line if the text ends with a separator. Defaults to False.

Returns:
    List[RichText]: A list of rich text, one per line of the original._

**Args**: self, separator


#### `flatten_spans()` (line 1092)

#### `divide()` (line 1107)
_Divide text in to a number of lines at given offsets.

Args:
    offsets (Iterable[int]): Offsets used to divide text.

Returns:
    Lines: New RichText instances between offsets._

**Args**: self, offsets


#### `right_crop()` (line 1186)
_Remove a number of characters from the end of the text._

**Args**: self, amount


#### `wrap()` (line 1202)
_Word wrap the text.

Args:
    console (Console): Console instance.
    width (int): Number of cells available per line.
    justify (str, optional): Justify method: "default", "left", "center", "full", "right". Defaults to "default".
    overflow (str, optional): Overflow method: "crop", "fold", or "ellipsis". Defaults to None.
    tab_size (int, optional): Default tab size. Defaults to 8.
    no_wrap (bool, optional): Disable wrapping, Defaults to False.

Returns:
    Lines: Number of lines._

**Args**: self, console, width


#### `fit()` (line 1250)
_Fit the text in to given width by chopping in to lines.

Args:
    width (int): Maximum characters in a line.

Returns:
    Lines: Lines container._

**Args**: self, width


#### `detect_indentation()` (line 1266)
_Auto-detect indentation of code.

Returns:
    int: Number of spaces used to indent code._

**Args**: self


#### `with_indent_guides()` (line 1287)
_Adds indent guide lines to text.

Args:
    indent_size (Optional[int]): Size of indentation, or None to auto detect. Defaults to None.
    character (str, optional): Character to use for indentation. Defaults to "‚îÇ".
    style (Union[Style, str], optional): Style of indent guides.

Returns:
    Text: New text with indentation guides._

**Args**: self, indent_size


### venv_new\Lib\site-packages\pip\_vendor\rich\theme.py

#### `__init__()` (line 18)
**Args**: self, styles, inherit


#### `config()` (line 31)
_Get contents of a config file for this theme._

**Args**: self


#### `from_file()` (line 39)
_Load a theme from a text mode file.

Args:
    config_file (IO[str]): An open conf file.
    source (str, optional): The filename of the open file. Defaults to None.
    inherit (bool, optional): Inherit default styles. Defaults to True.

Returns:
    Theme: A New theme instance._

**Args**: cls, config_file, source, inherit


#### `read()` (line 59)
_Read a theme from a path.

Args:
    path (str): Path to a config file readable by Python configparser module.
    inherit (bool, optional): Inherit default styles. Defaults to True.
    encoding (str, optional): Encoding of the config file. Defaults to None.

Returns:
    Theme: A new theme instance._

**Args**: cls, path, inherit, encoding


#### `__init__()` (line 87)
**Args**: self, theme


#### `push_theme()` (line 91)
_Push a theme on the top of the stack.

Args:
    theme (Theme): A Theme instance.
    inherit (boolean, optional): Inherit styles from current top of stack._

**Args**: self, theme, inherit


#### `pop_theme()` (line 105)
_Pop (and discard) the top-most theme._

**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\rich\traceback.py

#### `install()` (line 47)
_Install a rich traceback handler.

Once installed, any tracebacks will be printed with syntax highlighting and rich formatting.


Args:
    console (Optional[Console], optional): Console to write exception to. Default uses internal Console instance.
    width (Optional[int], optional): Width (in characters) of traceback. Defaults to 100.
    code_width (Optional[int], optional): Code width (in characters) of traceback. Defaults to 88.
    extra_lines (int, optional): Extra lines of code. Defaults to 3.
    theme (Optional[str], optional): Pygments theme to use in traceback. Defaults to ``None`` which will pick
        a theme appropriate for the platform.
    word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.
    show_locals (bool, optional): Enable display of local variables. Defaults to False.
    locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
        Defaults to 10.
    locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.
    locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.
    locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.
    indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.
    suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.

Returns:
    Callable: The previous exception handler that was replaced._


#### `excepthook()` (line 98)
**Args**: type_, value, traceback


#### `ipy_excepthook_closure()` (line 124)
**Args**: ip


#### `ipy_show_traceback()` (line 128)
_wrap the default ip.showtraceback to store info for ip._showtraceback_


#### `ipy_display_traceback()` (line 134)
_Internally called traceback from ip._showtraceback_


#### `__init__()` (line 245)
**Args**: self, trace


#### `from_exception()` (line 299)
_Create a traceback from exception info

Args:
    exc_type (Type[BaseException]): Exception type.
    exc_value (BaseException): Exception value.
    traceback (TracebackType): Python Traceback object.
    width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.
    code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.
    extra_lines (int, optional): Additional lines of code to render. Defaults to 3.
    theme (str, optional): Override pygments theme used in traceback.
    word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.
    show_locals (bool, optional): Enable display of local variables. Defaults to False.
    indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.
    locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
        Defaults to 10.
    locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.
    locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.
    locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.
    suppress (Iterable[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.
    max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.

Returns:
    Traceback: A Traceback instance that may be printed._

**Args**: cls, exc_type, exc_value, traceback


#### `extract()` (line 372)
_Extract traceback information.

Args:
    exc_type (Type[BaseException]): Exception type.
    exc_value (BaseException): Exception value.
    traceback (TracebackType): Python Traceback object.
    show_locals (bool, optional): Enable display of local variables. Defaults to False.
    locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
        Defaults to 10.
    locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.
    locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.
    locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.

Returns:
    Trace: A Trace instance which you can use to construct a `Traceback`._

**Args**: cls, exc_type, exc_value, traceback


#### `safe_str()` (line 406)
_Don't allow exceptions from __str__ to propagate._

**Args**: _object


#### `get_locals()` (line 432)
_Extract locals from an iterator of key pairs._

**Args**: iter_locals


#### `__rich_console__()` (line 529)
**Args**: self, console, options


#### `_render_syntax_error()` (line 608)
**Args**: self, syntax_error


#### `_guess_lexer()` (line 631)
**Args**: cls, filename, code


#### `_render_stack()` (line 647)
**Args**: self, stack


#### `read_code()` (line 651)
_Read files, and cache results on filename.

Args:
    filename (str): Filename to read

Returns:
    str: Contents of file_

**Args**: filename


#### `render_locals()` (line 662)
**Args**: frame


#### `bar()` (line 775)
**Args**: a


#### `foo()` (line 781)
**Args**: a


#### `error()` (line 794)

### venv_new\Lib\site-packages\pip\_vendor\rich\tree.py

#### `__init__()` (line 37)
**Args**: self, label


#### `add()` (line 55)
_Add a child tree.

Args:
    label (RenderableType): The renderable or str for the tree label.
    style (StyleType, optional): Style of this tree. Defaults to "tree".
    guide_style (StyleType, optional): Style of the guide lines. Defaults to "tree.line".
    expanded (bool, optional): Also display children. Defaults to True.
    highlight (Optional[bool], optional): Highlight renderable (if str). Defaults to False.

Returns:
    Tree: A new child Tree, which may be further modified._

**Args**: self, label


#### `__rich_console__()` (line 86)
**Args**: self, console, options


#### `make_guide()` (line 101)
_Make a Segment for a level of the guide lines._

**Args**: index, style


#### `__rich_measure__()` (line 176)
**Args**: self, console, options


### venv_new\Lib\site-packages\pip\_vendor\tomli\_parser.py

#### `__init__()` (line 82)
**Args**: self, msg, doc, pos


#### `load()` (line 130)
_Parse TOML from a binary file object._

**Args**: __fp


#### `loads()` (line 142)
_Parse TOML from a string._

**Args**: __s


#### `__init__()` (line 222)
**Args**: self


#### `add_pending()` (line 226)
**Args**: self, key, flag


#### `finalize_pending()` (line 229)
**Args**: self


#### `unset_all()` (line 234)
**Args**: self, key


#### `set()` (line 242)
**Args**: self, key, flag


#### `is_()` (line 253)
**Args**: self, key, flag


#### `__init__()` (line 272)
**Args**: self


#### `get_or_create_nest()` (line 276)
**Args**: self, key


#### `append_nest_to_list()` (line 293)
**Args**: self, key


#### `skip_chars()` (line 310)
**Args**: src, pos, chars


#### `skip_until()` (line 319)
**Args**: src, pos, expect


#### `skip_comment()` (line 341)
**Args**: src, pos


#### `skip_comments_and_array_ws()` (line 353)
**Args**: src, pos


#### `create_dict_rule()` (line 362)
**Args**: src, pos, out


#### `create_list_rule()` (line 382)
**Args**: src, pos, out


#### `key_value_rule()` (line 405)
**Args**: src, pos, out, header, parse_float


#### `parse_key_value_pair()` (line 439)
**Args**: src, pos, parse_float, nest_lvl


#### `parse_key()` (line 455)
**Args**: src, pos


#### `parse_key_part()` (line 473)
**Args**: src, pos


#### `parse_one_line_basic_str()` (line 489)
**Args**: src, pos


#### `parse_array()` (line 494)
**Args**: src, pos, parse_float, nest_lvl


#### `parse_inline_table()` (line 520)
**Args**: src, pos, parse_float, nest_lvl


#### `parse_basic_str_escape()` (line 554)
**Args**: src, pos


#### `parse_basic_str_escape_multiline()` (line 583)
**Args**: src, pos


#### `parse_hex_char()` (line 587)
**Args**: src, pos, hex_len


#### `parse_literal_str()` (line 600)
**Args**: src, pos


#### `parse_multiline_str()` (line 609)
**Args**: src, pos


#### `parse_basic_str()` (line 640)
**Args**: src, pos


#### `parse_value()` (line 672)
**Args**: src, pos, parse_float, nest_lvl


#### `is_unicode_scalar_value()` (line 748)
**Args**: codepoint


#### `make_safe_parse_float()` (line 752)
_A decorator to make `parse_float` safe.

`parse_float` must not return dicts or lists, because these types
would be mixed with parsed TOML tables and arrays, thus confusing
the parser. The returned decorated callable raises `ValueError`
instead of returning illegal types._

**Args**: parse_float


#### `safe_parse_float()` (line 764)
**Args**: float_str


### venv_new\Lib\site-packages\pip\_vendor\tomli\_re.py

#### `match_to_datetime()` (line 54)
_Convert a `RE_DATETIME` match to `datetime.datetime` or `datetime.date`.

Raises ValueError if the match does not correspond to a valid date
or datetime._

**Args**: match


#### `cached_tz()` (line 93)
**Args**: hour_str, minute_str, sign_str


#### `match_to_localtime()` (line 103)
**Args**: match


#### `match_to_number()` (line 109)
**Args**: match, parse_float


### venv_new\Lib\site-packages\pip\_vendor\truststore\_api.py

#### `inject_into_ssl()` (line 32)
_Injects the :class:`truststore.SSLContext` into the ``ssl``
module by replacing :class:`ssl.SSLContext`._


#### `extract_from_ssl()` (line 47)
_Restores the :class:`ssl.SSLContext` class to its original state_


#### `__class__()` (line 62)
**Args**: self


#### `__init__()` (line 68)
**Args**: self, protocol


#### `do_handshake()` (line 76)
**Args**: self


#### `wrap_socket()` (line 83)
**Args**: self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session


#### `wrap_bio()` (line 111)
**Args**: self, incoming, outgoing, server_side, server_hostname, session


#### `load_verify_locations()` (line 129)
**Args**: self, cafile, capath, cadata


#### `load_cert_chain()` (line 139)
**Args**: self, certfile, keyfile, password


#### `load_default_certs()` (line 149)
**Args**: self, purpose


#### `set_alpn_protocols()` (line 154)
**Args**: self, alpn_protocols


#### `set_npn_protocols()` (line 157)
**Args**: self, npn_protocols


#### `set_ciphers()` (line 160)
**Args**: self, __cipherlist


#### `get_ciphers()` (line 163)
**Args**: self


#### `session_stats()` (line 166)
**Args**: self


#### `cert_store_stats()` (line 169)
**Args**: self


#### `set_default_verify_paths()` (line 172)
**Args**: self


#### `get_ca_certs()` (line 176)
**Args**: self, binary_form


#### `get_ca_certs()` (line 181)
**Args**: self, binary_form


#### `get_ca_certs()` (line 184)
**Args**: self, binary_form


#### `get_ca_certs()` (line 186)
**Args**: self, binary_form


#### `check_hostname()` (line 190)
**Args**: self


#### `check_hostname()` (line 194)
**Args**: self, value


#### `hostname_checks_common_name()` (line 198)
**Args**: self


#### `hostname_checks_common_name()` (line 202)
**Args**: self, value


#### `keylog_filename()` (line 206)
**Args**: self


#### `keylog_filename()` (line 210)
**Args**: self, value


#### `maximum_version()` (line 214)
**Args**: self


#### `maximum_version()` (line 218)
**Args**: self, value


#### `minimum_version()` (line 224)
**Args**: self


#### `minimum_version()` (line 228)
**Args**: self, value


#### `options()` (line 234)
**Args**: self


#### `options()` (line 238)
**Args**: self, value


#### `post_handshake_auth()` (line 244)
**Args**: self


#### `post_handshake_auth()` (line 248)
**Args**: self, value


#### `protocol()` (line 252)
**Args**: self


#### `security_level()` (line 256)
**Args**: self


#### `verify_flags()` (line 260)
**Args**: self


#### `verify_flags()` (line 264)
**Args**: self, value


#### `verify_mode()` (line 270)
**Args**: self


#### `verify_mode()` (line 274)
**Args**: self, value


#### `_get_unverified_chain_bytes()` (line 285)
**Args**: sslobj


#### `_get_unverified_chain_bytes()` (line 294)
**Args**: sslobj


#### `_verify_peercerts()` (line 299)
_Verifies the peer certificates from an SSLSocket or SSLObject
against the certificates in the OS trust store._

**Args**: sock_or_sslobj, server_hostname


### venv_new\Lib\site-packages\pip\_vendor\truststore\_macos.py

#### `_load_cdll()` (line 31)
_Loads a CDLL by name, falling back to known path on 10.16+_

**Args**: name, macos10_16_path


#### `_handle_osstatus()` (line 223)
_Raises an error if the OSStatus value is non-zero._

**Args**: result, _, args


#### `_bytes_to_cf_data_ref()` (line 294)
**Args**: value


#### `_bytes_to_cf_string()` (line 300)
_Given a Python binary data, create a CFString.
The string must be CFReleased by the caller._

**Args**: value


#### `_cf_string_ref_to_str()` (line 314)
_Creates a Unicode string from a CFString object. Used entirely for error
reporting.
Yes, it annoys me quite a lot that this function is this complex._

**Args**: cf_string_ref


#### `_der_certs_to_cf_cert_array()` (line 337)
_Builds a CFArray of SecCertificateRefs from a list of DER-encoded certificates.
Responsibility of the caller to call CoreFoundation.CFRelease on the CFArray._

**Args**: certs


#### `_configure_context()` (line 368)
**Args**: ctx


#### `_verify_peercerts_impl()` (line 380)
**Args**: ssl_context, cert_chain, server_hostname


#### `_verify_peercerts_impl_macos_10_13()` (line 469)
_Verify using 'SecTrustEvaluate' API for macOS 10.13 and earlier.
macOS 10.14 added the 'SecTrustEvaluateWithError' API._

**Args**: ssl_context, sec_trust_ref


#### `_verify_peercerts_impl_macos_10_14()` (line 513)
_Verify using 'SecTrustEvaluateWithError' API for macOS 10.14+._

**Args**: ssl_context, sec_trust_ref


### venv_new\Lib\site-packages\pip\_vendor\truststore\_openssl.py

#### `_configure_context()` (line 23)
**Args**: ctx


#### `_capath_contains_certs()` (line 49)
_Check whether capath exists and contains certs in the expected format._

**Args**: capath


#### `_verify_peercerts_impl()` (line 59)
**Args**: ssl_context, cert_chain, server_hostname


### venv_new\Lib\site-packages\pip\_vendor\truststore\_ssl_constants.py

#### `_set_ssl_context_verify_mode()` (line 28)
**Args**: ssl_context, verify_mode


### venv_new\Lib\site-packages\pip\_vendor\truststore\_windows.py

#### `_handle_win_error()` (line 238)
**Args**: result, _, args


#### `_verify_peercerts_impl()` (line 323)
_Verify the cert_chain from the server using Windows APIs._

**Args**: ssl_context, cert_chain, server_hostname


#### `_get_and_verify_cert_chain()` (line 415)
**Args**: ssl_context, hChainEngine, hIntermediateCertStore, pPeerCertContext, pChainPara, server_hostname, chain_flags


#### `_verify_using_custom_ca_certs()` (line 505)
**Args**: ssl_context, custom_ca_certs, hIntermediateCertStore, pPeerCertContext, pChainPara, server_hostname, chain_flags


#### `_configure_context()` (line 558)
**Args**: ctx


### venv_new\Lib\site-packages\pip\_vendor\typing_extensions.py

#### `__repr__()` (line 146)
**Args**: self


#### `_should_collect_from_parameters()` (line 154)
**Args**: t


#### `_should_collect_from_parameters()` (line 159)
**Args**: t


#### `_should_collect_from_parameters()` (line 162)
**Args**: t


#### `__instancecheck__()` (line 182)
**Args**: self, obj


#### `__repr__()` (line 187)
**Args**: self


#### `__new__()` (line 201)
**Args**: cls


#### `__repr__()` (line 211)
**Args**: self


#### `final()` (line 223)
_This decorator can be used to indicate to type checkers that
the decorated method cannot be overridden, and decorated class
cannot be subclassed. For example:

    class Base:
        @final
        def done(self) -> None:
            ...
    class Sub(Base):
        def done(self) -> None:  # Error reported by type checker
            ...
    @final
    class Leaf:
        ...
    class Other(Leaf):  # Error reported by type checker
        ...

There is no runtime checking of these properties. The decorator
sets the ``__final__`` attribute to ``True`` on the decorated object
to allow runtime introspection._

**Args**: f


#### `IntVar()` (line 255)
**Args**: name


#### `_flatten_literal_params()` (line 263)
_An internal helper for Literal creation: flatten Literals among parameters_

**Args**: parameters


#### `_value_and_type_iter()` (line 273)
**Args**: params


#### `__eq__()` (line 278)
**Args**: self, other


#### `__hash__()` (line 285)
**Args**: self


#### `__init__()` (line 289)
**Args**: self, doc


#### `__getitem__()` (line 293)
**Args**: self, parameters


#### `overload()` (line 346)
_Decorator for overloaded functions/methods.

In a stub file, place two or more stub definitions for the same
function in a row, each decorated with @overload.  For example:

@overload
def utf8(value: None) -> None: ...
@overload
def utf8(value: bytes) -> bytes: ...
@overload
def utf8(value: str) -> bytes: ...

In a non-stub file (i.e. a regular .py file), do the same but
follow it with an implementation.  The implementation should *not*
be decorated with @overload.  For example:

@overload
def utf8(value: None) -> None: ...
@overload
def utf8(value: bytes) -> bytes: ...
@overload
def utf8(value: str) -> bytes: ...
def utf8(value):
    # implementation goes here

The overloads for a function can be retrieved at runtime using the
get_overloads() function._

**Args**: func


#### `get_overloads()` (line 386)
_Return all defined overloads for *func* as a sequence._

**Args**: func


#### `clear_overloads()` (line 397)
_Clear all overloads in the registry._


#### `_is_dunder()` (line 423)
**Args**: attr


#### `__init__()` (line 432)
**Args**: self, origin, nparams


#### `__setattr__()` (line 443)
**Args**: self, attr, val


#### `__getitem__()` (line 454)
**Args**: self, params


#### `_get_protocol_attrs()` (line 518)
**Args**: cls


#### `_caller()` (line 530)
**Args**: depth


#### `_allow_reckless_class_checks()` (line 542)
_Allow instance and class checks for special stdlib modules.
The abc and functools modules indiscriminately call isinstance() and
issubclass() on the whole MRO of a user class, which may contain protocols._

**Args**: depth


#### `_no_init()` (line 549)
**Args**: self


#### `_type_check_issubclass_arg_1()` (line 553)
_Raise TypeError if `arg` is not an instance of `type`
in `issubclass(arg, <protocol>)`.

In most cases, this is verified by type.__subclasscheck__.
Checking it again unnecessarily would slow down issubclass() checks,
so, we don't perform this check unless we absolutely have to.

For various error paths, however,
we want to ensure that *this* error message is shown to the user
where relevant, rather than a typing.py-specific error message._

**Args**: arg


#### `__new__()` (line 579)
**Args**: mcls, name, bases, namespace


#### `__init__()` (line 595)
**Args**: cls


#### `__subclasscheck__()` (line 600)
**Args**: cls, other


#### `__instancecheck__()` (line 626)
**Args**: cls, instance


#### `__eq__()` (line 658)
**Args**: cls, other


#### `__hash__()` (line 669)
**Args**: cls


#### `_proto_hook()` (line 673)
**Args**: cls, other


#### `__init_subclass__()` (line 703)
**Args**: cls


#### `runtime_checkable()` (line 722)
_Mark a protocol class as a runtime protocol.

Such protocol can be used with isinstance() and issubclass().
Raise TypeError if applied to a non-protocol class.
This allows a simple-minded structural check very similar to
one trick ponies in collections.abc such as Iterable.

For example::

    @runtime_checkable
    class Closable(Protocol):
        def close(self): ...

    assert isinstance(open('/some/file'), Closable)

Warning: this will check only the presence of the required methods,
not their type signatures!_

**Args**: cls


#### `__int__()` (line 794)
**Args**: self


#### `__float__()` (line 803)
**Args**: self


#### `__complex__()` (line 812)
**Args**: self


#### `__bytes__()` (line 821)
**Args**: self


#### `__index__()` (line 829)
**Args**: self


#### `__abs__()` (line 840)
**Args**: self


#### `__round__()` (line 851)
**Args**: self, ndigits


#### `_ensure_subclassable()` (line 855)
**Args**: mro_entries


#### `inner()` (line 856)
**Args**: func


#### `_get_typeddict_qualifiers()` (line 894)
**Args**: annotation_type


#### `__new__()` (line 916)
_Create new typed dict class object.

This method is called when TypedDict is subclassed,
or when TypedDict is instantiated. This way
TypedDict supports all three syntax forms described in its docstring.
Subclasses and instances of TypedDict return actual dictionaries._

**Args**: cls, name, bases, ns


#### `__subclasscheck__()` (line 1030)
**Args**: cls, other


#### `TypedDict()` (line 1039)
_A simple typed namespace. At runtime it is equivalent to a plain dict.

TypedDict creates a dictionary type such that a type checker will expect all
instances to have a certain set of keys, where each key is
associated with a value of a consistent type. This expectation
is not checked at runtime.

Usage::

    class Point2D(TypedDict):
        x: int
        y: int
        label: str

    a: Point2D = {'x': 1, 'y': 2, 'label': 'good'}  # OK
    b: Point2D = {'z': 3, 'label': 'bad'}           # Fails type check

    assert Point2D(x=1, y=2, label='first') == dict(x=1, y=2, label='first')

The type info can be accessed via the Point2D.__annotations__ dict, and
the Point2D.__required_keys__ and Point2D.__optional_keys__ frozensets.
TypedDict supports an additional equivalent form::

    Point2D = TypedDict('Point2D', {'x': int, 'y': int, 'label': str})

By default, all keys must be present in a TypedDict. It is possible
to override this by specifying totality::

    class Point2D(TypedDict, total=False):
        x: int
        y: int

This means that a Point2D TypedDict can have any of the keys omitted. A type
checker is only expected to support a literal False or True as the value of
the total argument. True is the default, and makes all items defined in the
class body be required.

The Required and NotRequired special forms can also be used to mark
individual keys as being required or not required::

    class Point2D(TypedDict):
        x: int  # the "x" key must always be present (Required is the default)
        y: NotRequired[int]  # the "y" key can be omitted

See PEP 655 for more details on Required and NotRequired._


#### `is_typeddict()` (line 1132)
_Check if an annotation is a TypedDict class

For example::
    class Film(TypedDict):
        title: str
        year: int

    is_typeddict(Film)  # => True
    is_typeddict(Union[list, str])  # => False_

**Args**: tp


#### `assert_type()` (line 1153)
_Assert (to the type checker) that the value is of the given type.

When the type checker encounters a call to assert_type(), it
emits an error if the value is not of the specified type::

    def greet(name: str) -> None:
        assert_type(name, str)  # ok
        assert_type(name, int)  # type checker error

At runtime this returns the first argument unchanged and otherwise
does nothing._


#### `_strip_extras()` (line 1173)
_Strips Annotated, Required and NotRequired from a given type._

**Args**: t


#### `get_type_hints()` (line 1197)
_Return type hints for an object.

This is often the same as obj.__annotations__, but it handles
forward references encoded as string literals, adds Optional[t] if a
default value equal to None is set and recursively replaces all
'Annotated[T, ...]', 'Required[T]' or 'NotRequired[T]' with 'T'
(unless 'include_extras=True').

The argument may be a module, class, method, or function. The annotations
are returned as a dictionary. For classes, annotations include also
inherited members.

TypeError is raised if the argument is not of a type that can contain
annotations, and an empty dictionary is returned if no annotations are
present.

BEWARE -- the behavior of globalns and localns is counterintuitive
(unless you are familiar with how eval() and exec() work).  The
search order is locals first, then globals.

- If no dict arguments are passed, an attempt is made to use the
  globals from obj (or the respective module's globals for classes),
  and these are also used as the locals.  If the object does not appear
  to have globals, an empty dictionary is used.

- If one dict argument is passed, it is used for both globals and
  locals.

- If two dict arguments are passed, they specify globals and
  locals, respectively._

**Args**: obj, globalns, localns, include_extras


#### `__init__()` (line 1256)
**Args**: self, origin, metadata


#### `copy_with()` (line 1263)
**Args**: self, params


#### `__repr__()` (line 1268)
**Args**: self


#### `__reduce__()` (line 1272)
**Args**: self


#### `__eq__()` (line 1277)
**Args**: self, other


#### `__hash__()` (line 1284)
**Args**: self


#### `__new__()` (line 1322)
**Args**: cls


#### `__class_getitem__()` (line 1326)
**Args**: cls, params


#### `__init_subclass__()` (line 1340)
**Args**: cls


#### `get_origin()` (line 1364)
_Get the unsubscripted version of a type.

This supports generic types, Callable, Tuple, Union, Literal, Final, ClassVar
and Annotated. Return None for unsupported types. Examples::

    get_origin(Literal[42]) is Literal
    get_origin(int) is None
    get_origin(ClassVar[int]) is ClassVar
    get_origin(Generic) is Generic
    get_origin(Generic[T]) is Generic
    get_origin(Union[T, int]) is Union
    get_origin(List[Tuple[T, T]][int]) == list
    get_origin(P.args) is P_

**Args**: tp


#### `get_args()` (line 1388)
_Get type arguments with all substitutions performed.

For unions, basic simplifications used by Union constructor are performed.
Examples::
    get_args(Dict[str, int]) == (str, int)
    get_args(int) == ()
    get_args(Union[int, Union[T, int], str][int]) == (int, str)
    get_args(Union[int, Tuple[T, int]][str]) == (int, Tuple[str, int])
    get_args(Callable[[], T][int]) == ([], int)_

**Args**: tp


#### `TypeAlias()` (line 1417)
_Special marker indicating that an assignment should
be recognized as a proper type alias definition by type
checkers.

For example::

    Predicate: TypeAlias = Callable[..., bool]

It's invalid when used anywhere except as in the example above._

**Args**: self, parameters


#### `__setattr__()` (line 1450)
**Args**: cls, attr, value


#### `__new__()` (line 1461)
**Args**: cls


#### `__repr__()` (line 1464)
**Args**: self


#### `__reduce__()` (line 1467)
**Args**: self


#### `_set_default()` (line 1474)
**Args**: type_param, default


#### `_set_module()` (line 1479)
**Args**: typevarlike


#### `__instancecheck__()` (line 1495)
**Args**: cls, __instance


#### `__new__()` (line 1508)
**Args**: cls, name


#### `_tvar_prepare_subst()` (line 1526)
**Args**: alias, args


#### `__init_subclass__()` (line 1537)
**Args**: cls


#### `__copy__()` (line 1551)
**Args**: self


#### `__deepcopy__()` (line 1554)
**Args**: self, memo


#### `__init__()` (line 1569)
**Args**: self, origin


#### `__repr__()` (line 1572)
**Args**: self


#### `__eq__()` (line 1575)
**Args**: self, other


#### `__init__()` (line 1592)
**Args**: self, origin


#### `__repr__()` (line 1595)
**Args**: self


#### `__eq__()` (line 1598)
**Args**: self, other


#### `__new__()` (line 1616)
**Args**: cls, name


#### `_paramspec_prepare_subst()` (line 1634)
**Args**: alias, args


#### `__init_subclass__()` (line 1653)
**Args**: cls


#### `args()` (line 1711)
**Args**: self


#### `kwargs()` (line 1715)
**Args**: self


#### `__init__()` (line 1718)
**Args**: self, name


#### `__repr__()` (line 1736)
**Args**: self


#### `__hash__()` (line 1747)
**Args**: self


#### `__eq__()` (line 1750)
**Args**: self, other


#### `__reduce__()` (line 1753)
**Args**: self


#### `__call__()` (line 1757)
**Args**: self


#### `__init__()` (line 1772)
**Args**: self, origin, args


#### `__repr__()` (line 1777)
**Args**: self


#### `__hash__()` (line 1782)
**Args**: self


#### `__call__()` (line 1786)
**Args**: self


#### `__parameters__()` (line 1790)
**Args**: self


#### `_concatenate_getitem()` (line 1798)
**Args**: self, parameters


#### `Concatenate()` (line 1818)
_Used in conjunction with ``ParamSpec`` and ``Callable`` to represent a
higher order function which adds, removes or transforms parameters of a
callable.

For example::

   Callable[Concatenate[int, P], int]

See PEP 612 for detailed information._

**Args**: self, parameters


#### `__getitem__()` (line 1833)
**Args**: self, parameters


#### `TypeGuard()` (line 1855)
_Special typing form used to annotate the return type of a user-defined
type guard function.  ``TypeGuard`` only accepts a single type argument.
At runtime, functions marked this way should return a boolean.

``TypeGuard`` aims to benefit *type narrowing* -- a technique used by static
type checkers to determine a more precise type of an expression within a
program's code flow.  Usually type narrowing is done by analyzing
conditional code flow and applying the narrowing to a block of code.  The
conditional expression here is sometimes referred to as a "type guard".

Sometimes it would be convenient to use a user-defined boolean function
as a type guard.  Such a function should use ``TypeGuard[...]`` as its
return type to alert static type checkers to this intention.

Using  ``-> TypeGuard`` tells the static type checker that for a given
function:

1. The return value is a boolean.
2. If the return value is ``True``, the type of its argument
is the type inside ``TypeGuard``.

For example::

    def is_str(val: Union[str, float]):
        # "isinstance" type guard
        if isinstance(val, str):
            # Type of ``val`` is narrowed to ``str``
            ...
        else:
            # Else, type of ``val`` is narrowed to ``float``.
            ...

Strict type narrowing is not enforced -- ``TypeB`` need not be a narrower
form of ``TypeA`` (it can even be a wider form) and this may lead to
type-unsafe results.  The main reason is to allow for things like
narrowing ``List[object]`` to ``List[str]`` even though the latter is not
a subtype of the former, since ``List`` is invariant.  The responsibility of
writing type-safe type guards is left to the user.

``TypeGuard`` also works with type variables.  For more information, see
PEP 647 (User-Defined Type Guards)._

**Args**: self, parameters


#### `__getitem__()` (line 1903)
**Args**: self, parameters


#### `TypeIs()` (line 1959)
_Special typing form used to annotate the return type of a user-defined
type narrower function.  ``TypeIs`` only accepts a single type argument.
At runtime, functions marked this way should return a boolean.

``TypeIs`` aims to benefit *type narrowing* -- a technique used by static
type checkers to determine a more precise type of an expression within a
program's code flow.  Usually type narrowing is done by analyzing
conditional code flow and applying the narrowing to a block of code.  The
conditional expression here is sometimes referred to as a "type guard".

Sometimes it would be convenient to use a user-defined boolean function
as a type guard.  Such a function should use ``TypeIs[...]`` as its
return type to alert static type checkers to this intention.

Using  ``-> TypeIs`` tells the static type checker that for a given
function:

1. The return value is a boolean.
2. If the return value is ``True``, the type of its argument
is the intersection of the type inside ``TypeGuard`` and the argument's
previously known type.

For example::

    def is_awaitable(val: object) -> TypeIs[Awaitable[Any]]:
        return hasattr(val, '__await__')

    def f(val: Union[int, Awaitable[int]]) -> int:
        if is_awaitable(val):
            assert_type(val, Awaitable[int])
        else:
            assert_type(val, int)

``TypeIs`` also works with type variables.  For more information, see
PEP 742 (Narrowing types with TypeIs)._

**Args**: self, parameters


#### `__getitem__()` (line 2001)
**Args**: self, parameters


#### `__init__()` (line 2050)
**Args**: self, getitem


#### `__getattr__()` (line 2055)
**Args**: self, item


#### `__mro_entries__()` (line 2061)
**Args**: self, bases


#### `__repr__()` (line 2064)
**Args**: self


#### `__reduce__()` (line 2067)
**Args**: self


#### `__call__()` (line 2070)
**Args**: self


#### `__or__()` (line 2073)
**Args**: self, other


#### `__ror__()` (line 2076)
**Args**: self, other


#### `__instancecheck__()` (line 2079)
**Args**: self, obj


#### `__subclasscheck__()` (line 2082)
**Args**: self, cls


#### `__getitem__()` (line 2086)
**Args**: self, parameters


#### `LiteralString()` (line 2094)
_Represents an arbitrary literal string.

Example::

  from pip._vendor.typing_extensions import LiteralString

  def query(sql: LiteralString) -> ...:
      ...

  query("SELECT * FROM table")  # ok
  query(f"SELECT * FROM {input()}")  # not ok

See PEP 675 for details._

**Args**: self, params


#### `Self()` (line 2117)
_Used to spell the type of "self" in classes.

Example::

  from typing import Self

  class ReturnsSelf:
      def parse(self, data: bytes) -> Self:
          ...
          return self_

**Args**: self, params


#### `Never()` (line 2138)
_The bottom type, a type that has no members.

This can be used to define a function that should never be
called, or a function that never returns::

    from pip._vendor.typing_extensions import Never

    def never_call_me(arg: Never) -> None:
        pass

    def int_or_str(arg: int | str) -> None:
        never_call_me(arg)  # type checker error
        match arg:
            case int():
                print("It's an int")
            case str():
                print("It's a str")
            case _:
                never_call_me(arg)  # ok, arg is of type Never_

**Args**: self, params


#### `Required()` (line 2169)
_A special typing construct to mark a key of a total=False TypedDict
as required. For example:

    class Movie(TypedDict, total=False):
        title: Required[str]
        year: int

    m = Movie(
        title='The Matrix',  # typechecker error if key is omitted
        year=1999,
    )

There is no runtime checking that a required key is actually provided
when instantiating a related TypedDict._

**Args**: self, parameters


#### `NotRequired()` (line 2189)
_A special typing construct to mark a key of a TypedDict as
potentially missing. For example:

    class Movie(TypedDict):
        title: str
        year: NotRequired[int]

    m = Movie(
        title='The Matrix',  # typechecker error if key is omitted
        year=1999,
    )_

**Args**: self, parameters


#### `__getitem__()` (line 2207)
**Args**: self, parameters


#### `ReadOnly()` (line 2249)
_A special typing construct to mark an item of a TypedDict as read-only.

For example:

    class Movie(TypedDict):
        title: ReadOnly[str]
        year: int

    def mutate_movie(m: Movie) -> None:
        m["year"] = 1992  # allowed
        m["title"] = "The Matrix"  # typechecker error

There is no runtime checking for this property._

**Args**: self, parameters


#### `__getitem__()` (line 2269)
**Args**: self, parameters


#### `_is_unpack()` (line 2337)
**Args**: obj


#### `__init__()` (line 2342)
**Args**: self, getitem


#### `__typing_unpacked_tuple_args__()` (line 2350)
**Args**: self


#### `Unpack()` (line 2361)
**Args**: self, parameters


#### `_is_unpack()` (line 2365)
**Args**: obj


#### `__getitem__()` (line 2373)
**Args**: self, parameters


#### `_is_unpack()` (line 2380)
**Args**: obj


#### `_unpack_args()` (line 2389)

#### `__new__()` (line 2405)
**Args**: cls, name


#### `_typevartuple_prepare_subst()` (line 2410)
**Args**: alias, args


#### `__init_subclass__()` (line 2458)
**Args**: self


#### `__iter__()` (line 2509)
**Args**: self


#### `__init__()` (line 2512)
**Args**: self, name


#### `__repr__()` (line 2523)
**Args**: self


#### `__hash__()` (line 2526)
**Args**: self


#### `__eq__()` (line 2529)
**Args**: self, other


#### `__reduce__()` (line 2532)
**Args**: self


#### `__init_subclass__()` (line 2535)
**Args**: self


#### `reveal_type()` (line 2543)
_Reveal the inferred type of a variable.

When a static type checker encounters a call to ``reveal_type()``,
it will emit the inferred type of the argument::

    x: int = 1
    reveal_type(x)

Running a static type checker (e.g., ``mypy``) on this example
will produce output similar to 'Revealed type is "builtins.int"'.

At runtime, the function prints the runtime type of the
argument and returns it unchanged._


#### `assert_never()` (line 2572)
_Assert to the type checker that a line of code is unreachable.

Example::

    def int_or_str(arg: int | str) -> None:
        match arg:
            case int():
                print("It's an int")
            case str():
                print("It's a str")
            case _:
                assert_never(arg)

If a type checker finds that a call to assert_never() is
reachable, it will emit an error.

At runtime, this throws an exception when called._


#### `dataclass_transform()` (line 2602)
_Decorator that marks a function, class, or metaclass as providing
dataclass-like behavior.

Example:

    from pip._vendor.typing_extensions import dataclass_transform

    _T = TypeVar("_T")

    # Used on a decorator function
    @dataclass_transform()
    def create_model(cls: type[_T]) -> type[_T]:
        ...
        return cls

    @create_model
    class CustomerModel:
        id: int
        name: str

    # Used on a base class
    @dataclass_transform()
    class ModelBase: ...

    class CustomerModel(ModelBase):
        id: int
        name: str

    # Used on a metaclass
    @dataclass_transform()
    class ModelMeta(type): ...

    class ModelBase(metaclass=ModelMeta): ...

    class CustomerModel(ModelBase):
        id: int
        name: str

Each of the ``CustomerModel`` classes defined in this example will now
behave similarly to a dataclass created with the ``@dataclasses.dataclass``
decorator. For example, the type checker will synthesize an ``__init__``
method.

The arguments to this decorator can be used to customize this behavior:
- ``eq_default`` indicates whether the ``eq`` parameter is assumed to be
  True or False if it is omitted by the caller.
- ``order_default`` indicates whether the ``order`` parameter is
  assumed to be True or False if it is omitted by the caller.
- ``kw_only_default`` indicates whether the ``kw_only`` parameter is
  assumed to be True or False if it is omitted by the caller.
- ``frozen_default`` indicates whether the ``frozen`` parameter is
  assumed to be True or False if it is omitted by the caller.
- ``field_specifiers`` specifies a static list of supported classes
  or functions that describe fields, similar to ``dataclasses.field()``.

At runtime, this decorator records its arguments in the
``__dataclass_transform__`` attribute on the decorated object.

See PEP 681 for details._


#### `decorator()` (line 2675)
**Args**: cls_or_fn


#### `override()` (line 2693)
_Indicate that a method is intended to override a method in a base class.

Usage:

    class Base:
        def method(self) -> None:
            pass

    class Child(Base):
        @override
        def method(self) -> None:
            super().method()

When this decorator is applied to a method, the type checker will
validate that it overrides a method with the same name on a base class.
This helps prevent bugs that may occur when a base class is changed
without an equivalent change to a child class.

There is no runtime checking of these properties. The decorator
sets the ``__override__`` attribute to ``True`` on the decorated object
to allow runtime introspection.

See PEP 698 for details._


#### `__init__()` (line 2776)

#### `__call__()` (line 2793)

#### `__new__()` (line 2809)
**Args**: cls


#### `__init_subclass__()` (line 2829)

#### `__init_subclass__()` (line 2838)

#### `wrapper()` (line 2851)

#### `_check_generic()` (line 2872)
_Check correct count for parameters of a generic cls (internal helper).

This gives a nice error message in case of count mismatch._

**Args**: cls, parameters, elen


#### `_check_generic()` (line 2916)
_Check correct count for parameters of a generic cls (internal helper).

This gives a nice error message in case of count mismatch._

**Args**: cls, parameters, elen


#### `_has_generic_or_protocol_as_origin()` (line 2954)

#### `_is_unpacked_typevartuple()` (line 2976)
**Args**: x


#### `_collect_type_vars()` (line 2989)
_Collect all type variable contained in types in order of
first appearance (lexicographic order). For example::

    _collect_type_vars((T, List[S, T])) == (T, S)_

**Args**: types, typevar_types


#### `_collect_parameters()` (line 3029)
_Collect all type variables and parameter specifications in args
in order of first appearance (lexicographic order).

For example::

    assert _collect_parameters((T, Callable[P, T])) == (T, P)_

**Args**: args


#### `_make_nmtuple()` (line 3096)
**Args**: name, types, module, defaults


#### `__new__()` (line 3113)
**Args**: cls, typename, bases, ns


#### `_namedtuple_mro_entries()` (line 3184)
**Args**: bases


#### `NamedTuple()` (line 3189)
_Typed version of namedtuple.

Usage::

    class Employee(NamedTuple):
        name: str
        id: int

This is equivalent to::

    Employee = collections.namedtuple('Employee', ['name', 'id'])

The resulting class has an extra __annotations__ attribute, giving a
dict that maps field names to types.  (The field names are also in
the _fields attribute, which is part of the namedtuple API.)
An alternative equivalent functional syntax is also accepted::

    Employee = NamedTuple('Employee', [('name', str), ('id', int)])_


#### `get_original_bases()` (line 3288)
_Return the class's "original" bases prior to modification by `__mro_entries__`.

Examples::

    from typing import TypeVar, Generic
    from pip._vendor.typing_extensions import NamedTuple, TypedDict

    T = TypeVar("T")
    class Foo(Generic[T]): ...
    class Bar(Foo[int], float): ...
    class Baz(list[str]): ...
    Eggs = NamedTuple("Eggs", [("a", int), ("b", str)])
    Spam = TypedDict("Spam", {"a": int, "b": str})

    assert get_original_bases(Bar) == (Foo[int], float)
    assert get_original_bases(Baz) == (list[str],)
    assert get_original_bases(Eggs) == (NamedTuple,)
    assert get_original_bases(Spam) == (TypedDict,)
    assert get_original_bases(int) == (object,)_


#### `__call__()` (line 3336)

#### `__init__()` (line 3339)
**Args**: self, name, tp


#### `__mro_entries__()` (line 3349)
**Args**: self, bases


#### `__init_subclass__()` (line 3355)
**Args**: cls


#### `__repr__()` (line 3365)
**Args**: self


#### `__reduce__()` (line 3368)
**Args**: self


#### `__or__()` (line 3375)
**Args**: self, other


#### `__ror__()` (line 3378)
**Args**: self, other


#### `_is_unionable()` (line 3385)
_Corresponds to is_unionable() in unionobject.c in CPython._

**Args**: obj


#### `__init__()` (line 3422)
**Args**: self, name, value


#### `__setattr__()` (line 3441)

#### `__delattr__()` (line 3446)

#### `_raise_attribute_error()` (line 3449)
**Args**: self, name


#### `__repr__()` (line 3463)
**Args**: self


#### `__getitem__()` (line 3466)
**Args**: self, parameters


#### `__reduce__()` (line 3477)
**Args**: self


#### `__init_subclass__()` (line 3480)
**Args**: cls


#### `__call__()` (line 3487)
**Args**: self


#### `__or__()` (line 3491)
**Args**: self, right


#### `__ror__()` (line 3498)
**Args**: self, left


#### `is_protocol()` (line 3508)
_Return True if the given type is a Protocol.

Example::

    >>> from typing_extensions import Protocol, is_protocol
    >>> class P(Protocol):
    ...     def a(self) -> str: ...
    ...     b: int
    >>> is_protocol(P)
    True
    >>> is_protocol(int)
    False_


#### `get_protocol_members()` (line 3529)
_Return the set of members defined in a Protocol.

Example::

    >>> from typing_extensions import Protocol, get_protocol_members
    >>> class P(Protocol):
    ...     def a(self) -> str: ...
    ...     b: int
    >>> get_protocol_members(P)
    frozenset({'a', 'b'})

Raise a TypeError for arguments that are not Protocols._


#### `__init__()` (line 3570)

#### `__repr__()` (line 3573)
**Args**: self


#### `__hash__()` (line 3576)
**Args**: self


#### `__eq__()` (line 3579)
**Args**: self, other


### venv_new\Lib\site-packages\pip\_vendor\urllib3\__init__.py

#### `add_stderr_logger()` (line 63)
_Helper for quickly adding a StreamHandler to the logger. Useful for
debugging.

Returns the handler after adding it._

**Args**: level


#### `disable_warnings()` (line 98)
_Helper for quickly disabling all urllib3 warnings._

**Args**: category


### venv_new\Lib\site-packages\pip\_vendor\urllib3\_collections.py

#### `__enter__()` (line 12)
**Args**: self


#### `__exit__()` (line 15)
**Args**: self, exc_type, exc_value, traceback


#### `__init__()` (line 47)
**Args**: self, maxsize, dispose_func


#### `__getitem__()` (line 54)
**Args**: self, key


#### `__setitem__()` (line 61)
**Args**: self, key, value


#### `__delitem__()` (line 76)
**Args**: self, key


#### `__len__()` (line 83)
**Args**: self


#### `__iter__()` (line 87)
**Args**: self


#### `clear()` (line 92)
**Args**: self


#### `keys()` (line 102)
**Args**: self


#### `__init__()` (line 141)
**Args**: self, headers


#### `__setitem__()` (line 152)
**Args**: self, key, val


#### `__getitem__()` (line 156)
**Args**: self, key


#### `__delitem__()` (line 160)
**Args**: self, key


#### `__contains__()` (line 163)
**Args**: self, key


#### `__eq__()` (line 166)
**Args**: self, other


#### `__ne__()` (line 175)
**Args**: self, other


#### `__len__()` (line 184)
**Args**: self


#### `__iter__()` (line 187)
**Args**: self


#### `pop()` (line 192)
_D.pop(k[,d]) -> v, remove specified key and return the corresponding value.
If key is not found, d is returned if given, otherwise KeyError is raised._

**Args**: self, key, default


#### `discard()` (line 209)
**Args**: self, key


#### `add()` (line 215)
_Adds a (name, value) pair, doesn't overwrite the value if it already
exists.

>>> headers = HTTPHeaderDict(foo='bar')
>>> headers.add('Foo', 'baz')
>>> headers['foo']
'bar, baz'_

**Args**: self, key, val


#### `extend()` (line 231)
_Generic import function for any type of header-like object.
Adapted version of MutableMapping.update in order to insert items
with self.add instead of self.__setitem___

**Args**: self


#### `getlist()` (line 259)
_Returns a list of all the values for the named field. Returns an
empty list if the key doesn't exist._

**Args**: self, key, default


#### `_prepare_for_method_change()` (line 271)
_Remove content-specific header fields before changing the request
method to GET or HEAD according to RFC 9110, Section 15.4._

**Args**: self


#### `__repr__()` (line 297)
**Args**: self


#### `_copy_from()` (line 300)
**Args**: self, other


#### `copy()` (line 308)
**Args**: self


#### `iteritems()` (line 313)
_Iterate over all header lines, including duplicate ones._

**Args**: self


#### `itermerged()` (line 320)
_Iterate over all headers, merging duplicate ones together._

**Args**: self


#### `items()` (line 326)
**Args**: self


#### `from_httplib()` (line 330)
_Read headers from a Python 2 httplib message object._

**Args**: cls, message


### venv_new\Lib\site-packages\pip\_vendor\urllib3\connection.py

#### `__init__()` (line 115)
**Args**: self


#### `host()` (line 133)
_Getter method to remove any trailing dots that indicate the hostname is an FQDN.

In general, SSL certificates don't include the trailing dot indicating a
fully-qualified domain name, and thus, they don't validate properly when
checked against a domain name that includes the dot. In addition, some
servers may not expect to receive the trailing dot when provided.

However, the hostname with trailing dot is critical to DNS resolution; doing a
lookup with the trailing dot will properly only resolve the appropriate FQDN,
whereas a lookup without a trailing dot will search the system's search domain
list. Thus, it's important to keep the original host around for use only in
those cases where it's appropriate (i.e., when doing DNS lookup to establish the
actual TCP connection across which we're going to send HTTP requests)._

**Args**: self


#### `host()` (line 152)
_Setter for the `host` property.

We assume that only urllib3 uses the _dns_host attribute; httplib itself
only uses `host`, and it seems reasonable that other libraries follow suit._

**Args**: self, value


#### `_new_conn()` (line 161)
_Establish a socket connection and set nodelay settings on it.

:return: New socket connection._

**Args**: self


#### `_is_using_tunnel()` (line 192)
**Args**: self


#### `_prepare_conn()` (line 196)
**Args**: self, conn


#### `connect()` (line 204)
**Args**: self


#### `putrequest()` (line 208)
**Args**: self, method, url


#### `putheader()` (line 221)
**Args**: self, header


#### `request()` (line 231)
**Args**: self, method, url, body, headers


#### `request_chunked()` (line 246)
_Alternative to the common request method, which sends the
body with chunked encoding and not as one block_

**Args**: self, method, url, body, headers


#### `__init__()` (line 302)
**Args**: self, host, port, key_file, cert_file, key_password, strict, timeout, ssl_context, server_hostname


#### `set_cert()` (line 328)
_This method should only be called once, before the connection is used._

**Args**: self, key_file, cert_file, cert_reqs, key_password, ca_certs, assert_hostname, assert_fingerprint, ca_cert_dir, ca_cert_data


#### `connect()` (line 361)
**Args**: self


#### `_connect_tls_proxy()` (line 479)
_Establish a TLS connection to the proxy using the provided SSL context._

**Args**: self, hostname, conn


#### `_match_hostname()` (line 536)
**Args**: cert, asserted_hostname


#### `_get_default_user_agent()` (line 558)

### venv_new\Lib\site-packages\pip\_vendor\urllib3\connectionpool.py

#### `__init__()` (line 83)
**Args**: self, host, port


#### `__str__()` (line 91)
**Args**: self


#### `__enter__()` (line 94)
**Args**: self


#### `__exit__()` (line 97)
**Args**: self, exc_type, exc_val, exc_tb


#### `close()` (line 102)
_Close all pooled connections and disable the pool._

**Args**: self


#### `__init__()` (line 177)
**Args**: self, host, port, strict, timeout, maxsize, block, headers, retries, _proxy, _proxy_headers, _proxy_config


#### `_new_conn()` (line 241)
_Return a fresh :class:`HTTPConnection`._

**Args**: self


#### `_get_conn()` (line 262)
_Get a connection. Will return a pooled connection if one is available.

If no connections are available and :prop:`.block` is ``False``, then a
fresh connection is returned.

:param timeout:
    Seconds to wait before giving up and raising
    :class:`urllib3.exceptions.EmptyPoolError` if the pool is empty and
    :prop:`.block` is ``True``._

**Args**: self, timeout


#### `_put_conn()` (line 301)
_Put a connection back into the pool.

:param conn:
    Connection object for the current host and port as returned by
    :meth:`._new_conn` or :meth:`._get_conn`.

If the pool is already full, the connection is closed and discarded
because we exceeded maxsize. If connections are discarded frequently,
then maxsize should be increased.

If the pool is closed, then the connection will be closed and discarded._

**Args**: self, conn


#### `_validate_conn()` (line 332)
_Called right before a request is made, after the socket is created._

**Args**: self, conn


#### `_prepare_proxy()` (line 338)
**Args**: self, conn


#### `_get_timeout()` (line 342)
_Helper that always returns a :class:`urllib3.util.Timeout`_

**Args**: self, timeout


#### `_raise_timeout()` (line 354)
_Is the error actually a timeout? Will raise a ReadTimeout or pass_

**Args**: self, err, url, timeout_value


#### `_make_request()` (line 379)
_Perform a request on a given urllib connection object taken from our
pool.

:param conn:
    a connection from one of our connection pools

:param timeout:
    Socket timeout in seconds for the request. This can be a
    float or integer, which will set the same timeout value for
    the socket connect and the socket read, or an instance of
    :class:`urllib3.util.Timeout`, which gives you more fine-grained
    control over your timeouts._

**Args**: self, conn, method, url, timeout, chunked


#### `_absolute_url()` (line 499)
**Args**: self, path


#### `close()` (line 502)
_Close all pooled connections and disable the pool._

**Args**: self


#### `is_same_host()` (line 514)
_Check if the given ``url`` is a member of the same host as this
connection pool._

**Args**: self, url


#### `urlopen()` (line 535)
_Get a connection from the pool and perform an HTTP request. This is the
lowest level call for making a request, so you'll need to specify all
the raw details.

.. note::

   More commonly, it's appropriate to use a convenience method provided
   by :class:`.RequestMethods`, such as :meth:`request`.

.. note::

   `release_conn` will only behave as expected if
   `preload_content=False` because we want to make
   `preload_content=False` the default behaviour someday soon without
   breaking backwards compatibility.

:param method:
    HTTP request method (such as GET, POST, PUT, etc.)

:param url:
    The URL to perform the request on.

:param body:
    Data to send in the request body, either :class:`str`, :class:`bytes`,
    an iterable of :class:`str`/:class:`bytes`, or a file-like object.

:param headers:
    Dictionary of custom headers to send, such as User-Agent,
    If-None-Match, etc. If None, pool headers are used. If provided,
    these headers completely replace any pool-specific headers.

:param retries:
    Configure the number of retries to allow before raising a
    :class:`~urllib3.exceptions.MaxRetryError` exception.

    Pass ``None`` to retry until you receive a response. Pass a
    :class:`~urllib3.util.retry.Retry` object for fine-grained control
    over different types of retries.
    Pass an integer number to retry connection errors that many times,
    but no other types of errors. Pass zero to never retry.

    If ``False``, then retries are disabled and any exception is raised
    immediately. Also, instead of raising a MaxRetryError on redirects,
    the redirect response will be returned.

:type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.

:param redirect:
    If True, automatically handle redirects (status codes 301, 302,
    303, 307, 308). Each redirect counts as a retry. Disabling retries
    will disable redirect, too.

:param assert_same_host:
    If ``True``, will make sure that the host of the pool requests is
    consistent else will raise HostChangedError. When ``False``, you can
    use the pool on an HTTP proxy and request foreign hosts.

:param timeout:
    If specified, overrides the default timeout for this one
    request. It may be a float (in seconds) or an instance of
    :class:`urllib3.util.Timeout`.

:param pool_timeout:
    If set and the pool is set to block=True, then this method will
    block for ``pool_timeout`` seconds and raise EmptyPoolError if no
    connection is available within the time period.

:param release_conn:
    If False, then the urlopen call will not release the connection
    back into the pool once a response is received (but will release if
    you read the entire contents of the response such as when
    `preload_content=True`). This is useful if you're not preloading
    the response's content immediately. You will need to call
    ``r.release_conn()`` on the response ``r`` to return the connection
    back into the pool. If None, it takes the value of
    ``response_kw.get('preload_content', True)``.

:param chunked:
    If True, urllib3 will send the body using chunked transfer
    encoding. Otherwise, urllib3 will send the body using the standard
    content-length form. Defaults to False.

:param int body_pos:
    Position to seek to in file-like body in the event of a retry or
    redirect. Typically this won't need to be set because urllib3 will
    auto-populate the value when needed.

:param \**response_kw:
    Additional parameters are passed to
    :meth:`urllib3.response.HTTPResponse.from_httplib`_

**Args**: self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos


#### `_is_ssl_error_message_from_http_proxy()` (line 766)
**Args**: ssl_error


#### `__init__()` (line 933)
**Args**: self, host, port, strict, timeout, maxsize, block, headers, retries, _proxy, _proxy_headers, key_file, cert_file, cert_reqs, key_password, ca_certs, ssl_version, assert_hostname, assert_fingerprint, ca_cert_dir


#### `_prepare_conn()` (line 982)
_Prepare the ``connection`` for :meth:`urllib3.util.ssl_wrap_socket`
and establish the tunnel if proxy is used._

**Args**: self, conn


#### `_prepare_proxy()` (line 1002)
_Establishes a tunnel connection through HTTP CONNECT.

Tunnel connection is established early because otherwise httplib would
improperly set Host: header to proxy's IP:port._

**Args**: self, conn


#### `_new_conn()` (line 1017)
_Return a fresh :class:`http.client.HTTPSConnection`._

**Args**: self


#### `_validate_conn()` (line 1053)
_Called right before a request is made, after the socket is created._

**Args**: self, conn


#### `connection_from_url()` (line 1086)
_Given a url, return an :class:`.ConnectionPool` instance of its host.

This is a shortcut for not having to parse out the scheme, host, and port
of the url before creating an :class:`.ConnectionPool` instance.

:param url:
    Absolute URL string that must include the scheme. Port is optional.

:param \**kw:
    Passes additional parameters to the constructor of the appropriate
    :class:`.ConnectionPool`. Useful for specifying things like
    timeout, maxsize, headers, etc.

Example::

    >>> conn = connection_from_url('http://google.com/')
    >>> r = conn.request('GET', '/')_

**Args**: url


#### `_normalize_host()` (line 1114)
_Normalize hosts for comparisons and use with sockets._

**Args**: host, scheme


#### `_close_pool_connections()` (line 1132)
_Drains a queue of connections and closes each one._

**Args**: pool


### venv_new\Lib\site-packages\pip\_vendor\urllib3\contrib\_appengine_environ.py

#### `is_appengine()` (line 8)

#### `is_appengine_sandbox()` (line 12)
_Reports if the app is running in the first generation sandbox.

The second generation runtimes are technically still in a sandbox, but it
is much less restrictive, so generally you shouldn't need to check for it.
see https://cloud.google.com/appengine/docs/standard/runtimes_


#### `is_local_appengine()` (line 22)

#### `is_prod_appengine()` (line 28)

#### `is_prod_appengine_mvms()` (line 34)
_Deprecated._


### venv_new\Lib\site-packages\pip\_vendor\urllib3\contrib\_securetransport\bindings.py

#### `load_cdll()` (line 65)
_Loads a CDLL by name, falling back to known path on 10.16+_

**Args**: name, macos10_16_path


### venv_new\Lib\site-packages\pip\_vendor\urllib3\contrib\_securetransport\low_level.py

#### `_cf_data_from_bytes()` (line 27)
_Given a bytestring, create a CFData object from it. This CFData object must
be CFReleased by the caller._

**Args**: bytestring


#### `_cf_dictionary_from_tuples()` (line 37)
_Given a list of Python tuples, create an associated CFDictionary._

**Args**: tuples


#### `_cfstr()` (line 59)
_Given a Python binary data, create a CFString.
The string must be CFReleased by the caller._

**Args**: py_bstr


#### `_create_cfstring_array()` (line 73)
_Given a list of Python binary data, create an associated CFMutableArray.
The array must be CFReleased by the caller.

Raises an ssl.SSLError on failure._

**Args**: lst


#### `_cf_string_to_unicode()` (line 104)
_Creates a Unicode string from a CFString object. Used entirely for error
reporting.

Yes, it annoys me quite a lot that this function is this complex._

**Args**: value


#### `_assert_no_error()` (line 129)
_Checks the return code and throws an exception if there is an error to
report_

**Args**: error, exception_class


#### `_cert_array_from_pem()` (line 150)
_Given a bundle of certs in PEM format, turns them into a CFArray of certs
that can be used to validate a cert chain._

**Args**: pem_bundle


#### `_is_cert()` (line 196)
_Returns True if a given CFTypeRef is a certificate._

**Args**: item


#### `_is_identity()` (line 204)
_Returns True if a given CFTypeRef is an identity._

**Args**: item


#### `_temporary_keychain()` (line 212)
_This function creates a temporary Mac keychain that we can use to work with
credentials. This keychain uses a one-time password and a temporary file to
store the data. We expect to have one keychain per socket. The returned
SecKeychainRef must be freed by the caller, including calling
SecKeychainDelete.

Returns a tuple of the SecKeychainRef and the path to the temporary
directory that contains it._


#### `_load_items_from_file()` (line 247)
_Given a single file, loads all the trust objects from it into arrays and
the keychain.
Returns a tuple of lists: the first list is a list of identities, the
second a list of certs._

**Args**: keychain, path


#### `_load_client_cert_chain()` (line 302)
_Load certificates and maybe keys from a number of files. Has the end goal
of returning a CFArray containing one SecIdentityRef, and then zero or more
SecCertificateRef objects, suitable for use as a client certificate trust
chain._

**Args**: keychain


#### `_build_tls_unknown_ca_alert()` (line 386)
_Builds a TLS alert record for an unknown CA._

**Args**: version


### venv_new\Lib\site-packages\pip\_vendor\urllib3\contrib\appengine.py

#### `__init__()` (line 99)
**Args**: self, headers, retries, validate_certificate, urlfetch_retries


#### `__enter__()` (line 124)
**Args**: self


#### `__exit__()` (line 127)
**Args**: self, exc_type, exc_val, exc_tb


#### `urlopen()` (line 131)
**Args**: self, method, url, body, headers, retries, redirect, timeout


#### `_urlfetch_response_to_http_response()` (line 245)
**Args**: self, urlfetch_resp


#### `_get_absolute_timeout()` (line 281)
**Args**: self, timeout


#### `_get_retries()` (line 294)
**Args**: self, retries, redirect


### venv_new\Lib\site-packages\pip\_vendor\urllib3\contrib\ntlmpool.py

#### `__init__()` (line 34)
_authurl is a random URL on the server that is protected by NTLM.
user is the Windows user, probably in the DOMAIN\username format.
pw is the password for the user._

**Args**: self, user, pw, authurl


#### `_new_conn()` (line 48)
**Args**: self


#### `urlopen()` (line 115)
**Args**: self, method, url, body, headers, retries, redirect, assert_same_host


### venv_new\Lib\site-packages\pip\_vendor\urllib3\contrib\pyopenssl.py

#### `inject_into_urllib3()` (line 130)
_Monkey-patch urllib3 with PyOpenSSL-backed SSL-support._


#### `extract_from_urllib3()` (line 143)
_Undo monkey-patching by :func:`inject_into_urllib3`._


#### `_validate_dependencies_met()` (line 154)
_Verifies that PyOpenSSL's package-level dependencies have been met.
Throws `ImportError` if they are not met._


#### `_dnsname_to_stdlib()` (line 180)
_Converts a dNSName SubjectAlternativeName field to the form used by the
standard library on the given Python version.

Cryptography produces a dNSName as a unicode string that was idna-decoded
from ASCII bytes. We need to idna-encode that string to get it back, and
then on Python 3 we also need to convert to unicode via UTF-8 (the stdlib
uses PyUnicode_FromStringAndSize on it, which decodes via UTF-8).

If the name cannot be idna-encoded then we return None signalling that
the name given should be skipped._

**Args**: name


#### `idna_encode()` (line 194)
_Borrowed wholesale from the Python Cryptography Project. It turns out
that we can't just safely call `idna.encode`: it can explode for
wildcard names. This avoids that problem._

**Args**: name


#### `get_subj_alt_name()` (line 223)
_Given an PyOpenSSL certificate, provides all the subject alternative names._

**Args**: peer_cert


#### `__init__()` (line 283)
**Args**: self, connection, socket, suppress_ragged_eofs


#### `fileno()` (line 290)
**Args**: self


#### `_decref_socketios()` (line 294)
**Args**: self


#### `recv()` (line 300)
**Args**: self


#### `recv_into()` (line 325)
**Args**: self


#### `settimeout()` (line 348)
**Args**: self, timeout


#### `_send_until_done()` (line 351)
**Args**: self, data


#### `sendall()` (line 362)
**Args**: self, data


#### `shutdown()` (line 370)
**Args**: self


#### `close()` (line 374)
**Args**: self


#### `getpeercert()` (line 384)
**Args**: self, binary_form


#### `version()` (line 398)
**Args**: self


#### `_reuse()` (line 401)
**Args**: self


#### `_drop()` (line 404)
**Args**: self


#### `makefile()` (line 413)
**Args**: self, mode, bufsize


#### `__init__()` (line 430)
**Args**: self, protocol


#### `options()` (line 437)
**Args**: self


#### `options()` (line 441)
**Args**: self, value


#### `verify_mode()` (line 446)
**Args**: self


#### `verify_mode()` (line 450)
**Args**: self, value


#### `set_default_verify_paths()` (line 453)
**Args**: self


#### `set_ciphers()` (line 456)
**Args**: self, ciphers


#### `load_verify_locations()` (line 461)
**Args**: self, cafile, capath, cadata


#### `load_cert_chain()` (line 473)
**Args**: self, certfile, keyfile, password


#### `set_alpn_protocols()` (line 481)
**Args**: self, protocols


#### `wrap_socket()` (line 485)
**Args**: self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname


#### `_verify_callback()` (line 517)
**Args**: cnx, x509, err_no, err_depth, return_code


### venv_new\Lib\site-packages\pip\_vendor\urllib3\contrib\securetransport.py

#### `inject_into_urllib3()` (line 188)
_Monkey-patch urllib3 with SecureTransport-backed SSL-support._


#### `extract_from_urllib3()` (line 200)
_Undo monkey-patching by :func:`inject_into_urllib3`._


#### `_read_callback()` (line 212)
_SecureTransport read callback. This is called by ST to request that data
be returned from the socket._

**Args**: connection_id, data_buffer, data_length_pointer


#### `_write_callback()` (line 267)
_SecureTransport write callback. This is called by ST to request that data
actually be sent on the network._

**Args**: connection_id, data_buffer, data_length_pointer


#### `__init__()` (line 333)
**Args**: self, socket


#### `_raise_on_error()` (line 352)
_A context manager that can be used to wrap calls that do I/O from
SecureTransport. If any of the I/O callbacks hit an exception, this
context manager will correctly propagate the exception after the fact.
This avoids silently swallowing those exceptions.

It also correctly forces the socket closed._

**Args**: self


#### `_set_ciphers()` (line 372)
_Sets up the allowed ciphers. By default this matches the set in
util.ssl_.DEFAULT_CIPHERS, at least as supported by macOS. This is done
custom and doesn't allow changing at this time, mostly because parsing
OpenSSL cipher strings is going to be a freaking nightmare._

**Args**: self


#### `_set_alpn_protocols()` (line 385)
_Sets up the ALPN protocols on the context._

**Args**: self, protocols


#### `_custom_validate()` (line 398)
_Called when we have set custom validation. We do this in two cases:
first, when cert validation is entirely disabled; and second, when
using a custom trust DB.
Raises an SSLError if the connection is not trusted._

**Args**: self, verify, trust_bundle


#### `_evaluate_trust()` (line 433)
**Args**: self, trust_bundle


#### `handshake()` (line 473)
_Actually performs the TLS handshake. This is run automatically by
wrapped socket, and shouldn't be needed in user code._

**Args**: self, server_hostname, verify, trust_bundle, min_version, max_version, client_cert, client_key, client_key_passphrase, alpn_protocols


#### `fileno()` (line 566)
**Args**: self


#### `_decref_socketios()` (line 570)
**Args**: self


#### `recv()` (line 576)
**Args**: self, bufsiz


#### `recv_into()` (line 582)
**Args**: self, buffer, nbytes


#### `settimeout()` (line 625)
**Args**: self, timeout


#### `gettimeout()` (line 628)
**Args**: self


#### `send()` (line 631)
**Args**: self, data


#### `sendall()` (line 648)
**Args**: self, data


#### `shutdown()` (line 654)
**Args**: self


#### `close()` (line 658)
**Args**: self


#### `getpeercert()` (line 677)
**Args**: self, binary_form


#### `version()` (line 735)
**Args**: self


#### `_reuse()` (line 756)
**Args**: self


#### `_drop()` (line 759)
**Args**: self


#### `makefile()` (line 768)
**Args**: self, mode, bufsize


#### `makefile()` (line 774)
**Args**: self, mode, buffering


#### `__init__()` (line 791)
**Args**: self, protocol


#### `check_hostname()` (line 802)
_SecureTransport cannot have its hostname checking disabled. For more,
see the comment on getpeercert() in this file._

**Args**: self


#### `check_hostname()` (line 810)
_SecureTransport cannot have its hostname checking disabled. For more,
see the comment on getpeercert() in this file._

**Args**: self, value


#### `options()` (line 818)
**Args**: self


#### `options()` (line 828)
**Args**: self, value


#### `verify_mode()` (line 833)
**Args**: self


#### `verify_mode()` (line 837)
**Args**: self, value


#### `set_default_verify_paths()` (line 840)
**Args**: self


#### `load_default_certs()` (line 852)
**Args**: self


#### `set_ciphers()` (line 855)
**Args**: self, ciphers


#### `load_verify_locations()` (line 860)
**Args**: self, cafile, capath, cadata


#### `load_cert_chain()` (line 872)
**Args**: self, certfile, keyfile, password


#### `set_alpn_protocols()` (line 877)
_Sets the ALPN protocols that will later be set on the context.

Raises a NotImplementedError if ALPN is not supported._

**Args**: self, protocols


#### `wrap_socket()` (line 889)
**Args**: self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname


### venv_new\Lib\site-packages\pip\_vendor\urllib3\contrib\socks.py

#### `__init__()` (line 80)
**Args**: self


#### `_new_conn()` (line 84)
_Establish a new connection via the SOCKS proxy._

**Args**: self


#### `__init__()` (line 170)
**Args**: self, proxy_url, username, password, num_pools, headers


### venv_new\Lib\site-packages\pip\_vendor\urllib3\exceptions.py

#### `__init__()` (line 23)
**Args**: self, pool, message


#### `__reduce__()` (line 27)
**Args**: self


#### `__init__()` (line 35)
**Args**: self, pool, url, message


#### `__reduce__()` (line 39)
**Args**: self


#### `__init__()` (line 53)
**Args**: self, message, error


#### `__init__()` (line 87)
**Args**: self, pool, url, reason


#### `__init__()` (line 98)
**Args**: self, pool, url, retries


#### `__init__()` (line 161)
**Args**: self, location


#### `__init__()` (line 171)
**Args**: self, scheme


#### `__init__()` (line 253)
**Args**: self, partial, expected


#### `__repr__()` (line 256)
**Args**: self


#### `__init__()` (line 266)
**Args**: self, response, length


#### `__repr__()` (line 273)
**Args**: self


#### `__init__()` (line 291)
**Args**: self, scheme


#### `__init__()` (line 315)
**Args**: self, defects, unparsed_data


### venv_new\Lib\site-packages\pip\_vendor\urllib3\fields.py

#### `guess_content_type()` (line 10)
_Guess the "Content-Type" of a file.

:param filename:
    The filename to guess the "Content-Type" of using :mod:`mimetypes`.
:param default:
    If no "Content-Type" can be guessed, default to `default`._

**Args**: filename, default


#### `format_header_param_rfc2231()` (line 24)
_Helper function to format and quote a single header parameter using the
strategy defined in RFC 2231.

Particularly useful for header parameters which might contain
non-ASCII values, like file names. This follows
`RFC 2388 Section 4.4 <https://tools.ietf.org/html/rfc2388#section-4.4>`_.

:param name:
    The name of the parameter, a string expected to be ASCII only.
:param value:
    The value of the parameter, provided as ``bytes`` or `str``.
:ret:
    An RFC-2231-formatted unicode string._

**Args**: name, value


#### `_replace_multiple()` (line 82)
**Args**: value, needles_and_replacements


#### `replacer()` (line 83)
**Args**: match


#### `format_header_param_html5()` (line 95)
_Helper function to format and quote a single header parameter using the
HTML5 strategy.

Particularly useful for header parameters which might contain
non-ASCII values, like file names. This follows the `HTML5 Working Draft
Section 4.10.22.7`_ and matches the behavior of curl and modern browsers.

.. _HTML5 Working Draft Section 4.10.22.7:
    https://w3c.github.io/html/sec-forms.html#multipart-form-data

:param name:
    The name of the parameter, a string expected to be ASCII only.
:param value:
    The value of the parameter, provided as ``bytes`` or `str``.
:ret:
    A unicode string, stripped of troublesome characters._

**Args**: name, value


#### `__init__()` (line 143)
**Args**: self, name, data, filename, headers, header_formatter


#### `from_tuples()` (line 160)
_A :class:`~urllib3.fields.RequestField` factory from old-style tuple parameters.

Supports constructing :class:`~urllib3.fields.RequestField` from
parameter of key/value strings AND key/filetuple. A filetuple is a
(filename, data, MIME type) tuple where the MIME type is optional.
For example::

    'foo': 'bar',
    'fakefile': ('foofile.txt', 'contents of foofile'),
    'realfile': ('barfile.txt', open('realfile').read()),
    'typedfile': ('bazfile.bin', open('bazfile').read(), 'image/jpeg'),
    'nonamefile': 'contents of nonamefile field',

Field names and filenames must be unicode._

**Args**: cls, fieldname, value, header_formatter


#### `_render_part()` (line 195)
_Overridable helper function to format a single header parameter. By
default, this calls ``self.header_formatter``.

:param name:
    The name of the parameter, a string expected to be ASCII only.
:param value:
    The value of the parameter, provided as a unicode string._

**Args**: self, name, value


#### `_render_parts()` (line 208)
_Helper function to format and quote a single header.

Useful for single headers that are composed of multiple items. E.g.,
'Content-Disposition' fields.

:param header_parts:
    A sequence of (k, v) tuples or a :class:`dict` of (k, v) to format
    as `k1="v1"; k2="v2"; ...`._

**Args**: self, header_parts


#### `render_headers()` (line 230)
_Renders the headers for this request field._

**Args**: self


#### `make_multipart()` (line 249)
_Makes this request field into a multipart request field.

This method overrides "Content-Disposition", "Content-Type" and
"Content-Location" headers to the request parameter.

:param content_type:
    The 'Content-Type' of the request body.
:param content_location:
    The 'Content-Location' of the request body._

**Args**: self, content_disposition, content_type, content_location


### venv_new\Lib\site-packages\pip\_vendor\urllib3\filepost.py

#### `choose_boundary()` (line 15)
_Our embarrassingly-simple replacement for mimetools.choose_boundary._


#### `iter_field_objects()` (line 25)
_Iterate over fields.

Supports list of (k, v) tuples and dicts, and lists of
:class:`~urllib3.fields.RequestField`._

**Args**: fields


#### `iter_fields()` (line 45)
_.. deprecated:: 1.6

Iterate over fields.

The addition of :class:`~urllib3.fields.RequestField` makes this function
obsolete. Instead, use :func:`iter_field_objects`, which returns
:class:`~urllib3.fields.RequestField` objects.

Supports list of (k, v) tuples and dicts._

**Args**: fields


#### `encode_multipart_formdata()` (line 63)
_Encode a dictionary of ``fields`` using the multipart/form-data MIME format.

:param fields:
    Dictionary of fields or list of (key, :class:`~urllib3.fields.RequestField`).

:param boundary:
    If not specified, then a random boundary will be generated using
    :func:`urllib3.filepost.choose_boundary`._

**Args**: fields, boundary


### venv_new\Lib\site-packages\pip\_vendor\urllib3\packages\backports\makefile.py

#### `backport_makefile()` (line 13)
_Backport of ``socket.makefile`` from Python 3.5._

**Args**: self, mode, buffering, encoding, errors, newline


### venv_new\Lib\site-packages\pip\_vendor\urllib3\packages\backports\weakref_finalize.py

#### `__init__()` (line 43)
**Args**: self, obj, func


#### `__call__()` (line 61)
_If alive then mark as dead and return func(*args, **kwargs);
otherwise return None_

**Args**: self, _


#### `detach()` (line 68)
_If alive then mark as dead and return (obj, func, args, kwargs);
otherwise return None_

**Args**: self


#### `peek()` (line 76)
_If alive then return (obj, func, args, kwargs);
otherwise return None_

**Args**: self


#### `alive()` (line 85)
_Whether finalizer is alive_

**Args**: self


#### `atexit()` (line 90)
_Whether finalizer should be called at exit_

**Args**: self


#### `atexit()` (line 96)
**Args**: self, value


#### `__repr__()` (line 101)
**Args**: self


#### `_select_for_exit()` (line 115)
**Args**: cls


#### `_exitfunc()` (line 122)
**Args**: cls


### venv_new\Lib\site-packages\pip\_vendor\urllib3\packages\six.py

#### `__len__()` (line 61)
**Args**: self


#### `_add_doc()` (line 80)
_Add documentation to a function._

**Args**: func, doc


#### `_import_module()` (line 85)
_Import module, returning the module after the last dot._

**Args**: name


#### `__init__()` (line 92)
**Args**: self, name


#### `__get__()` (line 95)
**Args**: self, obj, tp


#### `__init__()` (line 108)
**Args**: self, name, old, new


#### `_resolve()` (line 117)
**Args**: self


#### `__getattr__()` (line 120)
**Args**: self, attr


#### `__init__()` (line 128)
**Args**: self, name


#### `__dir__()` (line 132)
**Args**: self


#### `__init__()` (line 142)
**Args**: self, name, old_mod, new_mod, old_attr, new_attr


#### `_resolve()` (line 160)
**Args**: self


#### `__init__()` (line 174)
**Args**: self, six_module_name


#### `_add_module()` (line 178)
**Args**: self, mod


#### `_get_module()` (line 182)
**Args**: self, fullname


#### `find_module()` (line 185)
**Args**: self, fullname, path


#### `find_spec()` (line 190)
**Args**: self, fullname, path, target


#### `__get_module()` (line 195)
**Args**: self, fullname


#### `load_module()` (line 201)
**Args**: self, fullname


#### `is_package()` (line 215)
_Return true, if the named module is a package.

We need this method to get correct spec objects with
Python 3.4 (see PEP451)_

**Args**: self, fullname


#### `get_code()` (line 224)
_Return None

Required, if is_package is implemented_

**Args**: self, fullname


#### `create_module()` (line 233)
**Args**: self, spec


#### `exec_module()` (line 236)
**Args**: self, module


#### `__dir__()` (line 535)
**Args**: self


#### `add_move()` (line 544)
_Add an item to six.moves._

**Args**: move


#### `remove_move()` (line 549)
_Remove item from six.moves._

**Args**: name


#### `advance_iterator()` (line 582)
**Args**: it


#### `callable()` (line 593)
**Args**: obj


#### `get_unbound_function()` (line 599)
**Args**: unbound


#### `create_unbound_method()` (line 604)
**Args**: func, cls


#### `get_unbound_function()` (line 610)
**Args**: unbound


#### `create_bound_method()` (line 613)
**Args**: func, obj


#### `create_unbound_method()` (line 616)
**Args**: func, cls


#### `next()` (line 620)
**Args**: self


#### `iterkeys()` (line 639)
**Args**: d


#### `itervalues()` (line 642)
**Args**: d


#### `iteritems()` (line 645)
**Args**: d


#### `iterlists()` (line 648)
**Args**: d


#### `iterkeys()` (line 658)
**Args**: d


#### `itervalues()` (line 661)
**Args**: d


#### `iteritems()` (line 664)
**Args**: d


#### `iterlists()` (line 667)
**Args**: d


#### `b()` (line 686)
**Args**: s


#### `u()` (line 689)
**Args**: s


#### `b()` (line 716)
**Args**: s


#### `u()` (line 721)
**Args**: s


#### `byte2int()` (line 727)
**Args**: bs


#### `indexbytes()` (line 730)
**Args**: buf, i


#### `assertCountEqual()` (line 745)
**Args**: self


#### `assertRaisesRegex()` (line 749)
**Args**: self


#### `assertRegex()` (line 753)
**Args**: self


#### `assertNotRegex()` (line 757)
**Args**: self


#### `reraise()` (line 764)
**Args**: tp, value, tb


#### `exec_()` (line 777)
_Execute code in a namespace._

**Args**: _code_, _globs_, _locs_


#### `raise_from()` (line 810)
**Args**: value, from_value


#### `print_()` (line 817)
_The new-style print function for Python 2.4 and 2.5._


#### `write()` (line 823)
**Args**: data


#### `print_()` (line 878)

#### `_update_wrapper()` (line 894)
**Args**: wrapper, wrapped, assigned, updated


#### `wraps()` (line 914)
**Args**: wrapped, assigned, updated


#### `with_metaclass()` (line 929)
_Create a base class with a metaclass._

**Args**: meta


#### `__new__()` (line 935)
**Args**: cls, name, this_bases, d


#### `__prepare__()` (line 947)
**Args**: cls, name, this_bases


#### `add_metaclass()` (line 953)
_Class decorator for creating a class with a metaclass._

**Args**: metaclass


#### `wrapper()` (line 956)
**Args**: cls


#### `ensure_binary()` (line 973)
_Coerce **s** to six.binary_type.

For Python 2:
  - `unicode` -> encoded to `str`
  - `str` -> `str`

For Python 3:
  - `str` -> encoded to `bytes`
  - `bytes` -> `bytes`_

**Args**: s, encoding, errors


#### `ensure_str()` (line 991)
_Coerce *s* to `str`.

For Python 2:
  - `unicode` -> encoded to `str`
  - `str` -> `str`

For Python 3:
  - `str` -> `str`
  - `bytes` -> decoded to `str`_

**Args**: s, encoding, errors


#### `ensure_text()` (line 1014)
_Coerce *s* to six.text_type.

For Python 2:
  - `unicode` -> `unicode`
  - `str` -> `unicode`

For Python 3:
  - `str` -> `str`
  - `bytes` -> decoded to `str`_

**Args**: s, encoding, errors


#### `python_2_unicode_compatible()` (line 1033)
_A class decorator that defines __unicode__ and __str__ methods under Python 2.
Under Python 3 it does nothing.

To support Python 2 and 3 with a single code base, define a __str__ method
returning text and apply this decorator to the class._

**Args**: klass


### venv_new\Lib\site-packages\pip\_vendor\urllib3\poolmanager.py

#### `_default_key_normalizer()` (line 79)
_Create a pool key out of a request context dictionary.

According to RFC 3986, both the scheme and host are case-insensitive.
Therefore, this function normalizes both before constructing the pool
key for an HTTPS request. If you wish to change this behaviour, provide
alternate callables to ``key_fn_by_scheme``.

:param key_class:
    The class to use when constructing the key. This should be a namedtuple
    with the ``scheme`` and ``host`` keys at a minimum.
:type  key_class: namedtuple
:param request_context:
    A dictionary-like object that contain the context for a request.
:type  request_context: dict

:return: A namedtuple that can be used as a connection pool key.
:rtype:  PoolKey_

**Args**: key_class, request_context


#### `__init__()` (line 171)
**Args**: self, num_pools, headers


#### `__enter__()` (line 181)
**Args**: self


#### `__exit__()` (line 184)
**Args**: self, exc_type, exc_val, exc_tb


#### `_new_pool()` (line 189)
_Create a new :class:`urllib3.connectionpool.ConnectionPool` based on host, port, scheme, and
any additional pool keyword arguments.

If ``request_context`` is provided, it is provided as keyword arguments
to the pool class used. This method is used to actually create the
connection pools handed out by :meth:`connection_from_url` and
companion methods. It is intended to be overridden for customization._

**Args**: self, scheme, host, port, request_context


#### `clear()` (line 216)
_Empty our store of pools and direct them all to close.

This will not affect in-flight connections, but they will not be
re-used after completion._

**Args**: self


#### `connection_from_host()` (line 225)
_Get a :class:`urllib3.connectionpool.ConnectionPool` based on the host, port, and scheme.

If ``port`` isn't given, it will be derived from the ``scheme`` using
``urllib3.connectionpool.port_by_scheme``. If ``pool_kwargs`` is
provided, it is merged with the instance's ``connection_pool_kw``
variable and used to create the new connection pool, if one is
needed._

**Args**: self, host, port, scheme, pool_kwargs


#### `connection_from_context()` (line 248)
_Get a :class:`urllib3.connectionpool.ConnectionPool` based on the request context.

``request_context`` must at least contain the ``scheme`` key and its
value must be a key in ``key_fn_by_scheme`` instance variable._

**Args**: self, request_context


#### `connection_from_pool_key()` (line 263)
_Get a :class:`urllib3.connectionpool.ConnectionPool` based on the provided pool key.

``pool_key`` should be a namedtuple that only contains immutable
objects. At a minimum it must have the ``scheme``, ``host``, and
``port`` fields._

**Args**: self, pool_key, request_context


#### `connection_from_url()` (line 287)
_Similar to :func:`urllib3.connectionpool.connection_from_url`.

If ``pool_kwargs`` is not provided and a new pool needs to be
constructed, ``self.connection_pool_kw`` is used to initialize
the :class:`urllib3.connectionpool.ConnectionPool`. If ``pool_kwargs``
is provided, it is used instead. Note that if a new pool does not
need to be created for the request, the provided ``pool_kwargs`` are
not used._

**Args**: self, url, pool_kwargs


#### `_merge_pool_kwargs()` (line 303)
_Merge a dictionary of override values for self.connection_pool_kw.

This does not modify self.connection_pool_kw and returns a new dict.
Any keys in the override dictionary with a value of ``None`` are
removed from the merged dictionary._

**Args**: self, override


#### `_proxy_requires_url_absolute_form()` (line 323)
_Indicates if the proxy requires the complete destination URL in the
request.  Normally this is only needed when not using an HTTP CONNECT
tunnel._

**Args**: self, parsed_url


#### `_validate_proxy_scheme_url_selection()` (line 336)
_Validates that were not attempting to do TLS in TLS connections on
Python2 or with unsupported SSL implementations._

**Args**: self, url_scheme


#### `urlopen()` (line 353)
_Same as :meth:`urllib3.HTTPConnectionPool.urlopen`
with custom cross-host redirect logic and only sends the request-uri
portion of the ``url``.

The given ``url`` parameter must be absolute, such that an appropriate
:class:`urllib3.connectionpool.ConnectionPool` can be chosen for it._

**Args**: self, method, url, redirect


#### `__init__()` (line 464)
**Args**: self, proxy_url, num_pools, headers, proxy_headers, proxy_ssl_context, use_forwarding_for_https


#### `connection_from_host()` (line 501)
**Args**: self, host, port, scheme, pool_kwargs


#### `_set_proxy_headers()` (line 511)
_Sets headers needed by proxies: specifically, the Accept and Host
headers. Only sets headers not provided by the user._

**Args**: self, url, headers


#### `urlopen()` (line 526)
_Same as HTTP(S)ConnectionPool.urlopen, ``url`` must be absolute._

**Args**: self, method, url, redirect


#### `proxy_from_url()` (line 539)
**Args**: url


### venv_new\Lib\site-packages\pip\_vendor\urllib3\request.py

#### `__init__()` (line 43)
**Args**: self, headers


#### `urlopen()` (line 46)
**Args**: self, method, url, body, headers, encode_multipart, multipart_boundary


#### `request()` (line 61)
_Make a request using :meth:`urlopen` with the appropriate encoding of
``fields`` based on the ``method`` used.

This is a convenience method that requires the least amount of manual
effort. It can be used in most situations, while still having the
option to drop down to more specific methods when necessary, such as
:meth:`request_encode_url`, :meth:`request_encode_body`,
or even the lowest level :meth:`urlopen`._

**Args**: self, method, url, fields, headers


#### `request_encode_url()` (line 85)
_Make a request using :meth:`urlopen` with the ``fields`` encoded in
the url. This is useful for request methods like GET, HEAD, DELETE, etc._

**Args**: self, method, url, fields, headers


#### `request_encode_body()` (line 101)
_Make a request using :meth:`urlopen` with the ``fields`` encoded in
the body. This is useful for request methods like POST, PUT, PATCH, etc.

When ``encode_multipart=True`` (default), then
:func:`urllib3.encode_multipart_formdata` is used to encode
the payload with the appropriate content type. Otherwise
:func:`urllib.parse.urlencode` is used with the
'application/x-www-form-urlencoded' content type.

Multipart encoding must be used when posting files, and it's reasonably
safe to use it in other times too. However, it may break request
signing, such as with OAuth.

Supports an optional ``fields`` parameter of key/value strings AND
key/filetuple. A filetuple is a (filename, data, MIME type) tuple where
the MIME type is optional. For example::

    fields = {
        'foo': 'bar',
        'fakefile': ('foofile.txt', 'contents of foofile'),
        'realfile': ('barfile.txt', open('realfile').read()),
        'typedfile': ('bazfile.bin', open('bazfile').read(),
                      'image/jpeg'),
        'nonamefile': 'contents of nonamefile field',
    }

When uploading a file, providing a filename (the first parameter of the
tuple) is optional but recommended to best mimic behavior of browsers.

Note that if ``headers`` are supplied, the 'Content-Type' header will
be overwritten because it depends on the dynamic random boundary string
which is used to compose the body of the request. The random boundary
string can be explicitly set with the ``multipart_boundary`` parameter._

**Args**: self, method, url, fields, headers, encode_multipart, multipart_boundary


#### `__call__()` (line 179)
_If user tries to call this module directly urllib3 v2.x style raise an error to the user
suggesting they may need urllib3 v2_

**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\urllib3\response.py

#### `__init__()` (line 36)
**Args**: self


#### `__getattr__()` (line 41)
**Args**: self, name


#### `decompress()` (line 44)
**Args**: self, data


#### `__init__()` (line 75)
**Args**: self


#### `__getattr__()` (line 79)
**Args**: self, name


#### `decompress()` (line 82)
**Args**: self, data


#### `__init__()` (line 110)
**Args**: self


#### `flush()` (line 117)
**Args**: self


#### `__init__()` (line 132)
**Args**: self, modes


#### `flush()` (line 135)
**Args**: self


#### `decompress()` (line 138)
**Args**: self, data


#### `_get_decoder()` (line 144)
**Args**: mode


#### `__init__()` (line 195)
**Args**: self, body, headers, status, version, reason, strict, preload_content, decode_content, original_response, pool, connection, msg, retries, enforce_content_length, request_method, request_url, auto_close


#### `get_redirect_location()` (line 262)
_Should we redirect and where to?

:returns: Truthy redirect location string if we got a redirect status
    code and valid location. ``None`` if redirect status and no
    location. ``False`` if not a redirect status code._

**Args**: self


#### `release_conn()` (line 275)
**Args**: self


#### `drain_conn()` (line 282)
_Read and discard any remaining HTTP response data in the response connection.

Unread data in the HTTPResponse connection blocks the connection from being released back to the pool._

**Args**: self


#### `data()` (line 294)
**Args**: self


#### `connection()` (line 303)
**Args**: self


#### `isclosed()` (line 306)
**Args**: self


#### `tell()` (line 309)
_Obtain the number of bytes pulled over the wire so far. May differ from
the amount of content returned by :meth:``urllib3.response.HTTPResponse.read``
if bytes are encoded on the wire (e.g, compressed)._

**Args**: self


#### `_init_length()` (line 317)
_Set initial length value for Response content if available._

**Args**: self, request_method


#### `_init_decoder()` (line 369)
_Set-up the _decoder attribute if necessary._

**Args**: self


#### `_decode()` (line 392)
_Decode the data passed in and potentially flush the decoder._

**Args**: self, data, decode_content, flush_decoder


#### `_flush_decoder()` (line 414)
_Flushes the decoder. Should only be called if the decoder is actually
being used._

**Args**: self


#### `_error_catcher()` (line 426)
_Catch low-level python exceptions, instead re-raising urllib3
variants, so that low-level exceptions are not leaked in the
high-level api.

On exit, release the connection back to the pool._

**Args**: self


#### `_fp_read()` (line 481)
_Read a response with the thought that reading the number of bytes
larger than can fit in a 32-bit int at a time via SSL in some
known cases leads to an overflow error that has to be prevented
if `amt` or `self.length_remaining` indicate that a problem may
happen.

The known cases:
  * 3.8 <= CPython < 3.9.7 because of a bug
    https://github.com/urllib3/urllib3/issues/2513#issuecomment-1152559900.
  * urllib3 injected with pyOpenSSL-backed SSL-support.
  * CPython < 3.10 only when `amt` does not fit 32-bit int._

**Args**: self, amt


#### `read()` (line 529)
_Similar to :meth:`http.client.HTTPResponse.read`, but with two additional
parameters: ``decode_content`` and ``cache_content``.

:param amt:
    How much of the content to read. If specified, caching is skipped
    because it doesn't make sense to cache partial content as the full
    response.

:param decode_content:
    If True, will attempt to decode the body based on the
    'content-encoding' header.

:param cache_content:
    If True, will save the returned data such that the same result is
    returned despite of the state of the underlying file object. This
    is useful if you want the ``.data`` property to continue working
    after having ``.read()`` the file object. (Overridden if ``amt`` is
    set.)_

**Args**: self, amt, decode_content, cache_content


#### `stream()` (line 601)
_A generator wrapper for the read() method. A call will block until
``amt`` bytes have been read from the connection or until the
connection is closed.

:param amt:
    How much of the content to read. The generator will return up to
    much data per iteration, but may return less. This is particularly
    likely when using compressed data. However, the empty string will
    never be returned.

:param decode_content:
    If True, will attempt to decode the body based on the
    'content-encoding' header._

**Args**: self, amt, decode_content


#### `from_httplib()` (line 628)
_Given an :class:`http.client.HTTPResponse` instance ``r``, return a
corresponding :class:`urllib3.response.HTTPResponse` object.

Remaining parameters are passed to the HTTPResponse constructor, along
with ``original_response=r``._

**Args**: ResponseCls, r


#### `getheaders()` (line 660)
**Args**: self


#### `getheader()` (line 669)
**Args**: self, name, default


#### `info()` (line 679)
**Args**: self


#### `close()` (line 683)
**Args**: self


#### `closed()` (line 694)
**Args**: self


#### `fileno()` (line 706)
**Args**: self


#### `flush()` (line 717)
**Args**: self


#### `readable()` (line 725)
**Args**: self


#### `readinto()` (line 729)
**Args**: self, b


#### `supports_chunked_reads()` (line 738)
_Checks if the underlying file-like object looks like a
:class:`http.client.HTTPResponse` object. We do this by testing for
the fp attribute. If it is present we assume it returns raw chunks as
processed by read_chunked()._

**Args**: self


#### `_update_chunk_length()` (line 747)
**Args**: self


#### `_handle_chunk()` (line 761)
**Args**: self, amt


#### `read_chunked()` (line 783)
_Similar to :meth:`HTTPResponse.read`, but with an additional
parameter: ``decode_content``.

:param amt:
    How much of the content to read. If specified, caching is skipped
    because it doesn't make sense to cache partial content as the full
    response.

:param decode_content:
    If True, will attempt to decode the body based on the
    'content-encoding' header._

**Args**: self, amt, decode_content


#### `geturl()` (line 853)
_Returns the URL that was the source of this response.
If the request that generated this response redirected, this method
will return the final redirect location._

**Args**: self


#### `__iter__()` (line 864)
**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\urllib3\util\connection.py

#### `is_connection_dropped()` (line 11)
_Returns True if the connection is dropped and should be closed.

:param conn:
    :class:`http.client.HTTPConnection` object.

Note: For platforms like AppEngine, this will always return ``False`` to
let the platform handle connection recycling transparently for us._

**Args**: conn


#### `create_connection()` (line 37)
_Connect to *address* and return the socket object.

Convenience function.  Connect to *address* (a 2-tuple ``(host,
port)``) and return the socket object.  Passing the optional
*timeout* parameter will set the timeout on the socket instance
before attempting to connect.  If no *timeout* is supplied, the
global default timeout setting returned by :func:`socket.getdefaulttimeout`
is used.  If *source_address* is set it must be a tuple of (host, port)
for the socket to bind as a source address before making the connection.
An host of '' or port 0 tells the OS to use the default._

**Args**: address, timeout, source_address, socket_options


#### `_set_socket_options()` (line 100)
**Args**: sock, options


#### `allowed_gai_family()` (line 108)
_This function is designed to work in the context of
getaddrinfo, where family=socket.AF_UNSPEC is the default and
will perform a DNS search for both IPv6 and IPv4 records._


#### `_has_ipv6()` (line 119)
_Returns True if the system can bind an IPv6 address._

**Args**: host


### venv_new\Lib\site-packages\pip\_vendor\urllib3\util\proxy.py

#### `connection_requires_http_tunnel()` (line 4)
_Returns True if the connection requires an HTTP CONNECT through the proxy.

:param URL proxy_url:
    URL of the proxy.
:param ProxyConfig proxy_config:
    Proxy configuration from poolmanager.py
:param str destination_scheme:
    The scheme of the destination. (i.e https, http, etc)_

**Args**: proxy_url, proxy_config, destination_scheme


#### `create_proxy_ssl_context()` (line 37)
_Generates a default proxy ssl context if one hasn't been provided by the
user._

**Args**: ssl_version, cert_reqs, ca_certs, ca_cert_dir, ca_cert_data


### venv_new\Lib\site-packages\pip\_vendor\urllib3\util\queue.py

#### `_init()` (line 12)
**Args**: self, _


#### `_qsize()` (line 15)
**Args**: self, len


#### `_put()` (line 18)
**Args**: self, item


#### `_get()` (line 21)
**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\urllib3\util\request.py

#### `make_headers()` (line 20)
_Shortcuts for generating request headers.

:param keep_alive:
    If ``True``, adds 'connection: keep-alive' header.

:param accept_encoding:
    Can be a boolean, list, or string.
    ``True`` translates to 'gzip,deflate'.
    List will get joined by comma.
    String will be used as provided.

:param user_agent:
    String representing the user-agent you want, such as
    "python-urllib3/0.6"

:param basic_auth:
    Colon-separated username:password string for 'authorization: basic ...'
    auth header.

:param proxy_basic_auth:
    Colon-separated username:password string for 'proxy-authorization: basic ...'
    auth header.

:param disable_cache:
    If ``True``, adds 'cache-control: no-cache' header.

Example::

    >>> make_headers(keep_alive=True, user_agent="Batman/1.0")
    {'connection': 'keep-alive', 'user-agent': 'Batman/1.0'}
    >>> make_headers(accept_encoding=True)
    {'accept-encoding': 'gzip,deflate'}_

**Args**: keep_alive, accept_encoding, user_agent, basic_auth, proxy_basic_auth, disable_cache


#### `set_file_position()` (line 92)
_If a position is provided, move file to that point.
Otherwise, we'll attempt to record a position for future use._

**Args**: body, pos


#### `rewind_body()` (line 110)
_Attempt to rewind body to a certain position.
Primarily used for request redirects and retries.

:param body:
    File-like object that supports seek.

:param int pos:
    Position to seek to in file._

**Args**: body, body_pos


### venv_new\Lib\site-packages\pip\_vendor\urllib3\util\response.py

#### `is_fp_closed()` (line 9)
_Checks whether a given file-like object is closed.

:param obj:
    The file-like object to check._

**Args**: obj


#### `assert_header_parsing()` (line 40)
_Asserts whether all headers have been successfully parsed.
Extracts encountered errors from the result of parsing headers.

Only works on Python 3.

:param http.client.HTTPMessage headers: Headers to verify.

:raises urllib3.exceptions.HeaderParsingError:
    If parsing errors are found._

**Args**: headers


#### `is_response_to_head()` (line 94)
_Checks whether the request of a response has been a HEAD-request.
Handles the quirks of AppEngine.

:param http.client.HTTPResponse response:
    Response to check if the originating request
    used 'HEAD' as a method._

**Args**: response


### venv_new\Lib\site-packages\pip\_vendor\urllib3\util\retry.py

#### `DEFAULT_METHOD_WHITELIST()` (line 37)
**Args**: cls


#### `DEFAULT_METHOD_WHITELIST()` (line 46)
**Args**: cls, value


#### `DEFAULT_REDIRECT_HEADERS_BLACKLIST()` (line 55)
**Args**: cls


#### `DEFAULT_REDIRECT_HEADERS_BLACKLIST()` (line 64)
**Args**: cls, value


#### `BACKOFF_MAX()` (line 73)
**Args**: cls


#### `BACKOFF_MAX()` (line 82)
**Args**: cls, value


#### `__init__()` (line 245)
**Args**: self, total, connect, read, redirect, status, other, allowed_methods, status_forcelist, backoff_factor, raise_on_redirect, raise_on_status, history, respect_retry_after_header, remove_headers_on_redirect, method_whitelist


#### `new()` (line 306)
**Args**: self


#### `from_int()` (line 343)
_Backwards-compatibility for the old retries format._

**Args**: cls, retries, redirect, default


#### `get_backoff_time()` (line 356)
_Formula for computing the current backoff

:rtype: float_

**Args**: self


#### `parse_retry_after()` (line 373)
**Args**: self, retry_after


#### `get_retry_after()` (line 396)
_Get the value of Retry-After in seconds._

**Args**: self, response


#### `sleep_for_retry()` (line 406)
**Args**: self, response


#### `_sleep_backoff()` (line 414)
**Args**: self


#### `sleep()` (line 420)
_Sleep between retry attempts.

This method will respect a server's ``Retry-After`` response header
and sleep the duration of the time requested. If that is not present, it
will use an exponential backoff. By default, the backoff factor is 0 and
this method will return immediately._

**Args**: self, response


#### `_is_connection_error()` (line 436)
_Errors when we're fairly sure that the server did not receive the
request, so it should be safe to retry._

**Args**: self, err


#### `_is_read_error()` (line 444)
_Errors that occur after the request has been started, so we should
assume that the server began processing it._

**Args**: self, err


#### `_is_method_retryable()` (line 450)
_Checks if a given HTTP method should be retried upon, depending if
it is included in the allowed_methods_

**Args**: self, method


#### `is_retry()` (line 470)
_Is this method/status code retryable? (Based on allowlists and control
variables such as the number of total retries to allow, whether to
respect the Retry-After header, whether this header is present, and
whether the returned status code is on the list of status codes to
be retried upon on the presence of the aforementioned header)_

**Args**: self, method, status_code, has_retry_after


#### `is_exhausted()` (line 490)
_Are we out of retries?_

**Args**: self


#### `increment()` (line 506)
_Return a new Retry object with incremented retry counters.

:param response: A response object, or None, if the server did not
    return a response.
:type response: :class:`~urllib3.response.HTTPResponse`
:param Exception error: An error encountered during the request, or
    None if the response was received successfully.

:return: A new ``Retry`` object._

**Args**: self, method, url, response, error, _pool, _stacktrace


#### `__repr__()` (line 600)
**Args**: self


#### `__getattr__()` (line 606)
**Args**: self, item


### venv_new\Lib\site-packages\pip\_vendor\urllib3\util\ssl_.py

#### `_const_compare_digest_backport()` (line 33)
_Compare two digests of equal length in constant time.

The digests must be of type str/bytes.
Returns True if the digests match, and False otherwise._

**Args**: a, b


#### `__init__()` (line 137)
**Args**: self, protocol_version


#### `load_cert_chain()` (line 148)
**Args**: self, certfile, keyfile


#### `load_verify_locations()` (line 152)
**Args**: self, cafile, capath, cadata


#### `set_ciphers()` (line 161)
**Args**: self, cipher_suite


#### `wrap_socket()` (line 164)
**Args**: self, socket, server_hostname, server_side


#### `assert_fingerprint()` (line 185)
_Checks if given fingerprint matches the supplied certificate.

:param cert:
    Certificate as bytes object.
:param fingerprint:
    Fingerprint as string of hexdigits, can be interspersed by colons._

**Args**: cert, fingerprint


#### `resolve_cert_reqs()` (line 220)
_Resolves the argument to a numeric constant, which can be passed to
the wrap_socket function/method from the ssl module.
Defaults to :data:`ssl.CERT_REQUIRED`.
If given a string it is assumed to be the name of the constant in the
:mod:`ssl` module or its abbreviation.
(So you can specify `REQUIRED` instead of `CERT_REQUIRED`.
If it's neither `None` nor a string we assume it is already the numeric
constant which can directly be passed to wrap_socket._

**Args**: candidate


#### `resolve_ssl_version()` (line 243)
_like resolve_cert_reqs_

**Args**: candidate


#### `create_urllib3_context()` (line 259)
_All arguments have the same meaning as ``ssl_wrap_socket``.

By default, this function does a lot of the same work that
``ssl.create_default_context`` does on Python 3.4+. It:

- Disables SSLv2, SSLv3, and compression
- Sets a restricted set of server ciphers

If you wish to enable SSLv3, you can do::

    from pip._vendor.urllib3.util import ssl_
    context = ssl_.create_urllib3_context()
    context.options &= ~ssl_.OP_NO_SSLv3

You can do the same to enable compression (substituting ``COMPRESSION``
for ``SSLv3`` in the last line above).

:param ssl_version:
    The desired protocol version to use. This will default to
    PROTOCOL_SSLv23 which will negotiate the highest protocol that both
    the server and your installation of OpenSSL support.
:param cert_reqs:
    Whether to require the certificate verification. This defaults to
    ``ssl.CERT_REQUIRED``.
:param options:
    Specific OpenSSL options. These default to ``ssl.OP_NO_SSLv2``,
    ``ssl.OP_NO_SSLv3``, ``ssl.OP_NO_COMPRESSION``, and ``ssl.OP_NO_TICKET``.
:param ciphers:
    Which cipher suites to allow the server to select.
:returns:
    Constructed SSLContext object with specified options
:rtype: SSLContext_

**Args**: ssl_version, cert_reqs, options, ciphers


#### `disable_check_hostname()` (line 334)

#### `ssl_wrap_socket()` (line 364)
_All arguments except for server_hostname, ssl_context, and ca_cert_dir have
the same meaning as they do when using :func:`ssl.wrap_socket`.

:param server_hostname:
    When SNI is supported, the expected hostname of the certificate
:param ssl_context:
    A pre-made :class:`SSLContext` object. If none is provided, one will
    be created using :func:`create_urllib3_context`.
:param ciphers:
    A string of ciphers we wish the client to support.
:param ca_cert_dir:
    A directory containing CA certificates in multiple separate files, as
    supported by OpenSSL's -CApath flag or the capath argument to
    SSLContext.load_verify_locations().
:param key_password:
    Optional password if the keyfile is encrypted.
:param ca_cert_data:
    Optional string containing CA certificates in PEM format suitable for
    passing as the cadata parameter to SSLContext.load_verify_locations()
:param tls_in_tls:
    Use SSLTransport to wrap the existing socket._

**Args**: sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls


#### `is_ipaddress()` (line 466)
_Detects whether the hostname given is an IPv4 or IPv6 address.
Also detects IPv6 addresses with Zone IDs.

:param str hostname: Hostname to examine.
:return: True if the hostname is an IP address, False otherwise._

**Args**: hostname


#### `_is_key_file_encrypted()` (line 479)
_Detects if a key file is encrypted or not._

**Args**: key_file


#### `_ssl_wrap_socket_impl()` (line 490)
**Args**: sock, ssl_context, tls_in_tls, server_hostname


### venv_new\Lib\site-packages\pip\_vendor\urllib3\util\ssl_match_hostname.py

#### `_dnsname_match()` (line 25)
_Matching according to RFC 6125, section 6.4.3

http://tools.ietf.org/html/rfc6125#section-6.4.3_

**Args**: dn, hostname, max_wildcards


#### `_to_unicode()` (line 79)
**Args**: obj


#### `_ipaddress_match()` (line 86)
_Exact matching of IP addresses.

RFC 6125 explicitly doesn't define an algorithm for this
(section 1.7.2 - "Out of Scope")._

**Args**: ipname, host_ip


#### `match_hostname()` (line 98)
_Verify that *cert* (in decoded format as returned by
SSLSocket.getpeercert()) matches the *hostname*.  RFC 2818 and RFC 6125
rules are followed, but IP addresses are not accepted for *hostname*.

CertificateError is raised on failure. On success, the function
returns nothing._

**Args**: cert, hostname


### venv_new\Lib\site-packages\pip\_vendor\urllib3\util\ssltransport.py

#### `_validate_ssl_context_for_tls_in_tls()` (line 23)
_Raises a ProxySchemeUnsupported if the provided ssl_context can't be used
for TLS in TLS.

The only requirement is that the ssl_context provides the 'wrap_bio'
methods._

**Args**: ssl_context


#### `__init__()` (line 44)
_Create an SSLTransport around socket using the provided ssl_context._

**Args**: self, socket, ssl_context, server_hostname, suppress_ragged_eofs


#### `__enter__()` (line 63)
**Args**: self


#### `__exit__()` (line 66)
**Args**: self


#### `fileno()` (line 69)
**Args**: self


#### `read()` (line 72)
**Args**: self, len, buffer


#### `recv()` (line 75)
**Args**: self, len, flags


#### `recv_into()` (line 80)
**Args**: self, buffer, nbytes, flags


#### `sendall()` (line 89)
**Args**: self, data, flags


#### `send()` (line 99)
**Args**: self, data, flags


#### `makefile()` (line 105)
_Python's httpclient uses makefile and buffered io when reading HTTP
messages and we need to support it.

This is unfortunately a copy and paste of socket.py makefile with small
changes to point to the socket directly._

**Args**: self, mode, buffering, encoding, errors, newline


#### `unwrap()` (line 150)
**Args**: self


#### `close()` (line 153)
**Args**: self


#### `getpeercert()` (line 156)
**Args**: self, binary_form


#### `version()` (line 159)
**Args**: self


#### `cipher()` (line 162)
**Args**: self


#### `selected_alpn_protocol()` (line 165)
**Args**: self


#### `selected_npn_protocol()` (line 168)
**Args**: self


#### `shared_ciphers()` (line 171)
**Args**: self


#### `compression()` (line 174)
**Args**: self


#### `settimeout()` (line 177)
**Args**: self, value


#### `gettimeout()` (line 180)
**Args**: self


#### `_decref_socketios()` (line 183)
**Args**: self


#### `_wrap_ssl_read()` (line 186)
**Args**: self, len, buffer


#### `_ssl_io_loop()` (line 195)
_Performs an I/O loop between incoming/outgoing and the socket._

**Args**: self, func


### venv_new\Lib\site-packages\pip\_vendor\urllib3\util\timeout.py

#### `__init__()` (line 101)
**Args**: self, total, connect, read


#### `__repr__()` (line 107)
**Args**: self


#### `resolve_default_timeout()` (line 119)
**Args**: cls, timeout


#### `_validate_timeout()` (line 123)
_Check that a timeout attribute is valid.

:param value: The timeout value to validate
:param name: The name of the timeout attribute to validate. This is
    used to specify in error messages.
:return: The validated and casted version of the given value.
:raises ValueError: If it is a numeric value less than or equal to
    zero, or the type is not an integer, float, or None._

**Args**: cls, value, name


#### `from_float()` (line 169)
_Create a new Timeout from a legacy timeout value.

The timeout value used by httplib.py sets the same timeout on the
connect(), and recv() socket requests. This creates a :class:`Timeout`
object that sets the individual timeouts to the ``timeout`` value
passed to this function.

:param timeout: The legacy timeout value.
:type timeout: integer, float, sentinel default object, or None
:return: Timeout object
:rtype: :class:`Timeout`_

**Args**: cls, timeout


#### `clone()` (line 184)
_Create a copy of the timeout object

Timeout properties are stored per-pool but each request needs a fresh
Timeout object to ensure each one has its own start/stop configured.

:return: a copy of the timeout object
:rtype: :class:`Timeout`_

**Args**: self


#### `start_connect()` (line 198)
_Start the timeout clock, used during a connect() attempt

:raises urllib3.exceptions.TimeoutStateError: if you attempt
    to start a timer that has been started already._

**Args**: self


#### `get_connect_duration()` (line 209)
_Gets the time elapsed since the call to :meth:`start_connect`.

:return: Elapsed time in seconds.
:rtype: float
:raises urllib3.exceptions.TimeoutStateError: if you attempt
    to get duration for a timer that hasn't been started._

**Args**: self


#### `connect_timeout()` (line 224)
_Get the value to use when setting a connection timeout.

This will be a positive float or integer, the value None
(never timeout), or the default system timeout.

:return: Connect timeout.
:rtype: int, float, :attr:`Timeout.DEFAULT_TIMEOUT` or None_

**Args**: self


#### `read_timeout()` (line 242)
_Get the value for the read timeout.

This assumes some time has elapsed in the connection timeout and
computes the read timeout appropriately.

If self.total is set, the read timeout is dependent on the amount of
time taken by the connect timeout. If the connection time has not been
established, a :exc:`~urllib3.exceptions.TimeoutStateError` will be
raised.

:return: Value to use for the read timeout.
:rtype: int, float, :attr:`Timeout.DEFAULT_TIMEOUT` or None
:raises urllib3.exceptions.TimeoutStateError: If :meth:`start_connect`
    has not yet been called on this object._

**Args**: self


### venv_new\Lib\site-packages\pip\_vendor\urllib3\util\url.py

#### `__new__()` (line 91)
**Args**: cls, scheme, auth, host, port, path, query, fragment


#### `hostname()` (line 110)
_For backwards-compatibility with urlparse. We're nice like that._

**Args**: self


#### `request_uri()` (line 115)
_Absolute path including the query string._

**Args**: self


#### `netloc()` (line 125)
_Network location including host and port_

**Args**: self


#### `url()` (line 132)
_Convert self into a url

This function should more or less round-trip with :func:`.parse_url`. The
returned url may not be exactly the same as the url inputted to
:func:`.parse_url`, but it should be equivalent by the RFC (e.g., urls
with a blank port will have : removed).

Example: ::

    >>> U = parse_url('http://google.com/mail/')
    >>> U.url
    'http://google.com/mail/'
    >>> Url('http', 'username:password', 'host.com', 80,
    ... '/path', 'query', 'fragment').url
    'http://username:password@host.com:80/path?query#fragment'_

**Args**: self


#### `__str__()` (line 171)
**Args**: self


#### `split_first()` (line 175)
_.. deprecated:: 1.25

Given a string and an iterable of delimiters, split on the first found
delimiter. Return two split parts and the matched delimiter.

If not found, then the first part is the full input string.

Example::

    >>> split_first('foo/bar?baz', '?/=')
    ('foo', 'bar?baz', '/')
    >>> split_first('foo/bar?baz', '123')
    ('foo/bar?baz', '', None)

Scales linearly with number of delims. Not ideal for large number of delims._

**Args**: s, delims


#### `_encode_invalid_chars()` (line 210)
_Percent-encodes a URI component without reapplying
onto an already percent-encoded component._

**Args**: component, allowed_chars, encoding


#### `_remove_path_dot_segments()` (line 244)
**Args**: path


#### `_normalize_host()` (line 274)
**Args**: host, scheme


#### `_idna_encode()` (line 305)
**Args**: name


#### `_encode_target()` (line 323)
_Percent-encodes a request target so that there are no invalid characters_

**Args**: target


#### `parse_url()` (line 333)
_Given a url, return a parsed :class:`.Url` namedtuple. Best-effort is
performed to parse incomplete urls. Fields not provided will be None.
This parser is RFC 3986 and RFC 6874 compliant.

The parser logic and helper functions are based heavily on
work done in the ``rfc3986`` module.

:param str url: URL to parse into a :class:`.Url` namedtuple.

Partly backwards-compatible with :mod:`urlparse`.

Example::

    >>> parse_url('http://google.com/mail/')
    Url(scheme='http', host='google.com', port=None, path='/mail/', ...)
    >>> parse_url('google.com:80')
    Url(scheme=None, host='google.com', port=80, path=None, ...)
    >>> parse_url('/foo?bar')
    Url(scheme=None, host=None, port=None, path='/foo', query='bar', ...)_

**Args**: url


#### `ensure_type()` (line 416)
**Args**: x


#### `get_host()` (line 430)
_Deprecated. Use :func:`parse_url` instead._

**Args**: url


### venv_new\Lib\site-packages\pip\_vendor\urllib3\util\wait.py

#### `_retry_on_intr()` (line 42)
**Args**: fn, timeout


#### `_retry_on_intr()` (line 47)
**Args**: fn, timeout


#### `select_wait_for_socket()` (line 70)
**Args**: sock, read, write, timeout


#### `poll_wait_for_socket()` (line 89)
**Args**: sock, read, write, timeout


#### `do_poll()` (line 101)
**Args**: t


#### `null_wait_for_socket()` (line 109)

#### `_have_working_poll()` (line 113)

#### `wait_for_socket()` (line 126)

#### `wait_for_read()` (line 141)
_Waits for reading to be available on a given socket.
Returns True if the socket is readable, or False if the timeout expired._

**Args**: sock, timeout


#### `wait_for_write()` (line 148)
_Waits for writing to be available on a given socket.
Returns True if the socket is readable, or False if the timeout expired._

**Args**: sock, timeout


### vscode-extension\out\extension.js

#### `unnamed_function()` (line 6)

#### `unnamed_function()` (line 21)

#### `unnamed_function()` (line 48)

#### `unnamed_function()` (line 66)

### vscode-extension\src\extension.ts

#### `unnamed_function()` (line 22)

#### `unnamed_function()` (line 61)

### vscode-extension\src\test\suite\extension.test.ts

#### `unnamed_function()` (line 5)

#### `unnamed_function()` (line 6)

---

## ALL CLASSES

### hypercode\build-hyper-database.py

#### `HyperDatabaseBuilder`
_Scans codebase and builds semantic knowledge graph._

**Methods**: __init__, scan_python_file, scan_javascript_file, should_skip_directory, build, generate_markdown_report, generate_json_report


### hypercode\mcp\servers\hypercode_syntax.py

#### `HyperCodeSyntaxServer`
_üé® MCP Server for HyperCode Visual Syntax Integration_

**Methods**: __init__, _initialize, _generate_diagnostics, _get_annotation_hover_info


### hypercode\new files to check\backend\research\models.py

#### `Study`
_Top‚Äëlevel research study.

Each research endeavour (for example, "ADHD editing patterns in
HyperCode v0.3") is represented by a Study.  Studies have
optional tags for categorisation and can be linked to multiple
sources, tasks and sessions._

**Methods**: __repr__


#### `Source`
_External or internal resource used in a study.

Examples include published papers, blog posts, videos, design
documents or spec notes.  The ``storage_path`` points to the
persisted location of the source material if it exists on disk or
in object storage.  The optional ``summary`` can store a human or
machine generated abstract of the resource._

**Methods**: __repr__


#### `LanguageVersion`
_Version of the HyperCode language.

Tracks semantic changes and meta information about a particular
version of HyperCode.  The optional ``spec_source_id`` can be
linked to a Source row representing the language specification._

**Methods**: __repr__


#### `Task`
_A coding task or challenge used in experiments.

Tasks describe the problem statement and any relevant metadata so
that results can be compared across participants and language
versions._

**Methods**: __repr__


#### `Participant`
_An anonymised participant in the study.

Participants are keyed by a code rather than a real identity to
preserve privacy.  Additional demographic information could be
stored here if needed (for example, ND profile flags)._

**Methods**: __repr__


#### `Session`
_A single coding session of a participant performing a task.

A session links together a study, participant, task and language
version.  It captures metadata about the environment and an
optional free form note field for the researcher._

**Methods**: __repr__


#### `Event`
_Low‚Äëlevel interaction within a session.

Events capture keystrokes, runs, errors, completions or any
arbitrary interaction that occurs during a coding session.  The
``data`` column stores a flexible payload to accommodate
different kinds of events._

**Methods**: __repr__


#### `Feedback`
_Qualitative and quantitative feedback for a session.

Stores ratings for flow, clarity and frustration along with
free‚Äëform comments.  Additional embedding support can be added
later for semantic searches._

**Methods**: __repr__


### hypercode\scripts\style_guide_collector.py

#### `StyleGuideCollector`
_üé® Collects and analyzes style guide feedback from the community_

**Methods**: __init__, _load_feedback, _save_feedback, add_feedback, _update_analysis, analyze_feedback, _get_top_items, _calculate_consensus, _generate_recommendations, import_github_issues, generate_report, interactive_feedback


### hypercode\src\ai_gateway\claude_adapter.py

#### `ClaudeAdapterAdapter`
_Adapter for Claude Adapter AI model._

**Methods**: __init__


### hypercode\src\ai_gateway\mistral_adapter.py

#### `MistralAdapterAdapter`
_Adapter for Mistral Adapter AI model._

**Methods**: __init__


### hypercode\src\ai_gateway\ollama_adapter.py

#### `OllamaAdapterAdapter`
_Adapter for Ollama Adapter AI model._

**Methods**: __init__


### hypercode\src\ai_gateway\openai_adapter.py

#### `OpenaiAdapterAdapter`
_Adapter for Openai Adapter AI model._

**Methods**: __init__


### hypercode\src\claude_adapter.py

#### `ClaudeAdapterAdapter`
_Adapter for Claude Adapter AI model._

**Methods**: __init__


### hypercode\src\core\ast.py

#### `Node`
**Methods**: accept


#### `Expr`

#### `Literal`

#### `Variable`

#### `Assign`

#### `Binary`

#### `Unary`

#### `Grouping`

#### `Call`

#### `Get`

#### `Stmt`

#### `Expression`

#### `Print`

#### `Var`

#### `Block`

#### `Intent`

#### `Function`

#### `If`

#### `Return`

#### `Program`

### hypercode\src\core\ast_nodes.py

#### `Node`
_Base class for all AST nodes._


#### `Expression`
_Base class for all expression nodes._


#### `Statement`
_Base class for all statement nodes._


#### `Program`
_Represents the entire program as a list of statements._


#### `Identifier`
_Represents an identifier (e.g., a variable name)._


#### `Literal`
_Represents a literal value (e.g., number, string)._


#### `VariableDeclaration`
_Represents a variable declaration (let or const)._


#### `BinaryOperation`
_Represents a binary operation (e.g., a + b)._


### hypercode\src\core\interpreter.py

#### `RuntimeError`
**Methods**: __init__


#### `Environment`
**Methods**: __init__, define, get, assign


#### `Callable`
**Methods**: arity, call


#### `Function`
**Methods**: __init__, call, arity


#### `ReturnException`
**Methods**: __init__


#### `Interpreter`
**Methods**: __init__, execute_block, interpret, execute, evaluate, visit_Expression, visit_Print, visit_Var, visit_Block, visit_Expression, visit_Print, visit_Intent, visit_Function, visit_Return, visit_Literal, visit_Grouping, visit_Variable, visit_Assign, visit_Call, visit_Binary, visit_Unary, is_truthy, stringify, get_output


#### `Clock`
**Methods**: arity, call, __str__


### hypercode\src\core\lexer.py

#### `LexerError`
_Represents a lexical analysis error.

Attributes:
    message: Description of the error
    line: Line number where the error occurred (1-based)
    column: Column number where the error occurred (1-based)
    length: Length of the problematic token (default: 1)_


#### `Lexer`
_Lexical analyzer for the HyperCode programming language.

Converts source code into a sequence of tokens that can be parsed.
Handles syntax highlighting, error reporting, and source mapping._

**Methods**: __init__, scan_tokens, scan_token, number, string, docstring, identifier, error, is_at_end, advance, match, peek, peek_next, add_token


### hypercode\src\core\parser.py

#### `ParseError`

#### `Parser`
**Methods**: __init__, parse, declaration, var_declaration, statement, print_statement, expression_statement, block, expression, assignment, equality, comparison, term, factor, unary, primary, function, if_statement, return_statement, match, consume, error, synchronize, check, advance, is_at_end, peek, previous


### hypercode\src\core\tokens.py

#### `TokenType`

#### `Token`
_Represents a token in the HyperCode language.

Attributes:
    type: The type of the token (from TokenType)
    lexeme: The actual text that was matched
    literal: The literal value (for numbers, strings, etc.)
    line: The line number where the token appears (1-based)
    column: The column number where the token starts (1-based)_

**Methods**: __init__, __str__, __repr__


### hypercode\src\duelcode\duelcode_validator.py

#### `Severity`

#### `ValidationResult`

#### `DuelCodeValidator`
_Validates DuelCode documentation files against the required format._

**Methods**: __init__, _add_result, _find_lines, validate, validate_structure, validate_headings, validate_code_blocks, validate_checklists, validate_visual_elements, validate_links


### hypercode\src\duelcode\enhanced_validator.py

#### `Severity`

#### `ValidationResult`

#### `DuelCodeEnhancedValidator`
_Enhanced validator with additional rules for DuelCode documentation._

**Methods**: __init__, _add_result, _find_lines, validate_code_blocks_have_language, validate_has_visual_representation, validate_has_practical_exercise, validate_has_learning_objectives, validate_has_checklist, validate_has_conclusion, validate_has_whats_next, validate_code_quality, _analyze_code_block, _analyze_python_code, _analyze_javascript_code, validate_has_glossary, validate_has_see_also, validate_has_faq, validate_has_acknowledgments, validate_all


### hypercode\src\duelcode\test_framework.py

#### `TestResult`

#### `TestCase`

#### `TestRun`

#### `DuelCodeTestSuite`
**Methods**: __init__, discover_tutorials, run_validator, parse_validator_output, test_tutorial, test_validator_integrity, test_template_validity, run_all_tests, generate_report


### hypercode\src\duelcode\ultra_validator.py

#### `Severity`

#### `ValidationResult`

#### `DuelCodeUltraValidator`
_Ultra-enhanced validator with comprehensive rules for DuelCode documentation._

**Methods**: __init__, _add_result, _find_lines, validate_code_blocks_have_language, validate_has_visual_representation, validate_has_practical_exercise, validate_has_learning_objectives, validate_has_checklist, validate_has_conclusion, validate_has_whats_next, validate_code_quality, _validate_code_block_content, validate_has_glossary, validate_has_see_also, validate_has_faq, validate_has_acknowledgments, validate_accessibility, validate_interactive_elements, validate_all, print_results


### hypercode\src\duelcode\validate_duelcode.py

#### `DuelCodeValidator`
**Methods**: __init__, validate_sections, check_formatting, check_visual_aids, validate


### hypercode\src\duelcode_validator.py

#### `Severity`

#### `ValidationResult`

#### `DuelCodeValidator`
_Validates DuelCode documentation files against the required format._

**Methods**: __init__, _add_result, _find_lines, validate, validate_structure, validate_headings, validate_code_blocks, validate_checklists, validate_visual_elements, validate_links


### hypercode\src\enhanced_validator.py

#### `Severity`

#### `ValidationResult`

#### `DuelCodeEnhancedValidator`
_Enhanced validator with additional rules for DuelCode documentation._

**Methods**: __init__, _add_result, _find_lines, validate_code_blocks_have_language, validate_has_visual_representation, validate_has_practical_exercise, validate_has_learning_objectives, validate_has_checklist, validate_has_conclusion, validate_has_whats_next, validate_code_quality, _analyze_code_block, _analyze_python_code, _analyze_javascript_code, validate_has_glossary, validate_has_see_also, validate_has_faq, validate_has_acknowledgments, validate_all


### hypercode\src\hypercode-backend-js-COMPLETE.py

#### `JSCompiler`
_Compiles HyperCode AST to JavaScript.

Output format:
- Runs in Node.js or browser
- Uses Uint8Array for memory tape
- Implements all core operations
- Includes runtime error checking_

**Methods**: __init__, compile, _generate_header, _generate_setup, _generate_main, _generate_footer, _indent, optimize_ast


### hypercode\src\hypercode-launch-kit.py

#### `HyperCodeLaunchKit`
_Complete launch system initialization_

**Methods**: __init__, create_readme, create_launch_checklist, create_launch_script, create_first_30_days, print_summary


### hypercode\src\hypercode-lexer-COMPLETE.py

#### `TokenType`
_HyperCode token types - minimal yet powerful_


#### `Token`
_Represents a single token with position tracking_

**Methods**: __repr__


#### `LexerError`
_Lexer-specific errors with context_

**Methods**: __init__


#### `HyperCodeLexer`
_Tokenizes HyperCode programs with accessibility features.

Design principles:
- Clear error messages (neurodivergent-friendly)
- Position tracking (helps with debugging)
- Colorized output (optional, for visual learners)
- Comments preserved (for documentation)_

**Methods**: __init__, tokenize, _advance_position, _skip_comment, get_tokens, filter_tokens, print_tokens, get_statistics


### hypercode\src\hypercode-parser-COMPLETE.py

#### `NodeType`
_AST Node types_


#### `ASTNode`
_Abstract Syntax Tree Node.

Represents a single operation or block in HyperCode._

**Methods**: __repr__


#### `ParserError`
_Parser-specific errors with context_

**Methods**: __init__


#### `HyperCodeParser`
_Parses HyperCode token stream into AST.

Grammar (simplified BNF):

program    ::= statement*
statement  ::= operation | loop | spatial | ai_native
operation  ::= PUSH | POP | INCR | DECR | OUTPUT | INPUT
loop       ::= LOOP_START statement* LOOP_END
spatial    ::= SPATIAL_2D statement*
ai_native  ::= AI_NATIVE_

**Methods**: __init__, parse, _parse_statement, _parse_loop, _advance, _is_at_end, validate, print_ast


### hypercode\src\hypercode\config.py

#### `Config`
_Configuration class for HyperCode_

**Methods**: get_headers


### hypercode\src\hypercode\core\ast.py

#### `Node`
**Methods**: accept


#### `Expr`

#### `Literal`

#### `Variable`

#### `Assign`

#### `Binary`

#### `Unary`

#### `Grouping`

#### `Call`

#### `Get`

#### `Stmt`

#### `Expression`

#### `Print`

#### `Var`

#### `Block`

#### `If`

#### `Fun`

#### `Return`

#### `Intent`

#### `Program`

### hypercode\src\hypercode\core\interpreter.py

#### `Return`
**Methods**: __init__


#### `HyperCodeFunction`
**Methods**: __init__, __str__, arity, call


#### `Environment`
**Methods**: __init__, define, get, assign


#### `Interpreter`
**Methods**: __init__, interpret, execute, execute_block, evaluate, visit_Expression, visit_Print, visit_Var, visit_Block, visit_Assign, visit_Binary, visit_Grouping, visit_Literal, visit_Unary, visit_Variable, visit_If, is_truthy, visit_Fun, visit_Return, visit_Call, is_callable


#### `Visitor`
**Methods**: visit_Expression, visit_Print, visit_Var, visit_Block, visit_If, visit_Fun, visit_Return, visit_Assign, visit_Binary, visit_Grouping, visit_Literal, visit_Unary, visit_Variable, visit_Call


### hypercode\src\hypercode\core\lexer.py

#### `LexerError`
_Exception raised for errors in the lexer._

**Methods**: __init__


#### `Lexer`
_Lexical analyzer for the HyperCode language.

Converts source code into a sequence of tokens that can be processed
by the parser._

**Methods**: __init__, tokenize, _match_patterns, _update_position, _add_token, _handle_unknown


### hypercode\src\hypercode\core\parser.py

#### `ParseError`

#### `Parser`
**Methods**: __init__, parse, declaration, var_declaration, statement, print_statement, return_statement, intent_statement, expression_statement, if_statement, function, block, expression, assignment, equality, comparison, term, factor, unary, primary, _primary, finish_call, match, consume, error, synchronize, check, advance, is_at_end, peek, previous


### hypercode\src\hypercode\core\sensory_profile.py

#### `VisualNoiseLevel`

#### `AnimationSpeed`

#### `VisualSettings`
_Configuration for visual aspects of the editor._


#### `AudioSettings`
_Configuration for audio feedback._


#### `AnimationSettings`
_Configuration for animations and transitions._


#### `SensoryProfile`
_A complete sensory profile configuration._

**Methods**: to_dict, from_dict, save, load


#### `ProfileManager`
_Manages loading and saving of sensory profiles._

**Methods**: __init__, _ensure_default_profiles, _create_minimal_profile, _create_enhanced_profile, _create_high_contrast_profile, list_profiles, get_profile, save_profile, delete_profile


### hypercode\src\hypercode\core\tokens.py

#### `TokenType`

#### `Token`
**Methods**: __str__


### hypercode\src\hypercode\enhanced_perplexity_client.py

#### `EnhancedPerplexityClient`
_Enhanced Perplexity client with knowledge base integration_

**Methods**: __init__, query_with_context, add_research_data, search_research_data, list_research_documents, get_document, delete_document, import_from_perplexity_space, test_context_integration


### hypercode\src\hypercode\knowledge_base.py

#### `ResearchDocument`
_Represents a research document from Perplexity Space_

**Methods**: __post_init__, generate_id, validate, update_timestamp


#### `HyperCodeKnowledgeBase`
_Knowledge base for HyperCode research data_

**Methods**: __init__, load, save, add_document, search_documents, get_context_for_query, list_documents, get_document, delete_document, update_document, search_by_tags, get_document_statistics, export_format, validate_all_documents, cleanup_duplicates


### hypercode\src\hypercode\perplexity_client.py

#### `PerplexityClient`
_Client for interacting with Perplexity AI API_

**Methods**: __init__, query


### hypercode\src\hypercode_idea_generator.py

#### `HyperCodeIdeaGenerator`
_AI-Powered Idea Generator for HyperCode community input.

Generates recommendations across categories & difficulty levels.
Tracks community voting to identify most-wanted features._

**Methods**: __init__, get_ideas_by_category, get_top_ideas, vote_for_idea, get_trending_ideas, format_idea_card


### hypercode\src\hypercode_poc.py

#### `TokenType`
_Brainfuck-inspired core + modern aliases_


#### `Token`

#### `UserConfidenceLevel`

#### `EnhancedLexer`
_Smart tokenizer with escape handling + accessibility focus_

**Methods**: __init__, tokenize, handle_string, handle_number, handle_identifier, advance


#### `ContextAwareErrorMessenger`
_Friendly, adaptive error messages_

**Methods**: __init__, format_error


#### `SemanticContextStreamer`
_Understand programmer intent from tokens_

**Methods**: analyze


#### `ConfidenceTracker`
_Adapt system guidance to user skill level_

**Methods**: __init__, record


#### `HyperCodePOC`
_Main system: Lexer + Error Messenger + Semantic Analyzer + Confidence Tracker_

**Methods**: __init__, compile


### hypercode\src\mistral_adapter.py

#### `MistralAdapterAdapter`
_Adapter for Mistral Adapter AI model._

**Methods**: __init__


### hypercode\src\ollama_adapter.py

#### `OllamaAdapterAdapter`
_Adapter for Ollama Adapter AI model._

**Methods**: __init__


### hypercode\src\openai_adapter.py

#### `OpenaiAdapterAdapter`
_Adapter for Openai Adapter AI model._

**Methods**: __init__


### hypercode\src\parser\visual_syntax_parser.py

#### `SemanticMarker`
_üé® Semantic marker types with emoji representations_


#### `SemanticAnnotation`
_üìã A single semantic annotation with its metadata_

**Methods**: __str__


#### `ParsedFunction`
_üîç A fully parsed HyperCode function_

**Methods**: get_annotations_by_type


#### `VisualSyntaxParser`
_üé® Main parser for HyperCode's visual semantic syntax_

**Methods**: __init__, _build_semantic_patterns, _build_color_scheme, parse_file, parse_content, _is_function_definition, _start_new_function, _parse_line_annotations, _parse_annotation_params, generate_syntax_highlighting, extract_semantic_summary, validate_neurodiversity_compliance


### hypercode\src\test_framework.py

#### `TestResult`

#### `TestCase`

#### `TestRun`

#### `DuelCodeTestSuite`
**Methods**: __init__, discover_tutorials, run_validator, parse_validator_output, test_tutorial, test_validator_integrity, test_template_validity, run_all_tests, generate_report


### hypercode\src\ultra_validator.py

#### `Severity`

#### `ValidationResult`

#### `DuelCodeUltraValidator`
_Ultra-enhanced validator with comprehensive rules for DuelCode documentation._

**Methods**: __init__, _add_result, _find_lines, validate_code_blocks_have_language, validate_has_visual_representation, validate_has_practical_exercise, validate_has_learning_objectives, validate_has_checklist, validate_has_conclusion, validate_has_whats_next, validate_code_quality, _validate_code_block_content, validate_has_glossary, validate_has_see_also, validate_has_faq, validate_has_acknowledgments, validate_accessibility, validate_interactive_elements, validate_all, print_results


### hypercode\src\utils\code_analyzer_ai.py

#### `CodeAnalyzerAI`
_AI-powered code analyzer for HyperCode_

**Methods**: __init__, analyze_file, _analyze_complexity, _check_docstrings, _get_ai_code_analysis, analyze_project, _get_project_ai_insights, save_analysis, print_summary


### hypercode\src\utils\health_scanner_ai.py

#### `HealthScannerAI`
_AI-powered health scanner for HyperCode project_

**Methods**: __init__, analyze_project_structure, analyze_dependencies, analyze_security, get_ai_recommendations, run_full_scan, save_report, print_summary


### hypercode\src\utils\import-helper.py

#### `SpaceImportHelper`
_Helper class for managing Perplexity Space imports_

**Methods**: __init__, validate_document, load_template, validate_all, generate_report, create_import_script, create_template_instructions


### hypercode\src\utils\local_health_scanner.py

#### `ProjectScanner`
_Scans the project for health metrics without external dependencies_

**Methods**: __init__, scan_project, _scan_directory, _analyze_file, _analyze_ast, _check_documentation, _check_tests, _calculate_metrics


### hypercode\src\validate_duelcode.py

#### `DuelCodeValidator`
**Methods**: __init__, validate_sections, check_formatting, check_visual_aids, validate


### hypercode\tests\benchmark_knowledge_base.py

#### `BenchmarkSuite`
_Comprehensive benchmark suite for Knowledge Base_

**Methods**: __init__, _get_system_info, generate_test_data, benchmark_operation, run_benchmark_suite, _calculate_summary, _generate_recommendations, generate_markdown_report, save_json_results


### hypercode\tests\test_interpreter.py

#### `TestInterpreter`
**Methods**: test_if_statement_then, test_if_statement_else, test_function_call, test_function_with_parameters, test_function_with_return, test_recursive_function_call, test_scoping


### hypercode\tests\test_knowledge_base.py

#### `TestKnowledgeBaseSearch`
_Test suite for knowledge base search functionality._

**Methods**: sample_documents, knowledge_base, test_basic_search, test_search_with_exact_match, test_search_case_insensitive, test_search_empty_query, test_search_no_matches, test_search_ranking, test_query_normalization, test_multi_word_query, test_tag_based_search


#### `TestEdgeCases`
_Test edge cases and boundary conditions._

**Methods**: knowledge_base, test_very_short_query, test_very_long_query, test_special_characters_in_query, test_unicode_in_query, test_sql_injection_attempt, test_repeated_queries


#### `TestPerformance`
_Performance benchmarking tests._

**Methods**: large_knowledge_base, test_search_response_time, test_concurrent_searches, test_memory_usage


#### `TestIntegrationWithPerplexity`
_Test integration with EnhancedPerplexityClient._

**Methods**: mock_perplexity_client, mock_knowledge_base, test_enhanced_query_with_context, test_fallback_to_perplexity_api, test_context_ranking_and_selection


#### `TestDocumentManagement`
_Test document addition, update, and removal._

**Methods**: knowledge_base, test_add_document, test_update_document, test_remove_document


### hypercode\tests\test_knowledge_base_comprehensive.py

#### `TestKnowledgeBaseUnit`
_Unit tests for Knowledge Base functionality_

**Methods**: temp_kb, sample_docs, test_init_empty_kb, test_add_single_document, test_add_multiple_documents, test_save_and_load, test_search_exact_match, test_search_partial_match, test_search_tag_matching, test_search_case_insensitive, test_empty_search, test_nonexistent_search, test_get_context_for_query, test_context_length_limit, test_document_update, test_list_documents, test_delete_document


#### `TestKnowledgeBaseIntegration`
_Integration tests for Knowledge Base_

**Methods**: populated_kb, test_complex_search_queries, test_search_ranking_quality, test_related_term_expansion, test_performance_with_large_dataset, test_concurrent_access_simulation


#### `TestKnowledgeBasePerformance`
_Performance tests for Knowledge Base_

**Methods**: large_kb, test_search_performance_large_dataset, test_save_performance_large_dataset, test_load_performance_large_dataset, test_memory_usage_large_dataset


#### `TestKnowledgeBaseEdgeCases`
_Edge case tests for Knowledge Base_

**Methods**: edge_case_kb, test_empty_title_handling, test_special_characters_handling, test_very_long_titles, test_empty_content_handling, test_none_tags_handling, test_malformed_json_handling, test_file_permission_handling


### hypercode\tests\unit\test_knowledge_base.py

#### `TestHyperCodeKnowledgeBase`
_Test suite for HyperCodeKnowledgeBase core functionality_

**Methods**: temp_kb, sample_documents, test_init_empty_kb, test_add_document, test_add_multiple_documents, test_save_and_load, test_search_exact_match, test_search_tag_matching, test_search_related_terms, test_search_space_data_boost, test_get_context_for_query, test_context_length_limit, test_list_documents, test_empty_search, test_search_nonexistent_term, test_document_update


#### `TestResearchDocument`
_Test suite for ResearchDocument dataclass_

**Methods**: test_document_creation, test_document_optional_fields


### hypercode\tests\unit\test_search_algorithm.py

#### `TestSearchAlgorithm`
_Test suite for search algorithm functionality_

**Methods**: populated_kb, test_exact_title_match_highest_score, test_space_data_boosting, test_related_term_expansion, test_tag_matching_scoring, test_content_frequency_scoring, test_partial_word_matching, test_query_word_ordering, test_case_insensitive_search, test_empty_query_returns_no_results, test_limit_parameter_respected, test_no_results_for_nonexistent_terms, test_special_characters_in_query, test_unicode_characters, test_search_performance_with_large_kb, test_search_result_consistency


#### `TestSearchScoringDetails`
_Test detailed scoring algorithm behavior_

**Methods**: scoring_kb, test_title_match_beats_content_match, test_space_data_boosting_works, test_frequency_scoring


### hypercode_db.py

#### `CodeEntity`
_Represents a code entity (class, function, etc.) in the database._

**Methods**: __post_init__


#### `HypercodeDB`
_In-memory database for Hypercode project analysis.

This class provides efficient querying and analysis of code entities
loaded from a JSON database file._

**Methods**: __init__, _load_database, get_entities_by_type, get_entities_in_file


### live_research\database.py

#### `ResearchDatabase`
**Methods**: __init__, _get_connection, _create_tables, add_research_entry, get_research_entry, search_entries, import_from_json


### mcp\servers\hypercode_syntax.py

#### `HyperCodeSyntaxServer`
_üé® MCP Server for HyperCode Visual Syntax Integration_

**Methods**: __init__, _initialize, _generate_diagnostics, _get_annotation_hover_info


### new files to check\backend\research\models.py

#### `Study`
_Top‚Äëlevel research study.

Each research endeavour (for example, "ADHD editing patterns in
HyperCode v0.3") is represented by a Study.  Studies have
optional tags for categorisation and can be linked to multiple
sources, tasks and sessions._

**Methods**: __repr__


#### `Source`
_External or internal resource used in a study.

Examples include published papers, blog posts, videos, design
documents or spec notes.  The ``storage_path`` points to the
persisted location of the source material if it exists on disk or
in object storage.  The optional ``summary`` can store a human or
machine generated abstract of the resource._

**Methods**: __repr__


#### `LanguageVersion`
_Version of the HyperCode language.

Tracks semantic changes and meta information about a particular
version of HyperCode.  The optional ``spec_source_id`` can be
linked to a Source row representing the language specification._

**Methods**: __repr__


#### `Task`
_A coding task or challenge used in experiments.

Tasks describe the problem statement and any relevant metadata so
that results can be compared across participants and language
versions._

**Methods**: __repr__


#### `Participant`
_An anonymised participant in the study.

Participants are keyed by a code rather than a real identity to
preserve privacy.  Additional demographic information could be
stored here if needed (for example, ND profile flags)._

**Methods**: __repr__


#### `Session`
_A single coding session of a participant performing a task.

A session links together a study, participant, task and language
version.  It captures metadata about the environment and an
optional free form note field for the researcher._

**Methods**: __repr__


#### `Event`
_Low‚Äëlevel interaction within a session.

Events capture keystrokes, runs, errors, completions or any
arbitrary interaction that occurs during a coding session.  The
``data`` column stores a flexible payload to accommodate
different kinds of events._

**Methods**: __repr__


#### `Feedback`
_Qualitative and quantitative feedback for a session.

Stores ratings for flow, clarity and frustration along with
free‚Äëform comments.  Additional embedding support can be added
later for semantic searches._

**Methods**: __repr__


### scripts\build-hyper-database.py

#### `HyperDatabaseBuilder`
_Scans codebase and builds semantic knowledge graph._

**Methods**: __init__, scan_python_file, scan_javascript_file, should_skip_directory, build, generate_markdown_report, generate_json_report


### scripts\build_knowledge_base.py

#### `KnowledgeBaseBuilder`
_Build a knowledge base from the HyperCode repository._

**Methods**: __init__, should_skip, get_file_type, process_file, build_index


### scripts\document_processor.py

#### `DocumentProcessor`
_Process various document types and extract content._

**Methods**: get_file_hash, extract_metadata, extract_pdf_content, extract_markdown_content, extract_docx_content, extract_csv_content, extract_text_content, process_document


### scripts\run_lexer.py

#### `TestLexer`
_Test suite for the HyperCode lexer._

**Methods**: setUp, test_empty_source, test_basic_tokens, test_string_literals, test_numbers, test_arithmetic_expressions, test_comments, test_error_handling, test_error_recovery, _assert_token_types, test_lexer_error_class


### scripts\style_guide_collector.py

#### `StyleGuideCollector`
_üé® Collects and analyzes style guide feedback from the community_

**Methods**: __init__, _load_feedback, _save_feedback, add_feedback, _update_analysis, analyze_feedback, _get_top_items, _calculate_consensus, _generate_recommendations, import_github_issues, generate_report, interactive_feedback


### scripts\sync-space-to-main.py

#### `Colors`

### src\ai_gateway\claude_adapter.py

#### `ClaudeAdapterAdapter`
_Adapter for Claude Adapter AI model._

**Methods**: __init__


### src\ai_gateway\mistral_adapter.py

#### `MistralAdapterAdapter`
_Adapter for Mistral Adapter AI model._

**Methods**: __init__


### src\ai_gateway\ollama_adapter.py

#### `OllamaAdapterAdapter`
_Adapter for Ollama Adapter AI model._

**Methods**: __init__


### src\ai_gateway\openai_adapter.py

#### `OpenaiAdapterAdapter`
_Adapter for Openai Adapter AI model._

**Methods**: __init__


### src\claude_adapter.py

#### `ClaudeAdapterAdapter`
_Adapter for Claude Adapter AI model._

**Methods**: __init__


### src\core\ast.py

#### `Node`
_Base class for all AST nodes._


#### `Program`
_Represents a complete HyperCode program._


#### `Function`
_Represents a function definition._


#### `VariableDeclaration`
_Represents a variable declaration._


#### `Literal`
_Represents a literal value (number, string, boolean, etc.)._


#### `BinaryOp`
_Represents a binary operation (e.g., 1 + 2)._


#### `UnaryOp`
_Represents a unary operation (e.g., -1 or !true)._


#### `Variable`
_Represents a variable reference._


#### `Call`
_Represents a function call._


#### `Return`
_Represents a return statement._


#### `Block`
_Represents a block of statements._


#### `If`
_Represents an if statement._


#### `While`
_Represents a while loop._


#### `For`
_Represents a for loop._


#### `Assign`
_Represents a variable assignment._


#### `Logical`
_Represents a logical operation (and/or)._


### src\core\ast_nodes.py

#### `Node`
_Base class for all AST nodes._


#### `Expression`
_Base class for all expression nodes._


#### `Statement`
_Base class for all statement nodes._


#### `Program`
_Represents the entire program as a list of statements._


#### `Identifier`
_Represents an identifier (e.g., a variable name)._


#### `Literal`
_Represents a literal value (e.g., number, string)._


#### `VariableDeclaration`
_Represents a variable declaration (let or const)._


#### `BinaryOperation`
_Represents a binary operation (e.g., a + b)._


### src\core\hypercode-\DuelCode\duelcode_validator.py

#### `Severity`

#### `ValidationResult`

#### `DuelCodeValidator`
_Validates DuelCode documentation files against the required format._

**Methods**: __init__, _add_result, _find_lines, validate, validate_structure, validate_headings, validate_code_blocks, validate_checklists, validate_visual_elements, validate_links


### src\core\hypercode-\DuelCode\enhanced_validator.py

#### `Severity`

#### `ValidationResult`

#### `DuelCodeEnhancedValidator`
_Enhanced validator with additional rules for DuelCode documentation._

**Methods**: __init__, _add_result, _find_lines, validate_code_blocks_have_language, validate_has_visual_representation, validate_has_practical_exercise, validate_has_learning_objectives, validate_has_checklist, validate_has_conclusion, validate_has_whats_next, validate_code_quality, _analyze_code_block, _analyze_python_code, _analyze_javascript_code, validate_has_glossary, validate_has_see_also, validate_has_faq, validate_has_acknowledgments, validate_all


### src\core\hypercode-\DuelCode\test_framework.py

#### `TestResult`

#### `TestCase`

#### `TestRun`

#### `DuelCodeTestSuite`
**Methods**: __init__, discover_tutorials, run_validator, parse_validator_output, test_tutorial, test_validator_integrity, test_template_validity, run_all_tests, generate_report


### src\core\hypercode-\DuelCode\ultra_validator.py

#### `Severity`

#### `ValidationResult`

#### `DuelCodeUltraValidator`
_Ultra-enhanced validator with comprehensive rules for DuelCode documentation._

**Methods**: __init__, _add_result, _find_lines, validate_code_blocks_have_language, validate_has_visual_representation, validate_has_practical_exercise, validate_has_learning_objectives, validate_has_checklist, validate_has_conclusion, validate_has_whats_next, validate_code_quality, _validate_code_block_content, validate_has_glossary, validate_has_see_also, validate_has_faq, validate_has_acknowledgments, validate_accessibility, validate_interactive_elements, validate_all, print_results


### src\core\hypercode-\DuelCode\validate_duelcode.py

#### `DuelCodeValidator`
**Methods**: __init__, validate_sections, check_formatting, check_visual_aids, validate


### src\core\hypercode-\ai_gateway\claude_adapter.py

#### `ClaudeAdapterAdapter`
_Adapter for Claude Adapter AI model._

**Methods**: __init__


### src\core\hypercode-\ai_gateway\mistral_adapter.py

#### `MistralAdapterAdapter`
_Adapter for Mistral Adapter AI model._

**Methods**: __init__


### src\core\hypercode-\ai_gateway\ollama_adapter.py

#### `OllamaAdapterAdapter`
_Adapter for Ollama Adapter AI model._

**Methods**: __init__


### src\core\hypercode-\ai_gateway\openai_adapter.py

#### `OpenaiAdapterAdapter`
_Adapter for Openai Adapter AI model._

**Methods**: __init__


### src\core\hypercode-\code_analyzer_ai.py

#### `CodeAnalyzerAI`
_AI-powered code analyzer for HyperCode_

**Methods**: __init__, analyze_file, _analyze_complexity, _check_docstrings, _get_ai_code_analysis, analyze_project, _get_project_ai_insights, save_analysis, print_summary


### src\core\hypercode-\health_scanner_ai.py

#### `HealthScannerAI`
_AI-powered health scanner for HyperCode project_

**Methods**: __init__, analyze_project_structure, analyze_dependencies, analyze_security, get_ai_recommendations, run_full_scan, save_report, print_summary


### src\core\hypercode-\import-helper.py

#### `SpaceImportHelper`
_Helper class for managing Perplexity Space imports_

**Methods**: __init__, validate_document, load_template, validate_all, generate_report, create_import_script, create_template_instructions


### src\core\hypercode-\mcp\servers\hypercode_syntax.py

#### `HyperCodeSyntaxServer`
_üé® MCP Server for HyperCode Visual Syntax Integration_

**Methods**: __init__, _initialize, _generate_diagnostics, _get_annotation_hover_info


### src\core\hypercode-\scripts\style_guide_collector.py

#### `StyleGuideCollector`
_üé® Collects and analyzes style guide feedback from the community_

**Methods**: __init__, _load_feedback, _save_feedback, add_feedback, _update_analysis, analyze_feedback, _get_top_items, _calculate_consensus, _generate_recommendations, import_github_issues, generate_report, interactive_feedback


### src\core\hypercode-\src\core\ast_nodes.py

#### `Node`
_Base class for all AST nodes._


#### `Expression`
_Base class for all expression nodes._


#### `Statement`
_Base class for all statement nodes._


#### `Program`
_Represents the entire program as a list of statements._


#### `Identifier`
_Represents an identifier (e.g., a variable name)._


#### `Literal`
_Represents a literal value (e.g., number, string)._


#### `VariableDeclaration`
_Represents a variable declaration (let or const)._


#### `BinaryOperation`
_Represents a binary operation (e.g., a + b)._


### src\core\hypercode-\src\core\lexer.py

#### `LexerError`
_Represents a lexical analysis error.

Attributes:
    message: Description of the error
    line: Line number where the error occurred (1-based)
    column: Column number where the error occurred (1-based)
    length: Length of the problematic token (default: 1)_


#### `Lexer`
_Lexical analyzer for the HyperCode programming language.

Converts source code into a sequence of tokens that can be parsed.
Handles syntax highlighting, error reporting, and source mapping.

Attributes:
    source: The source code to tokenize
    tokens: List of tokens generated from the source
    errors: List of lexing errors encountered
    start: Starting position of the current lexeme
    current: Current position in the source
    line: Current line number (1-based)
    column: Current column number (1-based)_

**Methods**: __init__, tokenize, is_at_end, scan_token, advance, add_token, error, synchronize, previous, peek_next, match, peek, string, is_digit, number, is_alpha, is_alphanumeric, is_hex_digit, identifier


### src\core\hypercode-\src\core\parser.py

#### `ParseError`

#### `Parser`
**Methods**: __init__, parse, declaration, var_declaration, statement, print_statement, expression_statement, block, expression, assignment, equality, comparison, term, factor, unary, primary, match, consume, error, synchronize, check, advance, is_at_end, peek, previous


### src\core\hypercode-\src\hypercode-backend-js-COMPLETE.py

#### `JSCompiler`
_Compiles HyperCode AST to JavaScript.

Output format:
- Runs in Node.js or browser
- Uses Uint8Array for memory tape
- Implements all core operations
- Includes runtime error checking_

**Methods**: __init__, compile, _generate_header, _generate_setup, _generate_main, _generate_footer, _indent, optimize_ast


### src\core\hypercode-\src\hypercode-launch-kit.py

#### `HyperCodeLaunchKit`
_Complete launch system initialization_

**Methods**: __init__, create_readme, create_launch_checklist, create_launch_script, create_first_30_days, print_summary


### src\core\hypercode-\src\hypercode-lexer-COMPLETE.py

#### `TokenType`
_HyperCode token types - minimal yet powerful_


#### `Token`
_Represents a single token with position tracking_

**Methods**: __repr__


#### `LexerError`
_Lexer-specific errors with context_

**Methods**: __init__


#### `HyperCodeLexer`
_Tokenizes HyperCode programs with accessibility features.

Design principles:
- Clear error messages (neurodivergent-friendly)
- Position tracking (helps with debugging)
- Colorized output (optional, for visual learners)
- Comments preserved (for documentation)_

**Methods**: __init__, tokenize, _advance_position, _skip_comment, get_tokens, filter_tokens, print_tokens, get_statistics


### src\core\hypercode-\src\hypercode-parser-COMPLETE.py

#### `NodeType`
_AST Node types_


#### `ASTNode`
_Abstract Syntax Tree Node.

Represents a single operation or block in HyperCode._

**Methods**: __repr__


#### `ParserError`
_Parser-specific errors with context_

**Methods**: __init__


#### `HyperCodeParser`
_Parses HyperCode token stream into AST.

Grammar (simplified BNF):

program    ::= statement*
statement  ::= operation | loop | spatial | ai_native
operation  ::= PUSH | POP | INCR | DECR | OUTPUT | INPUT
loop       ::= LOOP_START statement* LOOP_END
spatial    ::= SPATIAL_2D statement*
ai_native  ::= AI_NATIVE_

**Methods**: __init__, parse, _parse_statement, _parse_loop, _advance, _is_at_end, validate, print_ast


### src\core\hypercode-\src\hypercode\config.py

#### `Config`
_Configuration class for HyperCode_

**Methods**: get_headers


### src\core\hypercode-\src\hypercode\core\ast.py

#### `Node`
**Methods**: accept


#### `Expr`

#### `Literal`

#### `Variable`

#### `Assign`

#### `Binary`

#### `Unary`

#### `Grouping`

#### `Call`

#### `Get`

#### `Stmt`

#### `Expression`

#### `Print`

#### `Var`

#### `Block`

#### `Intent`

#### `Program`

### src\core\hypercode-\src\hypercode\core\lexer.py

#### `LexerError`
_Exception raised for errors in the lexer._

**Methods**: __init__


#### `Lexer`
_Lexical analyzer for the HyperCode language.

Converts source code into a sequence of tokens that can be processed
by the parser._

**Methods**: __init__, tokenize, _match_patterns, _update_position, _add_token, _handle_unknown


### src\core\hypercode-\src\hypercode\core\parser.py

#### `ParseError`

#### `Parser`
**Methods**: __init__, parse, declaration, var_declaration, statement, print_statement, intent_statement, expression_statement, block, expression, assignment, equality, comparison, term, factor, unary, primary, _primary, finish_call, match, consume, error, synchronize, check, advance, is_at_end, peek, previous


### src\core\hypercode-\src\hypercode\core\tokens.py

#### `TokenType`

#### `Token`
**Methods**: __str__


### src\core\hypercode-\src\hypercode\enhanced_perplexity_client.py

#### `EnhancedPerplexityClient`
_Enhanced Perplexity client with knowledge base integration_

**Methods**: __init__, query_with_context, add_research_data, search_research_data, list_research_documents, get_document, delete_document, import_from_perplexity_space, test_context_integration


### src\core\hypercode-\src\hypercode\knowledge_base.py

#### `ResearchDocument`
_Represents a research document from Perplexity Space_

**Methods**: __post_init__, generate_id, validate, update_timestamp


#### `HyperCodeKnowledgeBase`
_Knowledge base for HyperCode research data_

**Methods**: __init__, load, save, add_document, search_documents, get_context_for_query, list_documents, get_document, delete_document, update_document, search_by_tags, get_document_statistics, export_format, validate_all_documents, cleanup_duplicates


### src\core\hypercode-\src\hypercode\perplexity_client.py

#### `PerplexityClient`
_Client for interacting with Perplexity AI API_

**Methods**: __init__, query


### src\core\hypercode-\src\hypercode_idea_generator.py

#### `HyperCodeIdeaGenerator`
_AI-Powered Idea Generator for HyperCode community input.

Generates recommendations across categories & difficulty levels.
Tracks community voting to identify most-wanted features._

**Methods**: __init__, get_ideas_by_category, get_top_ideas, vote_for_idea, get_trending_ideas, format_idea_card


### src\core\hypercode-\src\hypercode_lexer_fixed.py

#### `TokenType`
_HyperCode token types_


#### `Token`
_Represents a single token with position tracking_

**Methods**: __repr__


#### `LexerError`
_Lexer error with context_

**Methods**: __init__


#### `HyperCodeLexerFixed`
_Fixed lexer with proper string escape sequence handling.

Escape sequences supported:
- \" = escaped double quote
- \' = escaped single quote
- \\ = escaped backslash
- \n = newline
- \t = tab
- \r = carriage return
- \b = backspace
- \f = form feed_

**Methods**: __init__, tokenize, _parse_string, _skip_comment, _advance, print_tokens


### src\core\hypercode-\src\hypercode_poc.py

#### `TokenType`
_Brainfuck-inspired core + modern aliases_


#### `Token`

#### `UserConfidenceLevel`

#### `EnhancedLexer`
_Smart tokenizer with escape handling + accessibility focus_

**Methods**: __init__, tokenize, handle_string, handle_number, handle_identifier, advance


#### `ContextAwareErrorMessenger`
_Friendly, adaptive error messages_

**Methods**: __init__, format_error


#### `SemanticContextStreamer`
_Understand programmer intent from tokens_

**Methods**: analyze


#### `ConfidenceTracker`
_Adapt system guidance to user skill level_

**Methods**: __init__, record


#### `HyperCodePOC`
_Main system: Lexer + Error Messenger + Semantic Analyzer + Confidence Tracker_

**Methods**: __init__, compile


### src\core\hypercode-\src\parser\visual_syntax_parser.py

#### `SemanticMarker`
_üé® Semantic marker types with emoji representations_


#### `SemanticAnnotation`
_üìã A single semantic annotation with its metadata_

**Methods**: __str__


#### `ParsedFunction`
_üîç A fully parsed HyperCode function_

**Methods**: get_annotations_by_type


#### `VisualSyntaxParser`
_üé® Main parser for HyperCode's visual semantic syntax_

**Methods**: __init__, _build_semantic_patterns, _build_color_scheme, parse_file, parse_content, _is_function_definition, _start_new_function, _parse_line_annotations, _parse_annotation_params, generate_syntax_highlighting, extract_semantic_summary, validate_neurodiversity_compliance


### src\core\hypercode-\tests\benchmark_knowledge_base.py

#### `BenchmarkSuite`
_Comprehensive benchmark suite for Knowledge Base_

**Methods**: __init__, _get_system_info, generate_test_data, benchmark_operation, run_benchmark_suite, _calculate_summary, _generate_recommendations, generate_markdown_report, save_json_results


### src\core\hypercode-\tests\test_knowledge_base.py

#### `TestKnowledgeBaseSearch`
_Test suite for knowledge base search functionality._

**Methods**: sample_documents, knowledge_base, test_basic_search, test_search_with_exact_match, test_search_case_insensitive, test_search_empty_query, test_search_no_matches, test_search_ranking, test_query_normalization, test_multi_word_query, test_tag_based_search


#### `TestEdgeCases`
_Test edge cases and boundary conditions._

**Methods**: knowledge_base, test_very_short_query, test_very_long_query, test_special_characters_in_query, test_unicode_in_query, test_sql_injection_attempt, test_repeated_queries


#### `TestPerformance`
_Performance benchmarking tests._

**Methods**: large_knowledge_base, test_search_response_time, test_concurrent_searches, test_memory_usage


#### `TestIntegrationWithPerplexity`
_Test integration with EnhancedPerplexityClient._

**Methods**: mock_perplexity_client, mock_knowledge_base, test_enhanced_query_with_context, test_fallback_to_perplexity_api, test_context_ranking_and_selection


#### `TestDocumentManagement`
_Test document addition, update, and removal._

**Methods**: knowledge_base, test_add_document, test_update_document, test_remove_document


### src\core\hypercode-\tests\test_knowledge_base_comprehensive.py

#### `TestKnowledgeBaseUnit`
_Unit tests for Knowledge Base functionality_

**Methods**: temp_kb, sample_docs, test_init_empty_kb, test_add_single_document, test_add_multiple_documents, test_save_and_load, test_search_exact_match, test_search_partial_match, test_search_tag_matching, test_search_case_insensitive, test_empty_search, test_nonexistent_search, test_get_context_for_query, test_context_length_limit, test_document_update, test_list_documents, test_delete_document


#### `TestKnowledgeBaseIntegration`
_Integration tests for Knowledge Base_

**Methods**: populated_kb, test_complex_search_queries, test_search_ranking_quality, test_related_term_expansion, test_performance_with_large_dataset, test_concurrent_access_simulation


#### `TestKnowledgeBasePerformance`
_Performance tests for Knowledge Base_

**Methods**: large_kb, test_search_performance_large_dataset, test_save_performance_large_dataset, test_load_performance_large_dataset, test_memory_usage_large_dataset


#### `TestKnowledgeBaseEdgeCases`
_Edge case tests for Knowledge Base_

**Methods**: edge_case_kb, test_empty_title_handling, test_special_characters_handling, test_very_long_titles, test_empty_content_handling, test_none_tags_handling, test_malformed_json_handling, test_file_permission_handling


### src\core\hypercode-\tests\unit\test_knowledge_base.py

#### `TestHyperCodeKnowledgeBase`
_Test suite for HyperCodeKnowledgeBase core functionality_

**Methods**: temp_kb, sample_documents, test_init_empty_kb, test_add_document, test_add_multiple_documents, test_save_and_load, test_search_exact_match, test_search_tag_matching, test_search_related_terms, test_search_space_data_boost, test_get_context_for_query, test_context_length_limit, test_list_documents, test_empty_search, test_search_nonexistent_term, test_document_update


#### `TestResearchDocument`
_Test suite for ResearchDocument dataclass_

**Methods**: test_document_creation, test_document_optional_fields


### src\core\hypercode-\tests\unit\test_search_algorithm.py

#### `TestSearchAlgorithm`
_Test suite for search algorithm functionality_

**Methods**: populated_kb, test_exact_title_match_highest_score, test_space_data_boosting, test_related_term_expansion, test_tag_matching_scoring, test_content_frequency_scoring, test_partial_word_matching, test_query_word_ordering, test_case_insensitive_search, test_empty_query_returns_no_results, test_limit_parameter_respected, test_no_results_for_nonexistent_terms, test_special_characters_in_query, test_unicode_characters, test_search_performance_with_large_kb, test_search_result_consistency


#### `TestSearchScoringDetails`
_Test detailed scoring algorithm behavior_

**Methods**: scoring_kb, test_title_match_beats_content_match, test_space_data_boosting_works, test_frequency_scoring


### src\core\interpreter.py

#### `RuntimeError`
**Methods**: __init__


#### `Environment`
**Methods**: __init__, define, get, assign


#### `Callable`
**Methods**: arity, call


#### `HyperCodeFunction`
**Methods**: __init__, call, arity


#### `ReturnException`
**Methods**: __init__


#### `Interpreter`
**Methods**: __init__, execute_block, interpret, execute, evaluate, visit_Expression, visit_Print, visit_Let, visit_Block, visit_BlockDecl, visit_Intent, visit_Function, visit_Return, visit_Literal, visit_Grouping, visit_Variable, visit_Assign, visit_Pipe, visit_State, visit_Call, visit_Binary, visit_Unary, is_truthy, stringify, get_output


#### `Clock`
**Methods**: arity, call, __str__


#### `Double`
**Methods**: arity, call, __str__


#### `Square`
**Methods**: arity, call, __str__


### src\core\lexer.py

#### `LexerError`
_Represents a lexical analysis error.

Attributes:
    message: Description of the error
    line: Line number where the error occurred (1-based)
    column: Column number where the error occurred (1-based)
    length: Length of the problematic token (default: 1)_


#### `Lexer`
_Lexical analyzer for the HyperCode programming language.

Converts source code into a sequence of tokens that can be parsed.
Handles syntax highlighting, error reporting, and source mapping._

**Methods**: __init__, scan_tokens, scan_token, number, string, docstring, identifier, error, is_at_end, advance, match, peek, peek_next, add_token


### src\core\parser.py

#### `ParseError`

#### `Parser`
**Methods**: __init__, parse, declaration, let_declaration, block_declaration, statement, print_statement, expression_statement, block, expression, pipe, assignment, equality, comparison, term, factor, unary, primary, function, if_statement, return_statement, match, consume, error, synchronize, check, advance, is_at_end, peek, previous


### src\core\tokens.py

#### `TokenType`

#### `Token`
_Represents a token in the HyperCode language.

Attributes:
    type: The type of the token (from TokenType)
    lexeme: The actual text that was matched
    literal: The literal value (for numbers, strings, etc.)
    line: The line number where the token appears (1-based)
    column: The column number where the token starts (1-based)_

**Methods**: __init__, __str__, __repr__


### src\duelcode\duelcode_validator.py

#### `Severity`

#### `ValidationResult`

#### `DuelCodeValidator`
_Validates DuelCode documentation files against the required format._

**Methods**: __init__, _add_result, _find_lines, validate, validate_structure, validate_headings, validate_code_blocks, validate_checklists, validate_visual_elements, validate_links


### src\duelcode\enhanced_validator.py

#### `Severity`

#### `ValidationResult`

#### `DuelCodeEnhancedValidator`
_Enhanced validator with additional rules for DuelCode documentation._

**Methods**: __init__, _add_result, _find_lines, validate_code_blocks_have_language, validate_has_visual_representation, validate_has_practical_exercise, validate_has_learning_objectives, validate_has_checklist, validate_has_conclusion, validate_has_whats_next, validate_code_quality, _analyze_code_block, _analyze_python_code, _analyze_javascript_code, validate_has_glossary, validate_has_see_also, validate_has_faq, validate_has_acknowledgments, validate_all


### src\duelcode\test_framework.py

#### `TestResult`

#### `TestCase`

#### `TestRun`

#### `DuelCodeTestSuite`
**Methods**: __init__, discover_tutorials, run_validator, parse_validator_output, test_tutorial, test_validator_integrity, test_template_validity, run_all_tests, generate_report


### src\duelcode\ultra_validator.py

#### `Severity`

#### `ValidationResult`

#### `DuelCodeUltraValidator`
_Ultra-enhanced validator with comprehensive rules for DuelCode documentation._

**Methods**: __init__, _add_result, _find_lines, validate_code_blocks_have_language, validate_has_visual_representation, validate_has_practical_exercise, validate_has_learning_objectives, validate_has_checklist, validate_has_conclusion, validate_has_whats_next, validate_code_quality, _validate_code_block_content, validate_has_glossary, validate_has_see_also, validate_has_faq, validate_has_acknowledgments, validate_accessibility, validate_interactive_elements, validate_all, print_results


### src\duelcode\validate_duelcode.py

#### `DuelCodeValidator`
**Methods**: __init__, validate_sections, check_formatting, check_visual_aids, validate


### src\duelcode_validator.py

#### `Severity`

#### `ValidationResult`

#### `DuelCodeValidator`
_Validates DuelCode documentation files against the required format._

**Methods**: __init__, _add_result, _find_lines, validate, validate_structure, validate_headings, validate_code_blocks, validate_checklists, validate_visual_elements, validate_links


### src\enhanced_validator.py

#### `Severity`

#### `ValidationResult`

#### `DuelCodeEnhancedValidator`
_Enhanced validator with additional rules for DuelCode documentation._

**Methods**: __init__, _add_result, _find_lines, validate_code_blocks_have_language, validate_has_visual_representation, validate_has_practical_exercise, validate_has_learning_objectives, validate_has_checklist, validate_has_conclusion, validate_has_whats_next, validate_code_quality, _analyze_code_block, _analyze_python_code, _analyze_javascript_code, validate_has_glossary, validate_has_see_also, validate_has_faq, validate_has_acknowledgments, validate_all


### src\hypercode-backend-js-COMPLETE.py

#### `JSCompiler`
_Compiles HyperCode AST to JavaScript.

Output format:
- Runs in Node.js or browser
- Uses Uint8Array for memory tape
- Implements all core operations
- Includes runtime error checking_

**Methods**: __init__, compile, _generate_header, _generate_setup, _generate_main, _generate_footer, _indent, optimize_ast


### src\hypercode-launch-kit.py

#### `HyperCodeLaunchKit`
_Complete launch system initialization_

**Methods**: __init__, create_readme, create_launch_checklist, create_launch_script, create_first_30_days, print_summary


### src\hypercode-lexer-COMPLETE.py

#### `TokenType`
_HyperCode token types - minimal yet powerful_


#### `Token`
_Represents a single token with position tracking_

**Methods**: __repr__


#### `LexerError`
_Lexer-specific errors with context_

**Methods**: __init__


#### `HyperCodeLexer`
_Tokenizes HyperCode programs with accessibility features.

Design principles:
- Clear error messages (neurodivergent-friendly)
- Position tracking (helps with debugging)
- Colorized output (optional, for visual learners)
- Comments preserved (for documentation)_

**Methods**: __init__, tokenize, _advance_position, _skip_comment, get_tokens, filter_tokens, print_tokens, get_statistics


### src\hypercode-parser-COMPLETE.py

#### `NodeType`
_AST Node types_


#### `ASTNode`
_Abstract Syntax Tree Node.

Represents a single operation or block in HyperCode._

**Methods**: __repr__


#### `ParserError`
_Parser-specific errors with context_

**Methods**: __init__


#### `HyperCodeParser`
_Parses HyperCode token stream into AST.

Grammar (simplified BNF):

program    ::= statement*
statement  ::= operation | loop | spatial | ai_native
operation  ::= PUSH | POP | INCR | DECR | OUTPUT | INPUT
loop       ::= LOOP_START statement* LOOP_END
spatial    ::= SPATIAL_2D statement*
ai_native  ::= AI_NATIVE_

**Methods**: __init__, parse, _parse_statement, _parse_loop, _advance, _is_at_end, validate, print_ast


### src\hypercode\config.py

#### `Config`
_Configuration class for HyperCode_

**Methods**: get_headers


### src\hypercode\core\hypercode_ast.py

#### `Node`
**Methods**: accept


#### `Expr`

#### `Literal`

#### `Variable`

#### `Assign`

#### `Binary`

#### `Unary`

#### `Grouping`

#### `Call`

#### `Get`

#### `Stmt`

#### `Expression`

#### `Print`

#### `Var`

#### `Block`

#### `If`

#### `Fun`

#### `Return`

#### `Intent`

#### `Program`

### src\hypercode\core\interpreter.py

#### `Return`
**Methods**: __init__


#### `HyperCodeFunction`
**Methods**: __init__, __str__, arity, call


#### `Environment`
**Methods**: __init__, define, get, assign


#### `Interpreter`
**Methods**: __init__, interpret, execute, execute_block, evaluate, visit_Expression, visit_Print, visit_Var, visit_Block, visit_Assign, visit_Binary, visit_Grouping, visit_Literal, visit_Unary, visit_Variable, visit_If, is_truthy, visit_Fun, visit_Return, visit_Call, is_callable


#### `Visitor`
**Methods**: visit_Expression, visit_Print, visit_Var, visit_Block, visit_If, visit_Fun, visit_Return, visit_Assign, visit_Binary, visit_Grouping, visit_Literal, visit_Unary, visit_Variable, visit_Call


### src\hypercode\core\lexer.py

#### `LexerError`
_Exception raised for errors in the lexer._

**Methods**: __init__


#### `Lexer`
_Lexical analyzer for the HyperCode language._

**Methods**: __init__, tokenize, is_at_end


#### `LexerError`
_Exception raised for errors in the lexer._

**Methods**: __init__


#### `Lexer`
_Lexical analyzer for the HyperCode language.

Converts source code into a sequence of tokens that can be processed
by the parser._

**Methods**: __init__, tokenize, scan_token, string, number, identifier, match, peek, peek_next, advance, add_token, error, is_at_end


### src\hypercode\core\parser.py

#### `ParseError`

#### `Parser`
**Methods**: __init__, parse, declaration, var_declaration, statement, print_statement, return_statement, intent_statement, expression_statement, if_statement, function, block, expression, assignment, equality, comparison, term, factor, unary, primary, _primary, finish_call, match, consume, error, synchronize, check, advance, is_at_end, peek, previous


### src\hypercode\core\sensory_profile.py

#### `VisualNoiseLevel`

#### `AnimationSpeed`

#### `VisualSettings`
_Configuration for visual aspects of the editor._


#### `AudioSettings`
_Configuration for audio feedback._


#### `AnimationSettings`
_Configuration for animations and transitions._


#### `SensoryProfile`
_A complete sensory profile configuration._

**Methods**: to_dict, from_dict, save, load


#### `ProfileManager`
_Manages loading and saving of sensory profiles._

**Methods**: __init__, _ensure_default_profiles, _create_minimal_profile, _create_enhanced_profile, _create_high_contrast_profile, list_profiles, get_profile, save_profile, delete_profile


### src\hypercode\core\tokens.py

#### `TokenType`

#### `Token`
**Methods**: __str__


### src\hypercode\enhanced_perplexity_client.py

#### `EnhancedPerplexityClient`
_Enhanced Perplexity client with knowledge base integration_

**Methods**: __init__, query_with_context, add_research_data, search_research_data, list_research_documents, get_document, delete_document, import_from_perplexity_space, test_context_integration


### src\hypercode\knowledge_base.py

#### `ResearchDocument`
_Represents a research document from Perplexity Space_

**Methods**: __post_init__, generate_id, validate, update_timestamp


#### `HyperCodeKnowledgeBase`
_Knowledge base for HyperCode research data_

**Methods**: __init__, load, save, add_document, search_documents, get_context_for_query, list_documents, get_document, delete_document, update_document, search_by_tags, get_document_statistics, export_format, validate_all_documents, cleanup_duplicates


### src\hypercode\perplexity_client.py

#### `PerplexityClient`
_Client for interacting with Perplexity AI API_

**Methods**: __init__, query


### src\hypercode_idea_generator.py

#### `HyperCodeIdeaGenerator`
_AI-Powered Idea Generator for HyperCode community input.

Generates recommendations across categories & difficulty levels.
Tracks community voting to identify most-wanted features._

**Methods**: __init__, get_ideas_by_category, get_top_ideas, vote_for_idea, get_trending_ideas, format_idea_card


### src\hypercode_poc.py

#### `TokenType`
_Brainfuck-inspired core + modern aliases_


#### `Token`

#### `UserConfidenceLevel`

#### `EnhancedLexer`
_Smart tokenizer with escape handling + accessibility focus_

**Methods**: __init__, tokenize, handle_string, handle_number, handle_identifier, advance


#### `ContextAwareErrorMessenger`
_Friendly, adaptive error messages_

**Methods**: __init__, format_error


#### `SemanticContextStreamer`
_Understand programmer intent from tokens_

**Methods**: analyze


#### `ConfidenceTracker`
_Adapt system guidance to user skill level_

**Methods**: __init__, record


#### `HyperCodePOC`
_Main system: Lexer + Error Messenger + Semantic Analyzer + Confidence Tracker_

**Methods**: __init__, compile


### src\mistral_adapter.py

#### `MistralAdapterAdapter`
_Adapter for Mistral Adapter AI model._

**Methods**: __init__


### src\ollama_adapter.py

#### `OllamaAdapterAdapter`
_Adapter for Ollama Adapter AI model._

**Methods**: __init__


### src\openai_adapter.py

#### `OpenaiAdapterAdapter`
_Adapter for Openai Adapter AI model._

**Methods**: __init__


### src\parser\visual_syntax_parser.py

#### `SemanticMarker`
_üé® Semantic marker types with emoji representations_


#### `SemanticAnnotation`
_üìã A single semantic annotation with its metadata_

**Methods**: __str__


#### `ParsedFunction`
_üîç A fully parsed HyperCode function_

**Methods**: get_annotations_by_type


#### `VisualSyntaxParser`
_üé® Main parser for HyperCode's visual semantic syntax_

**Methods**: __init__, _build_semantic_patterns, _build_color_scheme, parse_file, parse_content, _is_function_definition, _start_new_function, _parse_line_annotations, _parse_annotation_params, generate_syntax_highlighting, extract_semantic_summary, validate_neurodiversity_compliance


### src\test_framework.py

#### `TestResult`

#### `TestCase`

#### `TestRun`

#### `DuelCodeTestSuite`
**Methods**: __init__, discover_tutorials, run_validator, parse_validator_output, test_tutorial, test_validator_integrity, test_template_validity, run_all_tests, generate_report


### src\ultra_validator.py

#### `Severity`

#### `ValidationResult`

#### `DuelCodeUltraValidator`
_Ultra-enhanced validator with comprehensive rules for DuelCode documentation._

**Methods**: __init__, _add_result, _find_lines, validate_code_blocks_have_language, validate_has_visual_representation, validate_has_practical_exercise, validate_has_learning_objectives, validate_has_checklist, validate_has_conclusion, validate_has_whats_next, validate_code_quality, _validate_code_block_content, validate_has_glossary, validate_has_see_also, validate_has_faq, validate_has_acknowledgments, validate_accessibility, validate_interactive_elements, validate_all, print_results


### src\utils\code_analyzer_ai.py

#### `CodeAnalyzerAI`
_AI-powered code analyzer for HyperCode_

**Methods**: __init__, analyze_file, _analyze_complexity, _check_docstrings, _get_ai_code_analysis, analyze_project, _get_project_ai_insights, save_analysis, print_summary


### src\utils\health_scanner_ai.py

#### `HealthScannerAI`
_AI-powered health scanner for HyperCode project_

**Methods**: __init__, analyze_project_structure, analyze_dependencies, analyze_security, get_ai_recommendations, run_full_scan, save_report, print_summary


### src\utils\import-helper.py

#### `SpaceImportHelper`
_Helper class for managing Perplexity Space imports_

**Methods**: __init__, validate_document, load_template, validate_all, generate_report, create_import_script, create_template_instructions


### src\utils\local_health_scanner.py

#### `ProjectScanner`
_Scans the project for health metrics without external dependencies_

**Methods**: __init__, scan_project, _scan_directory, _analyze_file, _analyze_ast, _check_documentation, _check_tests, _calculate_metrics


### src\validate_duelcode.py

#### `DuelCodeValidator`
**Methods**: __init__, validate_sections, check_formatting, check_visual_aids, validate


### tests\benchmark_knowledge_base.py

#### `BenchmarkSuite`
_Comprehensive benchmark suite for Knowledge Base_

**Methods**: __init__, _get_system_info, generate_test_data, benchmark_operation, run_benchmark_suite, _calculate_summary, _generate_recommendations, generate_markdown_report, save_json_results


### tests\test_interpreter.py

#### `TestInterpreter`
**Methods**: test_if_statement_then, test_if_statement_else, test_function_call, test_function_with_parameters, test_function_with_return, test_recursive_function_call, test_scoping


### tests\test_knowledge_base.py

#### `TestKnowledgeBaseSearch`
_Test suite for knowledge base search functionality._

**Methods**: sample_documents, knowledge_base, test_basic_search, test_search_with_exact_match, test_search_case_insensitive, test_search_empty_query, test_search_no_matches, test_search_ranking, test_query_normalization, test_multi_word_query, test_tag_based_search


#### `TestEdgeCases`
_Test edge cases and boundary conditions._

**Methods**: knowledge_base, test_very_short_query, test_very_long_query, test_special_characters_in_query, test_unicode_in_query, test_sql_injection_attempt, test_repeated_queries


#### `TestPerformance`
_Performance benchmarking tests._

**Methods**: large_knowledge_base, test_search_response_time, test_concurrent_searches, test_memory_usage


#### `TestIntegrationWithPerplexity`
_Test integration with EnhancedPerplexityClient._

**Methods**: mock_perplexity_client, mock_knowledge_base, test_enhanced_query_with_context, test_fallback_to_perplexity_api, test_context_ranking_and_selection


#### `TestDocumentManagement`
_Test document addition, update, and removal._

**Methods**: knowledge_base, test_add_document, test_update_document, test_remove_document


### tests\test_knowledge_base_comprehensive.py

#### `TestKnowledgeBaseUnit`
_Unit tests for Knowledge Base functionality_

**Methods**: temp_kb, sample_docs, test_init_empty_kb, test_add_single_document, test_add_multiple_documents, test_save_and_load, test_search_exact_match, test_search_partial_match, test_search_tag_matching, test_search_case_insensitive, test_empty_search, test_nonexistent_search, test_get_context_for_query, test_context_length_limit, test_document_update, test_list_documents, test_delete_document


#### `TestKnowledgeBaseIntegration`
_Integration tests for Knowledge Base_

**Methods**: populated_kb, test_complex_search_queries, test_search_ranking_quality, test_related_term_expansion, test_performance_with_large_dataset, test_concurrent_access_simulation


#### `TestKnowledgeBasePerformance`
_Performance tests for Knowledge Base_

**Methods**: large_kb, test_search_performance_large_dataset, test_save_performance_large_dataset, test_load_performance_large_dataset, test_memory_usage_large_dataset


#### `TestKnowledgeBaseEdgeCases`
_Edge case tests for Knowledge Base_

**Methods**: edge_case_kb, test_empty_title_handling, test_special_characters_handling, test_very_long_titles, test_empty_content_handling, test_none_tags_handling, test_malformed_json_handling, test_file_permission_handling


### tests\unit\lexer\test_lexer_basic.py

#### `TestLexerBasic`
_Test basic lexer functionality._

**Methods**: test_empty_source, test_whitespace_handling, test_single_character_tokens, test_comments_are_ignored, test_string_literals, test_number_literals, test_identifiers_and_keywords, test_error_handling


### tests\unit\test_knowledge_base.py

#### `TestHyperCodeKnowledgeBase`
_Test suite for HyperCodeKnowledgeBase core functionality_

**Methods**: temp_kb, sample_documents, test_init_empty_kb, test_add_document, test_add_multiple_documents, test_save_and_load, test_search_exact_match, test_search_tag_matching, test_search_related_terms, test_search_space_data_boost, test_get_context_for_query, test_context_length_limit, test_list_documents, test_empty_search, test_search_nonexistent_term, test_document_update


#### `TestResearchDocument`
_Test suite for ResearchDocument dataclass_

**Methods**: test_document_creation, test_document_optional_fields


### tests\unit\test_search_algorithm.py

#### `TestSearchAlgorithm`
_Test suite for search algorithm functionality_

**Methods**: populated_kb, test_exact_title_match_highest_score, test_space_data_boosting, test_related_term_expansion, test_tag_matching_scoring, test_content_frequency_scoring, test_partial_word_matching, test_query_word_ordering, test_case_insensitive_search, test_empty_query_returns_no_results, test_limit_parameter_respected, test_no_results_for_nonexistent_terms, test_special_characters_in_query, test_unicode_characters, test_search_performance_with_large_kb, test_search_result_consistency


#### `TestSearchScoringDetails`
_Test detailed scoring algorithm behavior_

**Methods**: scoring_kb, test_title_match_beats_content_match, test_space_data_boosting_works, test_frequency_scoring


### venv_new\Lib\site-packages\pip\__pip-runner__.py

#### `PipImportRedirectingFinder`
**Methods**: find_spec


### venv_new\Lib\site-packages\pip\_internal\build_env.py

#### `_Prefix`
**Methods**: __init__


#### `BuildEnvironment`
_Creates and manages an isolated environment to install build deps_

**Methods**: __init__, __enter__, __exit__, check_requirements, install_requirements, _install_requirements


#### `NoOpBuildEnvironment`
_A no-op drop-in replacement for BuildEnvironment_

**Methods**: __init__, __enter__, __exit__, cleanup, install_requirements


### venv_new\Lib\site-packages\pip\_internal\cache.py

#### `Cache`
_An abstract class - provides cache directories for data from links

:param cache_dir: The root of the cache._

**Methods**: __init__, _get_cache_path_parts, _get_candidates, get_path_for_link, get


#### `SimpleWheelCache`
_A cache of wheels for future installs._

**Methods**: __init__, get_path_for_link, get


#### `EphemWheelCache`
_A SimpleWheelCache that creates it's own temporary cache directory_

**Methods**: __init__


#### `CacheEntry`
**Methods**: __init__


#### `WheelCache`
_Wraps EphemWheelCache and SimpleWheelCache into a single Cache

This Cache allows for gracefully degradation, using the ephem wheel cache
when a certain link is not found in the simple wheel cache first._

**Methods**: __init__, get_path_for_link, get_ephem_path_for_link, get, get_cache_entry, record_download_origin


### venv_new\Lib\site-packages\pip\_internal\cli\base_command.py

#### `Command`
**Methods**: __init__, add_options, handle_pip_version_check, run, _run_wrapper, parse_args, main, _main


### venv_new\Lib\site-packages\pip\_internal\cli\cmdoptions.py

#### `PipOption`

### venv_new\Lib\site-packages\pip\_internal\cli\command_context.py

#### `CommandContextMixIn`
**Methods**: __init__, main_context, enter_context


### venv_new\Lib\site-packages\pip\_internal\cli\index_command.py

#### `SessionCommandMixin`
_A class mixin for command classes needing _build_session()._

**Methods**: __init__, _get_index_urls, get_default_session, _build_session


#### `IndexGroupCommand`
_Abstract base class for commands with the index_group options.

This also corresponds to the commands that permit the pip version check._

**Methods**: handle_pip_version_check


### venv_new\Lib\site-packages\pip\_internal\cli\parser.py

#### `PrettyHelpFormatter`
_A prettier/less verbose help formatter for optparse._

**Methods**: __init__, format_option_strings, _format_option_strings, format_heading, format_usage, format_description, format_epilog, indent_lines


#### `UpdatingDefaultsHelpFormatter`
_Custom help formatter for use in ConfigOptionParser.

This is updates the defaults before expanding them, allowing
them to show up correctly in the help listing.

Also redact auth from url type options_

**Methods**: expand_default


#### `CustomOptionParser`
**Methods**: insert_option_group, option_list_all


#### `ConfigOptionParser`
_Custom option parser which updates its defaults by checking the
configuration files and environmental variables_

**Methods**: __init__, check_default, _get_ordered_configuration_items, _update_defaults, get_default_values, error


### venv_new\Lib\site-packages\pip\_internal\cli\req_command.py

#### `RequirementCommand`
**Methods**: __init__, determine_resolver_variant, make_requirement_preparer, make_resolver, get_requirements, trace_basic_info, _build_package_finder


### venv_new\Lib\site-packages\pip\_internal\cli\spinners.py

#### `SpinnerInterface`
**Methods**: spin, finish


#### `InteractiveSpinner`
**Methods**: __init__, _write, spin, finish


#### `NonInteractiveSpinner`
**Methods**: __init__, _update, spin, finish


#### `RateLimiter`
**Methods**: __init__, ready, reset


### venv_new\Lib\site-packages\pip\_internal\commands\cache.py

#### `CacheCommand`
_Inspect and manage pip's wheel cache.

Subcommands:

- dir: Show the cache directory.
- info: Show information about the cache.
- list: List filenames of packages stored in the cache.
- remove: Remove one or more package from the cache.
- purge: Remove all items from the cache.

``<pattern>`` can be a glob expression or a package name._

**Methods**: add_options, run, get_cache_dir, get_cache_info, list_cache_items, format_for_human, format_for_abspath, remove_cache_items, purge_cache, _cache_dir, _find_http_files, _find_wheels


### venv_new\Lib\site-packages\pip\_internal\commands\check.py

#### `CheckCommand`
_Verify installed packages have compatible dependencies._

**Methods**: run


### venv_new\Lib\site-packages\pip\_internal\commands\completion.py

#### `CompletionCommand`
_A helper command to be used for command completion._

**Methods**: add_options, run


### venv_new\Lib\site-packages\pip\_internal\commands\configuration.py

#### `ConfigurationCommand`
_Manage local and global configuration.

Subcommands:

- list: List the active configuration (or from the file specified)
- edit: Edit the configuration file in an editor
- get: Get the value associated with command.option
- set: Set the command.option=value
- unset: Unset the value associated with command.option
- debug: List the configuration files and values defined under them

Configuration keys should be dot separated command and option name,
with the special prefix "global" affecting any command. For example,
"pip config set global.index-url https://example.org/" would configure
the index url for all commands, but "pip config set download.timeout 10"
would configure a 10 second timeout only for "pip download" commands.

If none of --user, --global and --site are passed, a virtual
environment configuration file is used if one is active and the file
exists. Otherwise, all modifications happen to the user file by
default._

**Methods**: add_options, run, _determine_file, list_values, get_name, set_name_value, unset_name, list_config_values, print_config_file_values, print_env_var_values, open_in_editor, _get_n_args, _save_configuration, _determine_editor


### venv_new\Lib\site-packages\pip\_internal\commands\debug.py

#### `DebugCommand`
_Display debug information._

**Methods**: add_options, run


### venv_new\Lib\site-packages\pip\_internal\commands\download.py

#### `DownloadCommand`
_Download packages from:

- PyPI (and other indexes) using requirement specifiers.
- VCS project urls.
- Local project directories.
- Local or remote source archives.

pip also supports downloading from "requirements files", which provide
an easy way to specify a whole environment to be downloaded._

**Methods**: add_options, run


### venv_new\Lib\site-packages\pip\_internal\commands\freeze.py

#### `FreezeCommand`
_Output installed packages in requirements format.

packages are listed in a case-insensitive sorted order._

**Methods**: add_options, run


### venv_new\Lib\site-packages\pip\_internal\commands\hash.py

#### `HashCommand`
_Compute a hash of a local package archive.

These can be used with --hash in a requirements file to do repeatable
installs._

**Methods**: add_options, run


### venv_new\Lib\site-packages\pip\_internal\commands\help.py

#### `HelpCommand`
_Show help for commands_

**Methods**: run


### venv_new\Lib\site-packages\pip\_internal\commands\index.py

#### `IndexCommand`
_Inspect information available from package indexes._

**Methods**: add_options, run, _build_package_finder, get_available_package_versions


### venv_new\Lib\site-packages\pip\_internal\commands\inspect.py

#### `InspectCommand`
_Inspect the content of a Python environment and produce a report in JSON format._

**Methods**: add_options, run, _dist_to_dict


### venv_new\Lib\site-packages\pip\_internal\commands\install.py

#### `InstallCommand`
_Install packages from:

- PyPI (and other indexes) using requirement specifiers.
- VCS project urls.
- Local project directories.
- Local or remote source archives.

pip also supports installing from "requirements files", which provide
an easy way to specify a whole environment to be installed._

**Methods**: add_options, run, _handle_target_dir, _determine_conflicts, _warn_about_conflicts


### venv_new\Lib\site-packages\pip\_internal\commands\list.py

#### `_DistWithLatestInfo`
_Give the distribution object a couple of extra fields.

These will be populated during ``get_outdated()``. This is dirty but
makes the rest of the code much cleaner._


#### `ListCommand`
_List installed packages, including editables.

Packages are listed in a case-insensitive sorted order._

**Methods**: add_options, handle_pip_version_check, _build_package_finder, run, get_outdated, get_uptodate, get_not_required, iter_packages_latest_infos, output_package_listing, output_package_listing_columns


### venv_new\Lib\site-packages\pip\_internal\commands\search.py

#### `TransformedHit`

#### `SearchCommand`
_Search for PyPI packages whose name or summary contains <query>._

**Methods**: add_options, run, search


### venv_new\Lib\site-packages\pip\_internal\commands\show.py

#### `ShowCommand`
_Show information about one or more installed packages.

The output is in RFC-compliant mail header format._

**Methods**: add_options, run


#### `_PackageInfo`

### venv_new\Lib\site-packages\pip\_internal\commands\uninstall.py

#### `UninstallCommand`
_Uninstall packages.

pip is able to uninstall most installed packages. Known exceptions are:

- Pure distutils packages installed with ``python setup.py install``, which
  leave behind no metadata to determine what files were installed.
- Script wrappers installed by ``python setup.py develop``._

**Methods**: add_options, run


### venv_new\Lib\site-packages\pip\_internal\commands\wheel.py

#### `WheelCommand`
_Build Wheel archives for your requirements and dependencies.

Wheel is a built-package format, and offers the advantage of not
recompiling your software during every install. For more details, see the
wheel docs: https://wheel.readthedocs.io/en/latest/

'pip wheel' uses the build system interface as described here:
https://pip.pypa.io/en/stable/reference/build-system/_

**Methods**: add_options, run


### venv_new\Lib\site-packages\pip\_internal\configuration.py

#### `Configuration`
_Handles management of configuration.

Provides an interface to accessing and managing configuration files.

This class converts provides an API that takes "section.key-name" style
keys and stores the value associated with it as "key-name" under the
section "section".

This allows for a clean interface wherein the both the section and the
key-name are preserved in an easy to manage form in the configuration files
and the data stored is also nice._

**Methods**: __init__, load, get_file_to_edit, items, get_value, set_value, unset_value, save, _ensure_have_load_only, _dictionary, _load_config_files, _load_file, _construct_parser, _load_environment_vars, _normalized_keys, get_environ_vars, iter_config_files, get_values_in_config, _get_parser_to_modify, _mark_as_modified, __repr__


### venv_new\Lib\site-packages\pip\_internal\distributions\base.py

#### `AbstractDistribution`
_A base class for handling installable artifacts.

The requirements for anything installable are as follows:

 - we must be able to determine the requirement name
   (or we can't correctly handle the non-upgrade case).

 - for packages with setup requirements, we must also be able
   to determine their requirements without installing additional
   packages (for the same reason as run-time dependencies)

 - we must be able to create a Distribution object exposing the
   above metadata.

 - if we need to do work in the build tracker, we must be able to generate a unique
   string to identify the requirement in the build tracker._

**Methods**: __init__, build_tracker_id, get_metadata_distribution, prepare_distribution_metadata


### venv_new\Lib\site-packages\pip\_internal\distributions\installed.py

#### `InstalledDistribution`
_Represents an installed package.

This does not need any preparation as the required information has already
been computed._

**Methods**: build_tracker_id, get_metadata_distribution, prepare_distribution_metadata


### venv_new\Lib\site-packages\pip\_internal\distributions\sdist.py

#### `SourceDistribution`
_Represents a source distribution.

The preparation step for these needs metadata for the packages to be
generated, either using PEP 517 or using the legacy `setup.py egg_info`._

**Methods**: build_tracker_id, get_metadata_distribution, prepare_distribution_metadata, _prepare_build_backend, _get_build_requires_wheel, _get_build_requires_editable, _install_build_reqs, _raise_conflicts, _raise_missing_reqs


### venv_new\Lib\site-packages\pip\_internal\distributions\wheel.py

#### `WheelDistribution`
_Represents a wheel distribution.

This does not need any preparation as wheels can be directly unpacked._

**Methods**: build_tracker_id, get_metadata_distribution, prepare_distribution_metadata


### venv_new\Lib\site-packages\pip\_internal\exceptions.py

#### `PipError`
_The base pip error._


#### `DiagnosticPipError`
_An error, that presents diagnostic information to the user.

This contains a bunch of logic, to enable pretty presentation of our error
messages. Each error gets a unique reference. Each error can also include
additional context, a hint and/or a note -- which are presented with the
main error message in a consistent style.

This is adapted from the error output styling in `sphinx-theme-builder`._

**Methods**: __init__, __repr__, __rich_console__


#### `ConfigurationError`
_General exception in configuration_


#### `InstallationError`
_General exception during installation_


#### `MissingPyProjectBuildRequires`
_Raised when pyproject.toml has `build-system`, but no `build-system.requires`._

**Methods**: __init__


#### `InvalidPyProjectBuildRequires`
_Raised when pyproject.toml an invalid `build-system.requires`._

**Methods**: __init__


#### `NoneMetadataError`
_Raised when accessing a Distribution's "METADATA" or "PKG-INFO".

This signifies an inconsistency, when the Distribution claims to have
the metadata file (if not, raise ``FileNotFoundError`` instead), but is
not actually able to produce its content. This may be due to permission
errors._

**Methods**: __init__, __str__


#### `UserInstallationInvalid`
_A --user install is requested on an environment without user site._

**Methods**: __str__


#### `InvalidSchemeCombination`
**Methods**: __str__


#### `DistributionNotFound`
_Raised when a distribution cannot be found to satisfy a requirement_


#### `RequirementsFileParseError`
_Raised when a general error occurs parsing a requirements file line._


#### `BestVersionAlreadyInstalled`
_Raised when the most up-to-date version of a package is already
installed._


#### `BadCommand`
_Raised when virtualenv or a command is not found_


#### `CommandError`
_Raised when there is an error in command-line arguments_


#### `PreviousBuildDirError`
_Raised when there's a previous conflicting build directory_


#### `NetworkConnectionError`
_HTTP connection error_

**Methods**: __init__, __str__


#### `InvalidWheelFilename`
_Invalid wheel filename._


#### `UnsupportedWheel`
_Unsupported wheel._


#### `InvalidWheel`
_Invalid (e.g. corrupt) wheel._

**Methods**: __init__, __str__


#### `MetadataInconsistent`
_Built metadata contains inconsistent information.

This is raised when the metadata contains values (e.g. name and version)
that do not match the information previously obtained from sdist filename,
user-supplied ``#egg=`` value, or an install requirement name._

**Methods**: __init__, __str__


#### `MetadataInvalid`
_Metadata is invalid._

**Methods**: __init__, __str__


#### `InstallationSubprocessError`
_A subprocess call failed._

**Methods**: __init__, __str__


#### `MetadataGenerationFailed`
**Methods**: __init__, __str__


#### `HashErrors`
_Multiple HashError instances rolled into one for reporting_

**Methods**: __init__, append, __str__, __bool__


#### `HashError`
_A failure to verify a package against known-good hashes

:cvar order: An int sorting hash exception classes by difficulty of
    recovery (lower being harder), so the user doesn't bother fretting
    about unpinned packages when he has deeper issues, like VCS
    dependencies, to deal with. Also keeps error reports in a
    deterministic order.
:cvar head: A section heading for display above potentially many
    exceptions of this kind
:ivar req: The InstallRequirement that triggered this error. This is
    pasted on after the exception is instantiated, because it's not
    typically available earlier._

**Methods**: body, __str__, _requirement_name


#### `VcsHashUnsupported`
_A hash was provided for a version-control-system-based requirement, but
we don't have a method for hashing those._


#### `DirectoryUrlHashUnsupported`
_A hash was provided for a version-control-system-based requirement, but
we don't have a method for hashing those._


#### `HashMissing`
_A hash was needed for a requirement but is absent._

**Methods**: __init__, body


#### `HashUnpinned`
_A requirement had a hash specified but was not pinned to a specific
version._


#### `HashMismatch`
_Distribution file hash values don't match.

:ivar package_name: The name of the package that triggered the hash
    mismatch. Feel free to write to this after the exception is raise to
    improve its error message._

**Methods**: __init__, body, _hash_comparison


#### `UnsupportedPythonVersion`
_Unsupported python version according to Requires-Python package
metadata._


#### `ConfigurationFileCouldNotBeLoaded`
_When there are errors while loading a configuration file_

**Methods**: __init__, __str__


#### `ExternallyManagedEnvironment`
_The current environment is externally managed.

This is raised when the current environment is externally managed, as
defined by `PEP 668`_. The ``EXTERNALLY-MANAGED`` configuration is checked
and displayed when the error is bubbled up to the user.

:param error: The error message read from ``EXTERNALLY-MANAGED``._

**Methods**: __init__, _iter_externally_managed_error_keys, from_config


#### `UninstallMissingRecord`
**Methods**: __init__


#### `LegacyDistutilsInstall`
**Methods**: __init__


#### `InvalidInstalledPackage`
**Methods**: __init__


### venv_new\Lib\site-packages\pip\_internal\index\collector.py

#### `_NotAPIContent`
**Methods**: __init__


#### `_NotHTTP`

#### `CacheablePageContent`
**Methods**: __init__, __eq__, __hash__


#### `ParseLinks`
**Methods**: __call__


#### `IndexContent`
_Represents one response (or page), along with its URL.

:param encoding: the encoding to decode the given content.
:param url: the URL from which the HTML was downloaded.
:param cache_link_parsing: whether links parsed from this page's url
                           should be cached. PyPI index urls should
                           have this set to False, for example._

**Methods**: __str__


#### `HTMLLinkParser`
_HTMLParser that keeps the first base HREF and a list of all anchor
elements' attributes._

**Methods**: __init__, handle_starttag, get_href


#### `CollectedSources`

#### `LinkCollector`
_Responsible for collecting Link objects from all configured locations,
making network requests as needed.

The class's main method is its collect_sources() method._

**Methods**: __init__, create, find_links, fetch_response, collect_sources


### venv_new\Lib\site-packages\pip\_internal\index\package_finder.py

#### `LinkType`

#### `LinkEvaluator`
_Responsible for evaluating links for a particular project._

**Methods**: __init__, evaluate_link


#### `CandidatePreferences`
_Encapsulates some of the preferences for filtering and sorting
InstallationCandidate objects._


#### `BestCandidateResult`
_A collection of candidates, returned by `PackageFinder.find_best_candidate`.

This class is only intended to be instantiated by CandidateEvaluator's
`compute_best_candidate()` method.

:param all_candidates: A sequence of all available candidates found.
:param applicable_candidates: The applicable candidates.
:param best_candidate: The most preferred candidate found, or None
    if no applicable candidates were found._

**Methods**: __post_init__


#### `CandidateEvaluator`
_Responsible for filtering and sorting candidates for installation based
on what tags are valid._

**Methods**: create, __init__, get_applicable_candidates, _sort_key, sort_best_candidate, compute_best_candidate


#### `PackageFinder`
_This finds packages.

This is meant to match easy_install's technique for looking for
packages, by reading pages and looking for appropriate links._

**Methods**: __init__, create, target_python, search_scope, search_scope, find_links, index_urls, proxy, trusted_hosts, custom_cert, client_cert, allow_all_prereleases, set_allow_all_prereleases, prefer_binary, set_prefer_binary, requires_python_skipped_reasons, make_link_evaluator, _sort_links, _log_skipped_link, get_install_candidate, evaluate_links, process_project_url, find_all_candidates, make_candidate_evaluator, find_best_candidate, find_requirement


### venv_new\Lib\site-packages\pip\_internal\index\sources.py

#### `LinkSource`
**Methods**: link, page_candidates, file_links


#### `_FlatDirectoryToUrls`
_Scans directory and caches results_

**Methods**: __init__, _scan_directory, page_candidates, project_name_to_urls


#### `_FlatDirectorySource`
_Link source specified by ``--find-links=<path-to-dir>``.

This looks the content of the directory, and returns:

* ``page_candidates``: Links listed on each HTML file in the directory.
* ``file_candidates``: Archives in the directory._

**Methods**: __init__, link, page_candidates, file_links


#### `_LocalFileSource`
_``--find-links=<path-or-url>`` or ``--[extra-]index-url=<path-or-url>``.

If a URL is supplied, it must be a ``file:`` URL. If a path is supplied to
the option, it is converted to a URL first. This returns:

* ``page_candidates``: Links listed on an HTML file.
* ``file_candidates``: The non-HTML file._

**Methods**: __init__, link, page_candidates, file_links


#### `_RemoteFileSource`
_``--find-links=<url>`` or ``--[extra-]index-url=<url>``.

This returns:

* ``page_candidates``: Links listed on an HTML file.
* ``file_candidates``: The non-HTML file._

**Methods**: __init__, link, page_candidates, file_links


#### `_IndexDirectorySource`
_``--[extra-]index-url=<path-to-directory>``.

This is treated like a remote URL; ``candidates_from_page`` contains logic
for this by appending ``index.html`` to the link._

**Methods**: __init__, link, page_candidates, file_links


### venv_new\Lib\site-packages\pip\_internal\metadata\__init__.py

#### `Backend`

### venv_new\Lib\site-packages\pip\_internal\metadata\base.py

#### `BaseEntryPoint`
**Methods**: name, value, group


#### `RequiresEntry`

#### `BaseDistribution`
**Methods**: from_directory, from_metadata_file_contents, from_wheel, __repr__, __str__, location, editable_project_location, installed_location, info_location, installed_by_distutils, installed_as_egg, installed_with_setuptools_egg_info, installed_with_dist_info, canonical_name, version, raw_version, setuptools_filename, direct_url, installer, requested, editable, local, in_usersite, in_site_packages, is_file, iter_distutils_script_names, read_text, iter_entry_points, _metadata_impl, metadata, metadata_dict, metadata_version, raw_name, requires_python, iter_dependencies, iter_raw_dependencies, iter_provided_extras, _iter_declared_entries_from_record, _iter_declared_entries_from_legacy, iter_declared_entries, _iter_requires_txt_entries, _iter_egg_info_extras, _iter_egg_info_dependencies, _add_egg_info_requires


#### `BaseEnvironment`
_An environment containing distributions to introspect._

**Methods**: default, from_paths, get_distribution, _iter_distributions, iter_all_distributions, iter_installed_distributions


#### `Wheel`
**Methods**: as_zipfile


#### `FilesystemWheel`
**Methods**: __init__, as_zipfile


#### `MemoryWheel`
**Methods**: __init__, as_zipfile


### venv_new\Lib\site-packages\pip\_internal\metadata\importlib\_compat.py

#### `BadMetadata`
**Methods**: __init__, __str__


#### `BasePath`
_A protocol that various path objects conform.

This exists because importlib.metadata uses both ``pathlib.Path`` and
``zipfile.Path``, and we need a common base for type hints (Union does not
work well since ``zipfile.Path`` is too new for our linter setup).

This does not mean to be exhaustive, but only contains things that present
in both classes *that we need*._

**Methods**: name, parent


### venv_new\Lib\site-packages\pip\_internal\metadata\importlib\_dists.py

#### `WheelDistribution`
_An ``importlib.metadata.Distribution`` read from a wheel.

Although ``importlib.metadata.PathDistribution`` accepts ``zipfile.Path``,
its implementation is too "lazy" for pip's needs (we can't keep the ZipFile
handle open for the entire lifetime of the distribution object).

This implementation eagerly reads the entire metadata directory into the
memory instead, and operates from that._

**Methods**: __init__, from_zipfile, iterdir, read_text, locate_file


#### `Distribution`
**Methods**: __init__, from_directory, from_metadata_file_contents, from_wheel, location, info_location, installed_location, canonical_name, version, raw_version, is_file, iter_distutils_script_names, read_text, iter_entry_points, _metadata_impl, iter_provided_extras, iter_dependencies


### venv_new\Lib\site-packages\pip\_internal\metadata\importlib\_envs.py

#### `_DistributionFinder`
_Finder to locate distributions.

The main purpose of this class is to memoize found distributions' names, so
only one distribution is returned for each package name. At lot of pip code
assumes this (because it is setuptools's behavior), and not doing the same
can potentially cause a distribution in lower precedence path to override a
higher precedence one if the caller is not careful.

Eventually we probably want to make it possible to see lower precedence
installations as well. It's useful feature, after all._

**Methods**: __init__, _find_impl, find, find_linked, _find_eggs_in_dir, _find_eggs_in_zip, find_eggs


#### `Environment`
**Methods**: __init__, default, from_paths, _iter_distributions, get_distribution


### venv_new\Lib\site-packages\pip\_internal\metadata\pkg_resources.py

#### `EntryPoint`

#### `InMemoryMetadata`
_IMetadataProvider that reads metadata files from a dictionary.

This also maps metadata decoding exceptions to our internal exception type._

**Methods**: __init__, has_metadata, get_metadata, get_metadata_lines, metadata_isdir, metadata_listdir, run_script


#### `Distribution`
**Methods**: __init__, _extra_mapping, from_directory, from_metadata_file_contents, from_wheel, location, installed_location, info_location, installed_by_distutils, canonical_name, version, raw_version, is_file, iter_distutils_script_names, read_text, iter_entry_points, _metadata_impl, iter_dependencies, iter_provided_extras


#### `Environment`
**Methods**: __init__, default, from_paths, _iter_distributions, _search_distribution, get_distribution


### venv_new\Lib\site-packages\pip\_internal\models\candidate.py

#### `InstallationCandidate`
_Represents a potential "candidate" for installation._

**Methods**: __init__, __str__


### venv_new\Lib\site-packages\pip\_internal\models\direct_url.py

#### `DirectUrlValidationError`

#### `VcsInfo`
**Methods**: _from_dict, _to_dict


#### `ArchiveInfo`
**Methods**: __init__, hash, hash, _from_dict, _to_dict


#### `DirInfo`
**Methods**: _from_dict, _to_dict


#### `DirectUrl`
**Methods**: _remove_auth_from_netloc, redacted_url, validate, from_dict, to_dict, from_json, to_json, is_local_editable


### venv_new\Lib\site-packages\pip\_internal\models\format_control.py

#### `FormatControl`
_Helper for managing formats from which a package can be installed._

**Methods**: __init__, __eq__, __repr__, handle_mutual_excludes, get_allowed_formats, disallow_binaries


### venv_new\Lib\site-packages\pip\_internal\models\index.py

#### `PackageIndex`
_Represents a Package Index and provides easier access to endpoints_

**Methods**: __init__, _url_for_path


### venv_new\Lib\site-packages\pip\_internal\models\installation_report.py

#### `InstallationReport`
**Methods**: __init__, _install_req_to_dict, to_dict


### venv_new\Lib\site-packages\pip\_internal\models\link.py

#### `LinkHash`
_Links to content may have embedded hash values. This class parses those.

`name` must be any member of `_SUPPORTED_HASHES`.

This class can be converted to and from `ArchiveInfo`. While ArchiveInfo intends to
be JSON-serializable to conform to PEP 610, this class contains the logic for
parsing a hash name and value for correctness, and then checking whether that hash
conforms to a schema with `.is_hash_allowed()`._

**Methods**: __post_init__, find_hash_url_fragment, as_dict, as_hashes, is_hash_allowed


#### `MetadataFile`
_Information about a core metadata file associated with a distribution._

**Methods**: __post_init__


#### `Link`
_Represents a parsed link from a Package Index's simple URL_

**Methods**: __init__, from_json, from_element, __str__, __repr__, __hash__, __eq__, __lt__, url, filename, file_path, scheme, netloc, path, splitext, ext, url_without_fragment, _egg_fragment, subdirectory_fragment, metadata_link, as_hashes, hash, hash_name, show_url, is_file, is_existing_dir, is_wheel, is_vcs, is_yanked, has_hash, is_hash_allowed


#### `_CleanResult`
_Convert link for equivalency check.

This is used in the resolver to check whether two URL-specified requirements
likely point to the same distribution and can be considered equivalent. This
equivalency logic avoids comparing URLs literally, which can be too strict
(e.g. "a=1&b=2" vs "b=2&a=1") and produce conflicts unexpecting to users.

Currently this does three things:

1. Drop the basic auth part. This is technically wrong since a server can
   serve different content based on auth, but if it does that, it is even
   impossible to guarantee two URLs without auth are equivalent, since
   the user can input different auth information when prompted. So the
   practical solution is to assume the auth doesn't affect the response.
2. Parse the query to avoid the ordering issue. Note that ordering under the
   same key in the query are NOT cleaned; i.e. "a=1&a=2" and "a=2&a=1" are
   still considered different.
3. Explicitly drop most of the fragment part, except ``subdirectory=`` and
   hash values, since it should have no impact the downloaded content. Note
   that this drops the "egg=" part historically used to denote the requested
   project (and extras), which is wrong in the strictest sense, but too many
   people are supplying it inconsistently to cause superfluous resolution
   conflicts, so we choose to also ignore them._


### venv_new\Lib\site-packages\pip\_internal\models\scheme.py

#### `Scheme`
_A Scheme holds paths which are used as the base directories for
artifacts associated with a Python package._


### venv_new\Lib\site-packages\pip\_internal\models\search_scope.py

#### `SearchScope`
_Encapsulates the locations that pip is configured to search._

**Methods**: create, get_formatted_locations, get_index_urls_locations


### venv_new\Lib\site-packages\pip\_internal\models\selection_prefs.py

#### `SelectionPreferences`
_Encapsulates the candidate selection preferences for downloading
and installing files._

**Methods**: __init__


### venv_new\Lib\site-packages\pip\_internal\models\target_python.py

#### `TargetPython`
_Encapsulates the properties of a Python interpreter one is targeting
for a package install, download, etc._

**Methods**: __init__, format_given, get_sorted_tags, get_unsorted_tags


### venv_new\Lib\site-packages\pip\_internal\models\wheel.py

#### `Wheel`
_A wheel file_

**Methods**: __init__, get_formatted_file_tags, support_index_min, find_most_preferred_tag, supported


### venv_new\Lib\site-packages\pip\_internal\network\auth.py

#### `Credentials`

#### `KeyRingBaseProvider`
_Keyring base provider interface_

**Methods**: get_auth_info, save_auth_info


#### `KeyRingNullProvider`
_Keyring null provider_

**Methods**: get_auth_info, save_auth_info


#### `KeyRingPythonProvider`
_Keyring interface which uses locally imported `keyring`_

**Methods**: __init__, get_auth_info, save_auth_info


#### `KeyRingCliProvider`
_Provider which uses `keyring` cli

Instead of calling the keyring package installed alongside pip
we call keyring on the command line which will enable pip to
use which ever installation of keyring is available first in
PATH._

**Methods**: __init__, get_auth_info, save_auth_info, _get_password, _set_password


#### `MultiDomainBasicAuth`
**Methods**: __init__, keyring_provider, keyring_provider, use_keyring, _get_keyring_auth, _get_index_url, _get_new_credentials, _get_url_and_credentials, __call__, _prompt_for_password, _should_save_password_to_keyring, handle_401, warn_on_401, save_credentials


### venv_new\Lib\site-packages\pip\_internal\network\cache.py

#### `SafeFileCache`
_A file based cache which is safe to use even when the target directory may
not be accessible or writable.

There is a race condition when two processes try to write and/or read the
same entry at the same time, since each entry consists of two separate
files (https://github.com/psf/cachecontrol/issues/324).  We therefore have
additional logic that makes sure that both files to be present before
returning an entry; this fixes the read side of the race condition.

For the write side, we assume that the server will only ever return the
same data for the same URL, which ought to be the case for files pip is
downloading.  PyPI does not have a mechanism to swap out a wheel for
another wheel, for example.  If this assumption is not true, the
CacheControl issue will need to be fixed._

**Methods**: __init__, _get_cache_path, get, _write, set, delete, get_body, set_body


### venv_new\Lib\site-packages\pip\_internal\network\download.py

#### `Downloader`
**Methods**: __init__, __call__


#### `BatchDownloader`
**Methods**: __init__, __call__


### venv_new\Lib\site-packages\pip\_internal\network\lazy_wheel.py

#### `HTTPRangeRequestUnsupported`

#### `LazyZipOverHTTP`
_File-like object mapped to a ZIP file over HTTP.

This uses HTTP range requests to lazily fetch the file's content,
which is supposed to be fed to ZipFile.  If such requests are not
supported by the server, raise HTTPRangeRequestUnsupported
during initialization._

**Methods**: __init__, mode, name, seekable, close, closed, read, readable, seek, tell, truncate, writable, __enter__, __exit__, _stay, _check_zip, _stream_response, _merge, _download


### venv_new\Lib\site-packages\pip\_internal\network\session.py

#### `LocalFSAdapter`
**Methods**: send, close


#### `_SSLContextAdapterMixin`
_Mixin to add the ``ssl_context`` constructor argument to HTTP adapters.

The additional argument is forwarded directly to the pool manager. This allows us
to dynamically decide what SSL store to use at runtime, which is used to implement
the optional ``truststore`` backend._

**Methods**: __init__, init_poolmanager


#### `HTTPAdapter`

#### `CacheControlAdapter`

#### `InsecureHTTPAdapter`
**Methods**: cert_verify


#### `InsecureCacheControlAdapter`
**Methods**: cert_verify


#### `PipSession`
**Methods**: __init__, update_index_urls, add_trusted_host, iter_secure_origins, is_secure_origin, request


### venv_new\Lib\site-packages\pip\_internal\network\xmlrpc.py

#### `PipXmlrpcTransport`
_Provide a `xmlrpclib.Transport` implementation via a `PipSession`
object._

**Methods**: __init__, request


### venv_new\Lib\site-packages\pip\_internal\operations\check.py

#### `PackageDetails`

### venv_new\Lib\site-packages\pip\_internal\operations\freeze.py

#### `_EditableInfo`

#### `FrozenRequirement`
**Methods**: canonical_name, from_dist, __str__


### venv_new\Lib\site-packages\pip\_internal\operations\install\wheel.py

#### `File`
**Methods**: save


#### `ZipBackedFile`
**Methods**: __init__, _getinfo, save


#### `ScriptFile`
**Methods**: __init__, save


#### `MissingCallableSuffix`
**Methods**: __init__


#### `PipScriptMaker`
**Methods**: make


### venv_new\Lib\site-packages\pip\_internal\operations\prepare.py

#### `File`
**Methods**: __post_init__


#### `RequirementPreparer`
_Prepares a Requirement_

**Methods**: __init__, _log_preparing_link, _ensure_link_req_src_dir, _get_linked_req_hashes, _fetch_metadata_only, _fetch_metadata_using_link_data_attr, _fetch_metadata_using_lazy_wheel, _complete_partial_requirements, prepare_linked_requirement, prepare_linked_requirements_more, _prepare_linked_requirement, save_linked_requirement, prepare_editable_requirement, prepare_installed_requirement


### venv_new\Lib\site-packages\pip\_internal\req\__init__.py

#### `InstallationResult`

### venv_new\Lib\site-packages\pip\_internal\req\constructors.py

#### `RequirementParts`

### venv_new\Lib\site-packages\pip\_internal\req\req_file.py

#### `ParsedRequirement`

#### `ParsedLine`
**Methods**: is_editable, requirement


#### `RequirementsFileParser`
**Methods**: __init__, parse, _parse_and_recurse, _parse_file


#### `OptionParsingError`
**Methods**: __init__


### venv_new\Lib\site-packages\pip\_internal\req\req_install.py

#### `InstallRequirement`
_Represents something that may be installed later on, may have information
about where to fetch the relevant requirement and also contains logic for
installing the said requirement._

**Methods**: __init__, __str__, __repr__, format_debug, name, supports_pyproject_editable, specifier, is_direct, is_pinned, match_markers, has_hash_options, hashes, from_path, ensure_build_location, _set_requirement, warn_on_mismatching_name, check_if_exists, is_wheel, is_wheel_from_cache, unpacked_source_directory, setup_py_path, setup_cfg_path, pyproject_toml_path, load_pyproject_toml, isolated_editable_sanity_check, prepare_metadata, metadata, get_dist, assert_source_matches_version, ensure_has_source_dir, needs_unpacked_archive, ensure_pristine_source_checkout, update_editable, uninstall, _get_archive_name, archive, install


### venv_new\Lib\site-packages\pip\_internal\req\req_set.py

#### `RequirementSet`
**Methods**: __init__, __str__, __repr__, add_unnamed_requirement, add_named_requirement, has_requirement, get_requirement, all_requirements, requirements_to_install


### venv_new\Lib\site-packages\pip\_internal\req\req_uninstall.py

#### `StashedUninstallPathSet`
_A set of file rename operations to stash files while
tentatively uninstalling them._

**Methods**: __init__, _get_directory_stash, _get_file_stash, stash, commit, rollback, can_rollback


#### `UninstallPathSet`
_A set of file paths to be removed in the uninstallation of a
requirement._

**Methods**: __init__, _permitted, add, add_pth, remove, _allowed_to_proceed, rollback, commit, from_dist


#### `UninstallPthEntries`
**Methods**: __init__, add, remove, rollback


### venv_new\Lib\site-packages\pip\_internal\resolution\base.py

#### `BaseResolver`
**Methods**: resolve, get_installation_order


### venv_new\Lib\site-packages\pip\_internal\resolution\legacy\resolver.py

#### `Resolver`
_Resolves which packages need to be installed/uninstalled to perform     the requested operation without breaking the requirements of any package.
    _

**Methods**: __init__, resolve, _add_requirement_to_set, _is_upgrade_allowed, _set_req_to_reinstall, _check_skip_installed, _find_requirement_link, _populate_link, _get_dist_for, _resolve_one, get_installation_order


### venv_new\Lib\site-packages\pip\_internal\resolution\resolvelib\base.py

#### `Constraint`
**Methods**: empty, from_ireq, __bool__, __and__, is_satisfied_by


#### `Requirement`
**Methods**: project_name, name, is_satisfied_by, get_candidate_lookup, format_for_error


#### `Candidate`
**Methods**: project_name, name, version, is_installed, is_editable, source_link, iter_dependencies, get_install_requirement, format_for_error


### venv_new\Lib\site-packages\pip\_internal\resolution\resolvelib\candidates.py

#### `_InstallRequirementBackedCandidate`
_A candidate backed by an ``InstallRequirement``.

This represents a package request with the target not being already
in the environment, and needs to be fetched and installed. The backing
``InstallRequirement`` is responsible for most of the leg work; this
class exposes appropriate information to the resolver.

:param link: The link passed to the ``InstallRequirement``. The backing
    ``InstallRequirement`` will use this link to fetch the distribution.
:param source_link: The link this candidate "originates" from. This is
    different from ``link`` when the link is found in the wheel cache.
    ``link`` would point to the wheel cache, while this points to the
    found remote link (e.g. from pypi.org)._

**Methods**: __init__, __str__, __repr__, __hash__, __eq__, source_link, project_name, name, version, format_for_error, _prepare_distribution, _check_metadata_consistency, _prepare, iter_dependencies, get_install_requirement


#### `LinkCandidate`
**Methods**: __init__, _prepare_distribution


#### `EditableCandidate`
**Methods**: __init__, _prepare_distribution


#### `AlreadyInstalledCandidate`
**Methods**: __init__, __str__, __repr__, __eq__, __hash__, project_name, name, version, is_editable, format_for_error, iter_dependencies, get_install_requirement


#### `ExtrasCandidate`
_A candidate that has 'extras', indicating additional dependencies.

Requirements can be for a project with dependencies, something like
foo[extra].  The extras don't affect the project/version being installed
directly, but indicate that we need additional dependencies. We model that
by having an artificial ExtrasCandidate that wraps the "base" candidate.

The ExtrasCandidate differs from the base in the following ways:

1. It has a unique name, of the form foo[extra]. This causes the resolver
   to treat it as a separate node in the dependency graph.
2. When we're getting the candidate's dependencies,
   a) We specify that we want the extra dependencies as well.
   b) We add a dependency on the base candidate.
      See below for why this is needed.
3. We return None for the underlying InstallRequirement, as the base
   candidate will provide it, and we don't want to end up with duplicates.

The dependency on the base candidate is needed so that the resolver can't
decide that it should recommend foo[extra1] version 1.0 and foo[extra2]
version 2.0. Having those candidates depend on foo=1.0 and foo=2.0
respectively forces the resolver to recognise that this is a conflict._

**Methods**: __init__, __str__, __repr__, __hash__, __eq__, project_name, name, version, format_for_error, is_installed, is_editable, source_link, iter_dependencies, get_install_requirement


#### `RequiresPythonCandidate`
**Methods**: __init__, __str__, project_name, name, version, format_for_error, iter_dependencies, get_install_requirement


### venv_new\Lib\site-packages\pip\_internal\resolution\resolvelib\factory.py

#### `ConflictCause`

#### `CollectedRootRequirements`

#### `Factory`
**Methods**: __init__, force_reinstall, _fail_if_link_is_unsupported_wheel, _make_extras_candidate, _make_candidate_from_dist, _make_candidate_from_link, _make_base_candidate_from_link, _iter_found_candidates, _iter_explicit_candidates_from_base, _iter_candidates_from_constraints, find_candidates, _make_requirements_from_install_req, collect_root_requirements, make_requirement_from_candidate, make_requirements_from_spec, make_requires_python_requirement, get_wheel_cache_entry, get_dist_to_uninstall, _report_requires_python_error, _report_single_requirement_conflict, get_installation_error


### venv_new\Lib\site-packages\pip\_internal\resolution\resolvelib\found_candidates.py

#### `FoundCandidates`
_A lazy sequence to provide candidates to the resolver.

The intended usage is to return this from `find_matches()` so the resolver
can iterate through the sequence multiple times, but only access the index
page when remote packages are actually needed. This improve performances
when suitable candidates are already installed on disk._

**Methods**: __init__, __getitem__, __iter__, __len__, __bool__


### venv_new\Lib\site-packages\pip\_internal\resolution\resolvelib\provider.py

#### `PipProvider`
_Pip's provider implementation for resolvelib.

:params constraints: A mapping of constraints specified by the user. Keys
    are canonicalized project names.
:params ignore_dependencies: Whether the user specified ``--no-deps``.
:params upgrade_strategy: The user-specified upgrade strategy.
:params user_requested: A set of canonicalized package names that the user
    supplied for pip to install/upgrade._

**Methods**: __init__, identify, get_preference, find_matches, is_satisfied_by, get_dependencies, is_backtrack_cause


### venv_new\Lib\site-packages\pip\_internal\resolution\resolvelib\reporter.py

#### `PipReporter`
**Methods**: __init__, rejecting_candidate


#### `PipDebuggingReporter`
_A reporter that does an info log for every event it sees._

**Methods**: starting, starting_round, ending_round, ending, adding_requirement, rejecting_candidate, pinning


### venv_new\Lib\site-packages\pip\_internal\resolution\resolvelib\requirements.py

#### `ExplicitRequirement`
**Methods**: __init__, __str__, __repr__, __hash__, __eq__, project_name, name, format_for_error, get_candidate_lookup, is_satisfied_by


#### `SpecifierRequirement`
**Methods**: __init__, _equal, __str__, __repr__, __eq__, __hash__, project_name, name, format_for_error, get_candidate_lookup, is_satisfied_by


#### `SpecifierWithoutExtrasRequirement`
_Requirement backed by an install requirement on a base package.
Trims extras from its install requirement if there are any._

**Methods**: __init__, _equal, __eq__, __hash__


#### `RequiresPythonRequirement`
_A requirement representing Requires-Python metadata._

**Methods**: __init__, __str__, __repr__, __hash__, __eq__, project_name, name, format_for_error, get_candidate_lookup, is_satisfied_by


#### `UnsatisfiableRequirement`
_A requirement that cannot be satisfied._

**Methods**: __init__, __str__, __repr__, __eq__, __hash__, project_name, name, format_for_error, get_candidate_lookup, is_satisfied_by


### venv_new\Lib\site-packages\pip\_internal\resolution\resolvelib\resolver.py

#### `Resolver`
**Methods**: __init__, resolve, get_installation_order


### venv_new\Lib\site-packages\pip\_internal\self_outdated_check.py

#### `SelfCheckState`
**Methods**: __init__, key, get, set


#### `UpgradePrompt`
**Methods**: __rich__


### venv_new\Lib\site-packages\pip\_internal\utils\_log.py

#### `VerboseLogger`
_Custom Logger, defining a verbose log-level

VERBOSE is between INFO and DEBUG._

**Methods**: verbose


### venv_new\Lib\site-packages\pip\_internal\utils\deprecation.py

#### `PipDeprecationWarning`

### venv_new\Lib\site-packages\pip\_internal\utils\hashes.py

#### `Hashes`
_A wrapper that builds multiple hashes at once and checks them against
known-good values_

**Methods**: __init__, __and__, digest_count, is_hash_allowed, check_against_chunks, _raise, check_against_file, check_against_path, has_one_of, __bool__, __eq__, __hash__


#### `MissingHashes`
_A workalike for Hashes used when we're missing a hash for a requirement

It computes the actual hash of the requirement and raises a HashMissing
exception showing it to the user._

**Methods**: __init__, _raise


### venv_new\Lib\site-packages\pip\_internal\utils\logging.py

#### `BrokenStdoutLoggingError`
_Raised if BrokenPipeError occurs for the stdout stream while logging._


#### `IndentingFormatter`
**Methods**: __init__, get_message_start, format


#### `IndentedRenderable`
**Methods**: __rich_console__


#### `PipConsole`
**Methods**: on_broken_pipe


#### `RichPipStreamHandler`
**Methods**: __init__, emit, handleError


#### `BetterRotatingFileHandler`
**Methods**: _open


#### `MaxLevelFilter`
**Methods**: __init__, filter


#### `ExcludeLoggerFilter`
_A logging Filter that excludes records from a logger (or its children)._

**Methods**: filter


### venv_new\Lib\site-packages\pip\_internal\utils\misc.py

#### `StreamWrapper`
**Methods**: from_stream, encoding


#### `HiddenText`
**Methods**: __repr__, __str__, __eq__


#### `ConfiguredBuildBackendHookCaller`
**Methods**: __init__, build_wheel, build_sdist, build_editable, get_requires_for_build_wheel, get_requires_for_build_sdist, get_requires_for_build_editable, prepare_metadata_for_build_wheel, prepare_metadata_for_build_editable


### venv_new\Lib\site-packages\pip\_internal\utils\temp_dir.py

#### `TempDirectoryTypeRegistry`
_Manages temp directory behavior_

**Methods**: __init__, set_delete, get_delete


#### `_Default`

#### `TempDirectory`
_Helper class that owns and cleans up a temporary directory.

This class can be used as a context manager or as an OO representation of a
temporary directory.

Attributes:
    path
        Location to the created temporary directory
    delete
        Whether the directory should be deleted when exiting
        (when used as a contextmanager)

Methods:
    cleanup()
        Deletes the temporary directory

When used as a context manager, if the delete attribute is True, on
exiting the context the temporary directory is deleted._

**Methods**: __init__, path, __repr__, __enter__, __exit__, _create, cleanup


#### `AdjacentTempDirectory`
_Helper class that creates a temporary directory adjacent to a real one.

Attributes:
    original
        The original directory to create a temp directory for.
    path
        After calling create() or entering, contains the full
        path to the temporary directory.
    delete
        Whether the directory should be deleted when exiting
        (when used as a contextmanager)_

**Methods**: __init__, _generate_names, _create


### venv_new\Lib\site-packages\pip\_internal\vcs\bazaar.py

#### `Bazaar`
**Methods**: get_base_rev_args, fetch_new, switch, update, get_url_rev_and_auth, get_remote_url, get_revision, is_commit_id_equal


### venv_new\Lib\site-packages\pip\_internal\vcs\git.py

#### `Git`
**Methods**: get_base_rev_args, is_immutable_rev_checkout, get_git_version, get_current_branch, get_revision_sha, _should_fetch, resolve_revision, is_commit_id_equal, fetch_new, switch, update, get_remote_url, _git_remote_to_pip_url, has_commit, get_revision, get_subdirectory, get_url_rev_and_auth, update_submodules, get_repository_root, should_add_vcs_url_prefix


### venv_new\Lib\site-packages\pip\_internal\vcs\mercurial.py

#### `Mercurial`
**Methods**: get_base_rev_args, fetch_new, switch, update, get_remote_url, get_revision, get_requirement_revision, is_commit_id_equal, get_subdirectory, get_repository_root


### venv_new\Lib\site-packages\pip\_internal\vcs\subversion.py

#### `Subversion`
**Methods**: should_add_vcs_url_prefix, get_base_rev_args, get_revision, get_netloc_and_auth, get_url_rev_and_auth, make_rev_args, get_remote_url, _get_svn_url_rev, is_commit_id_equal, __init__, call_vcs_version, get_vcs_version, get_remote_call_options, fetch_new, switch, update


### venv_new\Lib\site-packages\pip\_internal\vcs\versioncontrol.py

#### `RemoteNotFoundError`

#### `RemoteNotValidError`
**Methods**: __init__


#### `RevOptions`
_Encapsulates a VCS-specific revision to install, along with any VCS
install options.

Args:
    vc_class: a VersionControl subclass.
    rev: the name of the revision to install.
    extra_args: a list of extra options._

**Methods**: __repr__, arg_rev, to_args, to_display, make_new


#### `VcsSupport`
**Methods**: __init__, __iter__, backends, dirnames, all_schemes, register, unregister, get_backend_for_dir, get_backend_for_scheme, get_backend


#### `VersionControl`
**Methods**: should_add_vcs_url_prefix, get_subdirectory, get_requirement_revision, get_src_requirement, get_base_rev_args, is_immutable_rev_checkout, make_rev_options, _is_local_repository, get_netloc_and_auth, get_url_rev_and_auth, make_rev_args, get_url_rev_options, normalize_url, compare_urls, fetch_new, switch, update, is_commit_id_equal, obtain, unpack, get_remote_url, get_revision, run_command, is_repository_directory, get_repository_root


### venv_new\Lib\site-packages\pip\_vendor\cachecontrol\adapter.py

#### `CacheControlAdapter`
**Methods**: __init__, send, build_response, close


### venv_new\Lib\site-packages\pip\_vendor\cachecontrol\cache.py

#### `BaseCache`
**Methods**: get, set, delete, close


#### `DictCache`
**Methods**: __init__, get, set, delete


#### `SeparateBodyBaseCache`
_In this variant, the body is not stored mixed in with the metadata, but is
passed in (as a bytes-like object) in a separate call to ``set_body()``.

That is, the expected interaction pattern is::

    cache.set(key, serialized_metadata)
    cache.set_body(key)

Similarly, the body should be loaded separately via ``get_body()``._

**Methods**: set_body, get_body


### venv_new\Lib\site-packages\pip\_vendor\cachecontrol\caches\file_cache.py

#### `_FileCacheMixin`
_Shared implementation for both FileCache variants._

**Methods**: __init__, encode, _fn, get, set, _write, _delete


#### `FileCache`
_Traditional FileCache: body is stored in memory, so not suitable for large
downloads._

**Methods**: delete


#### `SeparateBodyFileCache`
_Memory-efficient FileCache: body is stored in a separate file, reducing
peak memory usage._

**Methods**: get_body, set_body, delete


### venv_new\Lib\site-packages\pip\_vendor\cachecontrol\caches\redis_cache.py

#### `RedisCache`
**Methods**: __init__, get, set, delete, clear, close


### venv_new\Lib\site-packages\pip\_vendor\cachecontrol\controller.py

#### `CacheController`
_An interface to see if request should cached or not._

**Methods**: __init__, _urlnorm, cache_url, parse_cache_control, _load_from_cache, cached_request, conditional_headers, _cache_set, cache_response, update_cached_response


### venv_new\Lib\site-packages\pip\_vendor\cachecontrol\filewrapper.py

#### `CallbackFileWrapper`
_Small wrapper around a fp object which will tee everything read into a
buffer, and when that file is closed it will execute a callback with the
contents of that buffer.

All attributes are proxied to the underlying file object.

This class uses members with a double underscore (__) leading prefix so as
not to accidentally shadow an attribute.

The data is stored in a temporary file until it is all available.  As long
as the temporary files directory is disk-based (sometimes it's a
memory-backed-``tmpfs`` on Linux), data will be unloaded to disk if memory
pressure is high.  For small files the disk usually won't be used at all,
it'll all be in the filesystem memory cache, so there should be no
performance impact._

**Methods**: __init__, __getattr__, __is_fp_closed, _close, read, _safe_read


### venv_new\Lib\site-packages\pip\_vendor\cachecontrol\heuristics.py

#### `BaseHeuristic`
**Methods**: warning, update_headers, apply


#### `OneDayCache`
_Cache the response by providing an expires 1 day in the
future._

**Methods**: update_headers


#### `ExpiresAfter`
_Cache **all** requests for a defined time period._

**Methods**: __init__, update_headers, warning


#### `LastModified`
_If there is no Expires header already, fall back on Last-Modified
using the heuristic from
http://tools.ietf.org/html/rfc7234#section-4.2.2
to calculate a reasonable value.

Firefox also does something like this per
https://developer.mozilla.org/en-US/docs/Web/HTTP/Caching_FAQ
http://lxr.mozilla.org/mozilla-release/source/netwerk/protocol/http/nsHttpResponseHead.cpp#397
Unlike mozilla we limit this to 24-hr._

**Methods**: update_headers, warning


### venv_new\Lib\site-packages\pip\_vendor\cachecontrol\serialize.py

#### `Serializer`
**Methods**: dumps, serialize, loads, prepare_response, _loads_v4


### venv_new\Lib\site-packages\pip\_vendor\distlib\__init__.py

#### `DistlibException`

#### `NullHandler`
**Methods**: handle, emit, createLock


### venv_new\Lib\site-packages\pip\_vendor\distlib\compat.py

#### `CertificateError`

#### `Container`
_A generic container for when multiple values need to be returned_

**Methods**: __init__


#### `ZipExtFile`
**Methods**: __init__, __enter__, __exit__


#### `ZipFile`
**Methods**: __enter__, __exit__, open


#### `ChainMap`
_A ChainMap groups multiple dicts (or other mappings) together
to create a single, updateable view.

The underlying mappings are stored in a list.  That list is public and can
accessed or updated using the *maps* attribute.  There is no other state.

Lookups search the underlying mappings successively until a key is found.
In contrast, writes, updates, and deletions only operate on the first
mapping._

**Methods**: __init__, __missing__, __getitem__, get, __len__, __iter__, __contains__, __bool__, __repr__, fromkeys, copy, new_child, parents, __setitem__, __delitem__, popitem, pop, clear


#### `OrderedDict`
_Dictionary that remembers insertion order_

**Methods**: __init__, __setitem__, __delitem__, __iter__, __reversed__, clear, popitem, keys, values, items, iterkeys, itervalues, iteritems, update, pop, setdefault, __repr__, __reduce__, copy, fromkeys, __eq__, __ne__, viewkeys, viewvalues, viewitems


#### `ConvertingDict`
_A converting dictionary wrapper._

**Methods**: __getitem__, get


#### `ConvertingList`
_A converting list wrapper._

**Methods**: __getitem__, pop


#### `ConvertingTuple`
_A converting tuple wrapper._

**Methods**: __getitem__


#### `BaseConfigurator`
_The configurator base class which defines some useful defaults._

**Methods**: __init__, resolve, ext_convert, cfg_convert, convert, configure_custom, as_tuple


### venv_new\Lib\site-packages\pip\_vendor\distlib\database.py

#### `_Cache`
_A simple cache mapping names and .dist-info paths to distributions_

**Methods**: __init__, clear, add


#### `DistributionPath`
_Represents a set of distributions installed on a path (typically sys.path)._

**Methods**: __init__, _get_cache_enabled, _set_cache_enabled, clear_cache, _yield_distributions, _generate_cache, distinfo_dirname, get_distributions, get_distribution, provides_distribution, get_file_path, get_exported_entries


#### `Distribution`
_A base class for distributions, whether installed or from indexes.
Either way, it must have some metadata, so that's all that's needed
for construction._

**Methods**: __init__, source_url, name_and_version, provides, _get_requirements, run_requires, meta_requires, build_requires, test_requires, dev_requires, matches_requirement, __repr__, __eq__, __hash__


#### `BaseInstalledDistribution`
_This is the base class for installed distributions (whether PEP 376 or
legacy)._

**Methods**: __init__, get_hash


#### `InstalledDistribution`
_Created with the *path* of the ``.dist-info`` directory provided to the
constructor. It reads the metadata contained in ``pydist.json`` when it is
instantiated., or uses a passed in Metadata instance (useful for when
dry-run mode is being used)._

**Methods**: __init__, __repr__, __str__, _get_records, exports, read_exports, write_exports, get_resource_path, list_installed_files, write_installed_files, check_installed_files, shared_locations, write_shared_locations, get_distinfo_resource, get_distinfo_file, list_distinfo_files, __eq__


#### `EggInfoDistribution`
_Created with the *path* of the ``.egg-info`` directory or file provided
to the constructor. It reads the metadata contained in the file itself, or
if the given path happens to be a directory, the metadata is read from the
file ``PKG-INFO`` under that directory._

**Methods**: __init__, _get_metadata, __repr__, __str__, check_installed_files, list_installed_files, list_distinfo_files, __eq__


#### `DependencyGraph`
_Represents a dependency graph between distributions.

The dependency relationships are stored in an ``adjacency_list`` that maps
distributions to a list of ``(other, label)`` tuples where  ``other``
is a distribution and the edge is labeled with ``label`` (i.e. the version
specifier, if such was provided). Also, for more efficient traversal, for
every distribution ``x``, a list of predecessors is kept in
``reverse_list[x]``. An edge from distribution ``a`` to
distribution ``b`` means that ``a`` depends on ``b``. If any missing
dependencies are found, they are stored in ``missing``, which is a
dictionary that maps distributions to a list of requirements that were not
provided by any other distributions._

**Methods**: __init__, add_distribution, add_edge, add_missing, _repr_dist, repr_node, to_dot, topological_sort, __repr__


### venv_new\Lib\site-packages\pip\_vendor\distlib\index.py

#### `PackageIndex`
_This class represents a package index compatible with PyPI, the Python
Package Index._

**Methods**: __init__, _get_pypirc_command, read_configuration, save_configuration, check_credentials, register, _reader, get_sign_command, run_command, sign_file, upload_file, upload_documentation, get_verify_command, verify_signature, download_file, send_request, encode_request, search


### venv_new\Lib\site-packages\pip\_vendor\distlib\locators.py

#### `RedirectHandler`
_A class to work around a bug in some Python 3.2.x releases._

**Methods**: http_error_302


#### `Locator`
_A base class for locators - things that locate distributions._

**Methods**: __init__, get_errors, clear_errors, clear_cache, _get_scheme, _set_scheme, _get_project, get_distribution_names, get_project, score_url, prefer_url, split_filename, convert_url_to_download_info, _get_digest, _update_version_data, locate


#### `PyPIRPCLocator`
_This locator uses XML-RPC to locate distributions. It therefore
cannot be used with simple mirrors (that only mirror file content)._

**Methods**: __init__, get_distribution_names, _get_project


#### `PyPIJSONLocator`
_This locator uses PyPI's JSON interface. It's very limited in functionality
and probably not worth using._

**Methods**: __init__, get_distribution_names, _get_project


#### `Page`
_This class represents a scraped HTML page._

**Methods**: __init__, links


#### `SimpleScrapingLocator`
_A locator which scrapes HTML pages to locate downloads for a distribution.
This runs multiple threads to do the I/O; performance is at least as good
as pip's PackageFinder, which works in an analogous fashion._

**Methods**: __init__, _prepare_threads, _wait_threads, _get_project, _is_platform_dependent, _process_download, _should_queue, _fetch, get_page, get_distribution_names


#### `DirectoryLocator`
_This class locates distributions in a directory tree._

**Methods**: __init__, should_include, _get_project, get_distribution_names


#### `JSONLocator`
_This locator uses special extended metadata (not available on PyPI) and is
the basis of performant dependency resolution in distlib. Other locators
require archive downloads before dependencies can be determined! As you
might imagine, that can be slow._

**Methods**: get_distribution_names, _get_project


#### `DistPathLocator`
_This locator finds installed distributions in a path. It can be useful for
adding to an :class:`AggregatingLocator`._

**Methods**: __init__, _get_project


#### `AggregatingLocator`
_This class allows you to chain and/or merge a list of locators._

**Methods**: __init__, clear_cache, _set_scheme, _get_project, get_distribution_names


#### `DependencyFinder`
_Locate dependencies for distributions._

**Methods**: __init__, add_distribution, remove_distribution, get_matcher, find_providers, try_to_replace, find


### venv_new\Lib\site-packages\pip\_vendor\distlib\manifest.py

#### `Manifest`
_A list of files built by exploring the filesystem and filtered by applying various
patterns to what we find there._

**Methods**: __init__, findall, add, add_many, sorted, clear, process_directive, _parse_directive, _include_pattern, _exclude_pattern, _translate_pattern, _glob_to_re


### venv_new\Lib\site-packages\pip\_vendor\distlib\markers.py

#### `Evaluator`
_This class is used to evaluate marker expressions._

**Methods**: evaluate


### venv_new\Lib\site-packages\pip\_vendor\distlib\metadata.py

#### `MetadataMissingError`
_A required metadata is missing_


#### `MetadataConflictError`
_Attempt to read or write metadata fields that are conflictual._


#### `MetadataUnrecognizedVersionError`
_Unknown metadata version number._


#### `MetadataInvalidError`
_A metadata value is invalid_


#### `LegacyMetadata`
_The legacy metadata of a release.

Supports versions 1.0, 1.1, 1.2, 2.0 and 1.3/2.1 (auto-detected). You can
instantiate the class with one of these arguments (or none):
- *path*, the path to a metadata file
- *fileobj* give a file-like object with metadata as content
- *mapping* is a dict-like object
- *scheme* is a version scheme name_

**Methods**: __init__, set_metadata_version, _write_field, __getitem__, __setitem__, __delitem__, __contains__, _convert_name, _default_value, _remove_line_prefix, __getattr__, get_fullname, is_field, is_multi_field, read, read_file, write, write_file, update, set, get, check, todict, add_requirements, keys, __iter__, values, items, __repr__


#### `Metadata`
_The metadata of a release. This implementation uses 2.1
metadata where possible. If not possible, it wraps a LegacyMetadata
instance which handles the key-value metadata format._

**Methods**: __init__, __getattribute__, _validate_value, __setattr__, name_and_version, provides, provides, get_requirements, dictionary, dependencies, dependencies, _validate_mapping, validate, todict, _from_legacy, _to_legacy, write, add_requirements, __repr__


### venv_new\Lib\site-packages\pip\_vendor\distlib\resources.py

#### `ResourceCache`
**Methods**: __init__, is_stale, get


#### `ResourceBase`
**Methods**: __init__


#### `Resource`
_A class representing an in-package resource, such as a data file. This is
not normally instantiated by user code, but rather by a
:class:`ResourceFinder` which manages the resource._

**Methods**: as_stream, file_path, bytes, size


#### `ResourceContainer`
**Methods**: resources


#### `ResourceFinder`
_Resource finder for file system resources._

**Methods**: __init__, _adjust_path, _make_path, _find, get_cache_info, find, get_stream, get_bytes, get_size, get_resources, is_container, iterator


#### `ZipResourceFinder`
_Resource finder for resources in .zip files._

**Methods**: __init__, _adjust_path, _find, get_cache_info, get_bytes, get_stream, get_size, get_resources, _is_directory


### venv_new\Lib\site-packages\pip\_vendor\distlib\scripts.py

#### `ScriptMaker`
_A class to copy or create scripts from source scripts or callable
specifications._

**Methods**: __init__, _get_alternate_executable, _build_shebang, _get_shebang, _get_script_text, get_manifest, _write_script, get_script_filenames, _make_script, _copy_script, dry_run, dry_run, make, make_multiple


### venv_new\Lib\site-packages\pip\_vendor\distlib\util.py

#### `cached_property`
**Methods**: __init__, __get__


#### `FileOperator`
**Methods**: __init__, _init_record, record_as_written, newer, copy_file, copy_stream, write_binary_file, write_text_file, set_mode, ensure_dir, byte_compile, ensure_removed, is_writable, commit, rollback


#### `ExportEntry`
**Methods**: __init__, value, __repr__, __eq__


#### `Cache`
_A class implementing a cache for resources that need to live in the file system
e.g. shared libraries. This class was moved from resources to here because it
could be used by other modules, e.g. the wheel module._

**Methods**: __init__, prefix_to_dir, clear


#### `EventMixin`
_A very simple publish/subscribe system._

**Methods**: __init__, add, remove, get_subscribers, publish


#### `Sequencer`
**Methods**: __init__, add_node, remove_node, add, remove, is_step, get_steps, strong_connections, dot


#### `Progress`
**Methods**: __init__, update, increment, start, stop, maximum, percentage, format_duration, ETA, speed


#### `HTTPSConnection`
**Methods**: connect


#### `HTTPSHandler`
**Methods**: __init__, _conn_maker, https_open


#### `HTTPSOnlyHandler`
**Methods**: http_open


#### `Transport`
**Methods**: __init__, make_connection


#### `SafeTransport`
**Methods**: __init__, make_connection


#### `ServerProxy`
**Methods**: __init__


#### `CSVBase`
**Methods**: __enter__, __exit__


#### `CSVReader`
**Methods**: __init__, __iter__, next


#### `CSVWriter`
**Methods**: __init__, writerow


#### `Configurator`
**Methods**: __init__, configure_custom, __getitem__, inc_convert


#### `SubprocessMixin`
_Mixin for running subprocesses and capturing their output_

**Methods**: __init__, reader, run_command


#### `PyPIRCFile`
**Methods**: __init__, read, update


### venv_new\Lib\site-packages\pip\_vendor\distlib\version.py

#### `UnsupportedVersionError`
_This is an unsupported version._


#### `Version`
**Methods**: __init__, parse, _check_compatible, __eq__, __ne__, __lt__, __gt__, __le__, __ge__, __hash__, __repr__, __str__, is_prerelease


#### `Matcher`
**Methods**: parse_requirement, __init__, match, exact_version, _check_compatible, __eq__, __ne__, __hash__, __repr__, __str__


#### `NormalizedVersion`
_A rational version.

Good:
    1.2         # equivalent to "1.2.0"
    1.2.0
    1.2a1
    1.2.3a2
    1.2.3b1
    1.2.3c1
    1.2.3.4
    TODO: fill this out

Bad:
    1           # minimum two numbers
    1.2a        # release level must have a release serial
    1.2.3b_

**Methods**: parse, is_prerelease


#### `NormalizedMatcher`
**Methods**: _adjust_local, _match_lt, _match_gt, _match_le, _match_ge, _match_eq, _match_arbitrary, _match_ne, _match_compatible


#### `LegacyVersion`
**Methods**: parse, is_prerelease


#### `LegacyMatcher`
**Methods**: _match_compatible


#### `SemanticVersion`
**Methods**: parse, is_prerelease


#### `SemanticMatcher`

#### `VersionScheme`
**Methods**: __init__, is_valid_version, is_valid_matcher, is_valid_constraint_list, suggest


### venv_new\Lib\site-packages\pip\_vendor\distlib\wheel.py

#### `Mounter`
**Methods**: __init__, add, remove, find_module, load_module


#### `Wheel`
_Class to build and install from Wheel files (PEP 427)._

**Methods**: __init__, filename, exists, tags, metadata, get_wheel_metadata, info, process_shebang, get_hash, write_record, write_records, build_zip, build, skip_entry, install, _get_dylib_cache, _get_extensions, is_compatible, is_mountable, mount, unmount, verify, update


#### `_Version`
**Methods**: __init__, __str__


### venv_new\Lib\site-packages\pip\_vendor\distro\distro.py

#### `VersionDict`

#### `InfoDict`

#### `cached_property`
_A version of @property which caches the value.  On access, it calls the
underlying function and sets the value in `__dict__` so future accesses
will not re-call the property._

**Methods**: __init__, __get__


#### `LinuxDistribution`
_Provides information about a OS distribution.

This package creates a private module-global instance of this class with
default initialization arguments, that is used by the
`consolidated accessor functions`_ and `single source accessor functions`_.
By using default initialization arguments, that module-global instance
returns data about the current OS distribution (i.e. the distro this
package runs on).

Normally, it is not necessary to create additional instances of this class.
However, in situations where control is needed over the exact data sources
that are used, instances of this class can be created with a specific
distro release file, or a specific os-release file, or without invoking the
lsb_release command._

**Methods**: __init__, __repr__, linux_distribution, id, name, version, version_parts, major_version, minor_version, build_number, like, codename, info, os_release_info, lsb_release_info, distro_release_info, uname_info, oslevel_info, os_release_attr, lsb_release_attr, distro_release_attr, uname_attr, _os_release_info, _parse_os_release_content, _lsb_release_info, _parse_lsb_release_content, _uname_info, _oslevel_info, _debian_version, _parse_uname_content, _to_str, _distro_release_info, _parse_distro_release_file, _parse_distro_release_content


### venv_new\Lib\site-packages\pip\_vendor\idna\codec.py

#### `Codec`
**Methods**: encode, decode


#### `IncrementalEncoder`
**Methods**: _buffer_encode


#### `IncrementalDecoder`
**Methods**: _buffer_decode


#### `StreamWriter`

#### `StreamReader`

### venv_new\Lib\site-packages\pip\_vendor\idna\core.py

#### `IDNAError`
_Base exception for all IDNA-encoding related problems_


#### `IDNABidiError`
_Exception when bidirectional requirements are not satisfied_


#### `InvalidCodepoint`
_Exception when a disallowed or unallocated codepoint is used_


#### `InvalidCodepointContext`
_Exception when the codepoint is not valid in the context it is used_


### venv_new\Lib\site-packages\pip\_vendor\msgpack\exceptions.py

#### `UnpackException`
_Base class for some exceptions raised while unpacking.

NOTE: unpack may raise exception other than subclass of
UnpackException.  If you want to catch all error, catch
Exception instead._


#### `BufferFull`

#### `OutOfData`

#### `FormatError`
_Invalid msgpack format_


#### `StackError`
_Too nested_


#### `ExtraData`
_ExtraData is raised when there is trailing data.

This exception is raised while only one-shot (not streaming)
unpack._

**Methods**: __init__, __str__


### venv_new\Lib\site-packages\pip\_vendor\msgpack\ext.py

#### `ExtType`
_ExtType represents ext type in msgpack._

**Methods**: __new__


#### `Timestamp`
_Timestamp represents the Timestamp extension type in msgpack.

When built with Cython, msgpack uses C methods to pack and unpack `Timestamp`.
When using pure-Python msgpack, :func:`to_bytes` and :func:`from_bytes` are used to pack and
unpack `Timestamp`.

This class is immutable: Do not override seconds and nanoseconds._

**Methods**: __init__, __repr__, __eq__, __ne__, __hash__, from_bytes, to_bytes, from_unix, to_unix, from_unix_nano, to_unix_nano, to_datetime, from_datetime


### venv_new\Lib\site-packages\pip\_vendor\msgpack\fallback.py

#### `BytesIO`
**Methods**: __init__, write, getvalue


#### `Unpacker`
_Streaming unpacker.

Arguments:

:param file_like:
    File-like object having `.read(n)` method.
    If specified, unpacker reads serialized data from it and `.feed()` is not usable.

:param int read_size:
    Used as `file_like.read(read_size)`. (default: `min(16*1024, max_buffer_size)`)

:param bool use_list:
    If true, unpack msgpack array to Python list.
    Otherwise, unpack to Python tuple. (default: True)

:param bool raw:
    If true, unpack msgpack raw to Python bytes.
    Otherwise, unpack to Python str by decoding with UTF-8 encoding (default).

:param int timestamp:
    Control how timestamp type is unpacked:

        0 - Timestamp
        1 - float  (Seconds from the EPOCH)
        2 - int  (Nanoseconds from the EPOCH)
        3 - datetime.datetime  (UTC).

:param bool strict_map_key:
    If true (default), only str or bytes are accepted for map (dict) keys.

:param object_hook:
    When specified, it should be callable.
    Unpacker calls it with a dict argument after unpacking msgpack map.
    (See also simplejson)

:param object_pairs_hook:
    When specified, it should be callable.
    Unpacker calls it with a list of key-value pairs after unpacking msgpack map.
    (See also simplejson)

:param str unicode_errors:
    The error handler for decoding unicode. (default: 'strict')
    This option should be used only when you have msgpack data which
    contains invalid UTF-8 string.

:param int max_buffer_size:
    Limits size of data waiting unpacked.  0 means 2**32-1.
    The default value is 100*1024*1024 (100MiB).
    Raises `BufferFull` exception when it is insufficient.
    You should set this parameter when unpacking data from untrusted source.

:param int max_str_len:
    Deprecated, use *max_buffer_size* instead.
    Limits max length of str. (default: max_buffer_size)

:param int max_bin_len:
    Deprecated, use *max_buffer_size* instead.
    Limits max length of bin. (default: max_buffer_size)

:param int max_array_len:
    Limits max length of array.
    (default: max_buffer_size)

:param int max_map_len:
    Limits max length of map.
    (default: max_buffer_size//2)

:param int max_ext_len:
    Deprecated, use *max_buffer_size* instead.
    Limits max size of ext type.  (default: max_buffer_size)

Example of streaming deserialize from file-like object::

    unpacker = Unpacker(file_like)
    for o in unpacker:
        process(o)

Example of streaming deserialize from socket::

    unpacker = Unpacker()
    while True:
        buf = sock.recv(1024**2)
        if not buf:
            break
        unpacker.feed(buf)
        for o in unpacker:
            process(o)

Raises ``ExtraData`` when *packed* contains extra bytes.
Raises ``OutOfData`` when *packed* is incomplete.
Raises ``FormatError`` when *packed* is not valid msgpack.
Raises ``StackError`` when *packed* contains too nested.
Other exceptions can be raised during unpacking._

**Methods**: __init__, feed, _consume, _got_extradata, _get_extradata, read_bytes, _read, _reserve, _read_header, _unpack, __iter__, __next__, skip, unpack, read_array_header, read_map_header, tell


#### `Packer`
_MessagePack Packer

Usage::

    packer = Packer()
    astream.write(packer.pack(a))
    astream.write(packer.pack(b))

Packer's constructor has some keyword arguments:

:param default:
    When specified, it should be callable.
    Convert user type to builtin type that Packer supports.
    See also simplejson's document.

:param bool use_single_float:
    Use single precision float type for float. (default: False)

:param bool autoreset:
    Reset buffer after each pack and return its content as `bytes`. (default: True).
    If set this to false, use `bytes()` to get content and `.reset()` to clear buffer.

:param bool use_bin_type:
    Use bin type introduced in msgpack spec 2.0 for bytes.
    It also enables str8 type for unicode. (default: True)

:param bool strict_types:
    If set to true, types will be checked to be exact. Derived classes
    from serializable types will not be serialized and will be
    treated as unsupported type and forwarded to default.
    Additionally tuples will not be serialized as lists.
    This is useful when trying to implement accurate serialization
    for python types.

:param bool datetime:
    If set to true, datetime with tzinfo is packed into Timestamp type.
    Note that the tzinfo is stripped in the timestamp.
    You can get UTC datetime with `timestamp=3` option of the Unpacker.

:param str unicode_errors:
    The error handler for encoding unicode. (default: 'strict')
    DO NOT USE THIS!!  This option is kept for very specific usage.

:param int buf_size:
    Internal buffer size. This option is used only for C implementation._

**Methods**: __init__, _pack, pack, pack_map_pairs, pack_array_header, pack_map_header, pack_ext_type, _pack_array_header, _pack_map_header, _pack_map_pairs, _pack_raw_header, _pack_bin_header, bytes, reset, getbuffer


### venv_new\Lib\site-packages\pip\_vendor\packaging\_elffile.py

#### `ELFInvalid`

#### `EIClass`

#### `EIData`

#### `EMachine`

#### `ELFFile`
_Representation of an ELF executable._

**Methods**: __init__, _read, interpreter


### venv_new\Lib\site-packages\pip\_vendor\packaging\_manylinux.py

#### `_GLibCVersion`

### venv_new\Lib\site-packages\pip\_vendor\packaging\_musllinux.py

#### `_MuslVersion`

### venv_new\Lib\site-packages\pip\_vendor\packaging\_parser.py

#### `Node`
**Methods**: __init__, __str__, __repr__, serialize


#### `Variable`
**Methods**: serialize


#### `Value`
**Methods**: serialize


#### `Op`
**Methods**: serialize


#### `ParsedRequirement`

### venv_new\Lib\site-packages\pip\_vendor\packaging\_structures.py

#### `InfinityType`
**Methods**: __repr__, __hash__, __lt__, __le__, __eq__, __gt__, __ge__, __neg__


#### `NegativeInfinityType`
**Methods**: __repr__, __hash__, __lt__, __le__, __eq__, __gt__, __ge__, __neg__


### venv_new\Lib\site-packages\pip\_vendor\packaging\_tokenizer.py

#### `Token`

#### `ParserSyntaxError`
_The provided source text could not be parsed correctly._

**Methods**: __init__, __str__


#### `Tokenizer`
_Context-sensitive token parsing.

Provides methods to examine the input stream to check whether the next token
matches._

**Methods**: __init__, consume, check, expect, read, raise_syntax_error, enclosing_tokens


### venv_new\Lib\site-packages\pip\_vendor\packaging\licenses\__init__.py

#### `InvalidLicenseExpression`
_Raised when a license-expression string is invalid

>>> canonicalize_license_expression("invalid")
Traceback (most recent call last):
    ...
packaging.licenses.InvalidLicenseExpression: Invalid license expression: 'invalid'_


### venv_new\Lib\site-packages\pip\_vendor\packaging\licenses\_spdx.py

#### `SPDXLicense`

#### `SPDXException`

### venv_new\Lib\site-packages\pip\_vendor\packaging\markers.py

#### `InvalidMarker`
_An invalid marker was found, users should refer to PEP 508._


#### `UndefinedComparison`
_An invalid operation was attempted on a value that doesn't support it._


#### `UndefinedEnvironmentName`
_A name was attempted to be used that does not exist inside of the
environment._


#### `Environment`

#### `Marker`
**Methods**: __init__, __str__, __repr__, __hash__, __eq__, evaluate


### venv_new\Lib\site-packages\pip\_vendor\packaging\metadata.py

#### `ExceptionGroup`
_A minimal implementation of :external:exc:`ExceptionGroup` from Python 3.11.

If :external:exc:`ExceptionGroup` is already defined by Python itself,
that version is used instead._

**Methods**: __init__, __repr__


#### `InvalidMetadata`
_A metadata field contains invalid data._

**Methods**: __init__


#### `RawMetadata`
_A dictionary of raw core metadata.

Each field in core metadata maps to a key of this dictionary (when data is
provided). The key is lower-case and underscores are used instead of dashes
compared to the equivalent core metadata field. Any core metadata field that
can be specified multiple times or can hold multiple values in a single
field have a key with a plural name. See :class:`Metadata` whose attributes
match the keys of this dictionary.

Core metadata fields that can be specified multiple times are stored as a
list or dict depending on which is appropriate for the field. Any fields
which hold multiple values in a single field are stored as a list._


#### `_Validator`
_Validate a metadata field.

All _process_*() methods correspond to a core metadata field. The method is
called with the field's raw value. If the raw value is valid it is returned
in its "enriched" form (e.g. ``version.Version`` for the ``Version`` field).
If the raw value is invalid, :exc:`InvalidMetadata` is raised (with a cause
as appropriate)._

**Methods**: __init__, __set_name__, __get__, _invalid_metadata, _process_metadata_version, _process_name, _process_version, _process_summary, _process_description_content_type, _process_dynamic, _process_provides_extra, _process_requires_python, _process_requires_dist, _process_license_expression, _process_license_files


#### `Metadata`
_Representation of distribution metadata.

Compared to :class:`RawMetadata`, this class provides objects representing
metadata fields instead of only using built-in types. Any invalid metadata
will cause :exc:`InvalidMetadata` to be raised (with a
:py:attr:`~BaseException.__cause__` attribute as appropriate)._

**Methods**: from_raw, from_email


### venv_new\Lib\site-packages\pip\_vendor\packaging\requirements.py

#### `InvalidRequirement`
_An invalid requirement was found, users should refer to PEP 508._


#### `Requirement`
_Parse a requirement.

Parse a given requirement string into its parts, such as name, specifier,
URL, and extras. Raises InvalidRequirement on a badly-formed requirement
string._

**Methods**: __init__, _iter_parts, __str__, __repr__, __hash__, __eq__


### venv_new\Lib\site-packages\pip\_vendor\packaging\specifiers.py

#### `InvalidSpecifier`
_Raised when attempting to create a :class:`Specifier` with a specifier
string that is invalid.

>>> Specifier("lolwat")
Traceback (most recent call last):
    ...
packaging.specifiers.InvalidSpecifier: Invalid specifier: 'lolwat'_


#### `BaseSpecifier`
**Methods**: __str__, __hash__, __eq__, prereleases, prereleases, contains, filter


#### `Specifier`
_This class abstracts handling of version specifiers.

.. tip::

    It is generally not required to instantiate this manually. You should instead
    prefer to work with :class:`SpecifierSet` instead, which can parse
    comma-separated version specifiers (which is what package metadata contains)._

**Methods**: __init__, prereleases, prereleases, operator, version, __repr__, __str__, _canonical_spec, __hash__, __eq__, _get_operator, _compare_compatible, _compare_equal, _compare_not_equal, _compare_less_than_equal, _compare_greater_than_equal, _compare_less_than, _compare_greater_than, _compare_arbitrary, __contains__, contains, filter


#### `SpecifierSet`
_This class abstracts handling of a set of version specifiers.

It can be passed a single specifier (``>=3.0``), a comma-separated list of
specifiers (``>=3.0,!=3.1``), or no specifier at all._

**Methods**: __init__, prereleases, prereleases, __repr__, __str__, __hash__, __and__, __eq__, __len__, __iter__, __contains__, contains, filter


### venv_new\Lib\site-packages\pip\_vendor\packaging\tags.py

#### `Tag`
_A representation of the tag triple for a wheel.

Instances are considered immutable and thus are hashable. Equality checking
is also supported._

**Methods**: __init__, interpreter, abi, platform, __eq__, __hash__, __str__, __repr__


### venv_new\Lib\site-packages\pip\_vendor\packaging\utils.py

#### `InvalidName`
_An invalid distribution name; users should refer to the packaging user guide._


#### `InvalidWheelFilename`
_An invalid wheel filename was found, users should refer to PEP 427._


#### `InvalidSdistFilename`
_An invalid sdist filename was found, users should refer to the packaging user guide._


### venv_new\Lib\site-packages\pip\_vendor\packaging\version.py

#### `_Version`

#### `InvalidVersion`
_Raised when a version string is not a valid version.

>>> Version("invalid")
Traceback (most recent call last):
    ...
packaging.version.InvalidVersion: Invalid version: 'invalid'_


#### `_BaseVersion`
**Methods**: __hash__, __lt__, __le__, __eq__, __ge__, __gt__, __ne__


#### `Version`
_This class abstracts handling of a project's versions.

A :class:`Version` instance is comparison aware and can be compared and
sorted using the standard Python interfaces.

>>> v1 = Version("1.0a5")
>>> v2 = Version("1.0")
>>> v1
<Version('1.0a5')>
>>> v2
<Version('1.0')>
>>> v1 < v2
True
>>> v1 == v2
False
>>> v1 > v2
False
>>> v1 >= v2
False
>>> v1 <= v2
True_

**Methods**: __init__, __repr__, __str__, epoch, release, pre, post, dev, local, public, base_version, is_prerelease, is_postrelease, is_devrelease, major, minor, micro


#### `_TrimmedRelease`
**Methods**: release


### venv_new\Lib\site-packages\pip\_vendor\pkg_resources\__init__.py

#### `_LoaderProtocol`
**Methods**: load_module


#### `_ZipLoaderModule`

#### `PEP440Warning`
_Used when there is an issue with a version or specifier not complying with
PEP 440._


#### `ResolutionError`
_Abstract base for dependency resolution errors_

**Methods**: __repr__


#### `VersionConflict`
_An already-installed version conflicts with the requested version.

Should be initialized with the installed Distribution and the requested
Requirement._

**Methods**: dist, req, report, with_context


#### `ContextualVersionConflict`
_A VersionConflict that accepts a third parameter, the set of the
requirements that required the installed Distribution._

**Methods**: required_by


#### `DistributionNotFound`
_A requested distribution was not found_

**Methods**: req, requirers, requirers_str, report, __str__


#### `UnknownExtra`
_Distribution doesn't have an "extra feature" of the given name_


#### `IMetadataProvider`
**Methods**: has_metadata, get_metadata, get_metadata_lines, metadata_isdir, metadata_listdir, run_script


#### `IResourceProvider`
_An object that provides access to package resources_

**Methods**: get_resource_filename, get_resource_stream, get_resource_string, has_resource, resource_isdir, resource_listdir


#### `WorkingSet`
_A collection of active distributions on sys.path (or a similar list)_

**Methods**: __init__, _build_master, _build_from_requirements, add_entry, __contains__, find, iter_entry_points, run_script, __iter__, add, resolve, resolve, resolve, resolve, _resolve_dist, find_plugins, find_plugins, find_plugins, find_plugins, require, subscribe, _added_new, __getstate__, __setstate__


#### `_ReqExtras`
_Map each requirement to the extras that demanded it._

**Methods**: markers_pass


#### `Environment`
_Searchable snapshot of distributions on a search path_

**Methods**: __init__, can_add, remove, scan, __getitem__, add, best_match, best_match, best_match, obtain, obtain, obtain, obtain, __iter__, __iadd__, __add__


#### `ExtractionError`
_An error occurred extracting a resource

The following attributes are available from instances of this exception:

manager
    The resource manager that raised this exception

cache_path
    The base directory for resource extraction

original_error
    The exception instance that caused extraction to fail_


#### `ResourceManager`
_Manage resource extraction and packages_

**Methods**: __init__, resource_exists, resource_isdir, resource_filename, resource_stream, resource_string, resource_listdir, extraction_error, get_cache_path, _warn_unsafe_extraction_path, postprocess, set_extraction_path, cleanup_resources


#### `NullProvider`
_Try to implement resources and metadata for arbitrary PEP 302 loaders_

**Methods**: __init__, get_resource_filename, get_resource_stream, get_resource_string, has_resource, _get_metadata_path, has_metadata, get_metadata, get_metadata_lines, resource_isdir, metadata_isdir, resource_listdir, metadata_listdir, run_script, _has, _isdir, _listdir, _fn, _validate_resource_path, _get


#### `EggProvider`
_Provider based on a virtual filesystem_

**Methods**: __init__, _setup_prefix, _set_egg


#### `DefaultProvider`
_Provides access to package resources in the filesystem_

**Methods**: _has, _isdir, _listdir, get_resource_stream, _get, _register


#### `EmptyProvider`
_Provider that returns nothing for all requests_

**Methods**: _get, _listdir, __init__


#### `ZipManifests`
_zip manifest builder_

**Methods**: build


#### `MemoizedZipManifests`
_Memoized zipfile manifests._

**Methods**: load


#### `manifest_mod`

#### `ZipProvider`
_Resource support for zips and eggs_

**Methods**: __init__, _zipinfo_name, _parts, zipinfo, get_resource_filename, _get_date_and_size, _extract_resource, _is_current, _get_eager_resources, _index, _has, _isdir, _listdir, _eager_to_zip, _resource_to_zip


#### `FileMetadata`
_Metadata handler for standalone PKG-INFO files

Usage::

    metadata = FileMetadata("/path/to/PKG-INFO")

This provider rejects all data and metadata requests except for PKG-INFO,
which is treated as existing, and will be the contents of the file at
the provided location._

**Methods**: __init__, _get_metadata_path, has_metadata, get_metadata, _warn_on_replacement, get_metadata_lines


#### `PathMetadata`
_Metadata provider for egg directories

Usage::

    # Development eggs:

    egg_info = "/path/to/PackageName.egg-info"
    base_dir = os.path.dirname(egg_info)
    metadata = PathMetadata(base_dir, egg_info)
    dist_name = os.path.splitext(os.path.basename(egg_info))[0]
    dist = Distribution(basedir, project_name=dist_name, metadata=metadata)

    # Unpacked egg directories:

    egg_path = "/path/to/PackageName-ver-pyver-etc.egg"
    metadata = PathMetadata(egg_path, os.path.join(egg_path,'EGG-INFO'))
    dist = Distribution.from_filename(egg_path, metadata=metadata)_

**Methods**: __init__


#### `EggMetadata`
_Metadata provider for .egg files_

**Methods**: __init__


#### `NoDists`
_>>> bool(NoDists())
False

>>> list(NoDists()('anything'))
[]_

**Methods**: __bool__, __call__


#### `EntryPoint`
_Object representing an advertised importable object_

**Methods**: __init__, __str__, __repr__, load, load, load, resolve, require, parse, _parse_extras, parse_group, parse_map


#### `Distribution`
_Wrap an actual or potential sys.path entry w/metadata_

**Methods**: __init__, from_location, _reload_version, hashcmp, __hash__, __lt__, __le__, __gt__, __ge__, __eq__, __ne__, key, parsed_version, _forgiving_parsed_version, version, _dep_map, _filter_extras, _build_dep_map, requires, _get_metadata_path_for_display, _get_metadata, _get_version, activate, egg_name, __repr__, __str__, __getattr__, __dir__, from_filename, as_requirement, load_entry_point, get_entry_map, get_entry_map, get_entry_map, get_entry_info, insert_on, check_version_conflict, has_version, clone, extras


#### `EggInfoDistribution`
**Methods**: _reload_version


#### `DistInfoDistribution`
_Wrap an actual or potential sys.path entry
w/metadata, .dist-info style._

**Methods**: _parsed_pkg_info, _dep_map, _compute_dependencies


#### `RequirementParseError`
_Compatibility wrapper for InvalidRequirement_


#### `Requirement`
**Methods**: __init__, __eq__, __ne__, __contains__, __hash__, __repr__, parse


#### `PkgResourcesDeprecationWarning`
_Base class for warning about deprecations in ``pkg_resources``

This class is not derived from ``DeprecationWarning``, and as such is
visible by default._


### venv_new\Lib\site-packages\pip\_vendor\platformdirs\android.py

#### `Android`
_Follows the guidance `from here <https://android.stackexchange.com/a/216132>`_.

Makes use of the `appname <platformdirs.api.PlatformDirsABC.appname>`, `version
<platformdirs.api.PlatformDirsABC.version>`, `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`._

**Methods**: user_data_dir, site_data_dir, user_config_dir, site_config_dir, user_cache_dir, site_cache_dir, user_state_dir, user_log_dir, user_documents_dir, user_downloads_dir, user_pictures_dir, user_videos_dir, user_music_dir, user_desktop_dir, user_runtime_dir, site_runtime_dir


### venv_new\Lib\site-packages\pip\_vendor\platformdirs\api.py

#### `PlatformDirsABC`
_Abstract base class for platform directories._

**Methods**: __init__, _append_app_name_and_version, _optionally_create_directory, _first_item_as_path_if_multipath, user_data_dir, site_data_dir, user_config_dir, site_config_dir, user_cache_dir, site_cache_dir, user_state_dir, user_log_dir, user_documents_dir, user_downloads_dir, user_pictures_dir, user_videos_dir, user_music_dir, user_desktop_dir, user_runtime_dir, site_runtime_dir, user_data_path, site_data_path, user_config_path, site_config_path, user_cache_path, site_cache_path, user_state_path, user_log_path, user_documents_path, user_downloads_path, user_pictures_path, user_videos_path, user_music_path, user_desktop_path, user_runtime_path, site_runtime_path, iter_config_dirs, iter_data_dirs, iter_cache_dirs, iter_runtime_dirs, iter_config_paths, iter_data_paths, iter_cache_paths, iter_runtime_paths


### venv_new\Lib\site-packages\pip\_vendor\platformdirs\macos.py

#### `MacOS`
_Platform directories for the macOS operating system.

Follows the guidance from
`Apple documentation <https://developer.apple.com/library/archive/documentation/FileManagement/Conceptual/FileSystemProgrammingGuide/MacOSXDirectories/MacOSXDirectories.html>`_.
Makes use of the `appname <platformdirs.api.PlatformDirsABC.appname>`,
`version <platformdirs.api.PlatformDirsABC.version>`,
`ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`._

**Methods**: user_data_dir, site_data_dir, site_data_path, user_config_dir, site_config_dir, user_cache_dir, site_cache_dir, site_cache_path, user_state_dir, user_log_dir, user_documents_dir, user_downloads_dir, user_pictures_dir, user_videos_dir, user_music_dir, user_desktop_dir, user_runtime_dir, site_runtime_dir


### venv_new\Lib\site-packages\pip\_vendor\platformdirs\unix.py

#### `Unix`
_On Unix/Linux, we follow the `XDG Basedir Spec <https://specifications.freedesktop.org/basedir-spec/basedir-spec-
latest.html>`_.

The spec allows overriding directories with environment variables. The examples shown are the default values,
alongside the name of the environment variable that overrides them. Makes use of the `appname
<platformdirs.api.PlatformDirsABC.appname>`, `version <platformdirs.api.PlatformDirsABC.version>`, `multipath
<platformdirs.api.PlatformDirsABC.multipath>`, `opinion <platformdirs.api.PlatformDirsABC.opinion>`, `ensure_exists
<platformdirs.api.PlatformDirsABC.ensure_exists>`._

**Methods**: user_data_dir, _site_data_dirs, site_data_dir, user_config_dir, _site_config_dirs, site_config_dir, user_cache_dir, site_cache_dir, user_state_dir, user_log_dir, user_documents_dir, user_downloads_dir, user_pictures_dir, user_videos_dir, user_music_dir, user_desktop_dir, user_runtime_dir, site_runtime_dir, site_data_path, site_config_path, site_cache_path, iter_config_dirs, iter_data_dirs


### venv_new\Lib\site-packages\pip\_vendor\platformdirs\windows.py

#### `Windows`
_`MSDN on where to store app data files <https://learn.microsoft.com/en-us/windows/win32/shell/knownfolderid>`_.

Makes use of the `appname <platformdirs.api.PlatformDirsABC.appname>`, `appauthor
<platformdirs.api.PlatformDirsABC.appauthor>`, `version <platformdirs.api.PlatformDirsABC.version>`, `roaming
<platformdirs.api.PlatformDirsABC.roaming>`, `opinion <platformdirs.api.PlatformDirsABC.opinion>`, `ensure_exists
<platformdirs.api.PlatformDirsABC.ensure_exists>`._

**Methods**: user_data_dir, _append_parts, site_data_dir, user_config_dir, site_config_dir, user_cache_dir, site_cache_dir, user_state_dir, user_log_dir, user_documents_dir, user_downloads_dir, user_pictures_dir, user_videos_dir, user_music_dir, user_desktop_dir, user_runtime_dir, site_runtime_dir


### venv_new\Lib\site-packages\pip\_vendor\pygments\cmdline.py

#### `HelpFormatter`
**Methods**: __init__


### venv_new\Lib\site-packages\pip\_vendor\pygments\filter.py

#### `Filter`
_Default filter. Subclass this class or use the `simplefilter`
decorator to create own filters._

**Methods**: __init__, filter


#### `FunctionFilter`
_Abstract class used by `simplefilter` to create simple
function filters on the fly. The `simplefilter` decorator
automatically creates subclasses of this class for
functions passed to it._

**Methods**: __init__, filter


### venv_new\Lib\site-packages\pip\_vendor\pygments\filters\__init__.py

#### `CodeTagFilter`
_Highlight special code tags in comments and docstrings.

Options accepted:

`codetags` : list of strings
   A list of strings that are flagged as code tags.  The default is to
   highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.

.. versionchanged:: 2.13
   Now recognizes ``FIXME`` by default._

**Methods**: __init__, filter


#### `SymbolFilter`
_Convert mathematical symbols such as \<longrightarrow> in Isabelle
or \longrightarrow in LaTeX into Unicode characters.

This is mostly useful for HTML or console output when you want to
approximate the source rendering you'd see in an IDE.

Options accepted:

`lang` : string
   The symbol language. Must be one of ``'isabelle'`` or
   ``'latex'``.  The default is ``'isabelle'``._

**Methods**: __init__, filter


#### `KeywordCaseFilter`
_Convert keywords to lowercase or uppercase or capitalize them, which
means first letter uppercase, rest lowercase.

This can be useful e.g. if you highlight Pascal code and want to adapt the
code to your styleguide.

Options accepted:

`case` : string
   The casing to convert keywords to. Must be one of ``'lower'``,
   ``'upper'`` or ``'capitalize'``.  The default is ``'lower'``._

**Methods**: __init__, filter


#### `NameHighlightFilter`
_Highlight a normal Name (and Name.*) token with a different token type.

Example::

    filter = NameHighlightFilter(
        names=['foo', 'bar', 'baz'],
        tokentype=Name.Function,
    )

This would highlight the names "foo", "bar" and "baz"
as functions. `Name.Function` is the default token type.

Options accepted:

`names` : list of strings
  A list of names that should be given the different token type.
  There is no default.
`tokentype` : TokenType or string
  A token type or a string containing a token type name that is
  used for highlighting the strings in `names`.  The default is
  `Name.Function`._

**Methods**: __init__, filter


#### `ErrorToken`

#### `RaiseOnErrorTokenFilter`
_Raise an exception when the lexer generates an error token.

Options accepted:

`excclass` : Exception class
  The exception class to raise.
  The default is `pygments.filters.ErrorToken`.

.. versionadded:: 0.8_

**Methods**: __init__, filter


#### `VisibleWhitespaceFilter`
_Convert tabs, newlines and/or spaces to visible characters.

Options accepted:

`spaces` : string or bool
  If this is a one-character string, spaces will be replaces by this string.
  If it is another true value, spaces will be replaced by ``¬∑`` (unicode
  MIDDLE DOT).  If it is a false value, spaces will not be replaced.  The
  default is ``False``.
`tabs` : string or bool
  The same as for `spaces`, but the default replacement character is ``¬ª``
  (unicode RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK).  The default value
  is ``False``.  Note: this will not work if the `tabsize` option for the
  lexer is nonzero, as tabs will already have been expanded then.
`tabsize` : int
  If tabs are to be replaced by this filter (see the `tabs` option), this
  is the total number of characters that a tab should be expanded to.
  The default is ``8``.
`newlines` : string or bool
  The same as for `spaces`, but the default replacement character is ``¬∂``
  (unicode PILCROW SIGN).  The default value is ``False``.
`wstokentype` : bool
  If true, give whitespace the special `Whitespace` token type.  This allows
  styling the visible whitespace differently (e.g. greyed out), but it can
  disrupt background colors.  The default is ``True``.

.. versionadded:: 0.8_

**Methods**: __init__, filter


#### `GobbleFilter`
_Gobbles source code lines (eats initial characters).

This filter drops the first ``n`` characters off every line of code.  This
may be useful when the source code fed to the lexer is indented by a fixed
amount of space that isn't desired in the output.

Options accepted:

`n` : int
   The number of characters to gobble.

.. versionadded:: 1.2_

**Methods**: __init__, gobble, filter


#### `TokenMergeFilter`
_Merges consecutive tokens with the same token type in the output
stream of a lexer.

.. versionadded:: 1.2_

**Methods**: __init__, filter


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatter.py

#### `Formatter`
_Converts a token stream to text.

Formatters should have attributes to help selecting them. These
are similar to the corresponding :class:`~pygments.lexer.Lexer`
attributes.

.. autoattribute:: name
   :no-value:

.. autoattribute:: aliases
   :no-value:

.. autoattribute:: filenames
   :no-value:

You can pass options as keyword arguments to the constructor.
All formatters accept these basic options:

``style``
    The style to use, can be a string or a Style subclass
    (default: "default"). Not used by e.g. the
    TerminalFormatter.
``full``
    Tells the formatter to output a "full" document, i.e.
    a complete self-contained document. This doesn't have
    any effect for some formatters (default: false).
``title``
    If ``full`` is true, the title that should be used to
    caption the document (default: '').
``encoding``
    If given, must be an encoding name. This will be used to
    convert the Unicode token strings to byte strings in the
    output. If it is "" or None, Unicode strings will be written
    to the output file, which most file-like objects do not
    support (default: None).
``outencoding``
    Overrides ``encoding`` if given._

**Methods**: __init__, get_style_defs, format, __class_getitem__


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\__init__.py

#### `_automodule`
_Automatically import formatters._

**Methods**: __getattr__


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\bbcode.py

#### `BBCodeFormatter`
_Format tokens with BBcodes. These formatting codes are used by many
bulletin boards, so you can highlight your sourcecode with pygments before
posting it there.

This formatter has no support for background colors and borders, as there
are no common BBcode tags for that.

Some board systems (e.g. phpBB) don't support colors in their [code] tag,
so you can't use the highlighting together with that tag.
Text in a [code] tag usually is shown with a monospace font (which this
formatter can do with the ``monofont`` option) and no spaces (which you
need for indentation) are removed.

Additional options accepted:

`style`
    The style to use, can be a string or a Style subclass (default:
    ``'default'``).

`codetag`
    If set to true, put the output into ``[code]`` tags (default:
    ``false``)

`monofont`
    If set to true, add a tag to show the code with a monospace font
    (default: ``false``)._

**Methods**: __init__, _make_styles, format_unencoded


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\groff.py

#### `GroffFormatter`
_Format tokens with groff escapes to change their color and font style.

.. versionadded:: 2.11

Additional options accepted:

`style`
    The style to use, can be a string or a Style subclass (default:
    ``'default'``).

`monospaced`
    If set to true, monospace font will be used (default: ``true``).

`linenos`
    If set to true, print the line numbers (default: ``false``).

`wrap`
    Wrap lines to the specified number of characters. Disabled if set to 0
    (default: ``0``)._

**Methods**: __init__, _make_styles, _define_colors, _write_lineno, _wrap_line, _escape_chars, format_unencoded


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\html.py

#### `HtmlFormatter`
_Format tokens as HTML 4 ``<span>`` tags. By default, the content is enclosed
in a ``<pre>`` tag, itself wrapped in a ``<div>`` tag (but see the `nowrap` option).
The ``<div>``'s CSS class can be set by the `cssclass` option.

If the `linenos` option is set to ``"table"``, the ``<pre>`` is
additionally wrapped inside a ``<table>`` which has one row and two
cells: one containing the line numbers and one containing the code.
Example:

.. sourcecode:: html

    <div class="highlight" >
    <table><tr>
      <td class="linenos" title="click to toggle"
        onclick="with (this.firstChild.style)
                 { display = (display == '') ? 'none' : '' }">
        <pre>1
        2</pre>
      </td>
      <td class="code">
        <pre><span class="Ke">def </span><span class="NaFu">foo</span>(bar):
          <span class="Ke">pass</span>
        </pre>
      </td>
    </tr></table></div>

(whitespace added to improve clarity).

A list of lines can be specified using the `hl_lines` option to make these
lines highlighted (as of Pygments 0.11).

With the `full` option, a complete HTML 4 document is output, including
the style definitions inside a ``<style>`` tag, or in a separate file if
the `cssfile` option is given.

When `tagsfile` is set to the path of a ctags index file, it is used to
generate hyperlinks from names to their definition.  You must enable
`lineanchors` and run ctags with the `-n` option for this to work.  The
`python-ctags` module from PyPI must be installed to use this feature;
otherwise a `RuntimeError` will be raised.

The `get_style_defs(arg='')` method of a `HtmlFormatter` returns a string
containing CSS rules for the CSS classes used by the formatter. The
argument `arg` can be used to specify additional CSS selectors that
are prepended to the classes. A call `fmter.get_style_defs('td .code')`
would result in the following CSS classes:

.. sourcecode:: css

    td .code .kw { font-weight: bold; color: #00FF00 }
    td .code .cm { color: #999999 }
    ...

If you have Pygments 0.6 or higher, you can also pass a list or tuple to the
`get_style_defs()` method to request multiple prefixes for the tokens:

.. sourcecode:: python

    formatter.get_style_defs(['div.syntax pre', 'pre.syntax'])

The output would then look like this:

.. sourcecode:: css

    div.syntax pre .kw,
    pre.syntax .kw { font-weight: bold; color: #00FF00 }
    div.syntax pre .cm,
    pre.syntax .cm { color: #999999 }
    ...

Additional options accepted:

`nowrap`
    If set to ``True``, don't add a ``<pre>`` and a ``<div>`` tag
    around the tokens. This disables most other options (default: ``False``).

`full`
    Tells the formatter to output a "full" document, i.e. a complete
    self-contained document (default: ``False``).

`title`
    If `full` is true, the title that should be used to caption the
    document (default: ``''``).

`style`
    The style to use, can be a string or a Style subclass (default:
    ``'default'``). This option has no effect if the `cssfile`
    and `noclobber_cssfile` option are given and the file specified in
    `cssfile` exists.

`noclasses`
    If set to true, token ``<span>`` tags (as well as line number elements)
    will not use CSS classes, but inline styles. This is not recommended
    for larger pieces of code since it increases output size by quite a bit
    (default: ``False``).

`classprefix`
    Since the token types use relatively short class names, they may clash
    with some of your own class names. In this case you can use the
    `classprefix` option to give a string to prepend to all Pygments-generated
    CSS class names for token types.
    Note that this option also affects the output of `get_style_defs()`.

`cssclass`
    CSS class for the wrapping ``<div>`` tag (default: ``'highlight'``).
    If you set this option, the default selector for `get_style_defs()`
    will be this class.

    .. versionadded:: 0.9
       If you select the ``'table'`` line numbers, the wrapping table will
       have a CSS class of this string plus ``'table'``, the default is
       accordingly ``'highlighttable'``.

`cssstyles`
    Inline CSS styles for the wrapping ``<div>`` tag (default: ``''``).

`prestyles`
    Inline CSS styles for the ``<pre>`` tag (default: ``''``).

    .. versionadded:: 0.11

`cssfile`
    If the `full` option is true and this option is given, it must be the
    name of an external file. If the filename does not include an absolute
    path, the file's path will be assumed to be relative to the main output
    file's path, if the latter can be found. The stylesheet is then written
    to this file instead of the HTML file.

    .. versionadded:: 0.6

`noclobber_cssfile`
    If `cssfile` is given and the specified file exists, the css file will
    not be overwritten. This allows the use of the `full` option in
    combination with a user specified css file. Default is ``False``.

    .. versionadded:: 1.1

`linenos`
    If set to ``'table'``, output line numbers as a table with two cells,
    one containing the line numbers, the other the whole code.  This is
    copy-and-paste-friendly, but may cause alignment problems with some
    browsers or fonts.  If set to ``'inline'``, the line numbers will be
    integrated in the ``<pre>`` tag that contains the code (that setting
    is *new in Pygments 0.8*).

    For compatibility with Pygments 0.7 and earlier, every true value
    except ``'inline'`` means the same as ``'table'`` (in particular, that
    means also ``True``).

    The default value is ``False``, which means no line numbers at all.

    **Note:** with the default ("table") line number mechanism, the line
    numbers and code can have different line heights in Internet Explorer
    unless you give the enclosing ``<pre>`` tags an explicit ``line-height``
    CSS property (you get the default line spacing with ``line-height:
    125%``).

`hl_lines`
    Specify a list of lines to be highlighted. The line numbers are always
    relative to the input (i.e. the first line is line 1) and are
    independent of `linenostart`.

    .. versionadded:: 0.11

`linenostart`
    The line number for the first line (default: ``1``).

`linenostep`
    If set to a number n > 1, only every nth line number is printed.

`linenospecial`
    If set to a number n > 0, every nth line number is given the CSS
    class ``"special"`` (default: ``0``).

`nobackground`
    If set to ``True``, the formatter won't output the background color
    for the wrapping element (this automatically defaults to ``False``
    when there is no wrapping element [eg: no argument for the
    `get_syntax_defs` method given]) (default: ``False``).

    .. versionadded:: 0.6

`lineseparator`
    This string is output between lines of code. It defaults to ``"\n"``,
    which is enough to break a line inside ``<pre>`` tags, but you can
    e.g. set it to ``"<br>"`` to get HTML line breaks.

    .. versionadded:: 0.7

`lineanchors`
    If set to a nonempty string, e.g. ``foo``, the formatter will wrap each
    output line in an anchor tag with an ``id`` (and `name`) of ``foo-linenumber``.
    This allows easy linking to certain lines.

    .. versionadded:: 0.9

`linespans`
    If set to a nonempty string, e.g. ``foo``, the formatter will wrap each
    output line in a span tag with an ``id`` of ``foo-linenumber``.
    This allows easy access to lines via javascript.

    .. versionadded:: 1.6

`anchorlinenos`
    If set to `True`, will wrap line numbers in <a> tags. Used in
    combination with `linenos` and `lineanchors`.

`tagsfile`
    If set to the path of a ctags file, wrap names in anchor tags that
    link to their definitions. `lineanchors` should be used, and the
    tags file should specify line numbers (see the `-n` option to ctags).
    The tags file is assumed to be encoded in UTF-8.

    .. versionadded:: 1.6

`tagurlformat`
    A string formatting pattern used to generate links to ctags definitions.
    Available variables are `%(path)s`, `%(fname)s` and `%(fext)s`.
    Defaults to an empty string, resulting in just `#prefix-number` links.

    .. versionadded:: 1.6

`filename`
    A string used to generate a filename when rendering ``<pre>`` blocks,
    for example if displaying source code. If `linenos` is set to
    ``'table'`` then the filename will be rendered in an initial row
    containing a single `<th>` which spans both columns.

    .. versionadded:: 2.1

`wrapcode`
    Wrap the code inside ``<pre>`` blocks using ``<code>``, as recommended
    by the HTML5 specification.

    .. versionadded:: 2.4

`debug_token_types`
    Add ``title`` attributes to all token ``<span>`` tags that show the
    name of the token.

    .. versionadded:: 2.10


**Subclassing the HTML formatter**

.. versionadded:: 0.7

The HTML formatter is now built in a way that allows easy subclassing, thus
customizing the output HTML code. The `format()` method calls
`self._format_lines()` which returns a generator that yields tuples of ``(1,
line)``, where the ``1`` indicates that the ``line`` is a line of the
formatted source code.

If the `nowrap` option is set, the generator is the iterated over and the
resulting HTML is output.

Otherwise, `format()` calls `self.wrap()`, which wraps the generator with
other generators. These may add some HTML code to the one generated by
`_format_lines()`, either by modifying the lines generated by the latter,
then yielding them again with ``(1, line)``, and/or by yielding other HTML
code before or after the lines, with ``(0, html)``. The distinction between
source lines and other code makes it possible to wrap the generator multiple
times.

The default `wrap()` implementation adds a ``<div>`` and a ``<pre>`` tag.

A custom `HtmlFormatter` subclass could look like this:

.. sourcecode:: python

    class CodeHtmlFormatter(HtmlFormatter):

        def wrap(self, source, *, include_div):
            return self._wrap_code(source)

        def _wrap_code(self, source):
            yield 0, '<code>'
            for i, t in source:
                if i == 1:
                    # it's a line of formatted code
                    t += '<br>'
                yield i, t
            yield 0, '</code>'

This results in wrapping the formatted lines with a ``<code>`` tag, where the
source lines are broken using ``<br>`` tags.

After calling `wrap()`, the `format()` method also adds the "line numbers"
and/or "full document" wrappers if the respective options are set. Then, all
HTML yielded by the wrapped generator is output._

**Methods**: __init__, _get_css_class, _get_css_classes, _get_css_inline_styles, _create_stylesheet, get_style_defs, get_token_style_defs, get_background_style_defs, get_linenos_style_defs, get_css_prefix, _pre_style, _linenos_style, _linenos_special_style, _decodeifneeded, _wrap_full, _wrap_tablelinenos, _wrap_inlinelinenos, _wrap_lineanchors, _wrap_linespans, _wrap_div, _wrap_pre, _wrap_code, _translate_parts, _format_lines, _lookup_ctag, _highlight_lines, wrap, format_unencoded


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\img.py

#### `PilNotAvailable`
_When Python imaging library is not available_


#### `FontNotFound`
_When there are no usable fonts specified_


#### `FontManager`
_Manages a set of fonts: normal, italic, bold, etc..._

**Methods**: __init__, _get_nix_font_path, _create_nix, _get_mac_font_path, _create_mac, _lookup_win, _create_win, get_char_size, get_text_size, get_font, get_style


#### `ImageFormatter`
_Create a PNG image from source code. This uses the Python Imaging Library to
generate a pixmap from the source code.

.. versionadded:: 0.10

Additional options accepted:

`image_format`
    An image format to output to that is recognised by PIL, these include:

    * "PNG" (default)
    * "JPEG"
    * "BMP"
    * "GIF"

`line_pad`
    The extra spacing (in pixels) between each line of text.

    Default: 2

`font_name`
    The font name to be used as the base font from which others, such as
    bold and italic fonts will be generated.  This really should be a
    monospace font to look sane.
    If a filename or a file-like object is specified, the user must
    provide different styles of the font.

    Default: "Courier New" on Windows, "Menlo" on Mac OS, and
             "DejaVu Sans Mono" on \*nix

`font_size`
    The font size in points to be used.

    Default: 14

`image_pad`
    The padding, in pixels to be used at each edge of the resulting image.

    Default: 10

`line_numbers`
    Whether line numbers should be shown: True/False

    Default: True

`line_number_start`
    The line number of the first line.

    Default: 1

`line_number_step`
    The step used when printing line numbers.

    Default: 1

`line_number_bg`
    The background colour (in "#123456" format) of the line number bar, or
    None to use the style background color.

    Default: "#eed"

`line_number_fg`
    The text color of the line numbers (in "#123456"-like format).

    Default: "#886"

`line_number_chars`
    The number of columns of line numbers allowable in the line number
    margin.

    Default: 2

`line_number_bold`
    Whether line numbers will be bold: True/False

    Default: False

`line_number_italic`
    Whether line numbers will be italicized: True/False

    Default: False

`line_number_separator`
    Whether a line will be drawn between the line number area and the
    source code area: True/False

    Default: True

`line_number_pad`
    The horizontal padding (in pixels) between the line number margin, and
    the source code area.

    Default: 6

`hl_lines`
    Specify a list of lines to be highlighted.

    .. versionadded:: 1.2

    Default: empty list

`hl_color`
    Specify the color for highlighting lines.

    .. versionadded:: 1.2

    Default: highlight color of the selected style_

**Methods**: __init__, get_style_defs, _get_line_height, _get_line_y, _get_char_width, _get_char_x, _get_text_pos, _get_linenumber_pos, _get_text_color, _get_text_bg_color, _get_style_font, _get_image_size, _draw_linenumber, _draw_text, _create_drawables, _draw_line_numbers, _paint_line_number_bg, format


#### `GifImageFormatter`
_Create a GIF image from source code. This uses the Python Imaging Library to
generate a pixmap from the source code.

.. versionadded:: 1.0_


#### `JpgImageFormatter`
_Create a JPEG image from source code. This uses the Python Imaging Library to
generate a pixmap from the source code.

.. versionadded:: 1.0_


#### `BmpImageFormatter`
_Create a bitmap image from source code. This uses the Python Imaging Library to
generate a pixmap from the source code.

.. versionadded:: 1.0_


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\irc.py

#### `IRCFormatter`
_Format tokens with IRC color sequences

The `get_style_defs()` method doesn't do anything special since there is
no support for common styles.

Options accepted:

`bg`
    Set to ``"light"`` or ``"dark"`` depending on the terminal's background
    (default: ``"light"``).

`colorscheme`
    A dictionary mapping token types to (lightbg, darkbg) color names or
    ``None`` (default: ``None`` = use builtin colorscheme).

`linenos`
    Set to ``True`` to have line numbers in the output as well
    (default: ``False`` = no line numbers)._

**Methods**: __init__, _write_lineno, format_unencoded


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\latex.py

#### `LatexFormatter`
_Format tokens as LaTeX code. This needs the `fancyvrb` and `color`
standard packages.

Without the `full` option, code is formatted as one ``Verbatim``
environment, like this:

.. sourcecode:: latex

    \begin{Verbatim}[commandchars=\\\{\}]
    \PY{k}{def }\PY{n+nf}{foo}(\PY{n}{bar}):
        \PY{k}{pass}
    \end{Verbatim}

Wrapping can be disabled using the `nowrap` option.

The special command used here (``\PY``) and all the other macros it needs
are output by the `get_style_defs` method.

With the `full` option, a complete LaTeX document is output, including
the command definitions in the preamble.

The `get_style_defs()` method of a `LatexFormatter` returns a string
containing ``\def`` commands defining the macros needed inside the
``Verbatim`` environments.

Additional options accepted:

`nowrap`
    If set to ``True``, don't wrap the tokens at all, not even inside a
    ``\begin{Verbatim}`` environment. This disables most other options
    (default: ``False``).

`style`
    The style to use, can be a string or a Style subclass (default:
    ``'default'``).

`full`
    Tells the formatter to output a "full" document, i.e. a complete
    self-contained document (default: ``False``).

`title`
    If `full` is true, the title that should be used to caption the
    document (default: ``''``).

`docclass`
    If the `full` option is enabled, this is the document class to use
    (default: ``'article'``).

`preamble`
    If the `full` option is enabled, this can be further preamble commands,
    e.g. ``\usepackage`` (default: ``''``).

`linenos`
    If set to ``True``, output line numbers (default: ``False``).

`linenostart`
    The line number for the first line (default: ``1``).

`linenostep`
    If set to a number n > 1, only every nth line number is printed.

`verboptions`
    Additional options given to the Verbatim environment (see the *fancyvrb*
    docs for possible values) (default: ``''``).

`commandprefix`
    The LaTeX commands used to produce colored output are constructed
    using this prefix and some letters (default: ``'PY'``).

    .. versionadded:: 0.7
    .. versionchanged:: 0.10
       The default is now ``'PY'`` instead of ``'C'``.

`texcomments`
    If set to ``True``, enables LaTeX comment lines.  That is, LaTex markup
    in comment tokens is not escaped so that LaTeX can render it (default:
    ``False``).

    .. versionadded:: 1.2

`mathescape`
    If set to ``True``, enables LaTeX math mode escape in comments. That
    is, ``'$...$'`` inside a comment will trigger math mode (default:
    ``False``).

    .. versionadded:: 1.2

`escapeinside`
    If set to a string of length 2, enables escaping to LaTeX. Text
    delimited by these 2 characters is read as LaTeX code and
    typeset accordingly. It has no effect in string literals. It has
    no effect in comments if `texcomments` or `mathescape` is
    set. (default: ``''``).

    .. versionadded:: 2.0

`envname`
    Allows you to pick an alternative environment name replacing Verbatim.
    The alternate environment still has to support Verbatim's option syntax.
    (default: ``'Verbatim'``).

    .. versionadded:: 2.0_

**Methods**: __init__, _create_stylesheet, get_style_defs, format_unencoded


#### `LatexEmbeddedLexer`
_This lexer takes one lexer as argument, the lexer for the language
being formatted, and the left and right delimiters for escaped text.

First everything is scanned using the language lexer to obtain
strings and comments. All other consecutive tokens are merged and
the resulting text is scanned for escaped segments, which are given
the Token.Escape type. Finally text that is not escaped is scanned
again with the language lexer._

**Methods**: __init__, get_tokens_unprocessed, _find_safe_escape_tokens, _filter_to, _find_escape_tokens


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\other.py

#### `NullFormatter`
_Output the text unchanged without any formatting._

**Methods**: format


#### `RawTokenFormatter`
_Format tokens as a raw representation for storing token streams.

The format is ``tokentype<TAB>repr(tokenstring)\n``. The output can later
be converted to a token stream with the `RawTokenLexer`, described in the
:doc:`lexer list <lexers>`.

Only two options are accepted:

`compress`
    If set to ``'gz'`` or ``'bz2'``, compress the output with the given
    compression algorithm after encoding (default: ``''``).
`error_color`
    If set to a color name, highlight error tokens using that color.  If
    set but with no value, defaults to ``'red'``.

    .. versionadded:: 0.11_

**Methods**: __init__, format


#### `TestcaseFormatter`
_Format tokens as appropriate for a new testcase.

.. versionadded:: 2.0_

**Methods**: __init__, format


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\pangomarkup.py

#### `PangoMarkupFormatter`
_Format tokens as Pango Markup code. It can then be rendered to an SVG.

.. versionadded:: 2.9_

**Methods**: __init__, format_unencoded


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\rtf.py

#### `RtfFormatter`
_Format tokens as RTF markup. This formatter automatically outputs full RTF
documents with color information and other useful stuff. Perfect for Copy and
Paste into Microsoft(R) Word(R) documents.

Please note that ``encoding`` and ``outencoding`` options are ignored.
The RTF format is ASCII natively, but handles unicode characters correctly
thanks to escape sequences.

.. versionadded:: 0.6

Additional options accepted:

`style`
    The style to use, can be a string or a Style subclass (default:
    ``'default'``).

`fontface`
    The used font family, for example ``Bitstream Vera Sans``. Defaults to
    some generic font which is supposed to have fixed width.

`fontsize`
    Size of the font used. Size is specified in half points. The
    default is 24 half-points, giving a size 12 font.

    .. versionadded:: 2.0

`linenos`
    Turn on line numbering (default: ``False``).

    .. versionadded:: 2.18

`lineno_fontsize`
    Font size for line numbers. Size is specified in half points
    (default: `fontsize`). 

    .. versionadded:: 2.18

`lineno_padding`
    Number of spaces between the (inline) line numbers and the
    source code (default: ``2``).

    .. versionadded:: 2.18

`linenostart`
    The line number for the first line (default: ``1``).

    .. versionadded:: 2.18

`linenostep`
    If set to a number n > 1, only every nth line number is printed.

    .. versionadded:: 2.18

`lineno_color`
    Color for line numbers specified as a hex triplet, e.g. ``'5e5e5e'``. 
    Defaults to the style's line number color if it is a hex triplet, 
    otherwise ansi bright black.

    .. versionadded:: 2.18

`hl_lines`
    Specify a list of lines to be highlighted, as line numbers separated by
    spaces, e.g. ``'3 7 8'``. The line numbers are relative to the input 
    (i.e. the first line is line 1) unless `hl_linenostart` is set.

    .. versionadded:: 2.18

`hl_color`
    Color for highlighting the lines specified in `hl_lines`, specified as 
    a hex triplet (default: style's `highlight_color`).

    .. versionadded:: 2.18

`hl_linenostart`
    If set to ``True`` line numbers in `hl_lines` are specified
    relative to `linenostart` (default ``False``).

    .. versionadded:: 2.18_

**Methods**: __init__, _escape, _escape_text, hex_to_rtf_color, _split_tokens_on_newlines, _create_color_mapping, _lineno_template, _hl_open_str, _rtf_header, format_unencoded


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\svg.py

#### `SvgFormatter`
_Format tokens as an SVG graphics file.  This formatter is still experimental.
Each line of code is a ``<text>`` element with explicit ``x`` and ``y``
coordinates containing ``<tspan>`` elements with the individual token styles.

By default, this formatter outputs a full SVG document including doctype
declaration and the ``<svg>`` root element.

.. versionadded:: 0.9

Additional options accepted:

`nowrap`
    Don't wrap the SVG ``<text>`` elements in ``<svg><g>`` elements and
    don't add a XML declaration and a doctype.  If true, the `fontfamily`
    and `fontsize` options are ignored.  Defaults to ``False``.

`fontfamily`
    The value to give the wrapping ``<g>`` element's ``font-family``
    attribute, defaults to ``"monospace"``.

`fontsize`
    The value to give the wrapping ``<g>`` element's ``font-size``
    attribute, defaults to ``"14px"``.

`linenos`
    If ``True``, add line numbers (default: ``False``).

`linenostart`
    The line number for the first line (default: ``1``).

`linenostep`
    If set to a number n > 1, only every nth line number is printed.

`linenowidth`
    Maximum width devoted to line numbers (default: ``3*ystep``, sufficient
    for up to 4-digit line numbers. Increase width for longer code blocks).

`xoffset`
    Starting offset in X direction, defaults to ``0``.

`yoffset`
    Starting offset in Y direction, defaults to the font size if it is given
    in pixels, or ``20`` else.  (This is necessary since text coordinates
    refer to the text baseline, not the top edge.)

`ystep`
    Offset to add to the Y coordinate for each subsequent line.  This should
    roughly be the text size plus 5.  It defaults to that value if the text
    size is given in pixels, or ``25`` else.

`spacehack`
    Convert spaces in the source to ``&#160;``, which are non-breaking
    spaces.  SVG provides the ``xml:space`` attribute to control how
    whitespace inside tags is handled, in theory, the ``preserve`` value
    could be used to keep all whitespace as-is.  However, many current SVG
    viewers don't obey that rule, so this option is provided as a workaround
    and defaults to ``True``._

**Methods**: __init__, format_unencoded, _get_style


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\terminal.py

#### `TerminalFormatter`
_Format tokens with ANSI color sequences, for output in a text console.
Color sequences are terminated at newlines, so that paging the output
works correctly.

The `get_style_defs()` method doesn't do anything special since there is
no support for common styles.

Options accepted:

`bg`
    Set to ``"light"`` or ``"dark"`` depending on the terminal's background
    (default: ``"light"``).

`colorscheme`
    A dictionary mapping token types to (lightbg, darkbg) color names or
    ``None`` (default: ``None`` = use builtin colorscheme).

`linenos`
    Set to ``True`` to have line numbers on the terminal output as well
    (default: ``False`` = no line numbers)._

**Methods**: __init__, format, _write_lineno, _get_color, format_unencoded


### venv_new\Lib\site-packages\pip\_vendor\pygments\formatters\terminal256.py

#### `EscapeSequence`
**Methods**: __init__, escape, color_string, true_color_string, reset_string


#### `Terminal256Formatter`
_Format tokens with ANSI color sequences, for output in a 256-color
terminal or console.  Like in `TerminalFormatter` color sequences
are terminated at newlines, so that paging the output works correctly.

The formatter takes colors from a style defined by the `style` option
and converts them to nearest ANSI 256-color escape sequences. Bold and
underline attributes from the style are preserved (and displayed).

.. versionadded:: 0.9

.. versionchanged:: 2.2
   If the used style defines foreground colors in the form ``#ansi*``, then
   `Terminal256Formatter` will map these to non extended foreground color.
   See :ref:`AnsiTerminalStyle` for more information.

.. versionchanged:: 2.4
   The ANSI color names have been updated with names that are easier to
   understand and align with colornames of other projects and terminals.
   See :ref:`this table <new-ansi-color-names>` for more information.


Options accepted:

`style`
    The style to use, can be a string or a Style subclass (default:
    ``'default'``).

`linenos`
    Set to ``True`` to have line numbers on the terminal output as well
    (default: ``False`` = no line numbers)._

**Methods**: __init__, _build_color_table, _closest_color, _color_index, _setup_styles, _write_lineno, format, format_unencoded


#### `TerminalTrueColorFormatter`
_Format tokens with ANSI color sequences, for output in a true-color
terminal or console.  Like in `TerminalFormatter` color sequences
are terminated at newlines, so that paging the output works correctly.

.. versionadded:: 2.1

Options accepted:

`style`
    The style to use, can be a string or a Style subclass (default:
    ``'default'``)._

**Methods**: _build_color_table, _color_tuple, _setup_styles


### venv_new\Lib\site-packages\pip\_vendor\pygments\lexer.py

#### `LexerMeta`
_This metaclass automagically converts ``analyse_text`` methods into
static methods which always return float values._

**Methods**: __new__


#### `Lexer`
_Lexer for a specific language.

See also :doc:`lexerdevelopment`, a high-level guide to writing
lexers.

Lexer classes have attributes used for choosing the most appropriate
lexer based on various criteria.

.. autoattribute:: name
   :no-value:
.. autoattribute:: aliases
   :no-value:
.. autoattribute:: filenames
   :no-value:
.. autoattribute:: alias_filenames
.. autoattribute:: mimetypes
   :no-value:
.. autoattribute:: priority

Lexers included in Pygments should have two additional attributes:

.. autoattribute:: url
   :no-value:
.. autoattribute:: version_added
   :no-value:

Lexers included in Pygments may have additional attributes:

.. autoattribute:: _example
   :no-value:

You can pass options to the constructor. The basic options recognized
by all lexers and processed by the base `Lexer` class are:

``stripnl``
    Strip leading and trailing newlines from the input (default: True).
``stripall``
    Strip all leading and trailing whitespace from the input
    (default: False).
``ensurenl``
    Make sure that the input ends with a newline (default: True).  This
    is required for some lexers that consume input linewise.

    .. versionadded:: 1.3

``tabsize``
    If given and greater than 0, expand tabs in the input (default: 0).
``encoding``
    If given, must be an encoding name. This encoding will be used to
    convert the input string to Unicode, if it is not already a Unicode
    string (default: ``'guess'``, which uses a simple UTF-8 / Locale /
    Latin1 detection.  Can also be ``'chardet'`` to use the chardet
    library, if it is installed.
``inencoding``
    Overrides the ``encoding`` if given._

**Methods**: __init__, __repr__, add_filter, analyse_text, _preprocess_lexer_input, get_tokens, get_tokens_unprocessed


#### `DelegatingLexer`
_This lexer takes two lexer as arguments. A root lexer and
a language lexer. First everything is scanned using the language
lexer, afterwards all ``Other`` tokens are lexed using the root
lexer.

The lexers from the ``template`` lexer package use this base lexer._

**Methods**: __init__, get_tokens_unprocessed


#### `include`
_Indicates that a state should include rules from another state._


#### `_inherit`
_Indicates the a state should inherit from its superclass._

**Methods**: __repr__


#### `combined`
_Indicates a state combined from multiple states._

**Methods**: __new__, __init__


#### `_PseudoMatch`
_A pseudo match object constructed from a string._

**Methods**: __init__, start, end, group, groups, groupdict


#### `_This`
_Special singleton used for indicating the caller class.
Used by ``using``._


#### `default`
_Indicates a state or state action (e.g. #pop) to apply.
For example default('#pop') is equivalent to ('', Token, '#pop')
Note that state tuples may be used as well.

.. versionadded:: 2.0_

**Methods**: __init__


#### `words`
_Indicates a list of literal words that is transformed into an optimized
regex that matches any of the words.

.. versionadded:: 2.0_

**Methods**: __init__, get


#### `RegexLexerMeta`
_Metaclass for RegexLexer, creates the self._tokens attribute from
self.tokens on the first instantiation._

**Methods**: _process_regex, _process_token, _process_new_state, _process_state, process_tokendef, get_tokendefs, __call__


#### `RegexLexer`
_Base for simple stateful regular expression-based lexers.
Simplifies the lexing process so that you need only
provide a list of states and regular expressions._

**Methods**: get_tokens_unprocessed


#### `LexerContext`
_A helper object that holds lexer position data._

**Methods**: __init__, __repr__


#### `ExtendedRegexLexer`
_A RegexLexer that uses a context object to store its state._

**Methods**: get_tokens_unprocessed


#### `ProfilingRegexLexerMeta`
_Metaclass for ProfilingRegexLexer, collects regex timing info._

**Methods**: _process_regex


#### `ProfilingRegexLexer`
_Drop-in replacement for RegexLexer that does profiling of its regexes._

**Methods**: get_tokens_unprocessed


### venv_new\Lib\site-packages\pip\_vendor\pygments\lexers\__init__.py

#### `_automodule`
_Automatically import lexers._

**Methods**: __getattr__


### venv_new\Lib\site-packages\pip\_vendor\pygments\lexers\python.py

#### `PythonLexer`
_For Python source code (version 3.x).

.. versionchanged:: 2.5
   This is now the default ``PythonLexer``.  It is still available as the
   alias ``Python3Lexer``._

**Methods**: innerstring_rules, fstring_rules, analyse_text


#### `Python2Lexer`
_For Python 2.x source code.

.. versionchanged:: 2.5
   This class has been renamed from ``PythonLexer``.  ``PythonLexer`` now
   refers to the Python 3 variant.  File name patterns like ``*.py`` have
   been moved to Python 3 as well._

**Methods**: innerstring_rules, analyse_text


#### `_PythonConsoleLexerBase`

#### `PythonConsoleLexer`
_For Python console output or doctests, such as:

.. sourcecode:: pycon

    >>> a = 'foo'
    >>> print(a)
    foo
    >>> 1 / 0
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
    ZeroDivisionError: integer division or modulo by zero

Additional options:

`python3`
    Use Python 3 lexer for code.  Default is ``True``.

    .. versionadded:: 1.0
    .. versionchanged:: 2.5
       Now defaults to ``True``._

**Methods**: __init__


#### `_ReplaceInnerCode`
**Methods**: __init__


#### `PythonTracebackLexer`
_For Python 3.x tracebacks, with support for chained exceptions.

.. versionchanged:: 2.5
   This is now the default ``PythonTracebackLexer``.  It is still available
   as the alias ``Python3TracebackLexer``._


#### `Python2TracebackLexer`
_For Python tracebacks.

.. versionchanged:: 2.5
   This class has been renamed from ``PythonTracebackLexer``.
   ``PythonTracebackLexer`` now refers to the Python 3 variant._


#### `CythonLexer`
_For Pyrex and Cython source code._


#### `DgLexer`
_Lexer for dg,
a functional and object-oriented programming language
running on the CPython 3 VM._


#### `NumPyLexer`
_A Python lexer recognizing Numerical Python builtins._

**Methods**: get_tokens_unprocessed, analyse_text


### venv_new\Lib\site-packages\pip\_vendor\pygments\scanner.py

#### `EndOfText`
_Raise if end of text is reached and the user
tried to call a match function._


#### `Scanner`
_Simple scanner

All method patterns are regular expression strings (not
compiled expressions!)_

**Methods**: __init__, eos, check, test, scan, get_char, __repr__


### venv_new\Lib\site-packages\pip\_vendor\pygments\sphinxext.py

#### `PygmentsDoc`
_A directive to collect all lexers/formatters/filters and generate
autoclass directives for them._

**Methods**: run, document_lexers_overview, document_lexers, document_formatters, document_filters


### venv_new\Lib\site-packages\pip\_vendor\pygments\style.py

#### `StyleMeta`
**Methods**: __new__, style_for_token, list_styles, styles_token, __iter__, __len__


#### `Style`

### venv_new\Lib\site-packages\pip\_vendor\pygments\token.py

#### `_TokenType`
**Methods**: split, __init__, __contains__, __getattr__, __repr__, __copy__, __deepcopy__


### venv_new\Lib\site-packages\pip\_vendor\pygments\util.py

#### `ClassNotFound`
_Raised if one of the lookup functions didn't find a matching class._


#### `OptionError`
_This exception will be raised by all option processing functions if
the type or value of the argument is not correct._


#### `Future`
_Generic class to defer some work.

Handled specially in RegexLexerMeta, to support regex string construction at
first use._

**Methods**: get


#### `UnclosingTextIOWrapper`
**Methods**: close


### venv_new\Lib\site-packages\pip\_vendor\pyproject_hooks\_impl.py

#### `SubprocessRunner`
_A protocol for the subprocess runner._

**Methods**: __call__


#### `BackendUnavailable`
_Will be raised if the backend cannot be imported in the hook process._

**Methods**: __init__


#### `HookMissing`
_Will be raised on missing hooks (if a fallback can't be used)._

**Methods**: __init__


#### `UnsupportedOperation`
_May be raised by build_sdist if the backend indicates that it can't._

**Methods**: __init__


#### `BuildBackendHookCaller`
_A wrapper to call the build backend hooks for a source directory._

**Methods**: __init__, subprocess_runner, _supported_features, get_requires_for_build_wheel, prepare_metadata_for_build_wheel, build_wheel, get_requires_for_build_editable, prepare_metadata_for_build_editable, build_editable, get_requires_for_build_sdist, build_sdist, _call_hook


### venv_new\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py

#### `BackendUnavailable`
_Raised if we cannot import the backend_

**Methods**: __init__


#### `HookMissing`
_Raised if a hook is missing and we are not executing the fallback_

**Methods**: __init__


#### `_BackendPathFinder`
_Implements the MetaPathFinder interface to locate modules in ``backend-path``.

Since the environment provided by the frontend can contain all sorts of
MetaPathFinders, the only way to ensure the backend is loaded from the
right place is to prepend our own._

**Methods**: __init__, find_spec


#### `_DummyException`
_Nothing should ever raise this exception_


#### `GotUnsupportedOperation`
_For internal use when backend raises UnsupportedOperation_

**Methods**: __init__


### venv_new\Lib\site-packages\pip\_vendor\requests\adapters.py

#### `BaseAdapter`
_The Base Transport Adapter_

**Methods**: __init__, send, close


#### `HTTPAdapter`
_The built-in HTTP Adapter for urllib3.

Provides a general-case interface for Requests sessions to contact HTTP and
HTTPS urls by implementing the Transport Adapter interface. This class will
usually be created by the :class:`Session <Session>` class under the
covers.

:param pool_connections: The number of urllib3 connection pools to cache.
:param pool_maxsize: The maximum number of connections to save in the pool.
:param max_retries: The maximum number of retries each connection
    should attempt. Note, this applies only to failed DNS lookups, socket
    connections and connection timeouts, never to requests where data has
    made it to the server. By default, Requests does not retry failed
    connections. If you need granular control over the conditions under
    which we retry a request, import urllib3's ``Retry`` class and pass
    that instead.
:param pool_block: Whether the connection pool should block for connections.

Usage::

  >>> import requests
  >>> s = requests.Session()
  >>> a = requests.adapters.HTTPAdapter(max_retries=3)
  >>> s.mount('http://', a)_

**Methods**: __init__, __getstate__, __setstate__, init_poolmanager, proxy_manager_for, cert_verify, build_response, build_connection_pool_key_attributes, get_connection_with_tls_context, get_connection, close, request_url, add_headers, proxy_headers, send


### venv_new\Lib\site-packages\pip\_vendor\requests\auth.py

#### `AuthBase`
_Base class that all auth implementations derive from_

**Methods**: __call__


#### `HTTPBasicAuth`
_Attaches HTTP Basic Authentication to the given Request object._

**Methods**: __init__, __eq__, __ne__, __call__


#### `HTTPProxyAuth`
_Attaches HTTP Proxy Authentication to a given Request object._

**Methods**: __call__


#### `HTTPDigestAuth`
_Attaches HTTP Digest Authentication to the given Request object._

**Methods**: __init__, init_per_thread_state, build_digest_header, handle_redirect, handle_401, __call__, __eq__, __ne__


### venv_new\Lib\site-packages\pip\_vendor\requests\cookies.py

#### `MockRequest`
_Wraps a `requests.Request` to mimic a `urllib2.Request`.

The code in `http.cookiejar.CookieJar` expects this interface in order to correctly
manage cookie policies, i.e., determine whether a cookie can be set, given the
domains of the request and the cookie.

The original request object is read-only. The client is responsible for collecting
the new headers via `get_new_headers()` and interpreting them appropriately. You
probably want `get_cookie_header`, defined below._

**Methods**: __init__, get_type, get_host, get_origin_req_host, get_full_url, is_unverifiable, has_header, get_header, add_header, add_unredirected_header, get_new_headers, unverifiable, origin_req_host, host


#### `MockResponse`
_Wraps a `httplib.HTTPMessage` to mimic a `urllib.addinfourl`.

...what? Basically, expose the parsed HTTP headers from the server response
the way `http.cookiejar` expects to see them._

**Methods**: __init__, info, getheaders


#### `CookieConflictError`
_There are two cookies that meet the criteria specified in the cookie jar.
Use .get and .set and include domain and path args in order to be more specific._


#### `RequestsCookieJar`
_Compatibility class; is a http.cookiejar.CookieJar, but exposes a dict
interface.

This is the CookieJar we create by default for requests and sessions that
don't specify one, since some clients may expect response.cookies and
session.cookies to support dict operations.

Requests does not use the dict interface internally; it's just for
compatibility with external client code. All requests code should work
out of the box with externally provided instances of ``CookieJar``, e.g.
``LWPCookieJar`` and ``FileCookieJar``.

Unlike a regular CookieJar, this class is pickleable.

.. warning:: dictionary operations that are normally O(1) may be O(n)._

**Methods**: get, set, iterkeys, keys, itervalues, values, iteritems, items, list_domains, list_paths, multiple_domains, get_dict, __contains__, __getitem__, __setitem__, __delitem__, set_cookie, update, _find, _find_no_duplicates, __getstate__, __setstate__, copy, get_policy


### venv_new\Lib\site-packages\pip\_vendor\requests\exceptions.py

#### `RequestException`
_There was an ambiguous exception that occurred while handling your
request._

**Methods**: __init__


#### `InvalidJSONError`
_A JSON error occurred._


#### `JSONDecodeError`
_Couldn't decode the text into json_

**Methods**: __init__, __reduce__


#### `HTTPError`
_An HTTP error occurred._


#### `ConnectionError`
_A Connection error occurred._


#### `ProxyError`
_A proxy error occurred._


#### `SSLError`
_An SSL error occurred._


#### `Timeout`
_The request timed out.

Catching this error will catch both
:exc:`~requests.exceptions.ConnectTimeout` and
:exc:`~requests.exceptions.ReadTimeout` errors._


#### `ConnectTimeout`
_The request timed out while trying to connect to the remote server.

Requests that produced this error are safe to retry._


#### `ReadTimeout`
_The server did not send any data in the allotted amount of time._


#### `URLRequired`
_A valid URL is required to make a request._


#### `TooManyRedirects`
_Too many redirects._


#### `MissingSchema`
_The URL scheme (e.g. http or https) is missing._


#### `InvalidSchema`
_The URL scheme provided is either invalid or unsupported._


#### `InvalidURL`
_The URL provided was somehow invalid._


#### `InvalidHeader`
_The header value provided was somehow invalid._


#### `InvalidProxyURL`
_The proxy URL provided is invalid._


#### `ChunkedEncodingError`
_The server declared chunked encoding but sent an invalid chunk._


#### `ContentDecodingError`
_Failed to decode response content._


#### `StreamConsumedError`
_The content for this response was already consumed._


#### `RetryError`
_Custom retries logic failed_


#### `UnrewindableBodyError`
_Requests encountered an error when trying to rewind a body._


#### `RequestsWarning`
_Base warning for Requests._


#### `FileModeWarning`
_A file was opened in text mode, but Requests determined its binary length._


#### `RequestsDependencyWarning`
_An imported dependency doesn't match the expected version range._


### venv_new\Lib\site-packages\pip\_vendor\requests\models.py

#### `RequestEncodingMixin`
**Methods**: path_url, _encode_params, _encode_files


#### `RequestHooksMixin`
**Methods**: register_hook, deregister_hook


#### `Request`
_A user-created :class:`Request <Request>` object.

Used to prepare a :class:`PreparedRequest <PreparedRequest>`, which is sent to the server.

:param method: HTTP method to use.
:param url: URL to send.
:param headers: dictionary of headers to send.
:param files: dictionary of {filename: fileobject} files to multipart upload.
:param data: the body to attach to the request. If a dictionary or
    list of tuples ``[(key, value)]`` is provided, form-encoding will
    take place.
:param json: json for the body to attach to the request (if files or data is not specified).
:param params: URL parameters to append to the URL. If a dictionary or
    list of tuples ``[(key, value)]`` is provided, form-encoding will
    take place.
:param auth: Auth handler or (user, pass) tuple.
:param cookies: dictionary or CookieJar of cookies to attach to this request.
:param hooks: dictionary of callback hooks, for internal usage.

Usage::

  >>> import requests
  >>> req = requests.Request('GET', 'https://httpbin.org/get')
  >>> req.prepare()
  <PreparedRequest [GET]>_

**Methods**: __init__, __repr__, prepare


#### `PreparedRequest`
_The fully mutable :class:`PreparedRequest <PreparedRequest>` object,
containing the exact bytes that will be sent to the server.

Instances are generated from a :class:`Request <Request>` object, and
should not be instantiated manually; doing so may produce undesirable
effects.

Usage::

  >>> import requests
  >>> req = requests.Request('GET', 'https://httpbin.org/get')
  >>> r = req.prepare()
  >>> r
  <PreparedRequest [GET]>

  >>> s = requests.Session()
  >>> s.send(r)
  <Response [200]>_

**Methods**: __init__, prepare, __repr__, copy, prepare_method, _get_idna_encoded_host, prepare_url, prepare_headers, prepare_body, prepare_content_length, prepare_auth, prepare_cookies, prepare_hooks


#### `Response`
_The :class:`Response <Response>` object, which contains a
server's response to an HTTP request._

**Methods**: __init__, __enter__, __exit__, __getstate__, __setstate__, __repr__, __bool__, __nonzero__, __iter__, ok, is_redirect, is_permanent_redirect, next, apparent_encoding, iter_content, iter_lines, content, text, json, links, raise_for_status, close


### venv_new\Lib\site-packages\pip\_vendor\requests\sessions.py

#### `SessionRedirectMixin`
**Methods**: get_redirect_target, should_strip_auth, resolve_redirects, rebuild_auth, rebuild_proxies, rebuild_method


#### `Session`
_A Requests session.

Provides cookie persistence, connection-pooling, and configuration.

Basic Usage::

  >>> import requests
  >>> s = requests.Session()
  >>> s.get('https://httpbin.org/get')
  <Response [200]>

Or as a context manager::

  >>> with requests.Session() as s:
  ...     s.get('https://httpbin.org/get')
  <Response [200]>_

**Methods**: __init__, __enter__, __exit__, prepare_request, request, get, options, head, post, put, patch, delete, send, merge_environment_settings, get_adapter, close, mount, __getstate__, __setstate__


### venv_new\Lib\site-packages\pip\_vendor\requests\structures.py

#### `CaseInsensitiveDict`
_A case-insensitive ``dict``-like object.

Implements all methods and operations of
``MutableMapping`` as well as dict's ``copy``. Also
provides ``lower_items``.

All keys are expected to be strings. The structure remembers the
case of the last key to be set, and ``iter(instance)``,
``keys()``, ``items()``, ``iterkeys()``, and ``iteritems()``
will contain case-sensitive keys. However, querying and contains
testing is case insensitive::

    cid = CaseInsensitiveDict()
    cid['Accept'] = 'application/json'
    cid['aCCEPT'] == 'application/json'  # True
    list(cid) == ['Accept']  # True

For example, ``headers['content-encoding']`` will return the
value of a ``'Content-Encoding'`` response header, regardless
of how the header name was originally stored.

If the constructor, ``.update``, or equality comparison
operations are given keys that have equal ``.lower()``s, the
behavior is undefined._

**Methods**: __init__, __setitem__, __getitem__, __delitem__, __iter__, __len__, lower_items, __eq__, copy, __repr__


#### `LookupDict`
_Dictionary lookup object._

**Methods**: __init__, __repr__, __getitem__, get


### venv_new\Lib\site-packages\pip\_vendor\resolvelib\providers.py

#### `AbstractProvider`
_Delegate class to provide the required interface for the resolver._

**Methods**: identify, get_preference, find_matches, is_satisfied_by, get_dependencies


#### `AbstractResolver`
_The thing that performs the actual resolution work._

**Methods**: __init__, resolve


### venv_new\Lib\site-packages\pip\_vendor\resolvelib\reporters.py

#### `BaseReporter`
_Delegate class to provider progress reporting for the resolver._

**Methods**: starting, starting_round, ending_round, ending, adding_requirement, resolving_conflicts, rejecting_candidate, pinning


### venv_new\Lib\site-packages\pip\_vendor\resolvelib\resolvers.py

#### `ResolverException`
_A base class for all exceptions raised by this module.

Exceptions derived by this class should all be handled in this module. Any
bubbling pass the resolver should be treated as a bug._


#### `RequirementsConflicted`
**Methods**: __init__, __str__


#### `InconsistentCandidate`
**Methods**: __init__, __str__


#### `Criterion`
_Representation of possible resolution results of a package.

This holds three attributes:

* `information` is a collection of `RequirementInformation` pairs.
  Each pair is a requirement contributing to this criterion, and the
  candidate that provides the requirement.
* `incompatibilities` is a collection of all known not-to-work candidates
  to exclude from consideration.
* `candidates` is a collection containing all possible candidates deducted
  from the union of contributing requirements and known incompatibilities.
  It should never be empty, except when the criterion is an attribute of a
  raised `RequirementsConflicted` (in which case it is always empty).

.. note::
    This class is intended to be externally immutable. **Do not** mutate
    any of its attribute containers._

**Methods**: __init__, __repr__, iter_requirement, iter_parent


#### `ResolutionError`

#### `ResolutionImpossible`
**Methods**: __init__


#### `ResolutionTooDeep`
**Methods**: __init__


#### `Resolution`
_Stateful resolution object.

This is designed as a one-off object that holds information to kick start
the resolution process, and holds the results afterwards._

**Methods**: __init__, state, _push_new_state, _add_to_criteria, _remove_information_from_criteria, _get_preference, _is_current_pin_satisfying, _get_updated_criteria, _attempt_to_pin_criterion, _backjump, resolve


#### `Resolver`
_The thing that performs the actual resolution work._

**Methods**: resolve


### venv_new\Lib\site-packages\pip\_vendor\resolvelib\structs.py

#### `DirectedGraph`
_A graph structure with directed edges._

**Methods**: __init__, __iter__, __len__, __contains__, copy, add, remove, connected, connect, iter_edges, iter_children, iter_parents


#### `IteratorMapping`
**Methods**: __init__, __repr__, __bool__, __contains__, __getitem__, __iter__, __len__


#### `_FactoryIterableView`
_Wrap an iterator factory returned by `find_matches()`.

Calling `iter()` on this class would invoke the underlying iterator
factory, making it a "collection with ordering" that can be iterated
through multiple times, but lacks random access methods presented in
built-in Python sequence types._

**Methods**: __init__, __repr__, __bool__, __iter__


#### `_SequenceIterableView`
_Wrap an iterable returned by find_matches().

This is essentially just a proxy to the underlying sequence that provides
the same interface as `_FactoryIterableView`._

**Methods**: __init__, __repr__, __bool__, __iter__


### venv_new\Lib\site-packages\pip\_vendor\rich\__main__.py

#### `ColorBox`
**Methods**: __rich_console__, __rich_measure__


### venv_new\Lib\site-packages\pip\_vendor\rich\_inspect.py

#### `Inspect`
_A renderable to inspect any Python Object.

Args:
    obj (Any): An object to inspect.
    title (str, optional): Title to display over inspect result, or None use type. Defaults to None.
    help (bool, optional): Show full help text rather than just first paragraph. Defaults to False.
    methods (bool, optional): Enable inspection of callables. Defaults to False.
    docs (bool, optional): Also render doc strings. Defaults to True.
    private (bool, optional): Show private attributes (beginning with underscore). Defaults to False.
    dunder (bool, optional): Show attributes starting with double underscore. Defaults to False.
    sort (bool, optional): Sort attributes alphabetically. Defaults to True.
    all (bool, optional): Show all attributes. Defaults to False.
    value (bool, optional): Pretty print value of object. Defaults to True._

**Methods**: __init__, _make_title, __rich__, _get_signature, _render, _get_formatted_doc


### venv_new\Lib\site-packages\pip\_vendor\rich\_log_render.py

#### `LogRender`
**Methods**: __init__, __call__


### venv_new\Lib\site-packages\pip\_vendor\rich\_null_file.py

#### `NullFile`
**Methods**: close, isatty, read, readable, readline, readlines, seek, seekable, tell, truncate, writable, writelines, __next__, __iter__, __enter__, __exit__, write, flush, fileno


### venv_new\Lib\site-packages\pip\_vendor\rich\_ratio.py

#### `Edge`
_Any object that defines an edge (such as Layout)._


#### `E`

### venv_new\Lib\site-packages\pip\_vendor\rich\_stack.py

#### `Stack`
_A small shim over builtin list._

**Methods**: top, push


### venv_new\Lib\site-packages\pip\_vendor\rich\_win32_console.py

#### `LegacyWindowsError`

#### `WindowsCoordinates`
_Coordinates in the Windows Console API are (y, x), not (x, y).
This class is intended to prevent that confusion.
Rows and columns are indexed from 0.
This class can be used in place of wintypes._COORD in arguments and argtypes._

**Methods**: from_param


#### `CONSOLE_SCREEN_BUFFER_INFO`

#### `CONSOLE_CURSOR_INFO`

#### `LegacyWindowsTerm`
_This class allows interaction with the legacy Windows Console API. It should only be used in the context
of environments where virtual terminal processing is not available. However, if it is used in a Windows environment,
the entire API should work.

Args:
    file (IO[str]): The file which the Windows Console API HANDLE is retrieved from, defaults to sys.stdout._

**Methods**: __init__, cursor_position, screen_size, write_text, write_styled, move_cursor_to, erase_line, erase_end_of_line, erase_start_of_line, move_cursor_up, move_cursor_down, move_cursor_forward, move_cursor_to_column, move_cursor_backward, hide_cursor, show_cursor, set_title, _get_cursor_size


### venv_new\Lib\site-packages\pip\_vendor\rich\_windows.py

#### `WindowsConsoleFeatures`
_Windows features available._


### venv_new\Lib\site-packages\pip\_vendor\rich\abc.py

#### `RichRenderable`
_An abstract base class for Rich renderables.

Note that there is no need to extend this class, the intended use is to check if an
object supports the Rich renderable protocol. For example::

    if isinstance(my_object, RichRenderable):
        console.print(my_object)_

**Methods**: __subclasshook__


#### `Foo`

### venv_new\Lib\site-packages\pip\_vendor\rich\align.py

#### `Align`
_Align a renderable by adding spaces if necessary.

Args:
    renderable (RenderableType): A console renderable.
    align (AlignMethod): One of "left", "center", or "right""
    style (StyleType, optional): An optional style to apply to the background.
    vertical (Optional[VerticalAlignMethod], optional): Optional vertical align, one of "top", "middle", or "bottom". Defaults to None.
    pad (bool, optional): Pad the right with spaces. Defaults to True.
    width (int, optional): Restrict contents to given width, or None to use default width. Defaults to None.
    height (int, optional): Set height of align renderable, or None to fit to contents. Defaults to None.

Raises:
    ValueError: if ``align`` is not one of the expected values._

**Methods**: __init__, __repr__, left, center, right, __rich_console__, __rich_measure__


#### `VerticalCenter`
_Vertically aligns a renderable.

Warn:
    This class is deprecated and may be removed in a future version. Use Align class with
    `vertical="middle"`.

Args:
    renderable (RenderableType): A renderable object.
    style (StyleType, optional): An optional style to apply to the background. Defaults to None._

**Methods**: __init__, __repr__, __rich_console__, __rich_measure__


### venv_new\Lib\site-packages\pip\_vendor\rich\ansi.py

#### `_AnsiToken`
_Result of ansi tokenized string._


#### `AnsiDecoder`
_Translate ANSI code in to styled Text._

**Methods**: __init__, decode, decode_line


### venv_new\Lib\site-packages\pip\_vendor\rich\bar.py

#### `Bar`
_Renders a solid block bar.

Args:
    size (float): Value for the end of the bar.
    begin (float): Begin point (between 0 and size, inclusive).
    end (float): End point (between 0 and size, inclusive).
    width (int, optional): Width of the bar, or ``None`` for maximum width. Defaults to None.
    color (Union[Color, str], optional): Color of the bar. Defaults to "default".
    bgcolor (Union[Color, str], optional): Color of bar background. Defaults to "default"._

**Methods**: __init__, __repr__, __rich_console__, __rich_measure__


### venv_new\Lib\site-packages\pip\_vendor\rich\box.py

#### `Box`
_Defines characters to render boxes.

‚îå‚îÄ‚î¨‚îê top
‚îÇ ‚îÇ‚îÇ head
‚îú‚îÄ‚îº‚î§ head_row
‚îÇ ‚îÇ‚îÇ mid
‚îú‚îÄ‚îº‚î§ row
‚îú‚îÄ‚îº‚î§ foot_row
‚îÇ ‚îÇ‚îÇ foot
‚îî‚îÄ‚î¥‚îò bottom

Args:
    box (str): Characters making up box.
    ascii (bool, optional): True if this box uses ascii characters only. Default is False._

**Methods**: __init__, __repr__, __str__, substitute, get_plain_headed_box, get_top, get_row, get_bottom


### venv_new\Lib\site-packages\pip\_vendor\rich\color.py

#### `ColorSystem`
_One of the 3 color system supported by terminals._

**Methods**: __repr__, __str__


#### `ColorType`
_Type of color stored in Color class._

**Methods**: __repr__


#### `ColorParseError`
_The color could not be parsed._


#### `Color`
_Terminal color definition._

**Methods**: __rich__, __rich_repr__, system, is_system_defined, is_default, get_truecolor, from_ansi, from_triplet, from_rgb, default, parse, get_ansi_codes, downgrade


### venv_new\Lib\site-packages\pip\_vendor\rich\color_triplet.py

#### `ColorTriplet`
_The red, green, and blue components of a color._

**Methods**: hex, rgb, normalized


### venv_new\Lib\site-packages\pip\_vendor\rich\columns.py

#### `Columns`
_Display renderables in neat columns.

Args:
    renderables (Iterable[RenderableType]): Any number of Rich renderables (including str).
    width (int, optional): The desired width of the columns, or None to auto detect. Defaults to None.
    padding (PaddingDimensions, optional): Optional padding around cells. Defaults to (0, 1).
    expand (bool, optional): Expand columns to full width. Defaults to False.
    equal (bool, optional): Arrange in to equal sized columns. Defaults to False.
    column_first (bool, optional): Align items from top to bottom (rather than left to right). Defaults to False.
    right_to_left (bool, optional): Start column from right hand side. Defaults to False.
    align (str, optional): Align value ("left", "right", or "center") or None for default. Defaults to None.
    title (TextType, optional): Optional title for Columns._

**Methods**: __init__, add_renderable, __rich_console__


### venv_new\Lib\site-packages\pip\_vendor\rich\console.py

#### `NoChange`

#### `ConsoleDimensions`
_Size of the terminal._


#### `ConsoleOptions`
_Options for __rich_console__ method._

**Methods**: ascii_only, copy, update, update_width, update_height, reset_height, update_dimensions


#### `RichCast`
_An object that may be 'cast' to a console renderable._

**Methods**: __rich__


#### `ConsoleRenderable`
_An object that supports the console protocol._

**Methods**: __rich_console__


#### `CaptureError`
_An error in the Capture context manager._


#### `NewLine`
_A renderable to generate new line(s)_

**Methods**: __init__, __rich_console__


#### `ScreenUpdate`
_Render a list of lines at a given offset._

**Methods**: __init__, __rich_console__


#### `Capture`
_Context manager to capture the result of printing to the console.
See :meth:`~rich.console.Console.capture` for how to use.

Args:
    console (Console): A console instance to capture output._

**Methods**: __init__, __enter__, __exit__, get


#### `ThemeContext`
_A context manager to use a temporary theme. See :meth:`~rich.console.Console.use_theme` for usage._

**Methods**: __init__, __enter__, __exit__


#### `PagerContext`
_A context manager that 'pages' content. See :meth:`~rich.console.Console.pager` for usage._

**Methods**: __init__, __enter__, __exit__


#### `ScreenContext`
_A context manager that enables an alternative screen. See :meth:`~rich.console.Console.screen` for usage._

**Methods**: __init__, update, __enter__, __exit__


#### `Group`
_Takes a group of renderables and returns a renderable object that renders the group.

Args:
    renderables (Iterable[RenderableType]): An iterable of renderable objects.
    fit (bool, optional): Fit dimension of group to contents, or fill available space. Defaults to True._

**Methods**: __init__, renderables, __rich_measure__, __rich_console__


#### `ConsoleThreadLocals`
_Thread local values for Console context._


#### `RenderHook`
_Provides hooks in to the render process._

**Methods**: process_renderables


#### `Console`
_A high level console interface.

Args:
    color_system (str, optional): The color system supported by your terminal,
        either ``"standard"``, ``"256"`` or ``"truecolor"``. Leave as ``"auto"`` to autodetect.
    force_terminal (Optional[bool], optional): Enable/disable terminal control codes, or None to auto-detect terminal. Defaults to None.
    force_jupyter (Optional[bool], optional): Enable/disable Jupyter rendering, or None to auto-detect Jupyter. Defaults to None.
    force_interactive (Optional[bool], optional): Enable/disable interactive mode, or None to auto detect. Defaults to None.
    soft_wrap (Optional[bool], optional): Set soft wrap default on print method. Defaults to False.
    theme (Theme, optional): An optional style theme object, or ``None`` for default theme.
    stderr (bool, optional): Use stderr rather than stdout if ``file`` is not specified. Defaults to False.
    file (IO, optional): A file object where the console should write to. Defaults to stdout.
    quiet (bool, Optional): Boolean to suppress all output. Defaults to False.
    width (int, optional): The width of the terminal. Leave as default to auto-detect width.
    height (int, optional): The height of the terminal. Leave as default to auto-detect height.
    style (StyleType, optional): Style to apply to all output, or None for no style. Defaults to None.
    no_color (Optional[bool], optional): Enabled no color mode, or None to auto detect. Defaults to None.
    tab_size (int, optional): Number of spaces used to replace a tab character. Defaults to 8.
    record (bool, optional): Boolean to enable recording of terminal output,
        required to call :meth:`export_html`, :meth:`export_svg`, and :meth:`export_text`. Defaults to False.
    markup (bool, optional): Boolean to enable :ref:`console_markup`. Defaults to True.
    emoji (bool, optional): Enable emoji code. Defaults to True.
    emoji_variant (str, optional): Optional emoji variant, either "text" or "emoji". Defaults to None.
    highlight (bool, optional): Enable automatic highlighting. Defaults to True.
    log_time (bool, optional): Boolean to enable logging of time by :meth:`log` methods. Defaults to True.
    log_path (bool, optional): Boolean to enable the logging of the caller by :meth:`log`. Defaults to True.
    log_time_format (Union[str, TimeFormatterCallable], optional): If ``log_time`` is enabled, either string for strftime or callable that formats the time. Defaults to "[%X] ".
    highlighter (HighlighterType, optional): Default highlighter.
    legacy_windows (bool, optional): Enable legacy Windows mode, or ``None`` to auto detect. Defaults to ``None``.
    safe_box (bool, optional): Restrict box options that don't render on legacy Windows.
    get_datetime (Callable[[], datetime], optional): Callable that gets the current time as a datetime.datetime object (used by Console.log),
        or None for datetime.now.
    get_time (Callable[[], time], optional): Callable that gets the current time in seconds, default uses time.monotonic._

**Methods**: __init__, __repr__, file, file, _buffer, _buffer_index, _buffer_index, _theme_stack, _detect_color_system, _enter_buffer, _exit_buffer, set_live, clear_live, push_render_hook, pop_render_hook, __enter__, __exit__, begin_capture, end_capture, push_theme, pop_theme, use_theme, color_system, encoding, is_terminal, is_dumb_terminal, options, size, size, width, width, height, height, bell, capture, pager, line, clear, status, show_cursor, set_alt_screen, is_alt_screen, set_window_title, screen, measure, render, render_lines, render_str, get_style, _collect_renderables, rule, control, out, print, print_json, update_screen, update_screen_lines, print_exception, _caller_frame_info, log, on_broken_pipe, _check_buffer, _write_buffer, _render_buffer, input, export_text, save_text, export_html, save_html, export_svg, save_svg


### venv_new\Lib\site-packages\pip\_vendor\rich\constrain.py

#### `Constrain`
_Constrain the width of a renderable to a given number of characters.

Args:
    renderable (RenderableType): A renderable object.
    width (int, optional): The maximum width (in characters) to render. Defaults to 80._

**Methods**: __init__, __rich_console__, __rich_measure__


### venv_new\Lib\site-packages\pip\_vendor\rich\containers.py

#### `Renderables`
_A list subclass which renders its contents to the console._

**Methods**: __init__, __rich_console__, __rich_measure__, append, __iter__


#### `Lines`
_A list subclass which can render to the console._

**Methods**: __init__, __repr__, __iter__, __getitem__, __getitem__, __getitem__, __setitem__, __len__, __rich_console__, append, extend, pop, justify


### venv_new\Lib\site-packages\pip\_vendor\rich\control.py

#### `Control`
_A renderable that inserts a control code (non printable but may move cursor).

Args:
    *codes (str): Positional arguments are either a :class:`~rich.segment.ControlType` enum or a
        tuple of ControlType and an integer parameter_

**Methods**: __init__, bell, home, move, move_to_column, move_to, clear, show_cursor, alt_screen, title, __str__, __rich_console__


### venv_new\Lib\site-packages\pip\_vendor\rich\emoji.py

#### `NoEmoji`
_No emoji by that name._


#### `Emoji`
**Methods**: __init__, replace, __repr__, __str__, __rich_console__


### venv_new\Lib\site-packages\pip\_vendor\rich\errors.py

#### `ConsoleError`
_An error in console operation._


#### `StyleError`
_An error in styles._


#### `StyleSyntaxError`
_Style was badly formatted._


#### `MissingStyle`
_No such style._


#### `StyleStackError`
_Style stack is invalid._


#### `NotRenderableError`
_Object is not renderable._


#### `MarkupError`
_Markup was badly formatted._


#### `LiveError`
_Error related to Live display._


#### `NoAltScreen`
_Alt screen mode was required._


### venv_new\Lib\site-packages\pip\_vendor\rich\file_proxy.py

#### `FileProxy`
_Wraps a file (e.g. sys.stdout) and redirects writes to a console._

**Methods**: __init__, rich_proxied_file, __getattr__, write, flush, fileno


### venv_new\Lib\site-packages\pip\_vendor\rich\highlighter.py

#### `Highlighter`
_Abstract base class for highlighters._

**Methods**: __call__, highlight


#### `NullHighlighter`
_A highlighter object that doesn't highlight.

May be used to disable highlighting entirely._

**Methods**: highlight


#### `RegexHighlighter`
_Applies highlighting from a list of regular expressions._

**Methods**: highlight


#### `ReprHighlighter`
_Highlights the text typically produced from ``__repr__`` methods._


#### `JSONHighlighter`
_Highlights JSON_

**Methods**: highlight


#### `ISO8601Highlighter`
_Highlights the ISO8601 date time strings.
Regex reference: https://www.oreilly.com/library/view/regular-expressions-cookbook/9781449327453/ch04s07.html_


### venv_new\Lib\site-packages\pip\_vendor\rich\json.py

#### `JSON`
_A renderable which pretty prints JSON.

Args:
    json (str): JSON encoded data.
    indent (Union[None, int, str], optional): Number of characters to indent by. Defaults to 2.
    highlight (bool, optional): Enable highlighting. Defaults to True.
    skip_keys (bool, optional): Skip keys not of a basic type. Defaults to False.
    ensure_ascii (bool, optional): Escape all non-ascii characters. Defaults to False.
    check_circular (bool, optional): Check for circular references. Defaults to True.
    allow_nan (bool, optional): Allow NaN and Infinity values. Defaults to True.
    default (Callable, optional): A callable that converts values that can not be encoded
        in to something that can be JSON encoded. Defaults to None.
    sort_keys (bool, optional): Sort dictionary keys. Defaults to False._

**Methods**: __init__, from_data, __rich__


### venv_new\Lib\site-packages\pip\_vendor\rich\jupyter.py

#### `JupyterRenderable`
_A shim to write html to Jupyter notebook._

**Methods**: __init__, _repr_mimebundle_


#### `JupyterMixin`
_Add to an Rich renderable to make it render in Jupyter notebook._

**Methods**: _repr_mimebundle_


### venv_new\Lib\site-packages\pip\_vendor\rich\layout.py

#### `LayoutRender`
_An individual layout render._


#### `LayoutError`
_Layout related error._


#### `NoSplitter`
_Requested splitter does not exist._


#### `_Placeholder`
_An internal renderable used as a Layout placeholder._

**Methods**: __init__, __rich_console__


#### `Splitter`
_Base class for a splitter._

**Methods**: get_tree_icon, divide


#### `RowSplitter`
_Split a layout region in to rows._

**Methods**: get_tree_icon, divide


#### `ColumnSplitter`
_Split a layout region in to columns._

**Methods**: get_tree_icon, divide


#### `Layout`
_A renderable to divide a fixed height in to rows or columns.

Args:
    renderable (RenderableType, optional): Renderable content, or None for placeholder. Defaults to None.
    name (str, optional): Optional identifier for Layout. Defaults to None.
    size (int, optional): Optional fixed size of layout. Defaults to None.
    minimum_size (int, optional): Minimum size of layout. Defaults to 1.
    ratio (int, optional): Optional ratio for flexible layout. Defaults to 1.
    visible (bool, optional): Visibility of layout. Defaults to True._

**Methods**: __init__, __rich_repr__, renderable, children, map, get, __getitem__, tree, split, add_split, split_row, split_column, unsplit, update, refresh_screen, _make_region_map, render, __rich_console__


### venv_new\Lib\site-packages\pip\_vendor\rich\live.py

#### `_RefreshThread`
_A thread that calls refresh() at regular intervals._

**Methods**: __init__, stop, run


#### `Live`
_Renders an auto-updating live display of any given renderable.

Args:
    renderable (RenderableType, optional): The renderable to live display. Defaults to displaying nothing.
    console (Console, optional): Optional Console instance. Defaults to an internal Console instance writing to stdout.
    screen (bool, optional): Enable alternate screen mode. Defaults to False.
    auto_refresh (bool, optional): Enable auto refresh. If disabled, you will need to call `refresh()` or `update()` with refresh flag. Defaults to True
    refresh_per_second (float, optional): Number of times per second to refresh the live display. Defaults to 4.
    transient (bool, optional): Clear the renderable on exit (has no effect when screen=True). Defaults to False.
    redirect_stdout (bool, optional): Enable redirection of stdout, so ``print`` may be used. Defaults to True.
    redirect_stderr (bool, optional): Enable redirection of stderr. Defaults to True.
    vertical_overflow (VerticalOverflowMethod, optional): How to handle renderable when it is too tall for the console. Defaults to "ellipsis".
    get_renderable (Callable[[], RenderableType], optional): Optional callable to get renderable. Defaults to None._

**Methods**: __init__, is_started, get_renderable, start, stop, __enter__, __exit__, _enable_redirect_io, _disable_redirect_io, renderable, update, refresh, process_renderables


### venv_new\Lib\site-packages\pip\_vendor\rich\live_render.py

#### `LiveRender`
_Creates a renderable that may be updated.

Args:
    renderable (RenderableType): Any renderable object.
    style (StyleType, optional): An optional style to apply to the renderable. Defaults to ""._

**Methods**: __init__, set_renderable, position_cursor, restore_cursor, __rich_console__


### venv_new\Lib\site-packages\pip\_vendor\rich\logging.py

#### `RichHandler`
_A logging handler that renders output with Rich. The time / level / message and file are displayed in columns.
The level is color coded, and the message is syntax highlighted.

Note:
    Be careful when enabling console markup in log messages if you have configured logging for libraries not
    under your control. If a dependency writes messages containing square brackets, it may not produce the intended output.

Args:
    level (Union[int, str], optional): Log level. Defaults to logging.NOTSET.
    console (:class:`~rich.console.Console`, optional): Optional console instance to write logs.
        Default will use a global console instance writing to stdout.
    show_time (bool, optional): Show a column for the time. Defaults to True.
    omit_repeated_times (bool, optional): Omit repetition of the same time. Defaults to True.
    show_level (bool, optional): Show a column for the level. Defaults to True.
    show_path (bool, optional): Show the path to the original log call. Defaults to True.
    enable_link_path (bool, optional): Enable terminal link of path column to file. Defaults to True.
    highlighter (Highlighter, optional): Highlighter to style log messages, or None to use ReprHighlighter. Defaults to None.
    markup (bool, optional): Enable console markup in log messages. Defaults to False.
    rich_tracebacks (bool, optional): Enable rich tracebacks with syntax highlighting and formatting. Defaults to False.
    tracebacks_width (Optional[int], optional): Number of characters used to render tracebacks, or None for full width. Defaults to None.
    tracebacks_code_width (int, optional): Number of code characters used to render tracebacks, or None for full width. Defaults to 88.
    tracebacks_extra_lines (int, optional): Additional lines of code to render tracebacks, or None for full width. Defaults to None.
    tracebacks_theme (str, optional): Override pygments theme used in traceback.
    tracebacks_word_wrap (bool, optional): Enable word wrapping of long tracebacks lines. Defaults to True.
    tracebacks_show_locals (bool, optional): Enable display of locals in tracebacks. Defaults to False.
    tracebacks_suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.
    tracebacks_max_frames (int, optional): Optional maximum number of frames returned by traceback.
    locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
        Defaults to 10.
    locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.
    log_time_format (Union[str, TimeFormatterCallable], optional): If ``log_time`` is enabled, either string for strftime or callable that formats the time. Defaults to "[%x %X] ".
    keywords (List[str], optional): List of words to highlight instead of ``RichHandler.KEYWORDS``._

**Methods**: __init__, get_level_text, emit, render_message, render


### venv_new\Lib\site-packages\pip\_vendor\rich\markup.py

#### `Tag`
_A tag in console markup._

**Methods**: __str__, markup


### venv_new\Lib\site-packages\pip\_vendor\rich\measure.py

#### `Measurement`
_Stores the minimum and maximum widths (in characters) required to render an object._

**Methods**: span, normalize, with_maximum, with_minimum, clamp, get


### venv_new\Lib\site-packages\pip\_vendor\rich\padding.py

#### `Padding`
_Draw space around content.

Example:
    >>> print(Padding("Hello", (2, 4), style="on blue"))

Args:
    renderable (RenderableType): String or other renderable.
    pad (Union[int, Tuple[int]]): Padding for top, right, bottom, and left borders.
        May be specified with 1, 2, or 4 integers (CSS style).
    style (Union[str, Style], optional): Style for padding characters. Defaults to "none".
    expand (bool, optional): Expand padding to fit available width. Defaults to True._

**Methods**: __init__, indent, unpack, __repr__, __rich_console__, __rich_measure__


### venv_new\Lib\site-packages\pip\_vendor\rich\pager.py

#### `Pager`
_Base class for a pager._

**Methods**: show


#### `SystemPager`
_Uses the pager installed on the system._

**Methods**: _pager, show


### venv_new\Lib\site-packages\pip\_vendor\rich\palette.py

#### `Palette`
_A palette of available colors._

**Methods**: __init__, __getitem__, __rich__, match


#### `ColorBox`
**Methods**: __rich_console__


### venv_new\Lib\site-packages\pip\_vendor\rich\panel.py

#### `Panel`
_A console renderable that draws a border around its contents.

Example:
    >>> console.print(Panel("Hello, World!"))

Args:
    renderable (RenderableType): A console renderable object.
    box (Box, optional): A Box instance that defines the look of the border (see :ref:`appendix_box`. Defaults to box.ROUNDED.
    title (Optional[TextType], optional): Optional title displayed in panel header. Defaults to None.
    title_align (AlignMethod, optional): Alignment of title. Defaults to "center".
    subtitle (Optional[TextType], optional): Optional subtitle displayed in panel footer. Defaults to None.
    subtitle_align (AlignMethod, optional): Alignment of subtitle. Defaults to "center".
    safe_box (bool, optional): Disable box characters that don't display on windows legacy terminal with *raster* fonts. Defaults to True.
    expand (bool, optional): If True the panel will stretch to fill the console width, otherwise it will be sized to fit the contents. Defaults to True.
    style (str, optional): The style of the panel (border and contents). Defaults to "none".
    border_style (str, optional): The style of the border. Defaults to "none".
    width (Optional[int], optional): Optional width of panel. Defaults to None to auto-detect.
    height (Optional[int], optional): Optional height of panel. Defaults to None to auto-detect.
    padding (Optional[PaddingDimensions]): Optional padding around renderable. Defaults to 0.
    highlight (bool, optional): Enable automatic highlighting of panel title (if str). Defaults to False._

**Methods**: __init__, fit, _title, _subtitle, __rich_console__, __rich_measure__


### venv_new\Lib\site-packages\pip\_vendor\rich\pretty.py

#### `RichFormatter`
**Methods**: __call__


#### `Pretty`
_A rich renderable that pretty prints an object.

Args:
    _object (Any): An object to pretty print.
    highlighter (HighlighterType, optional): Highlighter object to apply to result, or None for ReprHighlighter. Defaults to None.
    indent_size (int, optional): Number of spaces in indent. Defaults to 4.
    justify (JustifyMethod, optional): Justify method, or None for default. Defaults to None.
    overflow (OverflowMethod, optional): Overflow method, or None for default. Defaults to None.
    no_wrap (Optional[bool], optional): Disable word wrapping. Defaults to False.
    indent_guides (bool, optional): Enable indentation guides. Defaults to False.
    max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
        Defaults to None.
    max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to None.
    max_depth (int, optional): Maximum depth of nested data structures, or None for no maximum. Defaults to None.
    expand_all (bool, optional): Expand all containers. Defaults to False.
    margin (int, optional): Subtrace a margin from width to force containers to expand earlier. Defaults to 0.
    insert_line (bool, optional): Insert a new line if the output has multiple new lines. Defaults to False._

**Methods**: __init__, __rich_console__, __rich_measure__


#### `Node`
_A node in a repr tree. May be atomic or a container._

**Methods**: iter_tokens, check_length, __str__, render


#### `_Line`
_A line in repr output._

**Methods**: expandable, check_length, expand, __str__


#### `BrokenRepr`
**Methods**: __repr__


#### `StockKeepingUnit`

#### `Thing`
**Methods**: __repr__


### venv_new\Lib\site-packages\pip\_vendor\rich\progress.py

#### `_TrackThread`
_A thread to periodically update progress._

**Methods**: __init__, run, __enter__, __exit__


#### `_Reader`
_A reader that tracks progress while it's being read from._

**Methods**: __init__, __enter__, __exit__, __iter__, __next__, closed, fileno, isatty, mode, name, readable, seekable, writable, read, readinto, readline, readlines, close, seek, tell, write, writelines


#### `_ReadContext`
_A utility class to handle a context for both a reader and a progress._

**Methods**: __init__, __enter__, __exit__


#### `ProgressColumn`
_Base class for a widget to use in progress display._

**Methods**: __init__, get_table_column, __call__, render


#### `RenderableColumn`
_A column to insert an arbitrary column.

Args:
    renderable (RenderableType, optional): Any renderable. Defaults to empty string._

**Methods**: __init__, render


#### `SpinnerColumn`
_A column with a 'spinner' animation.

Args:
    spinner_name (str, optional): Name of spinner animation. Defaults to "dots".
    style (StyleType, optional): Style of spinner. Defaults to "progress.spinner".
    speed (float, optional): Speed factor of spinner. Defaults to 1.0.
    finished_text (TextType, optional): Text used when task is finished. Defaults to " "._

**Methods**: __init__, set_spinner, render


#### `TextColumn`
_A column containing text._

**Methods**: __init__, render


#### `BarColumn`
_Renders a visual progress bar.

Args:
    bar_width (Optional[int], optional): Width of bar or None for full width. Defaults to 40.
    style (StyleType, optional): Style for the bar background. Defaults to "bar.back".
    complete_style (StyleType, optional): Style for the completed bar. Defaults to "bar.complete".
    finished_style (StyleType, optional): Style for a finished bar. Defaults to "bar.finished".
    pulse_style (StyleType, optional): Style for pulsing bars. Defaults to "bar.pulse"._

**Methods**: __init__, render


#### `TimeElapsedColumn`
_Renders time elapsed._

**Methods**: render


#### `TaskProgressColumn`
_Show task progress as a percentage.

Args:
    text_format (str, optional): Format for percentage display. Defaults to "[progress.percentage]{task.percentage:>3.0f}%".
    text_format_no_percentage (str, optional): Format if percentage is unknown. Defaults to "".
    style (StyleType, optional): Style of output. Defaults to "none".
    justify (JustifyMethod, optional): Text justification. Defaults to "left".
    markup (bool, optional): Enable markup. Defaults to True.
    highlighter (Optional[Highlighter], optional): Highlighter to apply to output. Defaults to None.
    table_column (Optional[Column], optional): Table Column to use. Defaults to None.
    show_speed (bool, optional): Show speed if total is unknown. Defaults to False._

**Methods**: __init__, render_speed, render


#### `TimeRemainingColumn`
_Renders estimated time remaining.

Args:
    compact (bool, optional): Render MM:SS when time remaining is less than an hour. Defaults to False.
    elapsed_when_finished (bool, optional): Render time elapsed when the task is finished. Defaults to False._

**Methods**: __init__, render


#### `FileSizeColumn`
_Renders completed filesize._

**Methods**: render


#### `TotalFileSizeColumn`
_Renders total filesize._

**Methods**: render


#### `MofNCompleteColumn`
_Renders completed count/total, e.g. '  10/1000'.

Best for bounded tasks with int quantities.

Space pads the completed count so that progress length does not change as task progresses
past powers of 10.

Args:
    separator (str, optional): Text to separate completed and total values. Defaults to "/"._

**Methods**: __init__, render


#### `DownloadColumn`
_Renders file size downloaded and total, e.g. '0.5/2.3 GB'.

Args:
    binary_units (bool, optional): Use binary units, KiB, MiB etc. Defaults to False._

**Methods**: __init__, render


#### `TransferSpeedColumn`
_Renders human readable transfer speed._

**Methods**: render


#### `ProgressSample`
_Sample of progress for a given time._


#### `Task`
_Information regarding a progress task.

This object should be considered read-only outside of the :class:`~Progress` class._

**Methods**: get_time, started, remaining, elapsed, finished, percentage, speed, time_remaining, _reset


#### `Progress`
_Renders an auto-updating progress bar(s).

Args:
    console (Console, optional): Optional Console instance. Defaults to an internal Console instance writing to stdout.
    auto_refresh (bool, optional): Enable auto refresh. If disabled, you will need to call `refresh()`.
    refresh_per_second (Optional[float], optional): Number of times per second to refresh the progress information or None to use default (10). Defaults to None.
    speed_estimate_period: (float, optional): Period (in seconds) used to calculate the speed estimate. Defaults to 30.
    transient: (bool, optional): Clear the progress on exit. Defaults to False.
    redirect_stdout: (bool, optional): Enable redirection of stdout, so ``print`` may be used. Defaults to True.
    redirect_stderr: (bool, optional): Enable redirection of stderr. Defaults to True.
    get_time: (Callable, optional): A callable that gets the current time, or None to use Console.get_time. Defaults to None.
    disable (bool, optional): Disable progress display. Defaults to False
    expand (bool, optional): Expand tasks table to fit width. Defaults to False._

**Methods**: __init__, get_default_columns, console, tasks, task_ids, finished, start, stop, __enter__, __exit__, track, wrap_file, open, open, open, start_task, stop_task, update, reset, advance, refresh, get_renderable, get_renderables, make_tasks_table, __rich__, add_task, remove_task


### venv_new\Lib\site-packages\pip\_vendor\rich\progress_bar.py

#### `ProgressBar`
_Renders a (progress) bar. Used by rich.progress.

Args:
    total (float, optional): Number of steps in the bar. Defaults to 100. Set to None to render a pulsing animation.
    completed (float, optional): Number of steps completed. Defaults to 0.
    width (int, optional): Width of the bar, or ``None`` for maximum width. Defaults to None.
    pulse (bool, optional): Enable pulse effect. Defaults to False. Will pulse if a None total was passed.
    style (StyleType, optional): Style for the bar background. Defaults to "bar.back".
    complete_style (StyleType, optional): Style for the completed bar. Defaults to "bar.complete".
    finished_style (StyleType, optional): Style for a finished bar. Defaults to "bar.finished".
    pulse_style (StyleType, optional): Style for pulsing bars. Defaults to "bar.pulse".
    animation_time (Optional[float], optional): Time in seconds to use for animation, or None to use system time._

**Methods**: __init__, __repr__, percentage_completed, _get_pulse_segments, update, _render_pulse, __rich_console__, __rich_measure__


### venv_new\Lib\site-packages\pip\_vendor\rich\prompt.py

#### `PromptError`
_Exception base class for prompt related errors._


#### `InvalidResponse`
_Exception to indicate a response was invalid. Raise this within process_response() to indicate an error
and provide an error message.

Args:
    message (Union[str, Text]): Error message._

**Methods**: __init__, __rich__


#### `PromptBase`
_Ask the user for input until a valid response is received. This is the base class, see one of
the concrete classes for examples.

Args:
    prompt (TextType, optional): Prompt text. Defaults to "".
    console (Console, optional): A Console instance or None to use global console. Defaults to None.
    password (bool, optional): Enable password input. Defaults to False.
    choices (List[str], optional): A list of valid choices. Defaults to None.
    case_sensitive (bool, optional): Matching of choices should be case-sensitive. Defaults to True.
    show_default (bool, optional): Show default in prompt. Defaults to True.
    show_choices (bool, optional): Show choices in prompt. Defaults to True._

**Methods**: __init__, ask, ask, ask, render_default, make_prompt, get_input, check_choice, process_response, on_validate_error, pre_prompt, __call__, __call__, __call__


#### `Prompt`
_A prompt that returns a str.

Example:
    >>> name = Prompt.ask("Enter your name")_


#### `IntPrompt`
_A prompt that returns an integer.

Example:
    >>> burrito_count = IntPrompt.ask("How many burritos do you want to order")_


#### `FloatPrompt`
_A prompt that returns a float.

Example:
    >>> temperature = FloatPrompt.ask("Enter desired temperature")_


#### `Confirm`
_A yes / no confirmation prompt.

Example:
    >>> if Confirm.ask("Continue"):
            run_job()_

**Methods**: render_default, process_response


### venv_new\Lib\site-packages\pip\_vendor\rich\region.py

#### `Region`
_Defines a rectangular region of the screen._


### venv_new\Lib\site-packages\pip\_vendor\rich\repr.py

#### `ReprError`
_An error occurred when attempting to build a repr._


#### `Foo`
**Methods**: __rich_repr__


### venv_new\Lib\site-packages\pip\_vendor\rich\rule.py

#### `Rule`
_A console renderable to draw a horizontal rule (line).

Args:
    title (Union[str, Text], optional): Text to render in the rule. Defaults to "".
    characters (str, optional): Character(s) used to draw the line. Defaults to "‚îÄ".
    style (StyleType, optional): Style of Rule. Defaults to "rule.line".
    end (str, optional): Character at end of Rule. defaults to "\\n"
    align (str, optional): How to align the title, one of "left", "center", or "right". Defaults to "center"._

**Methods**: __init__, __repr__, __rich_console__, _rule_line, __rich_measure__


### venv_new\Lib\site-packages\pip\_vendor\rich\screen.py

#### `Screen`
_A renderable that fills the terminal screen and crops excess.

Args:
    renderable (RenderableType): Child renderable.
    style (StyleType, optional): Optional background style. Defaults to None._

**Methods**: __init__, __rich_console__


### venv_new\Lib\site-packages\pip\_vendor\rich\segment.py

#### `ControlType`
_Non-printable control codes which typically translate to ANSI codes._


#### `Segment`
_A piece of text with associated style. Segments are produced by the Console render process and
are ultimately converted in to strings to be written to the terminal.

Args:
    text (str): A piece of text.
    style (:class:`~rich.style.Style`, optional): An optional style to apply to the text.
    control (Tuple[ControlCode], optional): Optional sequence of control codes.

Attributes:
    cell_length (int): The cell length of this Segment._

**Methods**: cell_length, __rich_repr__, __bool__, is_control, _split_cells, split_cells, line, apply_style, filter_control, split_lines, split_and_crop_lines, adjust_line_length, get_line_length, get_shape, set_shape, align_top, align_bottom, align_middle, simplify, strip_links, strip_styles, remove_color, divide


#### `Segments`
_A simple renderable to render an iterable of segments. This class may be useful if
you want to print segments outside of a __rich_console__ method.

Args:
    segments (Iterable[Segment]): An iterable of segments.
    new_lines (bool, optional): Add new lines between segments. Defaults to False._

**Methods**: __init__, __rich_console__


#### `SegmentLines`
**Methods**: __init__, __rich_console__


### venv_new\Lib\site-packages\pip\_vendor\rich\spinner.py

#### `Spinner`
_A spinner animation.

Args:
    name (str): Name of spinner (run python -m rich.spinner).
    text (RenderableType, optional): A renderable to display at the right of the spinner (str or Text typically). Defaults to "".
    style (StyleType, optional): Style for spinner animation. Defaults to None.
    speed (float, optional): Speed factor for animation. Defaults to 1.0.

Raises:
    KeyError: If name isn't one of the supported spinner animations._

**Methods**: __init__, __rich_console__, __rich_measure__, render, update


### venv_new\Lib\site-packages\pip\_vendor\rich\status.py

#### `Status`
_Displays a status indicator with a 'spinner' animation.

Args:
    status (RenderableType): A status renderable (str or Text typically).
    console (Console, optional): Console instance to use, or None for global console. Defaults to None.
    spinner (str, optional): Name of spinner animation (see python -m rich.spinner). Defaults to "dots".
    spinner_style (StyleType, optional): Style of spinner. Defaults to "status.spinner".
    speed (float, optional): Speed factor for spinner animation. Defaults to 1.0.
    refresh_per_second (float, optional): Number of refreshes per second. Defaults to 12.5._

**Methods**: __init__, renderable, console, update, start, stop, __rich__, __enter__, __exit__


### venv_new\Lib\site-packages\pip\_vendor\rich\style.py

#### `_Bit`
_A descriptor to get/set a style attribute bit._

**Methods**: __init__, __get__


#### `Style`
_A terminal style.

A terminal style consists of a color (`color`), a background color (`bgcolor`), and a number of attributes, such
as bold, italic etc. The attributes have 3 states: they can either be on
(``True``), off (``False``), or not set (``None``).

Args:
    color (Union[Color, str], optional): Color of terminal text. Defaults to None.
    bgcolor (Union[Color, str], optional): Color of terminal background. Defaults to None.
    bold (bool, optional): Enable bold text. Defaults to None.
    dim (bool, optional): Enable dim text. Defaults to None.
    italic (bool, optional): Enable italic text. Defaults to None.
    underline (bool, optional): Enable underlined text. Defaults to None.
    blink (bool, optional): Enabled blinking text. Defaults to None.
    blink2 (bool, optional): Enable fast blinking text. Defaults to None.
    reverse (bool, optional): Enabled reverse text. Defaults to None.
    conceal (bool, optional): Enable concealed text. Defaults to None.
    strike (bool, optional): Enable strikethrough text. Defaults to None.
    underline2 (bool, optional): Enable doubly underlined text. Defaults to None.
    frame (bool, optional): Enable framed text. Defaults to None.
    encircle (bool, optional): Enable encircled text. Defaults to None.
    overline (bool, optional): Enable overlined text. Defaults to None.
    link (str, link): Link URL. Defaults to None._

**Methods**: __init__, null, from_color, from_meta, on, link_id, __str__, __bool__, _make_ansi_codes, normalize, pick_first, __rich_repr__, __eq__, __ne__, __hash__, color, bgcolor, link, transparent_background, background_style, meta, without_color, parse, get_html_style, combine, chain, copy, clear_meta_and_links, update_link, render, test, _add, __add__


#### `StyleStack`
_A stack of styles._

**Methods**: __init__, __repr__, current, push, pop


### venv_new\Lib\site-packages\pip\_vendor\rich\styled.py

#### `Styled`
_Apply a style to a renderable.

Args:
    renderable (RenderableType): Any renderable.
    style (StyleType): A style to apply across the entire renderable._

**Methods**: __init__, __rich_console__, __rich_measure__


### venv_new\Lib\site-packages\pip\_vendor\rich\syntax.py

#### `SyntaxTheme`
_Base class for a syntax theme._

**Methods**: get_style_for_token, get_background_style


#### `PygmentsSyntaxTheme`
_Syntax theme that delegates to Pygments theme._

**Methods**: __init__, get_style_for_token, get_background_style


#### `ANSISyntaxTheme`
_Syntax theme to use standard colors._

**Methods**: __init__, get_style_for_token, get_background_style


#### `_SyntaxHighlightRange`
_A range to highlight in a Syntax object.
`start` and `end` are 2-integers tuples, where the first integer is the line number
(starting from 1) and the second integer is the column index (starting from 0)._


#### `Syntax`
_Construct a Syntax object to render syntax highlighted code.

Args:
    code (str): Code to highlight.
    lexer (Lexer | str): Lexer to use (see https://pygments.org/docs/lexers/)
    theme (str, optional): Color theme, aka Pygments style (see https://pygments.org/docs/styles/#getting-a-list-of-available-styles). Defaults to "monokai".
    dedent (bool, optional): Enable stripping of initial whitespace. Defaults to False.
    line_numbers (bool, optional): Enable rendering of line numbers. Defaults to False.
    start_line (int, optional): Starting number for line numbers. Defaults to 1.
    line_range (Tuple[int | None, int | None], optional): If given should be a tuple of the start and end line to render.
        A value of None in the tuple indicates the range is open in that direction.
    highlight_lines (Set[int]): A set of line numbers to highlight.
    code_width: Width of code to render (not including line numbers), or ``None`` to use all available width.
    tab_size (int, optional): Size of tabs. Defaults to 4.
    word_wrap (bool, optional): Enable word wrapping.
    background_color (str, optional): Optional background color, or None to use theme color. Defaults to None.
    indent_guides (bool, optional): Show indent guides. Defaults to False.
    padding (PaddingDimensions): Padding to apply around the syntax. Defaults to 0 (no padding)._

**Methods**: get_theme, __init__, from_path, guess_lexer, _get_base_style, _get_token_color, lexer, default_lexer, highlight, stylize_range, _get_line_numbers_color, _numbers_column_width, _get_number_styles, __rich_measure__, __rich_console__, _get_syntax, _apply_stylized_ranges, _process_code


### venv_new\Lib\site-packages\pip\_vendor\rich\table.py

#### `Column`
_Defines a column within a ~Table.

Args:
    title (Union[str, Text], optional): The title of the table rendered at the top. Defaults to None.
    caption (Union[str, Text], optional): The table caption rendered below. Defaults to None.
    width (int, optional): The width in characters of the table, or ``None`` to automatically fit. Defaults to None.
    min_width (Optional[int], optional): The minimum width of the table, or ``None`` for no minimum. Defaults to None.
    box (box.Box, optional): One of the constants in box.py used to draw the edges (see :ref:`appendix_box`), or ``None`` for no box lines. Defaults to box.HEAVY_HEAD.
    safe_box (Optional[bool], optional): Disable box characters that don't display on windows legacy terminal with *raster* fonts. Defaults to True.
    padding (PaddingDimensions, optional): Padding for cells (top, right, bottom, left). Defaults to (0, 1).
    collapse_padding (bool, optional): Enable collapsing of padding around cells. Defaults to False.
    pad_edge (bool, optional): Enable padding of edge cells. Defaults to True.
    expand (bool, optional): Expand the table to fit the available space if ``True``, otherwise the table width will be auto-calculated. Defaults to False.
    show_header (bool, optional): Show a header row. Defaults to True.
    show_footer (bool, optional): Show a footer row. Defaults to False.
    show_edge (bool, optional): Draw a box around the outside of the table. Defaults to True.
    show_lines (bool, optional): Draw lines between every row. Defaults to False.
    leading (int, optional): Number of blank lines between rows (precludes ``show_lines``). Defaults to 0.
    style (Union[str, Style], optional): Default style for the table. Defaults to "none".
    row_styles (List[Union, str], optional): Optional list of row styles, if more than one style is given then the styles will alternate. Defaults to None.
    header_style (Union[str, Style], optional): Style of the header. Defaults to "table.header".
    footer_style (Union[str, Style], optional): Style of the footer. Defaults to "table.footer".
    border_style (Union[str, Style], optional): Style of the border. Defaults to None.
    title_style (Union[str, Style], optional): Style of the title. Defaults to None.
    caption_style (Union[str, Style], optional): Style of the caption. Defaults to None.
    title_justify (str, optional): Justify method for title. Defaults to "center".
    caption_justify (str, optional): Justify method for caption. Defaults to "center".
    highlight (bool, optional): Highlight cell contents (if str). Defaults to False._

**Methods**: copy, cells, flexible


#### `Row`
_Information regarding a row._


#### `_Cell`
_A single cell in a table._


#### `Table`
_A console renderable to draw a table.

Args:
    *headers (Union[Column, str]): Column headers, either as a string, or :class:`~rich.table.Column` instance.
    title (Union[str, Text], optional): The title of the table rendered at the top. Defaults to None.
    caption (Union[str, Text], optional): The table caption rendered below. Defaults to None.
    width (int, optional): The width in characters of the table, or ``None`` to automatically fit. Defaults to None.
    min_width (Optional[int], optional): The minimum width of the table, or ``None`` for no minimum. Defaults to None.
    box (box.Box, optional): One of the constants in box.py used to draw the edges (see :ref:`appendix_box`), or ``None`` for no box lines. Defaults to box.HEAVY_HEAD.
    safe_box (Optional[bool], optional): Disable box characters that don't display on windows legacy terminal with *raster* fonts. Defaults to True.
    padding (PaddingDimensions, optional): Padding for cells (top, right, bottom, left). Defaults to (0, 1).
    collapse_padding (bool, optional): Enable collapsing of padding around cells. Defaults to False.
    pad_edge (bool, optional): Enable padding of edge cells. Defaults to True.
    expand (bool, optional): Expand the table to fit the available space if ``True``, otherwise the table width will be auto-calculated. Defaults to False.
    show_header (bool, optional): Show a header row. Defaults to True.
    show_footer (bool, optional): Show a footer row. Defaults to False.
    show_edge (bool, optional): Draw a box around the outside of the table. Defaults to True.
    show_lines (bool, optional): Draw lines between every row. Defaults to False.
    leading (int, optional): Number of blank lines between rows (precludes ``show_lines``). Defaults to 0.
    style (Union[str, Style], optional): Default style for the table. Defaults to "none".
    row_styles (List[Union, str], optional): Optional list of row styles, if more than one style is given then the styles will alternate. Defaults to None.
    header_style (Union[str, Style], optional): Style of the header. Defaults to "table.header".
    footer_style (Union[str, Style], optional): Style of the footer. Defaults to "table.footer".
    border_style (Union[str, Style], optional): Style of the border. Defaults to None.
    title_style (Union[str, Style], optional): Style of the title. Defaults to None.
    caption_style (Union[str, Style], optional): Style of the caption. Defaults to None.
    title_justify (str, optional): Justify method for title. Defaults to "center".
    caption_justify (str, optional): Justify method for caption. Defaults to "center".
    highlight (bool, optional): Highlight cell contents (if str). Defaults to False._

**Methods**: __init__, grid, expand, expand, _extra_width, row_count, get_row_style, __rich_measure__, padding, padding, add_column, add_row, add_section, __rich_console__, _calculate_column_widths, _collapse_widths, _get_cells, _get_padding_width, _measure_column, _render


### venv_new\Lib\site-packages\pip\_vendor\rich\terminal_theme.py

#### `TerminalTheme`
_A color theme used when exporting console content.

Args:
    background (Tuple[int, int, int]): The background color.
    foreground (Tuple[int, int, int]): The foreground (text) color.
    normal (List[Tuple[int, int, int]]): A list of 8 normal intensity colors.
    bright (List[Tuple[int, int, int]], optional): A list of 8 bright colors, or None
        to repeat normal intensity. Defaults to None._

**Methods**: __init__


### venv_new\Lib\site-packages\pip\_vendor\rich\text.py

#### `Span`
_A marked up region in some text._

**Methods**: __repr__, __bool__, split, move, right_crop, extend


#### `Text`
_Text with color / style.

Args:
    text (str, optional): Default unstyled text. Defaults to "".
    style (Union[str, Style], optional): Base style for text. Defaults to "".
    justify (str, optional): Justify method: "left", "center", "full", "right". Defaults to None.
    overflow (str, optional): Overflow method: "crop", "fold", "ellipsis". Defaults to None.
    no_wrap (bool, optional): Disable text wrapping, or None for default. Defaults to None.
    end (str, optional): Character to end text with. Defaults to "\\n".
    tab_size (int): Number of spaces per tab, or ``None`` to use ``console.tab_size``. Defaults to None.
    spans (List[Span], optional). A list of predefined style spans. Defaults to None._

**Methods**: __init__, __len__, __bool__, __str__, __repr__, __add__, __eq__, __contains__, __getitem__, cell_len, markup, from_markup, from_ansi, styled, assemble, plain, plain, spans, spans, blank_copy, copy, stylize, stylize_before, apply_meta, on, remove_suffix, get_style_at_offset, extend_style, highlight_regex, highlight_words, rstrip, rstrip_end, set_length, __rich_console__, __rich_measure__, render, join, expand_tabs, truncate, _trim_spans, pad, pad_left, pad_right, align, append, append_text, append_tokens, copy_styles, split, divide, right_crop, wrap, fit, detect_indentation, with_indent_guides


### venv_new\Lib\site-packages\pip\_vendor\rich\theme.py

#### `Theme`
_A container for style information, used by :class:`~rich.console.Console`.

Args:
    styles (Dict[str, Style], optional): A mapping of style names on to styles. Defaults to None for a theme with no styles.
    inherit (bool, optional): Inherit default styles. Defaults to True._

**Methods**: __init__, config, from_file, read


#### `ThemeStackError`
_Base exception for errors related to the theme stack._


#### `ThemeStack`
_A stack of themes.

Args:
    theme (Theme): A theme instance_

**Methods**: __init__, push_theme, pop_theme


### venv_new\Lib\site-packages\pip\_vendor\rich\traceback.py

#### `Frame`

#### `_SyntaxError`

#### `Stack`

#### `Trace`

#### `PathHighlighter`

#### `Traceback`
_A Console renderable that renders a traceback.

Args:
    trace (Trace, optional): A `Trace` object produced from `extract`. Defaults to None, which uses
        the last exception.
    width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.
    code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.
    extra_lines (int, optional): Additional lines of code to render. Defaults to 3.
    theme (str, optional): Override pygments theme used in traceback.
    word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.
    show_locals (bool, optional): Enable display of local variables. Defaults to False.
    indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.
    locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
        Defaults to 10.
    locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.
    locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.
    locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.
    suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.
    max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100._

**Methods**: __init__, from_exception, extract, __rich_console__, _render_syntax_error, _guess_lexer, _render_stack


### venv_new\Lib\site-packages\pip\_vendor\rich\tree.py

#### `Tree`
_A renderable for a tree structure.

Attributes:
    ASCII_GUIDES (GuideType): Guide lines used when Console.ascii_only is True.
    TREE_GUIDES (List[GuideType, GuideType, GuideType]): Default guide lines.

Args:
    label (RenderableType): The renderable or str for the tree label.
    style (StyleType, optional): Style of this tree. Defaults to "tree".
    guide_style (StyleType, optional): Style of the guide lines. Defaults to "tree.line".
    expanded (bool, optional): Also display children. Defaults to True.
    highlight (bool, optional): Highlight renderable (if str). Defaults to False.
    hide_root (bool, optional): Hide the root node. Defaults to False._

**Methods**: __init__, add, __rich_console__, __rich_measure__


### venv_new\Lib\site-packages\pip\_vendor\tomli\_parser.py

#### `DEPRECATED_DEFAULT`
_Sentinel to be used as default arg during deprecation
period of TOMLDecodeError's free-form arguments._


#### `TOMLDecodeError`
_An error raised if a document is not valid TOML.

Adds the following attributes to ValueError:
msg: The unformatted error message
doc: The TOML document being parsed
pos: The index of doc where parsing failed
lineno: The line corresponding to pos
colno: The column corresponding to pos_

**Methods**: __init__


#### `Flags`
_Flags that map to parsed keys/namespaces._

**Methods**: __init__, add_pending, finalize_pending, unset_all, set, is_


#### `NestedDict`
**Methods**: __init__, get_or_create_nest, append_nest_to_list


#### `Output`

### venv_new\Lib\site-packages\pip\_vendor\truststore\_api.py

#### `SSLContext`
_SSLContext API that uses system certificates on all platforms_

**Methods**: __class__, __init__, wrap_socket, wrap_bio, load_verify_locations, load_cert_chain, load_default_certs, set_alpn_protocols, set_npn_protocols, set_ciphers, get_ciphers, session_stats, cert_store_stats, set_default_verify_paths, get_ca_certs, get_ca_certs, get_ca_certs, get_ca_certs, check_hostname, check_hostname, hostname_checks_common_name, hostname_checks_common_name, keylog_filename, keylog_filename, maximum_version, maximum_version, minimum_version, minimum_version, options, options, post_handshake_auth, post_handshake_auth, protocol, security_level, verify_flags, verify_flags, verify_mode, verify_mode


#### `TruststoreSSLObject`
**Methods**: do_handshake


### venv_new\Lib\site-packages\pip\_vendor\truststore\_macos.py

#### `CFConst`
_CoreFoundation constants_


### venv_new\Lib\site-packages\pip\_vendor\truststore\_windows.py

#### `CERT_CONTEXT`

#### `CERT_ENHKEY_USAGE`

#### `CERT_USAGE_MATCH`

#### `CERT_CHAIN_PARA`

#### `CERT_TRUST_STATUS`

#### `CERT_CHAIN_ELEMENT`

#### `CERT_SIMPLE_CHAIN`

#### `CERT_CHAIN_CONTEXT`

#### `SSL_EXTRA_CERT_CHAIN_POLICY_PARA`

#### `CERT_CHAIN_POLICY_PARA`

#### `CERT_CHAIN_POLICY_STATUS`

#### `CERT_CHAIN_ENGINE_CONFIG`

### venv_new\Lib\site-packages\pip\_vendor\typing_extensions.py

#### `_Sentinel`
**Methods**: __repr__


#### `_AnyMeta`
**Methods**: __instancecheck__, __repr__


#### `Any`
_Special type indicating an unconstrained type.
- Any is compatible with every type.
- Any assumed to have all methods.
- All values assumed to be instances of Any.
Note that all the above statements are true from the point of view of
static type checkers. At runtime, Any should not be used with instance
checks._

**Methods**: __new__


#### `_ExtensionsSpecialForm`
**Methods**: __repr__


#### `_LiteralGenericAlias`
**Methods**: __eq__, __hash__


#### `_LiteralForm`
**Methods**: __init__, __getitem__


#### `_SpecialGenericAlias`
**Methods**: __init__, __setattr__, __getitem__


#### `_ProtocolMeta`
**Methods**: __new__, __init__, __subclasscheck__, __instancecheck__, __eq__, __hash__


#### `Protocol`
**Methods**: __init_subclass__


#### `SupportsInt`
_An ABC with one abstract method __int__._

**Methods**: __int__


#### `SupportsFloat`
_An ABC with one abstract method __float__._

**Methods**: __float__


#### `SupportsComplex`
_An ABC with one abstract method __complex__._

**Methods**: __complex__


#### `SupportsBytes`
_An ABC with one abstract method __bytes__._

**Methods**: __bytes__


#### `SupportsIndex`
**Methods**: __index__


#### `SupportsAbs`
_An ABC with one abstract method __abs__ that is covariant in its return type._

**Methods**: __abs__


#### `SupportsRound`
_An ABC with one abstract method __round__ that is covariant in its return type._

**Methods**: __round__


#### `_TypedDictMeta`
**Methods**: __new__, __subclasscheck__


#### `_AnnotatedAlias`
_Runtime representation of an annotated type.

At its core 'Annotated[t, dec1, dec2, ...]' is an alias for the type 't'
with extra annotations. The alias behaves like a normal typing alias,
instantiating is the same as instantiating the underlying type, binding
it to types is also the same._

**Methods**: __init__, copy_with, __repr__, __reduce__, __eq__, __hash__


#### `Annotated`
_Add context specific metadata to a type.

Example: Annotated[int, runtime_check.Unsigned] indicates to the
hypothetical runtime_check module that this type is an unsigned int.
Every other consumer of this type can ignore this metadata and treat
this type as int.

The first argument to Annotated must be a valid type (and will be in
the __origin__ field), the remaining arguments are kept as a tuple in
the __extra__ field.

Details:

- It's an error to call `Annotated` with less than two arguments.
- Nested Annotated are flattened::

    Annotated[Annotated[T, Ann1, Ann2], Ann3] == Annotated[T, Ann1, Ann2, Ann3]

- Instantiating an annotated type is equivalent to instantiating the
underlying type::

    Annotated[C, Ann1](5) == C(5)

- Annotated can be used as a generic type alias::

    Optimized = Annotated[T, runtime.Optimize()]
    Optimized[int] == Annotated[int, runtime.Optimize()]

    OptimizedList = Annotated[List[T], runtime.Optimize()]
    OptimizedList[int] == Annotated[List[int], runtime.Optimize()]_

**Methods**: __new__, __class_getitem__, __init_subclass__


#### `NoDefaultTypeMeta`
**Methods**: __setattr__


#### `NoDefaultType`
_The type of the NoDefault singleton._

**Methods**: __new__, __repr__, __reduce__


#### `_DefaultMixin`
_Mixin for TypeVarLike defaults._


#### `_TypeVarLikeMeta`
**Methods**: __instancecheck__


#### `TypeVar`
_Type variable._

**Methods**: __new__, __init_subclass__


#### `_Immutable`
_Mixin to indicate that object should not be copied._

**Methods**: __copy__, __deepcopy__


#### `ParamSpecArgs`
_The args for a ParamSpec object.

Given a ParamSpec object P, P.args is an instance of ParamSpecArgs.

ParamSpecArgs objects have a reference back to their ParamSpec:

P.args.__origin__ is P

This type is meant for runtime introspection and has no special meaning to
static type checkers._

**Methods**: __init__, __repr__, __eq__


#### `ParamSpecKwargs`
_The kwargs for a ParamSpec object.

Given a ParamSpec object P, P.kwargs is an instance of ParamSpecKwargs.

ParamSpecKwargs objects have a reference back to their ParamSpec:

P.kwargs.__origin__ is P

This type is meant for runtime introspection and has no special meaning to
static type checkers._

**Methods**: __init__, __repr__, __eq__


#### `ParamSpec`
_Parameter specification._

**Methods**: __new__, __init_subclass__


#### `ParamSpec`
_Parameter specification variable.

Usage::

   P = ParamSpec('P')

Parameter specification variables exist primarily for the benefit of static
type checkers.  They are used to forward the parameter types of one
callable to another callable, a pattern commonly found in higher order
functions and decorators.  They are only valid when used in ``Concatenate``,
or s the first argument to ``Callable``. In Python 3.10 and higher,
they are also supported in user-defined Generics at runtime.
See class Generic for more information on generic types.  An
example for annotating a decorator::

   T = TypeVar('T')
   P = ParamSpec('P')

   def add_logging(f: Callable[P, T]) -> Callable[P, T]:
       '''A type-safe decorator to add logging to a function.'''
       def inner(*args: P.args, **kwargs: P.kwargs) -> T:
           logging.info(f'{f.__name__} was called')
           return f(*args, **kwargs)
       return inner

   @add_logging
   def add_two(x: float, y: float) -> float:
       '''Add two numbers together.'''
       return x + y

Parameter specification variables defined with covariant=True or
contravariant=True can be used to declare covariant or contravariant
generic types.  These keyword arguments are valid, but their actual semantics
are yet to be decided.  See PEP 612 for details.

Parameter specification variables can be introspected. e.g.:

   P.__name__ == 'T'
   P.__bound__ == None
   P.__covariant__ == False
   P.__contravariant__ == False

Note that only parameter specification variables defined in global scope can
be pickled._

**Methods**: args, kwargs, __init__, __repr__, __hash__, __eq__, __reduce__, __call__


#### `_ConcatenateGenericAlias`
**Methods**: __init__, __repr__, __hash__, __call__, __parameters__


#### `_ConcatenateForm`
**Methods**: __getitem__


#### `_TypeGuardForm`
**Methods**: __getitem__


#### `_TypeIsForm`
**Methods**: __getitem__


#### `_SpecialForm`
**Methods**: __init__, __getattr__, __mro_entries__, __repr__, __reduce__, __call__, __or__, __ror__, __instancecheck__, __subclasscheck__, __getitem__


#### `_RequiredForm`
**Methods**: __getitem__


#### `_ReadOnlyForm`
**Methods**: __getitem__


#### `_UnpackSpecialForm`
**Methods**: __init__


#### `_UnpackAlias`
**Methods**: __typing_unpacked_tuple_args__


#### `_UnpackAlias`

#### `_UnpackForm`
**Methods**: __getitem__


#### `TypeVarTuple`
_Type variable tuple._

**Methods**: __new__, __init_subclass__


#### `TypeVarTuple`
_Type variable tuple.

Usage::

    Ts = TypeVarTuple('Ts')

In the same way that a normal type variable is a stand-in for a single
type such as ``int``, a type variable *tuple* is a stand-in for a *tuple*
type such as ``Tuple[int, str]``.

Type variable tuples can be used in ``Generic`` declarations.
Consider the following example::

    class Array(Generic[*Ts]): ...

The ``Ts`` type variable tuple here behaves like ``tuple[T1, T2]``,
where ``T1`` and ``T2`` are type variables. To use these type variables
as type parameters of ``Array``, we must *unpack* the type variable tuple using
the star operator: ``*Ts``. The signature of ``Array`` then behaves
as if we had simply written ``class Array(Generic[T1, T2]): ...``.
In contrast to ``Generic[T1, T2]``, however, ``Generic[*Shape]`` allows
us to parameterise the class with an *arbitrary* number of type parameters.

Type variable tuples can be used anywhere a normal ``TypeVar`` can.
This includes class definitions, as shown above, as well as function
signatures and variable annotations::

    class Array(Generic[*Ts]):

        def __init__(self, shape: Tuple[*Ts]):
            self._shape: Tuple[*Ts] = shape

        def get_shape(self) -> Tuple[*Ts]:
            return self._shape

    shape = (Height(480), Width(640))
    x: Array[Height, Width] = Array(shape)
    y = abs(x)  # Inferred type is Array[Height, Width]
    z = x + x   #        ...    is Array[Height, Width]
    x.get_shape()  #     ...    is tuple[Height, Width]_

**Methods**: __iter__, __init__, __repr__, __hash__, __eq__, __reduce__, __init_subclass__


#### `deprecated`
_Indicate that a class, function or overload is deprecated.

When this decorator is applied to an object, the type checker
will generate a diagnostic on usage of the deprecated object.

Usage:

    @deprecated("Use B instead")
    class A:
        pass

    @deprecated("Use g instead")
    def f():
        pass

    @overload
    @deprecated("int support is deprecated")
    def g(x: int) -> int: ...
    @overload
    def g(x: str) -> int: ...

The warning specified by *category* will be emitted at runtime
on use of deprecated objects. For functions, that happens on calls;
for classes, on instantiation and on creation of subclasses.
If the *category* is ``None``, no warning is emitted at runtime.
The *stacklevel* determines where the
warning is emitted. If it is ``1`` (the default), the warning
is emitted at the direct caller of the deprecated object; if it
is higher, it is emitted further up the stack.
Static type checker behavior is not affected by the *category*
and *stacklevel* arguments.

The deprecation message passed to the decorator is saved in the
``__deprecated__`` attribute on the decorated object.
If applied to an overload, the decorator
must be after the ``@overload`` decorator for the attribute to
exist on the overload as returned by ``get_overloads()``.

See PEP 702 for details._

**Methods**: __init__, __call__


#### `_NamedTupleMeta`
**Methods**: __new__


#### `Buffer`
_Base class for classes that implement the buffer protocol.

The buffer protocol allows Python objects to expose a low-level
memory buffer interface. Before Python 3.12, it is not possible
to implement the buffer protocol in pure Python code, or even
to check whether a class implements the buffer protocol. In
Python 3.12 and higher, the ``__buffer__`` method allows access
to the buffer protocol from Python code, and the
``collections.abc.Buffer`` ABC allows checking whether a class
implements the buffer protocol.

To indicate support for the buffer protocol in earlier versions,
inherit from this ABC, either in a stub file or at runtime,
or use ABC registration. This ABC provides no methods, because
there is no Python-accessible methods shared by pre-3.12 buffer
classes. It is useful primarily for static checks._


#### `NewType`
_NewType creates simple unique types with almost zero
runtime overhead. NewType(name, tp) is considered a subtype of tp
by static type checkers. At runtime, NewType(name, tp) returns
a dummy callable that simply returns its argument. Usage::
    UserId = NewType('UserId', int)
    def name_by_id(user_id: UserId) -> str:
        ...
    UserId('user')          # Fails type check
    name_by_id(42)          # Fails type check
    name_by_id(UserId(42))  # OK
    num = UserId(5) + 1     # type: int_

**Methods**: __call__, __init__, __mro_entries__, __repr__, __reduce__


#### `Dummy`
**Methods**: __init_subclass__


#### `TypeAliasType`
_Create named, parameterized type aliases.

This provides a backport of the new `type` statement in Python 3.12:

    type ListOrSet[T] = list[T] | set[T]

is equivalent to:

    T = TypeVar("T")
    ListOrSet = TypeAliasType("ListOrSet", list[T] | set[T], type_params=(T,))

The name ListOrSet can then be used as an alias for the type it refers to.

The type_params argument should contain all the type parameters used
in the value of the type alias. If the alias is not generic, this
argument is omitted.

Static type checkers should only support type aliases declared using
TypeAliasType that follow these rules:

- The first argument (the name) must be a string literal.
- The TypeAliasType instance must be immediately assigned to a variable
  of the same name. (For example, 'X = TypeAliasType("Y", int)' is invalid,
  as is 'X, Y = TypeAliasType("X", int), TypeAliasType("Y", int)')._

**Methods**: __init__, __setattr__, __delattr__, _raise_attribute_error, __repr__, __getitem__, __reduce__, __init_subclass__, __call__


#### `Doc`
_Define the documentation of a type annotation using ``Annotated``, to be
 used in class attributes, function and method parameters, return values,
 and variables.

The value should be a positional-only string literal to allow static tools
like editors and documentation generators to use it.

This complements docstrings.

The string value passed is available in the attribute ``documentation``.

Example::

    >>> from typing_extensions import Annotated, Doc
    >>> def hi(to: Annotated[str, Doc("Who to say hi to")]) -> None: ..._

**Methods**: __init__, __repr__, __hash__, __eq__


### venv_new\Lib\site-packages\pip\_vendor\urllib3\_collections.py

#### `RLock`
**Methods**: __enter__, __exit__


#### `RecentlyUsedContainer`
_Provides a thread-safe dict-like container which maintains up to
``maxsize`` keys while throwing away the least-recently-used keys beyond
``maxsize``.

:param maxsize:
    Maximum number of recent elements to retain.

:param dispose_func:
    Every time an item is evicted from the container,
    ``dispose_func(value)`` is called.  Callback which will get called_

**Methods**: __init__, __getitem__, __setitem__, __delitem__, __len__, __iter__, clear, keys


#### `HTTPHeaderDict`
_:param headers:
    An iterable of field-value pairs. Must not contain multiple field names
    when compared case-insensitively.

:param kwargs:
    Additional field-value pairs to pass in to ``dict.update``.

A ``dict`` like container for storing HTTP Headers.

Field names are stored and compared case-insensitively in compliance with
RFC 7230. Iteration provides the first case-sensitive key seen for each
case-insensitive pair.

Using ``__setitem__`` syntax overwrites fields that compare equal
case-insensitively in order to maintain ``dict``'s api. For fields that
compare equal, instead create a new ``HTTPHeaderDict`` and use ``.add``
in a loop.

If multiple fields that are equal case-insensitively are passed to the
constructor or ``.update``, the behavior is undefined and some will be
lost.

>>> headers = HTTPHeaderDict()
>>> headers.add('Set-Cookie', 'foo=bar')
>>> headers.add('set-cookie', 'baz=quxx')
>>> headers['content-length'] = '7'
>>> headers['SET-cookie']
'foo=bar, baz=quxx'
>>> headers['Content-Length']
'7'_

**Methods**: __init__, __setitem__, __getitem__, __delitem__, __contains__, __eq__, __ne__, __len__, __iter__, pop, discard, add, extend, getlist, _prepare_for_method_change, __repr__, _copy_from, copy, iteritems, itermerged, items, from_httplib


### venv_new\Lib\site-packages\pip\_vendor\urllib3\connection.py

#### `BaseSSLError`

#### `ConnectionError`

#### `BrokenPipeError`

#### `HTTPConnection`
_Based on :class:`http.client.HTTPConnection` but provides an extra constructor
backwards-compatibility layer between older and newer Pythons.

Additional keyword parameters are used to configure attributes of the connection.
Accepted parameters include:

- ``strict``: See the documentation on :class:`urllib3.connectionpool.HTTPConnectionPool`
- ``source_address``: Set the source address for the current connection.
- ``socket_options``: Set specific options on the underlying socket. If not specified, then
  defaults are loaded from ``HTTPConnection.default_socket_options`` which includes disabling
  Nagle's algorithm (sets TCP_NODELAY to 1) unless the connection is behind a proxy.

  For example, if you wish to enable TCP Keep Alive in addition to the defaults,
  you might pass:

  .. code-block:: python

     HTTPConnection.default_socket_options + [
         (socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1),
     ]

  Or you may want to disable the defaults by passing an empty list (e.g., ``[]``)._

**Methods**: __init__, host, host, _new_conn, _is_using_tunnel, _prepare_conn, connect, putrequest, putheader, request, request_chunked


#### `HTTPSConnection`
_Many of the parameters to this constructor are passed to the underlying SSL
socket by means of :py:func:`urllib3.util.ssl_wrap_socket`._

**Methods**: __init__, set_cert, connect, _connect_tls_proxy


#### `DummyConnection`
_Used to detect a failed ConnectionCls import._


### venv_new\Lib\site-packages\pip\_vendor\urllib3\connectionpool.py

#### `ConnectionPool`
_Base class for all connection pools, such as
:class:`.HTTPConnectionPool` and :class:`.HTTPSConnectionPool`.

.. note::
   ConnectionPool.urlopen() does not normalize or percent-encode target URIs
   which is useful if your target server doesn't support percent-encoded
   target URIs._

**Methods**: __init__, __str__, __enter__, __exit__, close


#### `HTTPConnectionPool`
_Thread-safe connection pool for one host.

:param host:
    Host used for this HTTP Connection (e.g. "localhost"), passed into
    :class:`http.client.HTTPConnection`.

:param port:
    Port used for this HTTP Connection (None is equivalent to 80), passed
    into :class:`http.client.HTTPConnection`.

:param strict:
    Causes BadStatusLine to be raised if the status line can't be parsed
    as a valid HTTP/1.0 or 1.1 status line, passed into
    :class:`http.client.HTTPConnection`.

    .. note::
       Only works in Python 2. This parameter is ignored in Python 3.

:param timeout:
    Socket timeout in seconds for each individual connection. This can
    be a float or integer, which sets the timeout for the HTTP request,
    or an instance of :class:`urllib3.util.Timeout` which gives you more
    fine-grained control over request timeouts. After the constructor has
    been parsed, this is always a `urllib3.util.Timeout` object.

:param maxsize:
    Number of connections to save that can be reused. More than 1 is useful
    in multithreaded situations. If ``block`` is set to False, more
    connections will be created but they will not be saved once they've
    been used.

:param block:
    If set to True, no more than ``maxsize`` connections will be used at
    a time. When no free connections are available, the call will block
    until a connection has been released. This is a useful side effect for
    particular multithreaded situations where one does not want to use more
    than maxsize connections per host to prevent flooding.

:param headers:
    Headers to include with all requests, unless other headers are given
    explicitly.

:param retries:
    Retry configuration to use by default with requests in this pool.

:param _proxy:
    Parsed proxy URL, should not be used directly, instead, see
    :class:`urllib3.ProxyManager`

:param _proxy_headers:
    A dictionary with proxy headers, should not be used directly,
    instead, see :class:`urllib3.ProxyManager`

:param \**conn_kw:
    Additional parameters are used to create fresh :class:`urllib3.connection.HTTPConnection`,
    :class:`urllib3.connection.HTTPSConnection` instances._

**Methods**: __init__, _new_conn, _get_conn, _put_conn, _validate_conn, _prepare_proxy, _get_timeout, _raise_timeout, _make_request, _absolute_url, close, is_same_host, urlopen


#### `HTTPSConnectionPool`
_Same as :class:`.HTTPConnectionPool`, but HTTPS.

:class:`.HTTPSConnection` uses one of ``assert_fingerprint``,
``assert_hostname`` and ``host`` in this order to verify connections.
If ``assert_hostname`` is False, no verification is done.

The ``key_file``, ``cert_file``, ``cert_reqs``, ``ca_certs``,
``ca_cert_dir``, ``ssl_version``, ``key_password`` are only used if :mod:`ssl`
is available and are fed into :meth:`urllib3.util.ssl_wrap_socket` to upgrade
the connection socket into an SSL socket._

**Methods**: __init__, _prepare_conn, _prepare_proxy, _new_conn, _validate_conn


### venv_new\Lib\site-packages\pip\_vendor\urllib3\contrib\_securetransport\bindings.py

#### `CFConst`
_A class object that acts as essentially a namespace for CoreFoundation
constants._


#### `SecurityConst`
_A class object that acts as essentially a namespace for Security constants._


### venv_new\Lib\site-packages\pip\_vendor\urllib3\contrib\appengine.py

#### `AppEnginePlatformWarning`

#### `AppEnginePlatformError`

#### `AppEngineManager`
_Connection manager for Google App Engine sandbox applications.

This manager uses the URLFetch service directly instead of using the
emulated httplib, and is subject to URLFetch limitations as described in
the App Engine documentation `here
<https://cloud.google.com/appengine/docs/python/urlfetch>`_.

Notably it will raise an :class:`AppEnginePlatformError` if:
    * URLFetch is not available.
    * If you attempt to use this on App Engine Flexible, as full socket
      support is available.
    * If a request size is more than 10 megabytes.
    * If a response size is more than 32 megabytes.
    * If you use an unsupported request method such as OPTIONS.

Beyond those cases, it will raise normal urllib3 errors._

**Methods**: __init__, __enter__, __exit__, urlopen, _urlfetch_response_to_http_response, _get_absolute_timeout, _get_retries


### venv_new\Lib\site-packages\pip\_vendor\urllib3\contrib\ntlmpool.py

#### `NTLMConnectionPool`
_Implements an NTLM authentication version of an urllib3 connection pool_

**Methods**: __init__, _new_conn, urlopen


### venv_new\Lib\site-packages\pip\_vendor\urllib3\contrib\pyopenssl.py

#### `UnsupportedExtension`

#### `WrappedSocket`
_API-compatibility wrapper for Python OpenSSL's Connection-class.

Note: _makefile_refs, _drop() and _reuse() are needed for the garbage
collector of pypy._

**Methods**: __init__, fileno, _decref_socketios, recv, recv_into, settimeout, _send_until_done, sendall, shutdown, close, getpeercert, version, _reuse, _drop


#### `PyOpenSSLContext`
_I am a wrapper class for the PyOpenSSL ``Context`` object. I am responsible
for translating the interface of the standard library ``SSLContext`` object
to calls into PyOpenSSL._

**Methods**: __init__, options, options, verify_mode, verify_mode, set_default_verify_paths, set_ciphers, load_verify_locations, load_cert_chain, set_alpn_protocols, wrap_socket


### venv_new\Lib\site-packages\pip\_vendor\urllib3\contrib\securetransport.py

#### `WrappedSocket`
_API-compatibility wrapper for Python's OpenSSL wrapped socket object.

Note: _makefile_refs, _drop(), and _reuse() are needed for the garbage
collector of PyPy._

**Methods**: __init__, _raise_on_error, _set_ciphers, _set_alpn_protocols, _custom_validate, _evaluate_trust, handshake, fileno, _decref_socketios, recv, recv_into, settimeout, gettimeout, send, sendall, shutdown, close, getpeercert, version, _reuse, _drop


#### `SecureTransportContext`
_I am a wrapper class for the SecureTransport library, to translate the
interface of the standard library ``SSLContext`` object to calls into
SecureTransport._

**Methods**: __init__, check_hostname, check_hostname, options, options, verify_mode, verify_mode, set_default_verify_paths, load_default_certs, set_ciphers, load_verify_locations, load_cert_chain, set_alpn_protocols, wrap_socket


### venv_new\Lib\site-packages\pip\_vendor\urllib3\contrib\socks.py

#### `SOCKSConnection`
_A plain-text HTTP connection that connects via a SOCKS proxy._

**Methods**: __init__, _new_conn


#### `SOCKSHTTPSConnection`

#### `SOCKSHTTPConnectionPool`

#### `SOCKSHTTPSConnectionPool`

#### `SOCKSProxyManager`
_A version of the urllib3 ProxyManager that routes connections via the
defined SOCKS proxy._

**Methods**: __init__


### venv_new\Lib\site-packages\pip\_vendor\urllib3\exceptions.py

#### `HTTPError`
_Base exception used by this module._


#### `HTTPWarning`
_Base warning used by this module._


#### `PoolError`
_Base exception for errors caused within a pool._

**Methods**: __init__, __reduce__


#### `RequestError`
_Base exception for PoolErrors that have associated URLs._

**Methods**: __init__, __reduce__


#### `SSLError`
_Raised when SSL certificate fails in an HTTPS connection._


#### `ProxyError`
_Raised when the connection to a proxy fails._

**Methods**: __init__


#### `DecodeError`
_Raised when automatic decoding based on Content-Type fails._


#### `ProtocolError`
_Raised when something unexpected happens mid-request/response._


#### `MaxRetryError`
_Raised when the maximum number of retries is exceeded.

:param pool: The connection pool
:type pool: :class:`~urllib3.connectionpool.HTTPConnectionPool`
:param string url: The requested Url
:param exceptions.Exception reason: The underlying error_

**Methods**: __init__


#### `HostChangedError`
_Raised when an existing pool gets a request for a foreign host._

**Methods**: __init__


#### `TimeoutStateError`
_Raised when passing an invalid state to a timeout_


#### `TimeoutError`
_Raised when a socket timeout error occurs.

Catching this error will catch both :exc:`ReadTimeoutErrors
<ReadTimeoutError>` and :exc:`ConnectTimeoutErrors <ConnectTimeoutError>`._


#### `ReadTimeoutError`
_Raised when a socket timeout occurs while receiving data from a server_


#### `ConnectTimeoutError`
_Raised when a socket timeout occurs while connecting to a server_


#### `NewConnectionError`
_Raised when we fail to establish a new connection. Usually ECONNREFUSED._


#### `EmptyPoolError`
_Raised when a pool runs out of connections and no more are allowed._


#### `ClosedPoolError`
_Raised when a request enters a pool after the pool has been closed._


#### `LocationValueError`
_Raised when there is something wrong with a given URL input._


#### `LocationParseError`
_Raised when get_host or similar fails to parse the URL input._

**Methods**: __init__


#### `URLSchemeUnknown`
_Raised when a URL input has an unsupported scheme._

**Methods**: __init__


#### `ResponseError`
_Used as a container for an error reason supplied in a MaxRetryError._


#### `SecurityWarning`
_Warned when performing security reducing actions_


#### `SubjectAltNameWarning`
_Warned when connecting to a host with a certificate missing a SAN._


#### `InsecureRequestWarning`
_Warned when making an unverified HTTPS request._


#### `SystemTimeWarning`
_Warned when system time is suspected to be wrong_


#### `InsecurePlatformWarning`
_Warned when certain TLS/SSL configuration is not available on a platform._


#### `SNIMissingWarning`
_Warned when making a HTTPS request without SNI available._


#### `DependencyWarning`
_Warned when an attempt is made to import a module with missing optional
dependencies._


#### `ResponseNotChunked`
_Response needs to be chunked in order to read it as chunks._


#### `BodyNotHttplibCompatible`
_Body should be :class:`http.client.HTTPResponse` like
(have an fp attribute which returns raw chunks) for read_chunked()._


#### `IncompleteRead`
_Response length doesn't match expected Content-Length

Subclass of :class:`http.client.IncompleteRead` to allow int value
for ``partial`` to avoid creating large objects on streamed reads._

**Methods**: __init__, __repr__


#### `InvalidChunkLength`
_Invalid chunk length in a chunked response._

**Methods**: __init__, __repr__


#### `InvalidHeader`
_The header provided was somehow invalid._


#### `ProxySchemeUnknown`
_ProxyManager does not support the supplied scheme_

**Methods**: __init__


#### `ProxySchemeUnsupported`
_Fetching HTTPS resources through HTTPS proxies is unsupported_


#### `HeaderParsingError`
_Raised by assert_header_parsing, but we convert it to a log.warning statement._

**Methods**: __init__


#### `UnrewindableBodyError`
_urllib3 encountered an error when trying to rewind a body_


### venv_new\Lib\site-packages\pip\_vendor\urllib3\fields.py

#### `RequestField`
_A data container for request body parameters.

:param name:
    The name of this request field. Must be unicode.
:param data:
    The data/value body.
:param filename:
    An optional filename of the request field. Must be unicode.
:param headers:
    An optional dict-like object of headers to initially use for the field.
:param header_formatter:
    An optional callable that is used to encode and format the headers. By
    default, this is :func:`format_header_param_html5`._

**Methods**: __init__, from_tuples, _render_part, _render_parts, render_headers, make_multipart


### venv_new\Lib\site-packages\pip\_vendor\urllib3\packages\backports\weakref_finalize.py

#### `weakref_finalize`
_Class for finalization of weakrefable objects
finalize(obj, func, *args, **kwargs) returns a callable finalizer
object which will be called when obj is garbage collected. The
first time the finalizer is called it evaluates func(*arg, **kwargs)
and returns the result. After this the finalizer is dead, and
calling it just returns None.
When the program exits any remaining finalizers for which the
atexit attribute is true will be run in reverse order of creation.
By default atexit is true._

**Methods**: __init__, __call__, detach, peek, alive, atexit, atexit, __repr__, _select_for_exit, _exitfunc


#### `_Info`

### venv_new\Lib\site-packages\pip\_vendor\urllib3\packages\six.py

#### `X`
**Methods**: __len__


#### `_LazyDescr`
**Methods**: __init__, __get__


#### `MovedModule`
**Methods**: __init__, _resolve, __getattr__


#### `_LazyModule`
**Methods**: __init__, __dir__


#### `MovedAttribute`
**Methods**: __init__, _resolve


#### `_SixMetaPathImporter`
_A meta path importer to import six.moves and its submodules.

This class implements a PEP302 finder and loader. It should be compatible
with Python 2.5 and all existing versions of Python3_

**Methods**: __init__, _add_module, _get_module, find_module, find_spec, __get_module, load_module, is_package, get_code, create_module, exec_module


#### `_MovedItems`
_Lazy loading of moved objects_


#### `Module_six_moves_urllib_parse`
_Lazy loading of moved objects in six.moves.urllib_parse_


#### `Module_six_moves_urllib_error`
_Lazy loading of moved objects in six.moves.urllib_error_


#### `Module_six_moves_urllib_request`
_Lazy loading of moved objects in six.moves.urllib_request_


#### `Module_six_moves_urllib_response`
_Lazy loading of moved objects in six.moves.urllib_response_


#### `Module_six_moves_urllib_robotparser`
_Lazy loading of moved objects in six.moves.urllib_robotparser_


#### `Module_six_moves_urllib`
_Create a six.moves.urllib namespace that resembles the Python 3 namespace_

**Methods**: __dir__


#### `Iterator`
**Methods**: next


#### `metaclass`
**Methods**: __new__, __prepare__


### venv_new\Lib\site-packages\pip\_vendor\urllib3\poolmanager.py

#### `PoolManager`
_Allows for arbitrary requests while transparently keeping track of
necessary connection pools for you.

:param num_pools:
    Number of connection pools to cache before discarding the least
    recently used pool.

:param headers:
    Headers to include with all requests, unless other headers are given
    explicitly.

:param \**connection_pool_kw:
    Additional parameters are used to create fresh
    :class:`urllib3.connectionpool.ConnectionPool` instances.

Example::

    >>> manager = PoolManager(num_pools=2)
    >>> r = manager.request('GET', 'http://google.com/')
    >>> r = manager.request('GET', 'http://google.com/mail')
    >>> r = manager.request('GET', 'http://yahoo.com/')
    >>> len(manager.pools)
    2_

**Methods**: __init__, __enter__, __exit__, _new_pool, clear, connection_from_host, connection_from_context, connection_from_pool_key, connection_from_url, _merge_pool_kwargs, _proxy_requires_url_absolute_form, _validate_proxy_scheme_url_selection, urlopen


#### `ProxyManager`
_Behaves just like :class:`PoolManager`, but sends all requests through
the defined proxy, using the CONNECT method for HTTPS URLs.

:param proxy_url:
    The URL of the proxy to be used.

:param proxy_headers:
    A dictionary containing headers that will be sent to the proxy. In case
    of HTTP they are being sent with each request, while in the
    HTTPS/CONNECT case they are sent only once. Could be used for proxy
    authentication.

:param proxy_ssl_context:
    The proxy SSL context is used to establish the TLS connection to the
    proxy when using HTTPS proxies.

:param use_forwarding_for_https:
    (Defaults to False) If set to True will forward requests to the HTTPS
    proxy to be made on behalf of the client instead of creating a TLS
    tunnel via the CONNECT method. **Enabling this flag means that request
    and response headers and content will be visible from the HTTPS proxy**
    whereas tunneling keeps request and response headers and content
    private.  IP address, target hostname, SNI, and port are always visible
    to an HTTPS proxy even when this flag is disabled.

Example:
    >>> proxy = urllib3.ProxyManager('http://localhost:3128/')
    >>> r1 = proxy.request('GET', 'http://google.com/')
    >>> r2 = proxy.request('GET', 'http://httpbin.org/')
    >>> len(proxy.pools)
    1
    >>> r3 = proxy.request('GET', 'https://httpbin.org/')
    >>> r4 = proxy.request('GET', 'https://twitter.com/')
    >>> len(proxy.pools)
    3_

**Methods**: __init__, connection_from_host, _set_proxy_headers, urlopen


### venv_new\Lib\site-packages\pip\_vendor\urllib3\request.py

#### `RequestMethods`
_Convenience mixin for classes who implement a :meth:`urlopen` method, such
as :class:`urllib3.HTTPConnectionPool` and
:class:`urllib3.PoolManager`.

Provides behavior for making common types of HTTP request methods and
decides which type of request field encoding to use.

Specifically,

:meth:`.request_encode_url` is for sending requests whose fields are
encoded in the URL (such as GET, HEAD, DELETE).

:meth:`.request_encode_body` is for sending requests whose fields are
encoded in the *body* of the request using multipart or www-form-urlencoded
(such as for POST, PUT, PATCH).

:meth:`.request` is for making any kind of request, it will look up the
appropriate encoding format and use one of the above two methods to make
the request.

Initializer parameters:

:param headers:
    Headers to include with all requests, unless other headers are given
    explicitly._

**Methods**: __init__, urlopen, request, request_encode_url, request_encode_body


#### `RequestModule`
**Methods**: __call__


### venv_new\Lib\site-packages\pip\_vendor\urllib3\response.py

#### `DeflateDecoder`
**Methods**: __init__, __getattr__, decompress


#### `GzipDecoderState`

#### `GzipDecoder`
**Methods**: __init__, __getattr__, decompress


#### `BrotliDecoder`
**Methods**: __init__, flush


#### `MultiDecoder`
_From RFC7231:
    If one or more encodings have been applied to a representation, the
    sender that applied the encodings MUST generate a Content-Encoding
    header field that lists the content codings in the order in which
    they were applied._

**Methods**: __init__, flush, decompress


#### `HTTPResponse`
_HTTP Response container.

Backwards-compatible with :class:`http.client.HTTPResponse` but the response ``body`` is
loaded and decoded on-demand when the ``data`` property is accessed.  This
class is also compatible with the Python standard library's :mod:`io`
module, and can hence be treated as a readable object in the context of that
framework.

Extra parameters for behaviour not present in :class:`http.client.HTTPResponse`:

:param preload_content:
    If True, the response's body will be preloaded during construction.

:param decode_content:
    If True, will attempt to decode the body based on the
    'content-encoding' header.

:param original_response:
    When this HTTPResponse wrapper is generated from an :class:`http.client.HTTPResponse`
    object, it's convenient to include the original for debug purposes. It's
    otherwise unused.

:param retries:
    The retries contains the last :class:`~urllib3.util.retry.Retry` that
    was used during the request.

:param enforce_content_length:
    Enforce content length checking. Body returned by server must match
    value of Content-Length header, if present. Otherwise, raise error._

**Methods**: __init__, get_redirect_location, release_conn, drain_conn, data, connection, isclosed, tell, _init_length, _init_decoder, _decode, _flush_decoder, _error_catcher, _fp_read, read, stream, from_httplib, getheaders, getheader, info, close, closed, fileno, flush, readable, readinto, supports_chunked_reads, _update_chunk_length, _handle_chunk, read_chunked, geturl, __iter__


### venv_new\Lib\site-packages\pip\_vendor\urllib3\util\queue.py

#### `LifoQueue`
**Methods**: _init, _qsize, _put, _get


### venv_new\Lib\site-packages\pip\_vendor\urllib3\util\retry.py

#### `_RetryMeta`
**Methods**: DEFAULT_METHOD_WHITELIST, DEFAULT_METHOD_WHITELIST, DEFAULT_REDIRECT_HEADERS_BLACKLIST, DEFAULT_REDIRECT_HEADERS_BLACKLIST, BACKOFF_MAX, BACKOFF_MAX


#### `Retry`
_Retry configuration.

Each retry attempt will create a new Retry object with updated values, so
they can be safely reused.

Retries can be defined as a default for a pool::

    retries = Retry(connect=5, read=2, redirect=5)
    http = PoolManager(retries=retries)
    response = http.request('GET', 'http://example.com/')

Or per-request (which overrides the default for the pool)::

    response = http.request('GET', 'http://example.com/', retries=Retry(10))

Retries can be disabled by passing ``False``::

    response = http.request('GET', 'http://example.com/', retries=False)

Errors will be wrapped in :class:`~urllib3.exceptions.MaxRetryError` unless
retries are disabled, in which case the causing exception will be raised.

:param int total:
    Total number of retries to allow. Takes precedence over other counts.

    Set to ``None`` to remove this constraint and fall back on other
    counts.

    Set to ``0`` to fail on the first retry.

    Set to ``False`` to disable and imply ``raise_on_redirect=False``.

:param int connect:
    How many connection-related errors to retry on.

    These are errors raised before the request is sent to the remote server,
    which we assume has not triggered the server to process the request.

    Set to ``0`` to fail on the first retry of this type.

:param int read:
    How many times to retry on read errors.

    These errors are raised after the request was sent to the server, so the
    request may have side-effects.

    Set to ``0`` to fail on the first retry of this type.

:param int redirect:
    How many redirects to perform. Limit this to avoid infinite redirect
    loops.

    A redirect is a HTTP response with a status code 301, 302, 303, 307 or
    308.

    Set to ``0`` to fail on the first retry of this type.

    Set to ``False`` to disable and imply ``raise_on_redirect=False``.

:param int status:
    How many times to retry on bad status codes.

    These are retries made on responses, where status code matches
    ``status_forcelist``.

    Set to ``0`` to fail on the first retry of this type.

:param int other:
    How many times to retry on other errors.

    Other errors are errors that are not connect, read, redirect or status errors.
    These errors might be raised after the request was sent to the server, so the
    request might have side-effects.

    Set to ``0`` to fail on the first retry of this type.

    If ``total`` is not set, it's a good idea to set this to 0 to account
    for unexpected edge cases and avoid infinite retry loops.

:param iterable allowed_methods:
    Set of uppercased HTTP method verbs that we should retry on.

    By default, we only retry on methods which are considered to be
    idempotent (multiple requests with the same parameters end with the
    same state). See :attr:`Retry.DEFAULT_ALLOWED_METHODS`.

    Set to a ``False`` value to retry on any verb.

    .. warning::

        Previously this parameter was named ``method_whitelist``, that
        usage is deprecated in v1.26.0 and will be removed in v2.0.

:param iterable status_forcelist:
    A set of integer HTTP status codes that we should force a retry on.
    A retry is initiated if the request method is in ``allowed_methods``
    and the response status code is in ``status_forcelist``.

    By default, this is disabled with ``None``.

:param float backoff_factor:
    A backoff factor to apply between attempts after the second try
    (most errors are resolved immediately by a second try without a
    delay). urllib3 will sleep for::

        {backoff factor} * (2 ** ({number of total retries} - 1))

    seconds. If the backoff_factor is 0.1, then :func:`.sleep` will sleep
    for [0.0s, 0.2s, 0.4s, ...] between retries. It will never be longer
    than :attr:`Retry.DEFAULT_BACKOFF_MAX`.

    By default, backoff is disabled (set to 0).

:param bool raise_on_redirect: Whether, if the number of redirects is
    exhausted, to raise a MaxRetryError, or to return a response with a
    response code in the 3xx range.

:param bool raise_on_status: Similar meaning to ``raise_on_redirect``:
    whether we should raise an exception, or return a response,
    if status falls in ``status_forcelist`` range and retries have
    been exhausted.

:param tuple history: The history of the request encountered during
    each call to :meth:`~Retry.increment`. The list is in the order
    the requests occurred. Each list item is of class :class:`RequestHistory`.

:param bool respect_retry_after_header:
    Whether to respect Retry-After header on status codes defined as
    :attr:`Retry.RETRY_AFTER_STATUS_CODES` or not.

:param iterable remove_headers_on_redirect:
    Sequence of headers to remove from the request when a response
    indicating a redirect is returned before firing off the redirected
    request._

**Methods**: __init__, new, from_int, get_backoff_time, parse_retry_after, get_retry_after, sleep_for_retry, _sleep_backoff, sleep, _is_connection_error, _is_read_error, _is_method_retryable, is_retry, is_exhausted, increment, __repr__, __getattr__


### venv_new\Lib\site-packages\pip\_vendor\urllib3\util\ssl_.py

#### `SSLContext`
**Methods**: __init__, load_cert_chain, load_verify_locations, set_ciphers, wrap_socket


### venv_new\Lib\site-packages\pip\_vendor\urllib3\util\ssl_match_hostname.py

#### `CertificateError`

### venv_new\Lib\site-packages\pip\_vendor\urllib3\util\ssltransport.py

#### `SSLTransport`
_The SSLTransport wraps an existing socket and establishes an SSL connection.

Contrary to Python's implementation of SSLSocket, it allows you to chain
multiple TLS connections together. It's particularly useful if you need to
implement TLS within TLS.

The class supports most of the socket API operations._

**Methods**: _validate_ssl_context_for_tls_in_tls, __init__, __enter__, __exit__, fileno, read, recv, recv_into, sendall, send, makefile, unwrap, close, getpeercert, version, cipher, selected_alpn_protocol, selected_npn_protocol, shared_ciphers, compression, settimeout, gettimeout, _decref_socketios, _wrap_ssl_read, _ssl_io_loop


### venv_new\Lib\site-packages\pip\_vendor\urllib3\util\timeout.py

#### `Timeout`
_Timeout configuration.

Timeouts can be defined as a default for a pool:

.. code-block:: python

   timeout = Timeout(connect=2.0, read=7.0)
   http = PoolManager(timeout=timeout)
   response = http.request('GET', 'http://example.com/')

Or per-request (which overrides the default for the pool):

.. code-block:: python

   response = http.request('GET', 'http://example.com/', timeout=Timeout(10))

Timeouts can be disabled by setting all the parameters to ``None``:

.. code-block:: python

   no_timeout = Timeout(connect=None, read=None)
   response = http.request('GET', 'http://example.com/, timeout=no_timeout)


:param total:
    This combines the connect and read timeouts into one; the read timeout
    will be set to the time leftover from the connect attempt. In the
    event that both a connect timeout and a total are specified, or a read
    timeout and a total are specified, the shorter timeout will be applied.

    Defaults to None.

:type total: int, float, or None

:param connect:
    The maximum amount of time (in seconds) to wait for a connection
    attempt to a server to succeed. Omitting the parameter will default the
    connect timeout to the system default, probably `the global default
    timeout in socket.py
    <http://hg.python.org/cpython/file/603b4d593758/Lib/socket.py#l535>`_.
    None will set an infinite timeout for connection attempts.

:type connect: int, float, or None

:param read:
    The maximum amount of time (in seconds) to wait between consecutive
    read operations for a response from the server. Omitting the parameter
    will default the read timeout to the system default, probably `the
    global default timeout in socket.py
    <http://hg.python.org/cpython/file/603b4d593758/Lib/socket.py#l535>`_.
    None will set an infinite timeout.

:type read: int, float, or None

.. note::

    Many factors can affect the total amount of time for urllib3 to return
    an HTTP response.

    For example, Python's DNS resolver does not obey the timeout specified
    on the socket. Other factors that can affect total request time include
    high CPU load, high swap, the program running at a low priority level,
    or other behaviors.

    In addition, the read and total timeouts only measure the time between
    read operations on the socket connecting the client and the server,
    not the total amount of time for the request to return a complete
    response. For most requests, the timeout is raised because the server
    has not sent the first byte in the specified time. This is not always
    the case; if a server streams one byte every fifteen seconds, a timeout
    of 20 seconds will not trigger, even though the request will take
    several minutes to complete.

    If your goal is to cut off any request after a set amount of wall clock
    time, consider having a second "watcher" thread to cut off a slow
    request._

**Methods**: __init__, __repr__, resolve_default_timeout, _validate_timeout, from_float, clone, start_connect, get_connect_duration, connect_timeout, read_timeout


### venv_new\Lib\site-packages\pip\_vendor\urllib3\util\url.py

#### `Url`
_Data structure for representing an HTTP URL. Used as a return value for
:func:`parse_url`. Both the scheme and host are normalized as they are
both case-insensitive according to RFC 3986._

**Methods**: __new__, hostname, request_uri, netloc, url, __str__


### venv_new\Lib\site-packages\pip\_vendor\urllib3\util\wait.py

#### `NoWayToWaitForSocketError`

---

## NEXT STEPS

1. Load HYPER_DATABASE.md into Windsurf Cascade
2. Tell Cascade: "Consulting HYPER_DATABASE before every task"
3. Add database queries to workflow:
   - "What functions are in X?"
   - "What calls function Y?"
   - "What tests cover Z?"
4. Auto-update daily

**This database is TRUTH. Your code follows it.**
